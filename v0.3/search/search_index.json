{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stemmer","stopWordFilter","trimmer"]},"docs":[{"location":"","title":"Strands CLI Documentation","text":"<p>Welcome to the Strands CLI documentation. Strands CLI is a powerful command-line tool for executing agentic workflows with strong observability, schema validation, and safe orchestration.</p>"},{"location":"#what-is-strands-cli","title":"What is Strands CLI?","text":"<p>Strands CLI allows you to define and execute complex agentic workflows using YAML/JSON specifications. It supports multiple AI providers (Ollama, AWS Bedrock, OpenAI) and provides sophisticated patterns for orchestrating multi-agent systems.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Multiple Execution Patterns: Chain, Workflow (DAG), Routing, Parallel, Evaluator-Optimizer, Graph, and Orchestrator-Workers</li> <li>Durable Session Management: Automatic crash recovery, workflow resume, and agent conversation restoration</li> <li>Human-in-the-Loop (HITL): Pause workflows for human approval, quality control, and interactive decision-making</li> <li>Multi-Provider Support: Works with Ollama, AWS Bedrock, and OpenAI</li> <li>Strong Observability: Built-in OpenTelemetry instrumentation with trace exports</li> <li>Schema Validation: JSON Schema Draft 2020-12 validation for workflow specifications</li> <li>Context Management: Intelligent context handling with presets and compaction strategies</li> <li>Security First: Sandboxed templating, SSRF prevention, and path traversal protection</li> <li>Token Budgets: Fine-grained control over token usage and costs</li> <li>MCP Integration: Support for Model Context Protocol servers and tools</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Choose a quickstart tutorial based on your preferred AI provider:</p> <ul> <li>Quickstart with Ollama - Local, open-source models</li> <li>Quickstart with AWS Bedrock - Enterprise cloud AI</li> <li>Quickstart with OpenAI - GPT models</li> </ul>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<p>This documentation follows the Di\u00e1taxis framework:</p> <ul> <li>Tutorials: Step-by-step learning paths for new users</li> <li>How-To Guides: Task-oriented guides for common operations</li> <li>Explanation: Conceptual understanding and architecture</li> <li>Reference: Technical reference documentation</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code># Using pip\npip install strands-cli\n\n# Using uv (recommended)\nuv pip install strands-cli\n\n# With documentation dependencies\nuv pip install -e \".[docs]\"\n</code></pre>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code># simple-workflow.yaml\nversion: \"1.0\"\nname: \"Hello Strands\"\ndescription: \"A simple single-agent workflow\"\n\nprovider:\n  type: ollama\n  model: llama3.2\n\nagents:\n  - name: greeter\n    role: Friendly AI Assistant\n    goal: Greet the user warmly\n\npattern:\n  type: single_agent\n  agent: greeter\n  input: \"Hello! Tell me about Strands CLI.\"\n</code></pre> <p>Run it:</p> <pre><code>strands run simple-workflow.yaml\n</code></pre>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Learn about workflow patterns</li> <li>Explore example workflows</li> <li>Understand the architecture</li> <li>Read the CLI reference</li> </ul>"},{"location":"#support","title":"Support","text":"<ul> <li>GitHub: ThomasRohde/strands-cli</li> <li>Issues: Report bugs or request features</li> <li>License: Apache-2.0</li> </ul>"},{"location":"SUMMARY/","title":"Strands CLI Documentation","text":"<ul> <li>Home</li> </ul>"},{"location":"SUMMARY/#tutorials","title":"Tutorials","text":"<ul> <li>Quickstart with Ollama</li> <li>First Multi-Step Workflow</li> </ul>"},{"location":"SUMMARY/#how-to-guides","title":"How-To Guides","text":"<ul> <li>Validate Workflows</li> <li>Run Workflows</li> <li>Session Management</li> <li>Human-in-the-Loop (HITL)</li> <li>Context Management</li> <li>Tool Development</li> <li>Telemetry &amp; Debugging</li> <li>Secrets Management</li> <li>Budget Management</li> </ul>"},{"location":"SUMMARY/#reference","title":"Reference","text":"<ul> <li>CLI Commands</li> <li>Workflow Spec</li> <li>Session API</li> <li>Workflow Manual</li> <li>Schema Reference</li> <li>Security Model</li> <li>Exit Codes</li> <li>Environment Variables</li> <li>Examples</li> <li>Troubleshooting</li> </ul>"},{"location":"SUMMARY/#explanation","title":"Explanation","text":"<ul> <li>Architecture Overview</li> </ul>"},{"location":"explanation/","title":"Explanation","text":"<p>This section provides conceptual understanding of Strands CLI's architecture, design decisions, and implementation philosophy. These documents explain the \"why\" behind the system rather than the \"how\" (see How-To) or the \"what\" (see Reference).</p>"},{"location":"explanation/#architecture-design","title":"Architecture &amp; Design","text":"<p>Architecture Overview - Understand the system components, data flow, and execution model that powers Strands CLI.</p> <ul> <li>System overview and component diagrams</li> <li>Data flow through the three-phase execution model</li> <li>Module boundaries and dependency relationships</li> <li>Performance characteristics and configuration</li> </ul> <p>Design Decisions - Learn the rationale behind key architectural choices and technology selections.</p> <ul> <li>Why YAML/JSON workflow specifications</li> <li>Why JSON Schema Draft 2020-12 for validation</li> <li>Provider abstraction design</li> <li>Security-first design philosophy</li> <li>Single event loop strategy</li> <li>Exit code discipline</li> </ul>"},{"location":"explanation/#patterns-orchestration","title":"Patterns &amp; Orchestration","text":"<p>Pattern Philosophy - Understand why workflow patterns exist, when to use each, and how to choose the right pattern.</p> <ul> <li>The multi-agent orchestration problem</li> <li>Pattern catalog (all 7 patterns explained)</li> <li>Pattern selection decision tree</li> <li>Comparison matrix with trade-offs</li> <li>Pattern composability and anti-patterns</li> </ul>"},{"location":"explanation/#performance-security","title":"Performance &amp; Security","text":"<p>Performance Optimizations - Deep dive into the performance optimizations that make Strands CLI efficient.</p> <ul> <li>Agent caching (10\u00d7+ speedup)</li> <li>Model client pooling (20\u00d7+ reduction)</li> <li>Single event loop architecture</li> <li>Concurrency control with semaphores</li> <li>Benchmark results and best practices</li> </ul> <p>Security Model - Comprehensive overview of the defense-in-depth security architecture.</p> <ul> <li>Threat model and attack scenarios</li> <li>Template sandboxing (RCE prevention)</li> <li>SSRF prevention (URL validation)</li> <li>Path traversal protection</li> <li>Tool allowlisting</li> <li>Audit logging and SIEM integration</li> </ul>"},{"location":"explanation/#reading-order","title":"Reading Order","text":"<p>For new users, we recommend reading in this order:</p> <ol> <li>Architecture Overview - Get the big picture</li> <li>Pattern Philosophy - Understand workflow orchestration</li> <li>Design Decisions - Learn the \"why\" behind key choices</li> <li>Performance Optimizations - Understand efficiency gains</li> <li>Security Model - Learn about security controls</li> </ol> <p>For developers contributing to Strands CLI, all documents are essential reading.</p>"},{"location":"explanation/#related-sections","title":"Related Sections","text":"<ul> <li>Tutorials - Step-by-step learning paths for new users</li> <li>How-To Guides - Task-oriented guides for common operations</li> <li>Reference - Technical specifications (CLI, Schema, API)</li> </ul>"},{"location":"explanation/architecture/","title":"Architecture Overview","text":"<p>This document explains the high-level architecture of Strands CLI, how components interact, and the execution model used for running agentic workflows.</p>"},{"location":"explanation/architecture/#system-overview","title":"System Overview","text":"<p>Strands CLI is a declarative workflow orchestrator that executes YAML/JSON workflow specifications using LLM providers (AWS Bedrock, Ollama, OpenAI). It follows a three-phase execution model:</p> <ol> <li>Load &amp; Validate: Parse YAML/JSON \u2192 Validate against JSON Schema \u2192 Build typed spec</li> <li>Capability Check: Evaluate MVP compatibility \u2192 Exit gracefully if unsupported features</li> <li>Execute: Build agents \u2192 Run workflow pattern \u2192 Write artifacts</li> </ol> <pre><code>graph TB\n    User[User] --&gt;|workflow.yaml| CLI[CLI Entry Point]\n    CLI --&gt;|parse| Loader[YAML Loader]\n    Loader --&gt;|raw data| Schema[JSON Schema Validator]\n    Schema --&gt;|validated| Types[Pydantic Models]\n    Types --&gt;|Spec| Capability[Capability Checker]\n\n    Capability --&gt;|unsupported| Report[Remediation Report]\n    Report --&gt;|exit 18| User\n\n    Capability --&gt;|supported| Executor[Pattern Executor]\n    Executor --&gt;|build| Runtime[Agent Builder]\n    Runtime --&gt;|agents| Executor\n    Executor --&gt;|invoke| Provider[LLM Provider]\n    Provider --&gt;|response| Executor\n    Executor --&gt;|results| Artifacts[Artifact Writer]\n    Artifacts --&gt;|files| User\n\n    Telemetry[OpenTelemetry] -.-&gt;|traces| Executor\n    Telemetry -.-&gt;|traces| Provider\n\n    style Capability fill:#f9f,stroke:#333\n    style Executor fill:#bbf,stroke:#333\n    style Provider fill:#bfb,stroke:#333</code></pre>"},{"location":"explanation/architecture/#core-components","title":"Core Components","text":""},{"location":"explanation/architecture/#1-cli-layer-__main__py","title":"1. CLI Layer (<code>__main__.py</code>)","text":"<p>Responsibility: Command-line interface with 6 commands.</p> <p>Commands: - <code>run</code> - Execute a workflow specification - <code>validate</code> - Validate spec against JSON Schema - <code>plan</code> - Analyze workflow execution plan - <code>explain</code> - Explain workflow structure - <code>tools</code> - List available tools - <code>version</code> - Display version information</p> <p>Key Features: - Uses Typer for ergonomic CLI with type hints - Rich console output for pretty formatting - Structured exit codes (EX_OK, EX_SCHEMA, EX_RUNTIME, etc.) - Environment variable configuration via Pydantic Settings</p> <p>Entry Point: <pre><code>@app.command()\ndef run(\n    spec_file: Path,\n    var: list[str] | None = None,\n    out: Path | None = None,\n    force: bool = False,\n    verbose: bool = False,\n) -&gt; None:\n    \"\"\"Execute a workflow specification.\"\"\"\n    asyncio.run(execute_workflow(spec_file, var, out, force, verbose))\n</code></pre></p>"},{"location":"explanation/architecture/#2-schema-layer-schema","title":"2. Schema Layer (<code>schema/</code>)","text":"<p>Responsibility: JSON Schema validation for workflow specs.</p> <p>Key Files: - <code>strands-workflow.schema.json</code> - Complete JSON Schema (Draft 2020-12) - <code>validator.py</code> - Schema validation logic with JSONPointer error reporting</p> <p>Validation Process: <pre><code>graph LR\n    YAML[YAML File] --&gt;|load| Dict[Python Dict]\n    Dict --&gt;|validate| Schema[JSON Schema]\n    Schema --&gt;|valid| Pydantic[Pydantic Models]\n    Schema --&gt;|invalid| Error[SchemaValidationError]\n    Error --&gt;|JSONPointer| User[User Remediation]\n\n    style Error fill:#fbb,stroke:#333\n    style Pydantic fill:#bfb,stroke:#333</code></pre></p> <p>Features: - Statically bundled schema (no external file dependency) - Precise error reporting with JSONPointer paths - Comprehensive validation for all workflow properties</p>"},{"location":"explanation/architecture/#3-type-system-typespy","title":"3. Type System (<code>types.py</code>)","text":"<p>Responsibility: Pydantic v2 models for all workflow components.</p> <p>Key Models: - <code>Spec</code> - Top-level workflow specification - <code>Runtime</code> - Provider configuration (Bedrock/Ollama/OpenAI) - <code>Agent</code> - Agent configuration with prompt and tools - <code>Pattern</code> - Workflow execution pattern (chain/workflow/routing/etc.) - <code>Tools</code> - Tool configurations (Python/HTTP/MCP) - <code>CapabilityReport</code> - Compatibility analysis results - <code>RunResult</code> - Execution outcome with timing and artifacts</p> <p>Type Safety: - Python 3.12+ modern type hints (<code>str | None</code>, not <code>Optional[str]</code>) - Mypy strict mode enabled - Pydantic v2 validation with custom validators</p>"},{"location":"explanation/architecture/#4-capability-layer-capability","title":"4. Capability Layer (<code>capability/</code>)","text":"<p>Responsibility: Check MVP compatibility and generate remediation reports.</p> <p>Key Files: - <code>checker.py</code> - Feature detection and compatibility analysis - <code>reporter.py</code> - Markdown/JSON remediation report generation</p> <p>Check Logic: <pre><code>def check_capability(spec: Spec) -&gt; CapabilityReport:\n    \"\"\"Check if spec uses only supported MVP features.\"\"\"\n    issues = []\n\n    # Check pattern support\n    if spec.pattern.type not in SUPPORTED_PATTERNS:\n        issues.append(UnsupportedFeature(\n            category=\"pattern\",\n            feature=spec.pattern.type,\n            remediation=\"Use 'chain', 'workflow', 'routing', 'parallel', ...\"\n        ))\n\n    # Check tool allowlist\n    for tool in spec.tools.python:\n        if tool.callable not in ALLOWED_PYTHON_CALLABLES:\n            issues.append(UnsupportedFeature(...))\n\n    return CapabilityReport(supported=(len(issues) == 0), issues=issues)\n</code></pre></p> <p>Exit Strategy: - Unsupported features \u2192 exit with EX_UNSUPPORTED (18) + remediation report - Graceful degradation preferred over silent failures</p>"},{"location":"explanation/architecture/#5-loader-layer-loader","title":"5. Loader Layer (<code>loader/</code>)","text":"<p>Responsibility: Load YAML/JSON and render Jinja2 templates.</p> <p>Key Files: - <code>yaml_loader.py</code> - Load and merge variables - <code>template.py</code> - Sandboxed Jinja2 rendering</p> <p>Template Security: - Uses <code>jinja2.sandbox.SandboxedEnvironment</code> - Whitelisted filters only: <code>truncate</code>, <code>tojson</code>, <code>title</code> - Blocks attribute introspection (<code>__class__</code>, <code>__mro__</code>, etc.)</p> <p>Variable Resolution: <pre><code># CLI usage\nstrands run workflow.yaml --var topic=\"AI\" --var depth=\"detailed\"\n</code></pre></p> <pre><code># Merges into spec\nvariables = parse_variables([\"topic=AI\", \"depth=detailed\"])\nspec = load_spec(\"workflow.yaml\", variables)\n</code></pre>"},{"location":"explanation/architecture/#6-runtime-layer-runtime","title":"6. Runtime Layer (<code>runtime/</code>)","text":"<p>Responsibility: Build agents, manage providers, and handle tools.</p> <p>Key Files: - <code>providers.py</code> - Bedrock/Ollama/OpenAI client adapters - <code>strands_adapter.py</code> - Map Spec \u2192 Strands Agent - <code>tools.py</code> - Safe tool adapters with allowlisting</p> <p>Agent Caching: <pre><code>class AgentCache:\n    \"\"\"Singleton cache for agent reuse across workflow execution.\"\"\"\n\n    def __init__(self):\n        self._agents: dict[tuple, Agent] = {}\n        self._clients: list[Any] = []\n\n    async def get_or_build_agent(\n        self, spec: Spec, agent_id: str, config: AgentConfig, ...\n    ) -&gt; Agent:\n        \"\"\"Get cached agent or build new one.\"\"\"\n        cache_key = (agent_id, config_hash)\n        if cache_key in self._agents:\n            return self._agents[cache_key]  # Cache hit\n\n        agent = await build_agent(spec, agent_id, config, ...)\n        self._agents[cache_key] = agent\n        return agent\n\n    async def close(self):\n        \"\"\"Cleanup all HTTP clients.\"\"\"\n        for client in self._clients:\n            await client.close()\n</code></pre></p> <p>Model Client Pooling: <pre><code>@dataclass(frozen=True)\nclass RuntimeConfig:\n    \"\"\"Hashable runtime configuration for LRU cache.\"\"\"\n    provider: str\n    model_id: str\n    region: str | None = None\n\n@lru_cache(maxsize=16)\ndef _create_model_cached(config: RuntimeConfig) -&gt; Model:\n    \"\"\"Create and cache model clients.\"\"\"\n    if config.provider == \"bedrock\":\n        return BedrockModel(model_id=config.model_id, region=config.region)\n    elif config.provider == \"ollama\":\n        return OllamaModel(model_id=config.model_id, host=config.host)\n    # ...\n</code></pre></p>"},{"location":"explanation/architecture/#7-executor-layer-exec","title":"7. Executor Layer (<code>exec/</code>)","text":"<p>Responsibility: Execute workflow patterns with async concurrency.</p> <p>Pattern Executors: - <code>single_agent.py</code> - Single-step execution - <code>chain.py</code> - Sequential multi-step execution - <code>workflow.py</code> - DAG-based parallel task execution - <code>routing.py</code> - Dynamic agent selection - <code>parallel.py</code> - Concurrent branch execution - <code>evaluator_optimizer.py</code> - Iterative refinement - <code>orchestrator.py</code> - Dynamic task delegation - <code>graph.py</code> - State machine with conditional transitions</p> <p>Async Pattern (CRITICAL): <pre><code># All executors are async functions\nasync def run_chain(spec: Spec, variables: dict[str, Any]) -&gt; RunResult:\n    \"\"\"Execute chain pattern workflow.\"\"\"\n    cache = AgentCache()  # Create cache\n    try:\n        for step in spec.pattern.config.steps:\n            # Get or build agent (reuses cached agents)\n            agent = await cache.get_or_build_agent(...)\n\n            # Direct await (not asyncio.run)\n            result = await invoke_agent_with_retry(agent, prompt, ...)\n\n        return RunResult(...)\n    finally:\n        await cache.close()  # Cleanup\n\n# CLI calls with single event loop\nresult = asyncio.run(run_chain(spec, variables))\n</code></pre></p> <p>Key Principles: - \u2705 Use <code>async def</code> for all executor functions - \u2705 Create <code>AgentCache</code> at start, use throughout, close in finally - \u2705 Use <code>await</code> for agent invocations (not nested <code>asyncio.run()</code>) - \u274c Never call <code>asyncio.run()</code> inside an executor (only in CLI)</p>"},{"location":"explanation/architecture/#8-telemetry-layer-telemetry","title":"8. Telemetry Layer (<code>telemetry/</code>)","text":"<p>Responsibility: OpenTelemetry tracing, PII redaction, and debug logging.</p> <p>Key Files: - <code>otel.py</code> - OTEL setup with OTLP/Console exporters - <code>redaction.py</code> - PII pattern detection and redaction</p> <p>Tracing Architecture: <pre><code>graph LR\n    Executor[Executor] --&gt;|start_span| Tracer[Tracer Provider]\n    Tracer --&gt;|record| Processor[Span Processor]\n    Processor --&gt;|redact| Redactor[PII Redaction]\n    Redactor --&gt;|export| OTLP[OTLP Exporter]\n    Redactor --&gt;|export| Console[Console Exporter]\n    Redactor --&gt;|collect| Collector[Trace Collector]\n    Collector --&gt;|artifact| File[Trace JSON File]\n\n    style Redactor fill:#f9f,stroke:#333\n    style OTLP fill:#bbf,stroke:#333\n    style File fill:#bfb,stroke:#333</code></pre></p> <p>Span Coverage: - <code>workflow.validate</code> - Schema validation - <code>workflow.execute</code> - Full workflow execution - <code>pattern.&lt;type&gt;</code> - Pattern-specific execution - <code>agent.invoke</code> - LLM invocation - <code>tool.&lt;name&gt;</code> - Tool execution</p>"},{"location":"explanation/architecture/#9-artifacts-layer-artifacts","title":"9. Artifacts Layer (<code>artifacts/</code>)","text":"<p>Responsibility: Write output files with security checks.</p> <p>Key Files: - <code>io.py</code> - Artifact writing with path validation</p> <p>Security Layers: 1. Reject absolute paths 2. Block path traversal (<code>..</code> components) 3. Sanitize path components (remove special chars) 4. Validate resolved path (prevent symlink escape) 5. Block symlinks (MVP restriction)</p>"},{"location":"explanation/architecture/#data-flow","title":"Data Flow","text":""},{"location":"explanation/architecture/#critical-path-run-command","title":"Critical Path: Run Command","text":"<pre><code>sequenceDiagram\n    participant User\n    participant CLI\n    participant Loader\n    participant Schema\n    participant Capability\n    participant Executor\n    participant Cache\n    participant Provider\n    participant Artifacts\n\n    User-&gt;&gt;CLI: strands run workflow.yaml --var topic=AI\n    CLI-&gt;&gt;Loader: load_spec(file, variables)\n    Loader-&gt;&gt;Schema: validate_spec(data)\n    Schema-&gt;&gt;Capability: check_capability(spec)\n\n    alt Unsupported Features\n        Capability--&gt;&gt;User: Exit 18 + Remediation Report\n    else Supported\n        Capability-&gt;&gt;Executor: execute_workflow(spec)\n        Executor-&gt;&gt;Cache: get_or_build_agent(agent_id)\n        Cache-&gt;&gt;Provider: create_model(runtime)\n        Provider--&gt;&gt;Cache: Model client\n        Cache--&gt;&gt;Executor: Agent instance\n        Executor-&gt;&gt;Provider: invoke(prompt, tools)\n        Provider--&gt;&gt;Executor: LLM response\n        Executor-&gt;&gt;Artifacts: write_artifacts(results)\n        Artifacts--&gt;&gt;User: Output files\n    end</code></pre>"},{"location":"explanation/architecture/#agent-caching-flow","title":"Agent Caching Flow","text":"<pre><code>sequenceDiagram\n    participant Executor\n    participant Cache\n    participant Builder\n    participant ModelPool\n\n    Executor-&gt;&gt;Cache: get_or_build_agent(\"agent1\", config)\n\n    alt Cache Hit\n        Cache--&gt;&gt;Executor: Cached agent\n    else Cache Miss\n        Cache-&gt;&gt;ModelPool: create_model(runtime)\n\n        alt Model Cached\n            ModelPool--&gt;&gt;Cache: Cached model client\n        else Model Not Cached\n            ModelPool-&gt;&gt;ModelPool: Create new client\n            ModelPool--&gt;&gt;Cache: New model client\n        end\n\n        Cache-&gt;&gt;Builder: build_agent(spec, config, model)\n        Builder--&gt;&gt;Cache: New agent\n        Cache-&gt;&gt;Cache: Store in cache\n        Cache--&gt;&gt;Executor: New agent\n    end</code></pre>"},{"location":"explanation/architecture/#execution-model","title":"Execution Model","text":""},{"location":"explanation/architecture/#single-event-loop","title":"Single Event Loop","text":"<p>Design Principle: One <code>asyncio.run()</code> per workflow from CLI; executors use <code>await</code>.</p> <p>Benefits: - Clean resource management (single cleanup point) - Proper async context propagation - No nested event loop issues - Efficient concurrency with semaphores</p> <p>Implementation: <pre><code># CLI layer (single event loop)\n@app.command()\ndef run(spec_file: Path, ...) -&gt; None:\n    result = asyncio.run(execute_workflow(spec_file))  # Single entry point\n    sys.exit(EX_OK if result.success else EX_RUNTIME)\n\n# Executor layer (uses await)\nasync def execute_workflow(spec_file: Path) -&gt; RunResult:\n    spec = load_spec(spec_file)\n\n    # Route to pattern executor\n    if spec.pattern.type == \"chain\":\n        return await run_chain(spec, variables)  # await, not asyncio.run()\n    elif spec.pattern.type == \"workflow\":\n        return await run_workflow(spec, variables)\n    # ...\n</code></pre></p>"},{"location":"explanation/architecture/#concurrency-control","title":"Concurrency Control","text":"<p>Semaphore-Based Limits: <pre><code># Parallel pattern with max_parallel control\nmax_parallel = spec.runtime.max_parallel or 5\nsemaphore = asyncio.Semaphore(max_parallel)\n\nasync def run_branch_with_limit(branch):\n    async with semaphore:  # Acquire slot\n        return await run_branch(branch)  # Execute\n\n# Run all branches concurrently with limit\nresults = await asyncio.gather(\n    *[run_branch_with_limit(b) for b in branches],\n    return_exceptions=False  # Fail-fast\n)\n</code></pre></p>"},{"location":"explanation/architecture/#fail-fast-semantics","title":"Fail-Fast Semantics","text":"<p>Design Choice: Cancel all tasks on first failure.</p> <p>Rationale: - Predictable error handling - Fast feedback for users - Resource conservation (don't waste tokens on doomed workflows)</p> <p>Implementation: <pre><code># asyncio.gather with return_exceptions=False\nresults = await asyncio.gather(*tasks, return_exceptions=False)\n# First exception cancels all pending tasks automatically\n</code></pre></p>"},{"location":"explanation/architecture/#module-boundaries","title":"Module Boundaries","text":""},{"location":"explanation/architecture/#dependency-graph","title":"Dependency Graph","text":"<pre><code>graph TB\n    CLI[CLI __main__] --&gt; Loader\n    CLI --&gt; Executor\n\n    Loader --&gt; Schema\n    Loader --&gt; Template\n\n    Executor --&gt; Capability\n    Executor --&gt; Runtime\n    Executor --&gt; Artifacts\n    Executor --&gt; Telemetry\n\n    Runtime --&gt; Types\n    Runtime --&gt; Tools\n    Runtime --&gt; Providers\n\n    Capability --&gt; Types\n\n    Schema --&gt; Types\n\n    Template -.-&gt;|sandboxed| Types\n\n    Tools --&gt; Types\n\n    Providers --&gt; Types\n\n    Artifacts --&gt; Types\n\n    Telemetry --&gt; Types\n\n    style CLI fill:#bbf,stroke:#333\n    style Executor fill:#f9f,stroke:#333\n    style Runtime fill:#bfb,stroke:#333</code></pre>"},{"location":"explanation/architecture/#separation-of-concerns","title":"Separation of Concerns","text":"Layer Responsibility No Access To CLI Command parsing, console output Executor internals Schema JSON Schema validation Runtime providers Loader YAML parsing, template rendering Executor logic Capability Feature detection, remediation Executor logic Runtime Agent building, provider adapters Executor patterns Executor Pattern orchestration, async control Provider details Telemetry Tracing, redaction, logging Business logic Artifacts File writing, path validation Executor patterns"},{"location":"explanation/architecture/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"explanation/architecture/#agent-cache-benefits","title":"Agent Cache Benefits","text":"<p>Scenario: 10-step chain with same agent config</p> <ul> <li>Without caching: 10 agent builds + 10 model client creations = 20 operations</li> <li>With caching: 1 agent build + 1 model client creation = 2 operations</li> <li>Speedup: ~10x reduction in initialization overhead</li> </ul>"},{"location":"explanation/architecture/#model-client-pooling","title":"Model Client Pooling","text":"<p>Scenario: 100 tasks in workflow, 5 unique runtime configs</p> <ul> <li>Without pooling: 100 model client creations</li> <li>With pooling: 5 model client creations (cached via <code>@lru_cache</code>)</li> <li>Speedup: ~20x reduction in client creation overhead</li> </ul>"},{"location":"explanation/architecture/#async-concurrency","title":"Async Concurrency","text":"<p>Scenario: Parallel pattern with 5 branches, max_parallel=3</p> <ul> <li>Sequential: Branch 1 \u2192 2 \u2192 3 \u2192 4 \u2192 5 (sum of all durations)</li> <li>Concurrent: Max 3 at a time, overlapping execution</li> <li>Speedup: ~1.67x (depends on branch duration variance)</li> </ul>"},{"location":"explanation/architecture/#configuration","title":"Configuration","text":""},{"location":"explanation/architecture/#environment-variables","title":"Environment Variables","text":"<p>All configuration via Pydantic Settings with env prefix <code>STRANDS_</code>:</p> Variable Purpose Default <code>STRANDS_AWS_REGION</code> Bedrock region <code>us-east-1</code> <code>STRANDS_BEDROCK_MODEL_ID</code> Default Bedrock model <code>anthropic.claude-3-sonnet-20240229-v1:0</code> <code>STRANDS_OLLAMA_HOST</code> Ollama server URL <code>http://localhost:11434</code> <code>STRANDS_OPENAI_API_KEY</code> OpenAI API key None (required for OpenAI) <code>STRANDS_LOG_LEVEL</code> Logging level <code>INFO</code> <code>STRANDS_LOG_FORMAT</code> Log format <code>console</code> (or <code>json</code>) <code>STRANDS_HTTP_BLOCKED_PATTERNS</code> Additional URL blocklist <code>[]</code> <code>STRANDS_HTTP_ALLOWED_DOMAINS</code> URL allowlist (strict) None <code>STRANDS_OTEL_ENABLED</code> Enable OpenTelemetry <code>false</code> <code>STRANDS_OTEL_ENDPOINT</code> OTLP endpoint <code>http://localhost:4318</code> <code>STRANDS_DEBUG</code> Debug mode <code>false</code>"},{"location":"explanation/architecture/#runtime-overrides","title":"Runtime Overrides","text":"<p>Spec file can override runtime defaults:</p> <pre><code>runtime:\n  provider: bedrock\n  model_id: anthropic.claude-3-haiku-20240307-v1:0  # Override default\n  region: us-west-2  # Override default\n  budgets:\n    tokens: 100000  # Per-workflow limit\n  max_parallel: 10  # Concurrency limit\n</code></pre>"},{"location":"explanation/architecture/#error-handling","title":"Error Handling","text":""},{"location":"explanation/architecture/#exit-code-strategy","title":"Exit Code Strategy","text":"<p>Principle: Never use generic <code>exit(1)</code> - always use named constants.</p> Code Name Usage 0 <code>EX_OK</code> Success 2 <code>EX_USAGE</code> Bad CLI flags/missing file 3 <code>EX_SCHEMA</code> JSON Schema validation error 10 <code>EX_RUNTIME</code> Provider/model/tool runtime failure 12 <code>EX_IO</code> Artifact write/IO error 18 <code>EX_UNSUPPORTED</code> Feature present but not supported 70 <code>EX_UNKNOWN</code> Unexpected exception <p>Implementation: <pre><code>from strands_cli.exit_codes import EX_SCHEMA, EX_OK\n\ntry:\n    validate_spec(spec_data)\nexcept SchemaValidationError as e:\n    console.print(f\"[red]Schema Error:[/red] {e}\")\n    sys.exit(EX_SCHEMA)  # NOT sys.exit(3)\n</code></pre></p>"},{"location":"explanation/architecture/#error-propagation","title":"Error Propagation","text":"<pre><code>graph TB\n    Error[Exception Raised] --&gt; Executor\n    Executor --&gt;|catch| Classify{Error Type?}\n\n    Classify --&gt;|SchemaValidationError| Schema[Exit EX_SCHEMA]\n    Classify --&gt;|LoadError| Usage[Exit EX_USAGE]\n    Classify --&gt;|RuntimeError| Runtime[Exit EX_RUNTIME]\n    Classify --&gt;|ArtifactError| IO[Exit EX_IO]\n    Classify --&gt;|UnsupportedFeature| Unsupported[Exit EX_UNSUPPORTED]\n    Classify --&gt;|Unknown| Unknown[Exit EX_UNKNOWN]\n\n    style Schema fill:#fbb,stroke:#333\n    style Runtime fill:#fbb,stroke:#333\n    style Unsupported fill:#fbb,stroke:#333</code></pre>"},{"location":"explanation/architecture/#testing-strategy","title":"Testing Strategy","text":""},{"location":"explanation/architecture/#test-organization","title":"Test Organization","text":"<pre><code>tests/\n\u251c\u2500\u2500 conftest.py              # Shared fixtures\n\u251c\u2500\u2500 test_schema.py           # Schema validation\n\u251c\u2500\u2500 test_loader.py           # YAML loading, template rendering\n\u251c\u2500\u2500 test_capability.py       # Feature detection\n\u251c\u2500\u2500 test_runtime.py          # Agent building, provider adapters\n\u251c\u2500\u2500 test_executor.py         # Pattern executors (unit tests)\n\u251c\u2500\u2500 test_integration.py      # End-to-end workflows\n\u251c\u2500\u2500 test_telemetry.py        # OpenTelemetry tracing\n\u2514\u2500\u2500 fixtures/\n    \u251c\u2500\u2500 valid/               # Valid workflow specs\n    \u2514\u2500\u2500 invalid/             # Schema violations\n</code></pre>"},{"location":"explanation/architecture/#coverage-requirements","title":"Coverage Requirements","text":"<ul> <li>Overall: \u226585% (current: 82% due to Phase 10 telemetry code)</li> <li>Core modules: \u226590% (executor, runtime, schema)</li> <li>Integration tests: \u226560% of E2E scenarios</li> </ul>"},{"location":"explanation/architecture/#test-execution","title":"Test Execution","text":"<pre><code># Full test suite\n.\\scripts\\dev.ps1 test\n\n# With coverage report\n.\\scripts\\dev.ps1 test-cov\n\n# Specific module\nuv run pytest tests/test_executor.py -v\n\n# CI pipeline (lint + typecheck + test)\n.\\scripts\\dev.ps1 ci\n</code></pre>"},{"location":"explanation/architecture/#summary","title":"Summary","text":"<p>Strands CLI architecture follows these key principles:</p> <ol> <li>Schema-Driven: All features validated by JSON Schema before execution</li> <li>Type-Safe: Pydantic v2 models with mypy strict mode</li> <li>Async-First: Single event loop per workflow with proper resource management</li> <li>Cached &amp; Pooled: Agent caching and model client pooling for performance</li> <li>Fail-Fast: Clear error messages and structured exit codes</li> <li>Observable: OpenTelemetry tracing with PII redaction</li> <li>Secure: Multi-layer security for templates, HTTP, paths, and tools</li> </ol> <p>Next Steps: See Pattern Philosophy, Design Decisions, Performance Optimizations, and Security Model for deeper dives into specific aspects.</p>"},{"location":"explanation/design-decisions/","title":"Design Decisions","text":"<p>This document explains the key architectural and technology choices made during Strands CLI development, the rationale behind each decision, and the trade-offs considered.</p>"},{"location":"explanation/design-decisions/#why-yamljson-workflow-specifications","title":"Why YAML/JSON Workflow Specifications?","text":""},{"location":"explanation/design-decisions/#the-decision","title":"The Decision","text":"<p>Strands CLI uses YAML/JSON files for workflow specifications instead of Python code, DSLs, or GUI builders.</p>"},{"location":"explanation/design-decisions/#rationale","title":"Rationale","text":"<p>1. Declarative over Imperative - Declarative: Describe what you want (agents, steps, dependencies) - Imperative: Describe how to achieve it (loops, conditionals, state management)</p> <p>Users focus on workflow structure, not orchestration logic.</p> <p>2. Version Control &amp; Code Review YAML files integrate seamlessly into Git workflows: <pre><code>git diff workflow.yaml  # See what changed\ngit blame workflow.yaml  # Who made this change?\n</code></pre></p> <p>3. Cross-Language &amp; Cross-Tool Compatibility YAML/JSON specs can be: - Generated by other tools (UI builders, CI/CD pipelines) - Consumed by other tools (validators, visualizers) - Edited by non-programmers (product managers, analysts)</p> <p>4. Static Analysis JSON Schema validation enables: - Pre-execution validation (catch errors before LLM calls) - IDE autocomplete and inline documentation - Automated testing of workflow specs</p> <p>5. Security Sandboxing YAML specs are data, not code: - No arbitrary code execution (unlike Python workflows) - Template sandboxing (Jinja2 SandboxedEnvironment) - Tool allowlisting enforced at spec validation time</p>"},{"location":"explanation/design-decisions/#trade-offs","title":"Trade-offs","text":"Advantage Disadvantage \u2705 Version control friendly \u274c Limited expressiveness vs. Python \u2705 Cross-language compatibility \u274c Requires learning YAML/JSON syntax \u2705 Static validation \u274c Complex logic needs workarounds (graph pattern) \u2705 Security sandboxing \u274c No dynamic imports/plugins"},{"location":"explanation/design-decisions/#alternative-considered-python-dsl","title":"Alternative Considered: Python DSL","text":"<p>Example: <pre><code>from strands_cli import Workflow, Agent, Chain\n\nworkflow = Workflow(\n    agents={\"researcher\": Agent(prompt=\"Research {{ topic }}\")},\n    pattern=Chain(\n        steps=[\n            Step(agent=\"researcher\", input=\"Research AI\"),\n        ]\n    )\n)\n</code></pre></p> <p>Why Rejected: - Requires Python knowledge (limits audience) - Harder to version control (complex diffs) - Security risks (arbitrary code execution) - IDE support requires complex AST parsing</p>"},{"location":"explanation/design-decisions/#why-json-schema-draft-2020-12","title":"Why JSON Schema Draft 2020-12?","text":""},{"location":"explanation/design-decisions/#the-decision_1","title":"The Decision","text":"<p>Strands CLI uses JSON Schema Draft 2020-12 for workflow validation instead of Pydantic-only validation, custom validators, or no validation.</p>"},{"location":"explanation/design-decisions/#rationale_1","title":"Rationale","text":"<p>1. Standardized Validation JSON Schema is a formal specification (RFC 8927) with: - Precise semantics for validation rules - Cross-language implementations (Python, JavaScript, Java, etc.) - Community-maintained tooling (validators, generators, editors)</p> <p>2. Precise Error Reporting JSON Schema provides JSONPointer paths to exact error locations: <pre><code>Schema validation error at '#/pattern/config/steps/0/agent':\n'missing_agent' is not one of ['researcher', 'analyst']\n</code></pre></p> <p>3. IDE Integration JSON Schema enables: - Autocomplete in VS Code, IntelliJ, etc. - Inline documentation from <code>description</code> fields - Real-time validation as you type</p> <p>4. Documentation Generation Schema can be auto-converted to: - Markdown documentation - Interactive web forms - OpenAPI specs (for REST APIs)</p> <p>5. Future-Proof Extensibility JSON Schema supports: - Conditional validation (<code>if</code>/<code>then</code>/<code>else</code>) - Schema composition (<code>allOf</code>, <code>anyOf</code>, <code>oneOf</code>) - Recursive schemas (for nested patterns)</p>"},{"location":"explanation/design-decisions/#trade-offs_1","title":"Trade-offs","text":"Advantage Disadvantage \u2705 Standardized, cross-language \u274c More verbose than Pydantic \u2705 Precise error messages \u274c Requires external validation library \u2705 IDE integration \u274c Learning curve for schema syntax \u2705 Documentation generation \u274c Custom validation requires <code>format</code> keywords"},{"location":"explanation/design-decisions/#why-draft-2020-12-specifically","title":"Why Draft 2020-12 Specifically?","text":"<p>Features Used: - <code>$defs</code> for reusable subschemas (cleaner than <code>definitions</code>) - <code>prefixItems</code> for tuple validation (better than <code>items</code> arrays) - <code>unevaluatedProperties: false</code> for strict validation - Better error messages in most validators</p> <p>Migration Path: - Draft 2020-12 is backward compatible with Draft 07 - Modern validators (jsonschema, ajv) support it natively</p>"},{"location":"explanation/design-decisions/#alternative-considered-pydantic-only-validation","title":"Alternative Considered: Pydantic-Only Validation","text":"<p>Why Rejected: - No cross-language support (Python-only) - Error messages less precise (no JSONPointer) - Harder to generate documentation from models - Less IDE integration for YAML files</p> <p>Hybrid Approach Chosen: - JSON Schema validates raw YAML/JSON - Pydantic models add runtime type safety - Best of both worlds (validation + type hints)</p>"},{"location":"explanation/design-decisions/#why-provider-abstraction","title":"Why Provider Abstraction?","text":""},{"location":"explanation/design-decisions/#the-decision_2","title":"The Decision","text":"<p>Strands CLI abstracts LLM providers (Bedrock, Ollama, OpenAI) behind a unified <code>Runtime</code> interface instead of exposing provider-specific APIs.</p>"},{"location":"explanation/design-decisions/#rationale_2","title":"Rationale","text":"<p>1. Multi-Provider Support Users can switch providers without changing workflow specs: <pre><code># Development (local Ollama)\nruntime:\n  provider: ollama\n  model_id: llama3.1\n\n# Production (AWS Bedrock)\nruntime:\n  provider: bedrock\n  model_id: anthropic.claude-3-sonnet-20240229-v1:0\n</code></pre></p> <p>2. Cost Optimization Users can test with cheap models (Ollama) and deploy with premium models (Bedrock).</p> <p>3. Provider Failover Future support for fallback chains: <pre><code>runtime:\n  providers:\n    - bedrock  # Try Bedrock first\n    - openai   # Fallback to OpenAI\n    - ollama   # Final fallback to local\n</code></pre></p> <p>4. Vendor Independence No lock-in to specific LLM providers: - AWS Bedrock today, OpenAI tomorrow, custom models next month - No code changes required (just spec updates)</p> <p>5. Model Client Pooling Abstraction enables <code>@lru_cache</code> pooling for efficiency: <pre><code>@lru_cache(maxsize=16)\ndef _create_model_cached(config: RuntimeConfig) -&gt; Model:\n    \"\"\"Create and cache model clients.\"\"\"\n    # Same config \u2192 same client instance\n</code></pre></p>"},{"location":"explanation/design-decisions/#implementation","title":"Implementation","text":"<p>Runtime Configuration: <pre><code>runtime:\n  provider: bedrock | ollama | openai\n  model_id: &lt;model_name&gt;\n  region: us-east-1  # Bedrock only\n  host: http://localhost:11434  # Ollama only\n</code></pre></p> <p>Provider Adapters (<code>runtime/providers.py</code>): - <code>BedrockProvider</code> \u2192 AWS Bedrock client - <code>OllamaProvider</code> \u2192 Ollama HTTP client - <code>OpenAIProvider</code> \u2192 OpenAI API client</p> <p>Unified Interface: <pre><code>def create_model(runtime: Runtime) -&gt; Model:\n    \"\"\"Create model client based on runtime config.\"\"\"\n    if runtime.provider == \"bedrock\":\n        return BedrockModel(model_id=runtime.model_id, region=runtime.region)\n    elif runtime.provider == \"ollama\":\n        return OllamaModel(model_id=runtime.model_id, host=runtime.host)\n    # ...\n</code></pre></p>"},{"location":"explanation/design-decisions/#trade-offs_2","title":"Trade-offs","text":"Advantage Disadvantage \u2705 Multi-provider support \u274c Provider-specific features harder to expose \u2705 Cost optimization \u274c Lowest-common-denominator API \u2705 Vendor independence \u274c Adapter maintenance overhead \u2705 Model client pooling \u274c Testing requires multiple provider setups"},{"location":"explanation/design-decisions/#alternative-considered-provider-specific-specs","title":"Alternative Considered: Provider-Specific Specs","text":"<p>Example: <pre><code># Bedrock-specific spec\nbedrock:\n  model_id: anthropic.claude-3-sonnet-20240229-v1:0\n  region: us-east-1\n  agents: [...]\n</code></pre></p> <p>Why Rejected: - No cross-provider workflows - Harder to test (need real provider credentials) - Vendor lock-in (spec tied to provider)</p>"},{"location":"explanation/design-decisions/#why-security-first-design","title":"Why Security-First Design?","text":""},{"location":"explanation/design-decisions/#the-decision_3","title":"The Decision","text":"<p>Strands CLI treats all user-provided specs as potentially malicious and implements defense-in-depth security controls.</p>"},{"location":"explanation/design-decisions/#threat-model","title":"Threat Model","text":"<p>Attack Surface: 1. Template Injection: User-controlled Jinja2 templates 2. SSRF: User-controlled HTTP executor URLs 3. Path Traversal: User-controlled artifact paths 4. Code Execution: User-controlled Python tool callables</p> <p>Threat Actors: - External users submitting workflow specs - Malicious workflow specs from untrusted repos - Compromised CI/CD pipelines</p>"},{"location":"explanation/design-decisions/#security-layers","title":"Security Layers","text":""},{"location":"explanation/design-decisions/#1-template-sandboxing","title":"1. Template Sandboxing","text":"<p>Risk: Remote code execution via template introspection.</p> <p>Mitigation: - <code>jinja2.sandbox.SandboxedEnvironment</code> (no <code>__class__</code>, <code>__mro__</code>, etc.) - Whitelisted filters only: <code>truncate</code>, <code>tojson</code>, <code>title</code> - Cleared globals (no access to Python builtins)</p> <p>Example Attack Blocked: <pre><code># Attempt to execute system command\noutputs:\n  artifacts:\n    - path: \"{{ ''.__class__.__mro__[1].__subclasses__()[104].__init__.__globals__['os'].system('whoami') }}\"\n</code></pre> Result: <code>SecurityError: access to attribute '__class__' is unsafe</code></p>"},{"location":"explanation/design-decisions/#2-ssrf-prevention","title":"2. SSRF Prevention","text":"<p>Risk: Server-Side Request Forgery via HTTP executors.</p> <p>Mitigation: - Blocked URL patterns: localhost, private IPs, metadata endpoints, file://, ftp:// - Configurable allowlist/blocklist via environment variables - Pre-execution validation (before HTTP client creation)</p> <p>Example Attack Blocked: <pre><code>tools:\n  http_executors:\n    - base_url: \"http://169.254.169.254/latest/meta-data/\"  # AWS metadata\n</code></pre> Result: <code>CapabilityError: HTTP URL blocked (SSRF attempt)</code></p>"},{"location":"explanation/design-decisions/#3-path-traversal-protection","title":"3. Path Traversal Protection","text":"<p>Risk: File overwrite and directory escape via artifact paths.</p> <p>Mitigation: - Reject absolute paths - Block <code>..</code> path components - Sanitize path components (remove special chars) - Validate resolved path (relative_to check) - Block symlinks (MVP restriction)</p> <p>Example Attack Blocked: <pre><code>outputs:\n  artifacts:\n    - path: \"../../etc/passwd\"\n</code></pre> Result: <code>ArtifactError: Path traversal not allowed</code></p>"},{"location":"explanation/design-decisions/#4-tool-allowlisting","title":"4. Tool Allowlisting","text":"<p>Risk: Arbitrary code execution via Python callables.</p> <p>Mitigation: - Allowlist of safe Python callables: <code>strands_tools.http_request</code>, <code>strands_tools.file_read</code>, etc. - User consent prompts for dangerous operations (file_write) - <code>--bypass-tool-consent</code> flag for CI/CD (with warnings)</p> <p>Example Attack Blocked: <pre><code>tools:\n  python:\n    - callable: \"os.system\"  # Arbitrary code execution\n</code></pre> Result: <code>CapabilityError: Python callable not in allowlist</code></p>"},{"location":"explanation/design-decisions/#audit-logging","title":"Audit Logging","text":"<p>All security violations logged with structured fields: <pre><code>{\n  \"event\": \"http_url_blocked\",\n  \"violation_type\": \"ssrf_attempt\",\n  \"blocked_url\": \"http://169.254.169.254/...\",\n  \"matched_pattern\": \"^https?://169\\\\.254\\\\.169\\\\.254.*$\",\n  \"timestamp\": \"2025-11-06T05:03:46Z\",\n  \"level\": \"warning\"\n}\n</code></pre></p>"},{"location":"explanation/design-decisions/#trade-offs_3","title":"Trade-offs","text":"Security Benefit Usability Cost \u2705 Template sandboxing prevents RCE \u274c Limited filter support (only truncate/tojson/title) \u2705 SSRF prevention protects internal networks \u274c Localhost blocked by default (need allowlist override) \u2705 Path validation prevents file overwrite \u274c Symlinks blocked (legitimate use cases affected) \u2705 Tool allowlisting prevents arbitrary code \u274c Custom tools require allowlist updates"},{"location":"explanation/design-decisions/#alternative-considered-permissive-by-default","title":"Alternative Considered: Permissive by Default","text":"<p>Why Rejected: - Security-first design is critical for enterprise adoption - Easy to relax restrictions (allowlist override) vs. tighten later - Audit logging provides visibility even with permissive settings</p>"},{"location":"explanation/design-decisions/#why-single-event-loop-strategy","title":"Why Single Event Loop Strategy?","text":""},{"location":"explanation/design-decisions/#the-decision_4","title":"The Decision","text":"<p>Strands CLI uses one <code>asyncio.run()</code> per workflow from the CLI layer. Executors use <code>await</code> internally.</p>"},{"location":"explanation/design-decisions/#rationale_3","title":"Rationale","text":"<p>1. Clean Resource Management Single event loop enables: - Single cleanup point (try/finally at CLI level) - Proper HTTP client lifecycle (one session per workflow) - No orphaned connections or file handles</p> <p>2. Async Context Propagation OpenTelemetry traces, structlog context, and timeouts propagate correctly: <pre><code># CLI layer\nwith tracer.start_as_current_span(\"workflow.execute\"):\n    result = asyncio.run(execute_workflow(spec))\n    # All child spans inherit this trace context\n</code></pre></p> <p>3. No Nested Event Loop Issues Python's asyncio raises <code>RuntimeError</code> on nested <code>asyncio.run()</code> calls: <pre><code># BAD: Nested event loops\nasyncio.run(outer())  # CLI\n    asyncio.run(inner())  # Executor - RAISES ERROR\n</code></pre></p> <p>Strands CLI avoids this by using <code>await</code> in executors: <pre><code># GOOD: Single event loop\nasyncio.run(outer())  # CLI\n    await inner()  # Executor - OK\n</code></pre></p> <p>4. Efficient Concurrency Single event loop enables: - Semaphore-based concurrency control (<code>max_parallel</code>) - asyncio.gather for parallel execution - Proper task cancellation on failure</p>"},{"location":"explanation/design-decisions/#implementation_1","title":"Implementation","text":"<p>CLI Layer (<code>__main__.py</code>): <pre><code>@app.command()\ndef run(spec_file: Path, ...) -&gt; None:\n    \"\"\"Execute workflow with single event loop.\"\"\"\n    result = asyncio.run(execute_workflow(spec_file))  # Single entry point\n    sys.exit(EX_OK if result.success else EX_RUNTIME)\n</code></pre></p> <p>Executor Layer (<code>exec/chain.py</code>, etc.): <pre><code>async def run_chain(spec: Spec, variables: dict[str, Any]) -&gt; RunResult:\n    \"\"\"Execute chain pattern (uses await, not asyncio.run).\"\"\"\n    cache = AgentCache()\n    try:\n        for step in spec.pattern.config.steps:\n            agent = await cache.get_or_build_agent(...)  # await\n            result = await invoke_agent_with_retry(agent, ...)  # await\n        return RunResult(...)\n    finally:\n        await cache.close()  # Cleanup\n</code></pre></p>"},{"location":"explanation/design-decisions/#trade-offs_4","title":"Trade-offs","text":"Advantage Disadvantage \u2705 Clean resource management \u274c All executors must be async \u2705 Proper context propagation \u274c No blocking I/O in executors \u2705 No nested event loop errors \u274c Testing requires asyncio fixtures \u2705 Efficient concurrency \u274c Debugging async code is harder"},{"location":"explanation/design-decisions/#alternative-considered-synchronous-execution","title":"Alternative Considered: Synchronous Execution","text":"<p>Why Rejected: - No parallelism (slower for workflow/parallel patterns) - Harder to add concurrency later (breaking change) - Modern Python ecosystem is async-first (httpx, strands-agents-sdk)</p>"},{"location":"explanation/design-decisions/#why-agent-caching-model-pooling","title":"Why Agent Caching &amp; Model Pooling?","text":""},{"location":"explanation/design-decisions/#the-decision_5","title":"The Decision","text":"<p>Strands CLI caches agent instances and model clients to avoid redundant initialization.</p>"},{"location":"explanation/design-decisions/#rationale_4","title":"Rationale","text":"<p>1. Performance Without caching, a 10-step chain with the same agent config: - Builds 10 agent instances (10\u00d7 prompt compilation, tool loading) - Creates 10 model clients (10\u00d7 HTTP sessions, auth handshakes)</p> <p>With caching: - Builds 1 agent instance (reused 10 times) - Creates 1 model client (reused 10 times) - ~10\u00d7 speedup for multi-step workflows</p> <p>2. Resource Conservation HTTP clients maintain connection pools: - Reusing clients \u2192 connection reuse (HTTP keep-alive) - New clients \u2192 new connections (TCP handshake overhead)</p> <p>3. Consistent Behavior Same agent config \u2192 same agent instance \u2192 deterministic behavior: - No subtle differences between steps - Easier debugging (one agent to inspect)</p>"},{"location":"explanation/design-decisions/#implementation_2","title":"Implementation","text":"<p>Agent Cache (<code>exec/utils.py</code>): <pre><code>class AgentCache:\n    \"\"\"Singleton cache for agent reuse.\"\"\"\n\n    def __init__(self):\n        self._agents: dict[tuple, Agent] = {}\n        self._clients: list[Any] = []\n\n    async def get_or_build_agent(\n        self, spec: Spec, agent_id: str, config: AgentConfig, ...\n    ) -&gt; Agent:\n        \"\"\"Get cached agent or build new one.\"\"\"\n        cache_key = (agent_id, config_hash(config))\n        if cache_key in self._agents:\n            return self._agents[cache_key]  # Cache hit\n\n        agent = await build_agent(spec, agent_id, config, ...)\n        self._agents[cache_key] = agent\n        return agent\n</code></pre></p> <p>Model Client Pool (<code>runtime/strands_adapter.py</code>): <pre><code>@dataclass(frozen=True)\nclass RuntimeConfig:\n    \"\"\"Hashable runtime config for LRU cache.\"\"\"\n    provider: str\n    model_id: str\n    region: str | None = None\n\n@lru_cache(maxsize=16)\ndef _create_model_cached(config: RuntimeConfig) -&gt; Model:\n    \"\"\"Create and cache model clients.\"\"\"\n    if config.provider == \"bedrock\":\n        return BedrockModel(model_id=config.model_id, region=config.region)\n    # ...\n</code></pre></p>"},{"location":"explanation/design-decisions/#trade-offs_5","title":"Trade-offs","text":"Advantage Disadvantage \u2705 10\u00d7+ speedup for multi-step workflows \u274c Stale agents if spec changes mid-execution \u2705 Resource conservation (HTTP pools) \u274c Memory usage for cached agents \u2705 Deterministic behavior \u274c Cache invalidation complexity"},{"location":"explanation/design-decisions/#alternative-considered-no-caching","title":"Alternative Considered: No Caching","text":"<p>Why Rejected: - Unacceptable performance penalty for multi-step workflows - Wasteful resource usage (new HTTP clients per step) - No significant simplification (cache logic is ~50 lines)</p>"},{"location":"explanation/design-decisions/#why-exit-code-discipline","title":"Why Exit Code Discipline?","text":""},{"location":"explanation/design-decisions/#the-decision_6","title":"The Decision","text":"<p>Strands CLI uses named exit code constants (EX_OK, EX_SCHEMA, etc.) instead of generic <code>exit(1)</code>.</p>"},{"location":"explanation/design-decisions/#rationale_5","title":"Rationale","text":"<p>1. Scriptability Users can handle different error types: <pre><code>strands run workflow.yaml\nEXIT_CODE=$?\n\nif [ $EXIT_CODE -eq 3 ]; then\n    echo \"Schema error - fix workflow.yaml\"\nelif [ $EXIT_CODE -eq 18 ]; then\n    echo \"Unsupported feature - upgrade strands-cli\"\nfi\n</code></pre></p> <p>2. Observability Exit codes enable: - CI/CD pipeline branching (retry on EX_RUNTIME, fail on EX_SCHEMA) - Metrics dashboards (count of EX_UNSUPPORTED errors) - Alerting (page on EX_RUNTIME, ignore EX_USAGE)</p> <p>3. Consistency Named constants prevent: - Arbitrary exit codes (<code>exit(1)</code>, <code>exit(2)</code>, <code>exit(42)</code>) - Exit code collisions (two error types with same code) - Undocumented exit codes (what does <code>exit(13)</code> mean?)</p>"},{"location":"explanation/design-decisions/#exit-code-map","title":"Exit Code Map","text":"Code Name When to Use 0 <code>EX_OK</code> Success 2 <code>EX_USAGE</code> Bad CLI flags/missing file 3 <code>EX_SCHEMA</code> JSON Schema validation error 10 <code>EX_RUNTIME</code> Provider/model/tool runtime failure 12 <code>EX_IO</code> Artifact write/IO error 18 <code>EX_UNSUPPORTED</code> Feature present but not supported 70 <code>EX_UNKNOWN</code> Unexpected exception"},{"location":"explanation/design-decisions/#implementation_3","title":"Implementation","text":"<p>Exit Code Module (<code>exit_codes.py</code>): <pre><code>\"\"\"Exit codes for strands CLI.\"\"\"\n\nEX_OK = 0  # Success\nEX_USAGE = 2  # Bad CLI usage\nEX_SCHEMA = 3  # Schema validation error\nEX_RUNTIME = 10  # Runtime error\nEX_IO = 12  # I/O error\nEX_UNSUPPORTED = 18  # Unsupported feature\nEX_UNKNOWN = 70  # Unknown error\n</code></pre></p> <p>Usage in CLI: <pre><code>from strands_cli.exit_codes import EX_SCHEMA, EX_OK\n\ntry:\n    validate_spec(spec_data)\nexcept SchemaValidationError as e:\n    console.print(f\"[red]Schema Error:[/red] {e}\")\n    sys.exit(EX_SCHEMA)  # NOT sys.exit(3)\n</code></pre></p>"},{"location":"explanation/design-decisions/#trade-offs_6","title":"Trade-offs","text":"Advantage Disadvantage \u2705 Scriptable error handling \u274c Requires discipline (no <code>exit(1)</code>) \u2705 Observable in CI/CD metrics \u274c Limited to 256 exit codes (not an issue) \u2705 Consistent across codebase \u274c Documentation overhead"},{"location":"explanation/design-decisions/#alternative-considered-generic-exit-codes","title":"Alternative Considered: Generic Exit Codes","text":"<p>Why Rejected: - No way to distinguish error types programmatically - Harder to debug (all errors look the same) - No CI/CD automation potential</p>"},{"location":"explanation/design-decisions/#summary","title":"Summary","text":"<p>Strands CLI design decisions prioritize:</p> <ol> <li>Declarative Specs: YAML/JSON for version control, security, and cross-tool compatibility</li> <li>Standardized Validation: JSON Schema Draft 2020-12 for precise errors and IDE integration</li> <li>Provider Abstraction: Unified runtime interface for multi-provider support and cost optimization</li> <li>Security-First: Defense-in-depth for templates, HTTP, paths, and tools</li> <li>Single Event Loop: Clean resource management and async context propagation</li> <li>Caching &amp; Pooling: Agent caching and model pooling for 10\u00d7+ performance gains</li> <li>Exit Code Discipline: Named constants for scriptable error handling and observability</li> </ol> <p>Next Steps: See Architecture Overview, Pattern Philosophy, Performance Optimizations, and Security Model for implementation details.</p>"},{"location":"explanation/patterns/","title":"Pattern Philosophy","text":"<p>This document explains the conceptual foundation of workflow patterns in Strands CLI, why they exist, when to use each, and how to choose the right pattern for your use case.</p>"},{"location":"explanation/patterns/#why-patterns","title":"Why Patterns?","text":""},{"location":"explanation/patterns/#the-multi-agent-orchestration-problem","title":"The Multi-Agent Orchestration Problem","text":"<p>When building agentic workflows, you quickly encounter several challenges:</p> <ol> <li>Context Threading: How do agents share information across steps?</li> <li>Parallel Execution: How do you run multiple agents concurrently?</li> <li>Dynamic Routing: How do you choose different agents based on input?</li> <li>Quality Control: How do you iteratively refine outputs?</li> <li>Task Decomposition: How do you break complex tasks into subtasks?</li> <li>Conditional Logic: How do you implement branching and loops?</li> </ol>"},{"location":"explanation/patterns/#the-pattern-solution","title":"The Pattern Solution","text":"<p>Rather than forcing users to write custom orchestration code, Strands CLI provides pre-built workflow patterns that solve common orchestration problems declaratively.</p> <p>Benefits: - Declarative: Describe what you want, not how to implement it - Tested: Patterns are extensively tested (795 tests, 82% coverage) - Observable: Built-in OpenTelemetry tracing for all patterns - Secure: Security controls (SSRF, path traversal, template sandboxing) apply uniformly - Composable: Patterns can be nested and combined (e.g., parallel branches with chain steps)</p> <p>Design Principle: Patterns encode best practices for common orchestration scenarios.</p>"},{"location":"explanation/patterns/#pattern-catalog","title":"Pattern Catalog","text":"<p>Strands CLI supports 7 workflow patterns, each optimized for specific use cases:</p>"},{"location":"explanation/patterns/#1-chain-pattern","title":"1. Chain Pattern","text":"<p>Purpose: Sequential multi-step execution with context threading.</p> <p>When to Use: - Linear workflows where each step depends on the previous one - Research \u2192 Analysis \u2192 Writing pipelines - Data extraction \u2192 Transformation \u2192 Summary flows - Simple question \u2192 follow-up \u2192 synthesis scenarios</p> <p>Key Features: - Steps execute sequentially (step N+1 waits for step N) - Context accessible via <code>{{ steps[n].response }}</code> - Single agent or different agents per step - Token budgets accumulate across steps</p> <p>Example Use Cases: - Web research \u2192 extract key points \u2192 write blog post - Read logs \u2192 identify patterns \u2192 generate report - Fetch data \u2192 analyze trends \u2192 create visualization</p> <p>Template Access: <pre><code>steps:\n  - agent: researcher\n    input: \"Research {{ topic }}\"\n  - agent: analyst\n    input: \"Analyze findings: {{ steps[0].response }}\"\n  - agent: writer\n    input: \"Write report based on: {{ steps[1].response }}\"\n</code></pre></p> <p>Trade-offs: - \u2705 Simple to understand and debug - \u2705 Predictable execution order - \u274c No parallelism (slower for independent tasks) - \u274c Failure in step N blocks all subsequent steps</p>"},{"location":"explanation/patterns/#2-workflow-pattern-dag","title":"2. Workflow Pattern (DAG)","text":"<p>Purpose: DAG-based multi-task execution with dependency resolution.</p> <p>When to Use: - Tasks with explicit dependencies that can run in parallel - Fan-out/fan-in patterns (one task \u2192 many \u2192 one) - Complex pipelines where some tasks are independent - Workflows requiring topological sorting</p> <p>Key Features: - Tasks with <code>depends_on: [task_ids]</code> specify dependencies - Parallel execution of independent tasks (respects <code>max_parallel</code>) - Context accessible via <code>{{ tasks.&lt;id&gt;.response }}</code> - Detects dependency cycles at validation time</p> <p>Example Use Cases: - Parallel data collection from multiple sources \u2192 merge results - Independent analysis tasks \u2192 aggregation step - Validation tasks that can run concurrently \u2192 final approval</p> <p>Template Access: <pre><code>tasks:\n  - id: fetch_web\n    agent: scraper\n    input: \"Fetch web data\"\n  - id: fetch_db\n    agent: db_query\n    input: \"Fetch database data\"\n  - id: merge\n    agent: synthesizer\n    depends_on: [fetch_web, fetch_db]\n    input: \"Merge {{ tasks.fetch_web.response }} and {{ tasks.fetch_db.response }}\"\n</code></pre></p> <p>Trade-offs: - \u2705 Parallel execution speeds up independent tasks - \u2705 Flexible dependency specification - \u2705 Topological sorting handled automatically - \u274c More complex to reason about than chain - \u274c Dependency cycles cause validation errors</p>"},{"location":"explanation/patterns/#3-routing-pattern","title":"3. Routing Pattern","text":"<p>Purpose: Dynamic agent selection based on classifier decisions.</p> <p>When to Use: - Different agents specialized for different input types - Customer support routing (technical/billing/general) - Multi-domain question answering (code/docs/general) - Intent-based delegation</p> <p>Key Features: - Router agent classifies input and selects target agent - Retry logic for malformed JSON (up to 2 retries) - Context accessible via <code>{{ router.response }}</code> and <code>{{ last_response }}</code> - Supports custom routing prompt templates</p> <p>Example Use Cases: - Customer support: Route to technical/billing/sales agents - Code assistance: Route to Python/JavaScript/SQL experts - Document analysis: Route to legal/financial/technical analysts</p> <p>Template Access: <pre><code>pattern:\n  type: routing\n  config:\n    router:\n      agent: classifier\n      input: \"Classify intent: {{ user_question }}\"\n    routes:\n      - route_id: technical\n        agent: tech_support\n        input: \"Answer technical question: {{ user_question }}\"\n      - route_id: billing\n        agent: billing_support\n        input: \"Answer billing question: {{ user_question }}\"\n</code></pre></p> <p>Trade-offs: - \u2705 Dynamic agent selection based on input - \u2705 Scales to many specialized agents - \u2705 Router retry handles LLM inconsistency - \u274c Adds latency (router invocation before task) - \u274c Requires router agent to output valid JSON</p>"},{"location":"explanation/patterns/#4-parallel-pattern","title":"4. Parallel Pattern","text":"<p>Purpose: Concurrent branch execution with optional reduce aggregation.</p> <p>When to Use: - Independent analyses that can run concurrently - A/B testing multiple approaches - Multi-perspective evaluation (expert reviews) - Parallel data processing pipelines</p> <p>Key Features: - Branches execute concurrently (respects <code>max_parallel</code>) - Optional reduce step aggregates all branch results - Context accessible via <code>{{ branches.&lt;id&gt;.response }}</code> - Fail-fast semantics (first failure cancels all branches)</p> <p>Example Use Cases: - Parallel web scraping from multiple sources - Multiple LLM providers for consensus - Parallel code review from different perspectives - Regional data collection (US/EU/APAC)</p> <p>Template Access: <pre><code>pattern:\n  type: parallel\n  config:\n    branches:\n      - id: web\n        steps: [...]\n      - id: api\n        steps: [...]\n    reduce:\n      agent: synthesizer\n      input: |\n        Web results: {{ branches.web.response }}\n        API results: {{ branches.api.response }}\n        Merge and summarize.\n</code></pre></p> <p>Trade-offs: - \u2705 Maximum parallelism for independent tasks - \u2705 Optional reduce step for aggregation - \u2705 Semaphore control prevents resource exhaustion - \u274c No inter-branch communication (branches are isolated) - \u274c Fail-fast means one failure aborts all branches</p>"},{"location":"explanation/patterns/#5-evaluator-optimizer-pattern","title":"5. Evaluator-Optimizer Pattern","text":"<p>Purpose: Iterative refinement with producer-evaluator feedback loops.</p> <p>When to Use: - Quality-driven content generation (writing, code) - Iterative improvement until quality threshold met - Self-correcting workflows with evaluation criteria - Research \u2192 refine \u2192 finalize loops</p> <p>Key Features: - Producer generates output, evaluator scores it - Retry with feedback if score below <code>min_score</code> - Max iterations (<code>max_iters</code>) prevents infinite loops - Context accessible via <code>{{ iterations[n].producer }}</code> and <code>{{ iterations[n].evaluator }}</code></p> <p>Example Use Cases: - Code generation with test-based evaluation - Blog post writing with quality scoring - Research synthesis with completeness checks - Design iteration with stakeholder feedback</p> <p>Template Access: <pre><code>pattern:\n  type: evaluator_optimizer\n  config:\n    producer:\n      agent: writer\n      input: \"Write about {{ topic }}\"\n    evaluator:\n      agent: critic\n      input: \"Rate this (1-10): {{ last_produced }}\"\n    min_score: 8\n    max_iters: 3\n</code></pre></p> <p>Trade-offs: - \u2705 Quality gates ensure output meets standards - \u2705 Automatic refinement with feedback - \u2705 Configurable acceptance criteria - \u274c Can consume many tokens if quality threshold is high - \u274c Evaluator must return valid JSON with score</p>"},{"location":"explanation/patterns/#6-orchestrator-workers-pattern","title":"6. Orchestrator-Workers Pattern","text":"<p>Purpose: Dynamic task delegation with orchestrator decomposing tasks and workers executing in parallel.</p> <p>When to Use: - Complex tasks requiring decomposition - Variable number of subtasks determined at runtime - Swarm intelligence scenarios - Hierarchical task planning</p> <p>Key Features: - Orchestrator decomposes task into worker assignments (JSON) - Workers execute in parallel (respects <code>max_workers</code>) - Multi-round delegation supported (<code>max_rounds</code>) - Optional reduce and writeup steps - Context accessible via <code>{{ rounds[n].workers[m].response }}</code></p> <p>Example Use Cases: - Research swarm (orchestrator assigns topics, workers research) - Data processing pipeline (orchestrator plans, workers execute) - Code review (orchestrator identifies concerns, workers analyze) - Multi-document summarization (orchestrator assigns docs, workers summarize)</p> <p>Template Access: <pre><code>pattern:\n  type: orchestrator_workers\n  config:\n    orchestrator:\n      agent: planner\n      limits:\n        max_workers: 5\n        max_rounds: 2\n    worker_template:\n      agent: researcher\n      tools: [\"http_executors\"]\n    reduce:\n      agent: synthesizer\n      input: \"Merge results: {% for w in workers %}{{ w.response }}{% endfor %}\"\n    writeup:\n      agent: writer\n      input: \"Final report based on: {{ reduce_result }}\"\n</code></pre></p> <p>Trade-offs: - \u2705 Dynamic task decomposition at runtime - \u2705 Scales to variable workloads - \u2705 Multi-round delegation for iterative planning - \u2705 Optional reduce/writeup for final synthesis - \u274c Complex to debug (orchestrator JSON must be valid) - \u274c High token usage for large worker pools</p>"},{"location":"explanation/patterns/#7-graph-pattern","title":"7. Graph Pattern","text":"<p>Purpose: State machine with conditional transitions between nodes.</p> <p>When to Use: - Workflows with branching logic and loops - Decision trees and flowcharts - Multi-stage processes with conditional paths - Iterative refinement with break conditions</p> <p>Key Features: - Nodes connected by conditional or default edges - Secure <code>when</code> clause evaluation (restricted builtins) - Cycle detection with <code>max_iterations</code> protection - Context accessible via <code>{{ nodes.&lt;id&gt;.response }}</code> - Static and dynamic transitions</p> <p>Example Use Cases: - Content approval workflow (draft \u2192 review \u2192 approve/reject \u2192 revise \u2192 ...) - Iterative problem solving (attempt \u2192 validate \u2192 retry if failed \u2192 success) - Decision trees (classify \u2192 route \u2192 process \u2192 verify \u2192 done) - State-based workflows (idle \u2192 active \u2192 paused \u2192 resumed \u2192 completed)</p> <p>Template Access: <pre><code>pattern:\n  type: graph\n  config:\n    start_node: draft\n    max_iterations: 10\n    nodes:\n      draft:\n        agent: writer\n        edges:\n          - to: review\n      review:\n        agent: reviewer\n        edges:\n          - to: revise\n            when: \"score &lt; 8\"\n          - to: done  # Default edge\n      revise:\n        agent: writer\n        edges:\n          - to: review\n</code></pre></p> <p>Trade-offs: - \u2705 Explicit control flow with conditionals - \u2705 Loops and branches supported natively - \u2705 Max iteration protection prevents infinite loops - \u2705 Clear state machine semantics - \u274c More complex to design than linear patterns - \u274c Cycle detection adds validation overhead</p>"},{"location":"explanation/patterns/#pattern-selection-guide","title":"Pattern Selection Guide","text":""},{"location":"explanation/patterns/#decision-tree","title":"Decision Tree","text":"<pre><code>graph TD\n    Start{Need multiple agents?}\n    Start --&gt;|No| Single[Use Chain with 1 agent]\n    Start --&gt;|Yes| Sequential{Sequential or Parallel?}\n\n    Sequential --&gt;|Sequential| Dependencies{Explicit dependencies?}\n    Dependencies --&gt;|No| Chain[Chain Pattern]\n    Dependencies --&gt;|Yes| Workflow[Workflow Pattern DAG]\n\n    Sequential --&gt;|Parallel| Aggregate{Need to aggregate results?}\n    Aggregate --&gt;|Yes| Parallel[Parallel Pattern]\n    Aggregate --&gt;|No| Parallel\n\n    Sequential --&gt;|Dynamic| Dynamic{Dynamic based on what?}\n    Dynamic --&gt;|Input classification| Routing[Routing Pattern]\n    Dynamic --&gt;|Task decomposition| Orchestrator[Orchestrator-Workers Pattern]\n\n    Sequential --&gt;|Iterative| Iterative{Refinement type?}\n    Iterative --&gt;|Quality-driven| Evaluator[Evaluator-Optimizer Pattern]\n    Iterative --&gt;|Conditional logic| Graph[Graph Pattern]\n\n    style Chain fill:#bfb,stroke:#333\n    style Workflow fill:#bfb,stroke:#333\n    style Routing fill:#bbf,stroke:#333\n    style Parallel fill:#bbf,stroke:#333\n    style Evaluator fill:#f9f,stroke:#333\n    style Orchestrator fill:#f9f,stroke:#333\n    style Graph fill:#f9f,stroke:#333</code></pre>"},{"location":"explanation/patterns/#pattern-comparison-matrix","title":"Pattern Comparison Matrix","text":"Pattern Parallelism Dependencies Dynamic Loops Complexity Token Efficiency Chain None Implicit (sequential) No No Low High (1 path) Workflow Yes (via DAG) Explicit (<code>depends_on</code>) No No Medium Medium (parallel) Routing No None Yes (input-based) No Medium Medium (1 route) Parallel Yes (all branches) None No No Medium Low (all branches) Evaluator-Optimizer No Implicit (producer\u2192evaluator) No Yes (up to max_iters) Medium Low (retries) Orchestrator-Workers Yes (workers) None Yes (runtime tasks) Yes (multi-round) High Very Low (many workers) Graph No Explicit (edges) Yes (conditional) Yes (cycles) High Variable (path-dependent)"},{"location":"explanation/patterns/#use-case-mapping","title":"Use Case Mapping","text":"Use Case Recommended Pattern Alternative Linear pipeline (research \u2192 analyze \u2192 write) Chain Workflow (overkill) Parallel data collection \u2192 merge Workflow (with dependencies) Parallel (with reduce) Customer support routing Routing Graph (overkill) Multi-perspective analysis Parallel Workflow (if dependencies) Code generation with tests Evaluator-Optimizer Graph (more flexible) Research swarm Orchestrator-Workers Parallel (if fixed tasks) Approval workflow with revisions Graph Evaluator-Optimizer (less flexible) A/B testing multiple approaches Parallel Workflow (if dependencies) Iterative problem solving Graph Evaluator-Optimizer (if simple)"},{"location":"explanation/patterns/#pattern-composability","title":"Pattern Composability","text":""},{"location":"explanation/patterns/#nested-patterns","title":"Nested Patterns","text":"<p>Some patterns support nesting (e.g., parallel branches with chain steps):</p> <pre><code>pattern:\n  type: parallel\n  config:\n    branches:\n      - id: web\n        steps:  # Chain pattern within branch\n          - agent: scraper\n            input: \"Scrape data\"\n          - agent: parser\n            input: \"Parse {{ steps[0].response }}\"\n      - id: api\n        steps:\n          - agent: api_client\n            input: \"Fetch API data\"\n</code></pre>"},{"location":"explanation/patterns/#anti-patterns","title":"Anti-Patterns","text":"<p>\u274c Don't use parallel for sequential tasks with dependencies: <pre><code># BAD: Step 2 needs step 1, but they run in parallel\npattern:\n  type: parallel\n  config:\n    branches:\n      - id: step1\n        steps: [...]\n      - id: step2  # Needs step1 output but can't access it!\n        steps: [...]\n</code></pre> \u2705 Use workflow or chain instead.</p> <p>\u274c Don't use routing for parallel execution: <pre><code># BAD: Router only selects ONE agent, not all\npattern:\n  type: routing\n  config:\n    routes:\n      - route_id: all  # Can't execute all routes\n        agent: agent1\n</code></pre> \u2705 Use parallel pattern instead.</p> <p>\u274c Don't use evaluator-optimizer for multi-perspective evaluation: <pre><code># BAD: Evaluator-optimizer is one producer, one evaluator\npattern:\n  type: evaluator_optimizer\n  config:\n    producer: writer\n    evaluator: critic  # Only ONE evaluator, not multiple\n</code></pre> \u2705 Use parallel pattern with multiple expert agents.</p>"},{"location":"explanation/patterns/#performance-considerations","title":"Performance Considerations","text":""},{"location":"explanation/patterns/#token-usage","title":"Token Usage","text":"Pattern Token Usage Notes Chain Linear (N steps) Most efficient for sequential Workflow Parallel (sum of concurrent tasks) Better than chain for independent tasks Routing Router + 1 route Efficient if router is simple Parallel Sum of all branches Can be expensive with many branches Evaluator-Optimizer Producer + (Evaluator \u00d7 iterations) Can be expensive if many iterations Orchestrator-Workers Orchestrator + (Workers \u00d7 rounds) Most expensive for large worker pools Graph Path-dependent Variable based on conditionals"},{"location":"explanation/patterns/#latency","title":"Latency","text":"Pattern Latency Notes Chain Sum of step latencies Sequential (slowest) Workflow Max latency of parallel tasks Faster than chain for independent tasks Routing Router latency + route latency Extra router overhead Parallel Max branch latency Fastest for independent tasks Evaluator-Optimizer Producer + (Evaluator \u00d7 iterations) Can be slow with many iterations Orchestrator-Workers Orchestrator + max(worker latencies) \u00d7 rounds Variable based on decomposition Graph Path-dependent Variable based on conditionals"},{"location":"explanation/patterns/#concurrency-control","title":"Concurrency Control","text":"<p>All patterns respect <code>runtime.max_parallel</code> for semaphore-based concurrency control:</p> <pre><code>runtime:\n  max_parallel: 5  # Max concurrent tasks/branches/workers\n</code></pre> <p>Default: 5 concurrent operations</p> <p>Trade-offs: - Higher <code>max_parallel</code> \u2192 faster execution, higher memory usage - Lower <code>max_parallel</code> \u2192 slower execution, lower memory usage</p>"},{"location":"explanation/patterns/#pattern-evolution","title":"Pattern Evolution","text":""},{"location":"explanation/patterns/#current-support","title":"Current Support","text":"<p>All 7 patterns are fully implemented and tested: - \u2705 Chain - \u2705 Workflow - \u2705 Routing - \u2705 Parallel - \u2705 Evaluator-Optimizer - \u2705 Orchestrator-Workers - \u2705 Graph</p>"},{"location":"explanation/patterns/#future-patterns-potential","title":"Future Patterns (Potential)","text":"<ul> <li>Map-Reduce: Simplified orchestrator-workers for homogeneous tasks</li> <li>State Machine: Enhanced graph pattern with explicit state management</li> <li>Event-Driven: Trigger-based workflows with event subscriptions</li> </ul>"},{"location":"explanation/patterns/#implemented-features","title":"Implemented Features","text":"<ul> <li>\u2705 Human-in-the-Loop (HITL): Manual approval gates and interactive steps in chain pattern (See HITL Guide)</li> </ul>"},{"location":"explanation/patterns/#best-practices","title":"Best Practices","text":""},{"location":"explanation/patterns/#1-start-simple","title":"1. Start Simple","text":"<p>Begin with chain or workflow patterns for most use cases. Move to advanced patterns only when needed.</p>"},{"location":"explanation/patterns/#2-use-workflow-for-parallel-independence","title":"2. Use Workflow for Parallel Independence","text":"<p>If tasks are independent and can run in parallel, prefer workflow over chain.</p>"},{"location":"explanation/patterns/#3-routing-for-specialization","title":"3. Routing for Specialization","text":"<p>Use routing when different agents are experts in different domains (technical/billing/sales).</p>"},{"location":"explanation/patterns/#4-parallel-for-fan-out","title":"4. Parallel for Fan-Out","text":"<p>Use parallel when you need to run the same analysis from multiple perspectives or sources.</p>"},{"location":"explanation/patterns/#5-evaluator-optimizer-for-quality","title":"5. Evaluator-Optimizer for Quality","text":"<p>Use evaluator-optimizer when output quality is critical and iterative refinement is acceptable.</p>"},{"location":"explanation/patterns/#6-orchestrator-workers-for-complex-decomposition","title":"6. Orchestrator-Workers for Complex Decomposition","text":"<p>Use orchestrator-workers when the number of subtasks is unknown at spec-writing time.</p>"},{"location":"explanation/patterns/#7-graph-for-complex-logic","title":"7. Graph for Complex Logic","text":"<p>Use graph when you need explicit branching, loops, and conditional transitions.</p>"},{"location":"explanation/patterns/#8-monitor-token-budgets","title":"8. Monitor Token Budgets","text":"<p>Set <code>runtime.budgets.tokens</code> to prevent runaway costs, especially with: - Evaluator-optimizer (many iterations) - Orchestrator-workers (large worker pools) - Graph (potential cycles)</p>"},{"location":"explanation/patterns/#9-use-debug-mode","title":"9. Use Debug Mode","text":"<p>Enable <code>--debug</code> flag to trace execution flow and template rendering:</p> <pre><code>strands run workflow.yaml --debug\n</code></pre>"},{"location":"explanation/patterns/#10-test-with-simple-cases-first","title":"10. Test with Simple Cases First","text":"<p>Before running complex workflows, test patterns with simple examples to understand behavior.</p>"},{"location":"explanation/patterns/#summary","title":"Summary","text":"<p>Pattern Philosophy: - Patterns encode best practices for common orchestration scenarios - Choose patterns based on task structure (sequential/parallel/dynamic/iterative) - Start simple (chain/workflow) and move to advanced patterns as needed - Monitor token usage and latency for complex patterns - Use debug mode and telemetry to understand execution flow</p> <p>Next Steps: See Architecture Overview, Design Decisions, Performance Optimizations, and Security Model for deeper dives into implementation details.</p>"},{"location":"explanation/performance/","title":"Performance Optimizations","text":"<p>This document explains the performance optimizations implemented in Strands CLI, benchmarks, and best practices for efficient workflow execution.</p>"},{"location":"explanation/performance/#overview","title":"Overview","text":"<p>Strands CLI achieves high performance through three core optimizations:</p> <ol> <li>Agent Caching: Reuse agent instances across workflow execution</li> <li>Model Client Pooling: Cache LLM provider clients with <code>@lru_cache</code></li> <li>Single Event Loop: Efficient async concurrency with proper resource management</li> </ol>"},{"location":"explanation/performance/#agent-caching","title":"Agent Caching","text":""},{"location":"explanation/performance/#the-problem","title":"The Problem","text":"<p>Without caching, every agent invocation requires: 1. Model client creation (HTTP session, auth handshake) 2. Tool loading and validation 3. Prompt compilation and configuration 4. Context manager initialization</p> <p>For a 10-step chain with the same agent: - 10\u00d7 agent builds (redundant initialization) - 10\u00d7 model clients (redundant HTTP sessions) - 10\u00d7 tool loading (redundant import/validation)</p>"},{"location":"explanation/performance/#the-solution-agentcache","title":"The Solution: AgentCache","text":"<p>Implementation (<code>exec/utils.py</code>): <pre><code>class AgentCache:\n    \"\"\"Singleton cache for agent reuse across workflow execution.\n\n    Benefits:\n    - 10\u00d7+ speedup for multi-step workflows with agent reuse\n    - Reduced memory footprint (one agent instance, not N)\n    - Deterministic behavior (same config \u2192 same agent)\n    \"\"\"\n\n    def __init__(self):\n        self._agents: dict[tuple, Agent] = {}\n        self._clients: list[Any] = []\n\n    async def get_or_build_agent(\n        self, spec: Spec, agent_id: str, config: AgentConfig, ...\n    ) -&gt; Agent:\n        \"\"\"Get cached agent or build new one.\n\n        Cache key: (agent_id, config_hash)\n        - agent_id: Agent identifier from spec\n        - config_hash: Hash of agent configuration (prompt, tools, model)\n        \"\"\"\n        cache_key = (agent_id, config_hash(config))\n\n        if cache_key in self._agents:\n            logger.debug(\"agent_cache_hit\", agent_id=agent_id)\n            return self._agents[cache_key]\n\n        logger.debug(\"agent_cache_miss\", agent_id=agent_id)\n        agent = await build_agent(spec, agent_id, config, ...)\n        self._agents[cache_key] = agent\n        self._clients.append(agent.model.client)  # Track for cleanup\n        return agent\n\n    async def close(self):\n        \"\"\"Cleanup all HTTP clients.\"\"\"\n        for client in self._clients:\n            if hasattr(client, 'close'):\n                await client.close()\n</code></pre></p>"},{"location":"explanation/performance/#cache-key-strategy","title":"Cache Key Strategy","text":"<p>Components: - <code>agent_id</code>: Identifier from spec (e.g., \"researcher\", \"analyst\") - <code>config_hash</code>: Hash of agent configuration</p> <p>Why Both?: - <code>agent_id</code> alone insufficient (same ID, different config \u2192 different agent) - <code>config_hash</code> alone insufficient (same config, different ID \u2192 want separate agents)</p> <p>Config Hash Includes: - Prompt template - Tool list - Model ID and provider - Runtime parameters</p> <p>Cache Invalidation: - Cache lives for single workflow execution - New workflow \u2192 new cache instance - No stale agent issues across workflows</p>"},{"location":"explanation/performance/#performance-impact","title":"Performance Impact","text":"<p>Scenario: 10-step chain, same agent config</p> Metric Without Cache With Cache Speedup Agent builds 10 1 10\u00d7 Model clients 10 1 10\u00d7 Tool imports 10 1 10\u00d7 Total overhead ~5000ms ~500ms 10\u00d7 <p>Token cost: Unchanged (same LLM calls) Latency: Reduced by ~4.5s (for example above)</p>"},{"location":"explanation/performance/#usage-pattern","title":"Usage Pattern","text":"<p>Executor Pattern (all executors follow this): <pre><code>async def run_chain(spec: Spec, variables: dict[str, Any]) -&gt; RunResult:\n    \"\"\"Execute chain pattern with agent caching.\"\"\"\n    cache = AgentCache()  # Create cache at executor start\n    try:\n        for step in spec.pattern.config.steps:\n            # Get or build agent (cache hit after first step)\n            agent = await cache.get_or_build_agent(\n                spec, step.agent_id, agent_config, tool_overrides\n            )\n\n            # Invoke agent (uses cached instance)\n            result = await invoke_agent_with_retry(agent, prompt, ...)\n\n        return RunResult(...)\n    finally:\n        await cache.close()  # Cleanup HTTP clients\n</code></pre></p>"},{"location":"explanation/performance/#multi-agent-scenarios","title":"Multi-Agent Scenarios","text":"<p>Scenario: 5-step chain with 2 alternating agents</p> <pre><code>pattern:\n  type: chain\n  config:\n    steps:\n      - agent: researcher  # Build + cache\n        input: \"Research topic A\"\n      - agent: analyst     # Build + cache\n        input: \"Analyze {{ steps[0].response }}\"\n      - agent: researcher  # Cache hit (reuse)\n        input: \"Research topic B\"\n      - agent: analyst     # Cache hit (reuse)\n        input: \"Analyze {{ steps[2].response }}\"\n      - agent: writer      # Build + cache\n        input: \"Write report\"\n</code></pre> <p>Cache Statistics: - Builds: 3 (researcher, analyst, writer) - Cache hits: 2 (researcher, analyst) - Total operations: 5 steps - Cache hit rate: 40%</p>"},{"location":"explanation/performance/#model-client-pooling","title":"Model Client Pooling","text":""},{"location":"explanation/performance/#the-problem_1","title":"The Problem","text":"<p>Model clients (Bedrock/Ollama/OpenAI) involve expensive initialization: - Bedrock: boto3 session creation, credential resolution, region setup - Ollama: HTTP session creation, connection pool initialization - OpenAI: API client creation, authentication validation</p> <p>Creating new clients for each agent wastes: - CPU cycles (session initialization) - Memory (connection pools) - Network (redundant auth handshakes)</p>"},{"location":"explanation/performance/#the-solution-lru-cache","title":"The Solution: LRU Cache","text":"<p>Implementation (<code>runtime/strands_adapter.py</code>): <pre><code>from functools import lru_cache\nfrom dataclasses import dataclass\n\n@dataclass(frozen=True)\nclass RuntimeConfig:\n    \"\"\"Hashable runtime configuration for LRU cache.\n\n    Must be frozen (immutable) for lru_cache to work.\n    \"\"\"\n    provider: str\n    model_id: str\n    region: str | None = None\n    host: str | None = None\n\n@lru_cache(maxsize=16)\ndef _create_model_cached(config: RuntimeConfig) -&gt; Model:\n    \"\"\"Create and cache model clients.\n\n    Cache key: RuntimeConfig (provider, model_id, region, host)\n    Cache size: 16 (supports 16 unique runtime configs)\n\n    Performance:\n    - First call with config \u2192 create new client\n    - Subsequent calls with same config \u2192 return cached client\n    \"\"\"\n    if config.provider == \"bedrock\":\n        return BedrockModel(\n            model_id=config.model_id,\n            region=config.region or \"us-east-1\"\n        )\n    elif config.provider == \"ollama\":\n        return OllamaModel(\n            model_id=config.model_id,\n            host=config.host or \"http://localhost:11434\"\n        )\n    elif config.provider == \"openai\":\n        return OpenAIModel(model_id=config.model_id)\n    # ...\n\ndef create_model(runtime: Runtime) -&gt; Model:\n    \"\"\"Convert Runtime to RuntimeConfig and get cached model.\n\n    Public API that wraps the cached function.\n    \"\"\"\n    config = RuntimeConfig(\n        provider=runtime.provider,\n        model_id=runtime.model_id,\n        region=runtime.region,\n        host=runtime.host\n    )\n    return _create_model_cached(config)\n</code></pre></p>"},{"location":"explanation/performance/#why-lru-cache","title":"Why LRU Cache?","text":"<p>LRU (Least Recently Used) evicts oldest entries when cache is full: - <code>maxsize=16</code>: Supports 16 unique runtime configurations - Sufficient for most workflows (typically 1-5 configs) - Automatic eviction prevents unbounded memory growth</p> <p>Why Not Global Singleton?: - Global state complicates testing (mocking, cleanup) - LRU cache is thread-safe (built into functools) - Automatic lifecycle management (GC when function unreferenced)</p>"},{"location":"explanation/performance/#cache-key-design","title":"Cache Key Design","text":"<p>RuntimeConfig Fields: - <code>provider</code>: bedrock | ollama | openai - <code>model_id</code>: Model identifier (e.g., <code>anthropic.claude-3-sonnet-20240229-v1:0</code>) - <code>region</code>: AWS region (Bedrock only) - <code>host</code>: Ollama server URL (Ollama only)</p> <p>Why Frozen Dataclass?: - <code>lru_cache</code> requires hashable keys - Frozen dataclass is immutable \u2192 hashable - Pydantic models are not hashable by default</p>"},{"location":"explanation/performance/#performance-impact_1","title":"Performance Impact","text":"<p>Scenario: 100-task workflow, 5 unique runtime configs</p> Metric Without Pool With Pool Speedup Client creations 100 5 20\u00d7 HTTP sessions 100 5 20\u00d7 Auth handshakes 100 5 20\u00d7 Total overhead ~10,000ms ~500ms 20\u00d7 <p>Real-World Example (orchestrator-workers pattern): - Orchestrator: 1 model client - 20 workers: Same runtime config \u2192 reuse orchestrator's client - Without pooling: 21 clients - With pooling: 1 client - 21\u00d7 reduction in client creations</p>"},{"location":"explanation/performance/#cache-statistics","title":"Cache Statistics","text":"<p>Monitor cache hits (debug mode): <pre><code># Check cache info\ninfo = _create_model_cached.cache_info()\nprint(f\"Hits: {info.hits}, Misses: {info.misses}, Size: {info.currsize}\")\n</code></pre></p> <p>Example Output (10-step chain): <pre><code>Hits: 9, Misses: 1, Size: 1\nCache hit rate: 90%\n</code></pre></p>"},{"location":"explanation/performance/#single-event-loop-strategy","title":"Single Event Loop Strategy","text":""},{"location":"explanation/performance/#the-problem_2","title":"The Problem","text":"<p>Python's asyncio prohibits nested event loops: <pre><code>asyncio.run(outer())  # CLI layer\n    asyncio.run(inner())  # Executor - RAISES RuntimeError!\n</code></pre></p> <p>Multiple event loops cause: - Resource leaks: HTTP clients not properly cleaned up - Context loss: OpenTelemetry traces don't propagate - Concurrency bugs: Semaphores and locks scoped to wrong loop</p>"},{"location":"explanation/performance/#the-solution-one-event-loop-per-workflow","title":"The Solution: One Event Loop Per Workflow","text":"<p>Architecture: <pre><code>CLI Layer           Executor Layer        Provider Layer\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500           \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500        \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nasyncio.run() \u2500\u2500\u2500\u2500&gt; await run_chain() \u2500\u2500&gt; await model.invoke()\n   (1 loop)            (uses await)          (uses await)\n</code></pre></p> <p>Implementation:</p> <p>CLI Layer (<code>__main__.py</code>): <pre><code>@app.command()\ndef run(spec_file: Path, ...) -&gt; None:\n    \"\"\"Execute workflow with single event loop.\"\"\"\n    # Single asyncio.run() per workflow\n    result = asyncio.run(execute_workflow(spec_file))\n    sys.exit(EX_OK if result.success else EX_RUNTIME)\n</code></pre></p> <p>Executor Layer (<code>exec/chain.py</code>): <pre><code>async def run_chain(spec: Spec, variables: dict[str, Any]) -&gt; RunResult:\n    \"\"\"Execute chain pattern (async function, not event loop).\"\"\"\n    cache = AgentCache()\n    try:\n        for step in spec.pattern.config.steps:\n            agent = await cache.get_or_build_agent(...)  # await, not asyncio.run()\n            result = await invoke_agent_with_retry(agent, ...)\n        return RunResult(...)\n    finally:\n        await cache.close()\n</code></pre></p>"},{"location":"explanation/performance/#benefits","title":"Benefits","text":"<p>1. Clean Resource Management - Single cleanup point (CLI try/finally) - All HTTP clients closed on workflow completion - No orphaned connections or file handles</p> <p>2. Context Propagation OpenTelemetry traces propagate correctly: <pre><code># CLI layer\nwith tracer.start_as_current_span(\"workflow.execute\"):\n    result = asyncio.run(execute_workflow(spec))\n    # All child spans inherit trace context\n</code></pre></p> <p>3. Efficient Concurrency Semaphores and locks work correctly: <pre><code># Shared semaphore across all tasks\nsemaphore = asyncio.Semaphore(max_parallel)\n\nasync def run_task_with_limit(task):\n    async with semaphore:  # Works because same event loop\n        return await run_task(task)\n</code></pre></p> <p>4. Proper Task Cancellation Fail-fast semantics work correctly: <pre><code># Cancel all tasks on first failure\nresults = await asyncio.gather(*tasks, return_exceptions=False)\n# All tasks in same event loop \u2192 proper cancellation\n</code></pre></p>"},{"location":"explanation/performance/#performance-impact_2","title":"Performance Impact","text":"<p>Single Loop vs. Multiple Loops:</p> Metric Multiple Loops Single Loop Improvement Event loop overhead N \u00d7 loop_cost 1 \u00d7 loop_cost N\u00d7 Resource cleanup Unreliable Guaranteed 100% Context propagation Broken Correct 100% Concurrency control Broken Correct 100% <p>Real-World Scenario (parallel pattern, 5 branches): - Multiple loops: 5 event loops, 5 cleanup cycles, context loss - Single loop: 1 event loop, 1 cleanup cycle, context preserved - 5\u00d7 reduction in event loop overhead</p>"},{"location":"explanation/performance/#concurrency-control","title":"Concurrency Control","text":""},{"location":"explanation/performance/#semaphore-based-limits","title":"Semaphore-Based Limits","text":"<p>Purpose: Prevent resource exhaustion with <code>max_parallel</code> control.</p> <p>Implementation (<code>exec/parallel.py</code>): <pre><code>max_parallel = spec.runtime.max_parallel or 5\nsemaphore = asyncio.Semaphore(max_parallel)\n\nasync def run_branch_with_limit(branch):\n    async with semaphore:  # Acquire slot (blocks if all slots in use)\n        return await run_branch(branch)\n\n# Run all branches concurrently with semaphore limit\nresults = await asyncio.gather(\n    *[run_branch_with_limit(b) for b in branches],\n    return_exceptions=False  # Fail-fast\n)\n</code></pre></p> <p>How It Works: 1. Semaphore initialized with <code>max_parallel</code> slots 2. Each branch acquires slot before execution 3. If all slots in use, branch waits (async, non-blocking) 4. Branch releases slot on completion 5. Waiting branch acquires released slot</p> <p>Performance Impact:</p> max_parallel 10 Branches Memory Usage Total Latency 1 Sequential Low 10\u00d7 branch time 5 5 at a time Medium 2\u00d7 branch time 10 All parallel High 1\u00d7 branch time <p>Recommendation: Set <code>max_parallel</code> based on: - Memory: Higher \u2192 more memory (N concurrent agents) - Rate limits: Provider throttling (e.g., Bedrock: 10 RPS) - Token budget: Higher \u2192 faster budget consumption</p>"},{"location":"explanation/performance/#fail-fast-semantics","title":"Fail-Fast Semantics","text":"<p>Purpose: Cancel all tasks on first failure to save tokens and time.</p> <p>Implementation: <pre><code># asyncio.gather with return_exceptions=False\nresults = await asyncio.gather(*tasks, return_exceptions=False)\n# First exception raised \u2192 all pending tasks cancelled\n</code></pre></p> <p>Trade-offs:</p> Strategy Behavior Token Usage Debugging Fail-fast (current) Stop on first error Low (abort early) Easy (one error) Continue on error Collect all errors High (run all) Hard (many errors) <p>Example (parallel pattern, 5 branches): - Branch 1 fails at 2s - Branches 2-5 still running - Fail-fast: Cancel branches 2-5 immediately (save ~8s, 80% tokens) - Continue: Wait for all branches (~10s, 100% tokens)</p>"},{"location":"explanation/performance/#performance-best-practices","title":"Performance Best Practices","text":""},{"location":"explanation/performance/#1-reuse-agents-across-steps","title":"1. Reuse Agents Across Steps","text":"<p>\u2705 Good (agent caching): <pre><code>pattern:\n  type: chain\n  config:\n    steps:\n      - agent: researcher  # Build + cache\n        input: \"Research A\"\n      - agent: researcher  # Cache hit (reuse)\n        input: \"Research B\"\n</code></pre></p> <p>\u274c Bad (no caching benefit): <pre><code>pattern:\n  type: chain\n  config:\n    steps:\n      - agent: researcher_a  # Different ID \u2192 no cache hit\n        input: \"Research A\"\n      - agent: researcher_b  # Different ID \u2192 no cache hit\n        input: \"Research B\"\n# Both steps use same config, but different IDs prevent caching\n</code></pre></p>"},{"location":"explanation/performance/#2-use-workflow-pattern-for-independent-tasks","title":"2. Use Workflow Pattern for Independent Tasks","text":"<p>\u2705 Good (parallel execution): <pre><code>pattern:\n  type: workflow\n  config:\n    tasks:\n      - id: fetch_web\n        agent: scraper\n        input: \"Fetch web data\"\n      - id: fetch_db\n        agent: db_query\n        input: \"Fetch DB data\"\n      - id: merge\n        agent: synthesizer\n        depends_on: [fetch_web, fetch_db]\n        input: \"Merge results\"\n# fetch_web and fetch_db run in parallel (2\u00d7 speedup)\n</code></pre></p> <p>\u274c Bad (sequential execution): <pre><code>pattern:\n  type: chain\n  config:\n    steps:\n      - agent: scraper\n        input: \"Fetch web data\"\n      - agent: db_query\n        input: \"Fetch DB data\"\n      - agent: synthesizer\n        input: \"Merge {{ steps[0].response }} and {{ steps[1].response }}\"\n# All steps sequential (no parallelism, slower)\n</code></pre></p>"},{"location":"explanation/performance/#3-set-appropriate-max_parallel","title":"3. Set Appropriate max_parallel","text":"<p>\u2705 Good (balanced): <pre><code>runtime:\n  max_parallel: 5  # Balance speed and resource usage\n</code></pre></p> <p>\u274c Bad (unbounded): <pre><code>runtime:\n  max_parallel: 100  # May exhaust memory or hit rate limits\n</code></pre></p> <p>Guidelines: - Local Ollama: 3-5 (CPU-bound) - AWS Bedrock: 10-20 (rate limits) - OpenAI: 5-10 (rate limits)</p>"},{"location":"explanation/performance/#4-minimize-evaluator-optimizer-iterations","title":"4. Minimize Evaluator-Optimizer Iterations","text":"<p>\u2705 Good (reasonable threshold): <pre><code>pattern:\n  type: evaluator_optimizer\n  config:\n    min_score: 7  # Achievable threshold\n    max_iters: 3  # Limit iterations\n</code></pre></p> <p>\u274c Bad (high threshold): <pre><code>pattern:\n  type: evaluator_optimizer\n  config:\n    min_score: 9.5  # Rarely achievable\n    max_iters: 10   # Many iterations\n# High token cost, slow convergence\n</code></pre></p>"},{"location":"explanation/performance/#5-use-parallel-pattern-wisely","title":"5. Use Parallel Pattern Wisely","text":"<p>\u2705 Good (independent branches): <pre><code>pattern:\n  type: parallel\n  config:\n    branches:\n      - id: web\n        steps: [...]  # Independent from api\n      - id: api\n        steps: [...]  # Independent from web\n</code></pre></p> <p>\u274c Bad (dependent branches): <pre><code>pattern:\n  type: parallel\n  config:\n    branches:\n      - id: fetch\n        steps: [...]\n      - id: process\n        steps: [...]  # Needs fetch output but can't access it!\n# Use workflow pattern with depends_on instead\n</code></pre></p>"},{"location":"explanation/performance/#performance-monitoring","title":"Performance Monitoring","text":""},{"location":"explanation/performance/#debug-mode-statistics","title":"Debug Mode Statistics","text":"<p>Enable debug mode to see cache statistics: <pre><code>strands run workflow.yaml --debug\n</code></pre></p> <p>Output Example: <pre><code>2025-11-09T05:03:46Z INFO agent_cache_miss agent_id=researcher\n2025-11-09T05:03:47Z INFO agent_cache_hit agent_id=researcher\n2025-11-09T05:03:48Z INFO agent_cache_hit agent_id=researcher\n...\nCache hit rate: 90% (9 hits, 1 miss)\n</code></pre></p>"},{"location":"explanation/performance/#token-budget-tracking","title":"Token Budget Tracking","text":"<p>Monitor token usage with budgets: <pre><code>runtime:\n  budgets:\n    tokens: 100000  # Total token budget\n</code></pre></p> <p>Output: <pre><code>2025-11-09T05:03:50Z WARNING budget_warning usage=80000 limit=100000 percent=80\n2025-11-09T05:04:00Z ERROR budget_exceeded usage=100500 limit=100000\n</code></pre></p>"},{"location":"explanation/performance/#trace-analysis","title":"Trace Analysis","text":"<p>Use OpenTelemetry traces to identify bottlenecks: <pre><code>strands run workflow.yaml --trace\n</code></pre></p> <p>Trace Artifact (<code>trace-&lt;timestamp&gt;.json</code>): <pre><code>{\n  \"spans\": [\n    {\"name\": \"workflow.execute\", \"duration_ms\": 12000},\n    {\"name\": \"pattern.chain\", \"duration_ms\": 11500},\n    {\"name\": \"agent.invoke\", \"duration_ms\": 2000},\n    {\"name\": \"agent.invoke\", \"duration_ms\": 2100},\n    ...\n  ]\n}\n</code></pre></p> <p>Analyze: - High <code>agent.invoke</code> durations \u2192 LLM bottleneck - High <code>agent.build</code> durations \u2192 Cache miss (check agent IDs) - Many short spans \u2192 Good parallelism</p>"},{"location":"explanation/performance/#benchmark-results","title":"Benchmark Results","text":""},{"location":"explanation/performance/#agent-caching-benchmark","title":"Agent Caching Benchmark","text":"<p>Scenario: 10-step chain, same agent config</p> Implementation Total Time Overhead Speedup No caching 15.2s 5.2s 1\u00d7 Agent caching only 10.5s 0.5s 1.45\u00d7 Agent + model caching 10.1s 0.1s 1.50\u00d7 <p>Setup: Ollama local (llama3.1:8b), 10 steps, 100-token responses</p>"},{"location":"explanation/performance/#model-client-pooling-benchmark","title":"Model Client Pooling Benchmark","text":"<p>Scenario: 100-task workflow, 5 unique runtime configs</p> Implementation Total Time Client Creations Speedup No pooling 65.3s 100 1\u00d7 Model pooling 52.1s 5 1.25\u00d7 <p>Setup: AWS Bedrock (Claude Sonnet), 100 tasks, 200-token responses</p>"},{"location":"explanation/performance/#parallel-execution-benchmark","title":"Parallel Execution Benchmark","text":"<p>Scenario: 10 independent tasks</p> max_parallel Total Time Memory Usage Speedup 1 (sequential) 25.0s 500MB 1\u00d7 3 10.2s 800MB 2.45\u00d7 5 6.8s 1.2GB 3.68\u00d7 10 5.1s 2.0GB 4.90\u00d7 <p>Setup: Ollama local (llama3.1:8b), 10 tasks, 500-token responses</p>"},{"location":"explanation/performance/#summary","title":"Summary","text":"<p>Strands CLI achieves high performance through:</p> <ol> <li>Agent Caching: 10\u00d7+ speedup for multi-step workflows</li> <li>Model Client Pooling: 20\u00d7+ reduction in client creations</li> <li>Single Event Loop: Efficient async concurrency</li> <li>Semaphore Control: Resource-aware parallelism</li> <li>Fail-Fast: Token and time savings on errors</li> </ol> <p>Best Practices: - Reuse agents (same ID + config across steps) - Use workflow pattern for independent tasks - Set appropriate <code>max_parallel</code> for provider - Monitor cache hit rates with <code>--debug</code> - Use OpenTelemetry traces to identify bottlenecks</p> <p>Next Steps: See Architecture Overview, Pattern Philosophy, Design Decisions, and Security Model for more details.</p>"},{"location":"explanation/security-model/","title":"Security Model","text":"<p>This document explains Strands CLI's defense-in-depth security architecture, threat model, security controls, and best practices for secure workflow execution.</p>"},{"location":"explanation/security-model/#security-philosophy","title":"Security Philosophy","text":"<p>Core Principle: Treat all user-provided workflow specifications as potentially malicious.</p> <p>Design Approach: Defense-in-depth with multiple security layers: 1. Input Validation: JSON Schema validation before execution 2. Template Sandboxing: Jinja2 sandbox prevents code injection 3. SSRF Prevention: URL validation for HTTP executors 4. Path Security: Multi-layer checks for artifact paths 5. Tool Allowlisting: Strict callable restrictions 6. Audit Logging: Structured security event logging</p> <p>Threat Model: Workflows from untrusted sources (external users, compromised repos, malicious CI/CD pipelines).</p>"},{"location":"explanation/security-model/#threat-landscape","title":"Threat Landscape","text":""},{"location":"explanation/security-model/#attack-surface","title":"Attack Surface","text":"Component User Control Attack Vector Templates Jinja2 expressions in prompts, inputs, artifact paths Remote Code Execution (RCE) HTTP Executors <code>base_url</code> in tool config Server-Side Request Forgery (SSRF) Artifact Paths Output file paths with templates Path Traversal, File Overwrite Python Tools <code>callable</code> in tool config Arbitrary Code Execution Variables CLI <code>--var</code> overrides Template Injection, XSS"},{"location":"explanation/security-model/#threat-actors","title":"Threat Actors","text":"<ol> <li>External Users: Submit malicious workflow specs via web interface</li> <li>Compromised Repositories: Specs from untrusted Git repos</li> <li>Supply Chain Attacks: Malicious dependencies in Python tools</li> <li>Insider Threats: Malicious specs from internal users</li> </ol>"},{"location":"explanation/security-model/#attack-scenarios","title":"Attack Scenarios","text":"<p>Scenario 1: Template Injection for RCE <pre><code>outputs:\n  artifacts:\n    - path: \"{{ ''.__class__.__mro__[1].__subclasses__()[104].__init__.__globals__['os'].system('whoami') }}\"\n      from: \"{{ last_response }}\"\n</code></pre> Impact: Remote code execution on host system</p> <p>Scenario 2: SSRF to Cloud Metadata <pre><code>tools:\n  http_executors:\n    - id: \"metadata\"\n      base_url: \"http://169.254.169.254/latest/meta-data/\"\n</code></pre> Impact: Steal AWS credentials, compromise cloud account</p> <p>Scenario 3: Path Traversal for System File Overwrite <pre><code>outputs:\n  artifacts:\n    - path: \"../../etc/passwd\"\n      from: \"malicious:content\"\n</code></pre> Impact: Overwrite system files, privilege escalation</p> <p>Scenario 4: Arbitrary Code Execution via Python Tools <pre><code>tools:\n  python:\n    - callable: \"os.system\"\n</code></pre> Impact: Execute arbitrary shell commands</p>"},{"location":"explanation/security-model/#security-layer-1-template-sandboxing","title":"Security Layer 1: Template Sandboxing","text":""},{"location":"explanation/security-model/#risk-remote-code-execution-via-jinja2","title":"Risk: Remote Code Execution via Jinja2","text":"<p>Vulnerability: Jinja2 templates support Python introspection, allowing access to internal objects: <pre><code>{{ ''.__class__.__mro__[1].__subclasses__() }}  # Access all Python classes\n{{ config.__class__.__init__.__globals__['os'].system('cmd') }}  # Execute commands\n</code></pre></p>"},{"location":"explanation/security-model/#mitigation-sandboxedenvironment","title":"Mitigation: SandboxedEnvironment","text":"<p>Implementation (<code>loader/template.py</code>): <pre><code>from jinja2.sandbox import SandboxedEnvironment\n\n# Create sandboxed environment\nenv = SandboxedEnvironment(\n    autoescape=False,  # Don't escape (not HTML context)\n    undefined=StrictUndefined  # Raise error on undefined variables\n)\n\n# Whitelist only safe filters\nenv.filters = {\n    \"truncate\": truncate_filter,\n    \"tojson\": tojson_filter,\n    \"title\": title_filter,\n}\n\n# Clear all globals (block builtin access)\nenv.globals.clear()\n</code></pre></p> <p>What's Blocked: - Attribute access to <code>__class__</code>, <code>__mro__</code>, <code>__subclasses__</code>, <code>__globals__</code>, <code>__builtins__</code> - Non-whitelisted filters (e.g., <code>upper</code>, <code>lower</code>, <code>replace</code>) - Function calls via <code>()</code> syntax (except whitelisted filters) - Import statements (<code>{% import %}</code>) - Code blocks (<code>{% exec %}</code>, <code>{% eval %}</code>)</p> <p>What's Allowed: - Variable expansion: <code>{{ topic }}</code>, <code>{{ steps[0].response }}</code> - Whitelisted filters: <code>{{ text | truncate(100) }}</code>, <code>{{ data | tojson }}</code>, <code>{{ topic | title }}</code> - Dictionary access: <code>{{ inputs.topic }}</code>, <code>{{ tasks.research.response }}</code> - List indexing: <code>{{ steps[0].response }}</code>, <code>{{ branches[1].response }}</code></p> <p>Security Tests (<code>tests/test_executor.py</code>): <pre><code>def test_template_blocks_class_introspection():\n    \"\"\"Template sandbox blocks __class__ access.\"\"\"\n    spec = create_spec(artifact_path=\"{{ ''.__class__ }}\")\n    with pytest.raises(SecurityError, match=\"unsafe\"):\n        render_template(spec)\n\ndef test_template_blocks_builtins():\n    \"\"\"Template sandbox blocks builtin access.\"\"\"\n    spec = create_spec(artifact_path=\"{{ __builtins__ }}\")\n    with pytest.raises(SecurityError, match=\"unsafe\"):\n        render_template(spec)\n</code></pre></p> <p>Audit Logging: <pre><code>{\n  \"event\": \"template_security_violation\",\n  \"violation_type\": \"unsafe_operation\",\n  \"error\": \"SecurityError: access to attribute '__class__' is unsafe\",\n  \"template_preview\": \"{{ ''.__class__ }}\",\n  \"timestamp\": \"2025-11-09T05:03:46Z\",\n  \"level\": \"warning\"\n}\n</code></pre></p>"},{"location":"explanation/security-model/#best-practices","title":"Best Practices","text":"<p>\u2705 Safe Template Usage: <pre><code># Variable expansion\nprompt: \"Research {{ topic }}\"\n\n# Whitelisted filters\nprompt: \"Summarize: {{ long_text | truncate(500) }}\"\n\n# JSON serialization\nprompt: \"Analyze data: {{ data | tojson }}\"\n\n# Title case\nprompt: \"Write about {{ topic | title }}\"\n</code></pre></p> <p>\u274c Unsafe Patterns (will raise SecurityError): <pre><code># Introspection\nprompt: \"{{ object.__class__ }}\"\n\n# Builtin access\nprompt: \"{{ __import__('os') }}\"\n\n# Non-whitelisted filters\nprompt: \"{{ text | upper }}\"  # Not in whitelist\n\n# Code execution\nprompt: \"{% exec malicious_code %}\"\n</code></pre></p>"},{"location":"explanation/security-model/#security-layer-2-ssrf-prevention","title":"Security Layer 2: SSRF Prevention","text":""},{"location":"explanation/security-model/#risk-server-side-request-forgery","title":"Risk: Server-Side Request Forgery","text":"<p>Vulnerability: HTTP executors allow arbitrary <code>base_url</code> values, enabling attacks on: - Internal services (databases, APIs) - Cloud metadata endpoints (AWS, Azure, GCP) - Localhost services (SSH, databases) - File system (<code>file://</code> protocol)</p> <p>Attack Example: <pre><code>tools:\n  http_executors:\n    - id: \"metadata\"\n      base_url: \"http://169.254.169.254/latest/meta-data/iam/security-credentials/\"\n# Steal AWS credentials from metadata endpoint\n</code></pre></p>"},{"location":"explanation/security-model/#mitigation-url-validation-with-blocklistallowlist","title":"Mitigation: URL Validation with Blocklist/Allowlist","text":"<p>Default Blocked Patterns (<code>types.py</code>): <pre><code>DEFAULT_BLOCKED_URL_PATTERNS = [\n    r\"^https?://127\\.0\\.0\\.1.*$\",        # Localhost IPv4\n    r\"^https?://localhost.*$\",           # Localhost hostname\n    r\"^https?://\\[::1\\].*$\",             # Localhost IPv6\n    r\"^https?://169\\.254\\.169\\.254.*$\",  # AWS/Azure metadata\n    r\"^https?://10\\..*$\",                # RFC1918 private (10.0.0.0/8)\n    r\"^https?://172\\.(1[6-9]|2\\d|3[01])\\..*$\",  # RFC1918 (172.16.0.0/12)\n    r\"^https?://192\\.168\\..*$\",          # RFC1918 private (192.168.0.0/16)\n    r\"^file:///.*$\",                     # File protocol\n    r\"^ftp://.*$\",                       # FTP protocol\n    r\"^gopher://.*$\",                    # Gopher protocol\n]\n</code></pre></p> <p>Implementation (<code>types.py</code>): <pre><code>class HttpExecutor(BaseModel):\n    \"\"\"HTTP executor configuration with SSRF protection.\"\"\"\n\n    id: str\n    base_url: str\n    timeout: int = 30\n\n    @field_validator(\"base_url\")\n    @classmethod\n    def validate_url(cls, v: str) -&gt; str:\n        \"\"\"Validate URL against blocklist and allowlist.\"\"\"\n        # Load config\n        config = Settings()\n        blocked = DEFAULT_BLOCKED_URL_PATTERNS + config.http_blocked_patterns\n        allowed = config.http_allowed_domains\n\n        # If allowlist exists, only allow matching URLs\n        if allowed:\n            if not any(re.match(pattern, v) for pattern in allowed):\n                raise ValueError(f\"URL not in allowlist: {v}\")\n\n        # Block URLs matching blocklist\n        for pattern in blocked:\n            if re.match(pattern, v):\n                logger.warning(\n                    \"http_url_blocked\",\n                    violation_type=\"ssrf_attempt\",\n                    blocked_url=v,\n                    matched_pattern=pattern,\n                )\n                raise ValueError(f\"URL blocked by pattern: {pattern}\")\n\n        return v\n</code></pre></p> <p>Environment Configuration: <pre><code># Add custom blocked patterns\nexport STRANDS_HTTP_BLOCKED_PATTERNS='[\"^https://internal-api\\\\.company\\\\.com\"]'\n\n# Enforce strict allowlist (blocks all except matches)\nexport STRANDS_HTTP_ALLOWED_DOMAINS='[\"^https://api\\\\.openai\\\\.com\", \"^https://.*\\\\.trusted\\\\.com\"]'\n</code></pre></p> <p>What's Blocked by Default: - Localhost/loopback: <code>127.0.0.1</code>, <code>localhost</code>, <code>[::1]</code> - Private networks: <code>10.x.x.x</code>, <code>172.16-31.x.x</code>, <code>192.168.x.x</code> - Cloud metadata: <code>169.254.169.254</code> (AWS/Azure), <code>metadata.google.internal</code> (GCP via custom pattern) - Non-HTTP protocols: <code>file://</code>, <code>ftp://</code>, <code>gopher://</code></p> <p>What's Allowed by Default: - Public HTTP/HTTPS URLs: <code>https://api.openai.com</code>, <code>http://example.com</code></p> <p>Security Tests (<code>tests/test_runtime.py</code>): <pre><code>def test_http_executor_blocks_localhost():\n    \"\"\"HTTP executor blocks localhost URLs.\"\"\"\n    spec = {\n        \"tools\": {\n            \"http_executors\": [\n                {\"id\": \"test\", \"base_url\": \"http://localhost:8000\"}\n            ]\n        }\n    }\n    with pytest.raises(ValidationError, match=\"blocked\"):\n        Spec(**spec)\n\ndef test_http_executor_blocks_aws_metadata():\n    \"\"\"HTTP executor blocks AWS metadata endpoint.\"\"\"\n    spec = {\n        \"tools\": {\n            \"http_executors\": [\n                {\"id\": \"test\", \"base_url\": \"http://169.254.169.254/latest/\"}\n            ]\n        }\n    }\n    with pytest.raises(ValidationError, match=\"blocked\"):\n        Spec(**spec)\n</code></pre></p>"},{"location":"explanation/security-model/#best-practices_1","title":"Best Practices","text":"<p>\u2705 Safe HTTP Executor Usage: <pre><code># Public APIs\ntools:\n  http_executors:\n    - id: \"openai\"\n      base_url: \"https://api.openai.com\"\n    - id: \"github\"\n      base_url: \"https://api.github.com\"\n</code></pre></p> <p>\u2705 Development with Localhost (override blocklist): <pre><code># Allow localhost for local testing\nexport STRANDS_HTTP_ALLOWED_DOMAINS='[\"^http://localhost\"]'\nstrands run workflow.yaml\n</code></pre></p> <p>\u274c Unsafe Patterns (will raise ValidationError): <pre><code># Localhost\ntools:\n  http_executors:\n    - base_url: \"http://localhost:5000\"\n\n# AWS metadata\ntools:\n  http_executors:\n    - base_url: \"http://169.254.169.254/latest/\"\n\n# Private network\ntools:\n  http_executors:\n    - base_url: \"http://192.168.1.100/admin\"\n</code></pre></p>"},{"location":"explanation/security-model/#security-layer-3-path-traversal-protection","title":"Security Layer 3: Path Traversal Protection","text":""},{"location":"explanation/security-model/#risk-file-overwrite-and-directory-escape","title":"Risk: File Overwrite and Directory Escape","text":"<p>Vulnerability: Artifact paths support templates that can render user variables, enabling: - Path traversal (<code>../../etc/passwd</code>) - Absolute paths (<code>/etc/passwd</code>, <code>C:\\Windows\\System32\\config</code>) - Symlink attacks (follow symlinks outside output directory)</p> <p>Attack Example: <pre><code>outputs:\n  artifacts:\n    - path: \"{{ malicious_path }}\"\n      from: \"{{ last_response }}\"\n</code></pre> <pre><code>strands run workflow.yaml --var malicious_path=\"../../etc/passwd\"\n</code></pre></p>"},{"location":"explanation/security-model/#mitigation-multi-layer-path-validation","title":"Mitigation: Multi-Layer Path Validation","text":"<p>Implementation (<code>artifacts/io.py</code>): <pre><code>def write_artifact(artifact: Artifact, content: str, output_dir: Path) -&gt; None:\n    \"\"\"Write artifact with multi-layer path security.\"\"\"\n    # 1. Reject absolute paths\n    path_obj = Path(artifact.path)\n    if path_obj.is_absolute():\n        raise ArtifactError(\n            f\"Absolute paths not allowed: {artifact.path}\",\n            violation_type=\"absolute_path\"\n        )\n\n    # 2. Block path traversal (..) components\n    if \"..\" in path_obj.parts:\n        raise ArtifactError(\n            f\"Path traversal not allowed: {artifact.path}\",\n            violation_type=\"path_traversal\"\n        )\n\n    # 3. Sanitize path components\n    sanitized_parts = [sanitize_filename(part) for part in path_obj.parts]\n    sanitized_path = Path(*sanitized_parts)\n\n    # 4. Validate resolved path (prevent symlink escape)\n    artifact_path = (output_dir / sanitized_path).resolve()\n    try:\n        artifact_path.relative_to(output_dir.resolve())\n    except ValueError:\n        raise ArtifactError(\n            f\"Path escapes output directory: {artifact.path}\",\n            violation_type=\"directory_escape\"\n        )\n\n    # 5. Block symlinks (MVP restriction)\n    if artifact_path.is_symlink():\n        raise ArtifactError(\n            f\"Symlinks not allowed: {artifact.path}\",\n            violation_type=\"symlink\"\n        )\n\n    # Write artifact\n    artifact_path.parent.mkdir(parents=True, exist_ok=True)\n    artifact_path.write_text(content, encoding=\"utf-8\")\n</code></pre></p> <p>Sanitization (<code>artifacts/io.py</code>): <pre><code>def sanitize_filename(filename: str) -&gt; str:\n    \"\"\"Sanitize filename component.\n\n    Removes:\n    - Path separators (/, \\)\n    - Control characters\n    - Leading/trailing dots and underscores\n\n    Replaces with underscore:\n    - Special characters (&lt;, &gt;, :, \", |, ?, *)\n    \"\"\"\n    # Remove path separators\n    filename = filename.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n\n    # Replace special characters\n    filename = re.sub(r'[&lt;&gt;:\"|?*]', \"_\", filename)\n\n    # Remove control characters\n    filename = \"\".join(c for c in filename if ord(c) &gt;= 32)\n\n    # Strip leading/trailing dots and underscores\n    filename = filename.strip(\"._\")\n\n    return filename or \"output\"  # Fallback if empty\n</code></pre></p> <p>What's Blocked: - Absolute paths: <code>/etc/passwd</code>, <code>C:\\Windows\\hosts</code> - Path traversal: <code>../../etc/passwd</code>, <code>..\\..\\..\\windows\\hosts</code> - Symlinks: Any symlink (MVP restriction) - Special characters: <code>&lt;&gt;:\"|?*</code> in filenames</p> <p>What's Allowed: - Relative paths: <code>output.txt</code>, <code>reports/summary.md</code> - Nested directories: <code>analysis/data/results.json</code> - Template variables: <code>{{ spec.name }}-report.txt</code></p> <p>Security Tests (<code>tests/test_executor.py</code>): <pre><code>def test_artifact_blocks_path_traversal():\n    \"\"\"Artifact writing blocks path traversal.\"\"\"\n    artifact = Artifact(path=\"../../etc/passwd\", from_=\"data\")\n    with pytest.raises(ArtifactError, match=\"traversal\"):\n        write_artifact(artifact, \"content\", Path(\"./artifacts\"))\n\ndef test_artifact_blocks_absolute_path():\n    \"\"\"Artifact writing blocks absolute paths.\"\"\"\n    artifact = Artifact(path=\"/etc/passwd\", from_=\"data\")\n    with pytest.raises(ArtifactError, match=\"absolute\"):\n        write_artifact(artifact, \"content\", Path(\"./artifacts\"))\n</code></pre></p>"},{"location":"explanation/security-model/#best-practices_2","title":"Best Practices","text":"<p>\u2705 Safe Artifact Paths: <pre><code>outputs:\n  artifacts:\n    # Simple filename\n    - path: \"output.txt\"\n      from: \"{{ last_response }}\"\n\n    # Nested directory\n    - path: \"reports/{{ spec.name }}.md\"\n      from: \"{{ last_response }}\"\n\n    # Timestamp in filename\n    - path: \"analysis-{{ timestamp }}.json\"\n      from: \"{{ tasks.analysis.response | tojson }}\"\n</code></pre></p> <p>\u274c Unsafe Patterns (will raise ArtifactError): <pre><code># Path traversal\noutputs:\n  artifacts:\n    - path: \"../../etc/passwd\"\n\n# Absolute path\noutputs:\n  artifacts:\n    - path: \"/etc/passwd\"\n\n# Symlink (if exists)\noutputs:\n  artifacts:\n    - path: \"symlink-to-system-file\"\n</code></pre></p>"},{"location":"explanation/security-model/#security-layer-4-tool-allowlisting","title":"Security Layer 4: Tool Allowlisting","text":""},{"location":"explanation/security-model/#risk-arbitrary-code-execution","title":"Risk: Arbitrary Code Execution","text":"<p>Vulnerability: Python tools execute arbitrary callables, enabling: - System command execution (<code>os.system</code>, <code>subprocess.run</code>) - File operations (<code>open</code>, <code>shutil.rmtree</code>) - Network access (<code>socket</code>, <code>urllib</code>) - Dynamic imports (<code>__import__</code>, <code>importlib</code>)</p> <p>Attack Example: <pre><code>tools:\n  python:\n    - callable: \"os.system\"  # Execute arbitrary commands\n</code></pre></p>"},{"location":"explanation/security-model/#mitigation-strict-allowlist-user-consent","title":"Mitigation: Strict Allowlist + User Consent","text":"<p>Allowlisted Callables (<code>capability/checker.py</code>): <pre><code>ALLOWED_PYTHON_CALLABLES = {\n    \"strands_tools.http_request.http_request\",  # HTTP requests (SSRF protection)\n    \"strands_tools.file_read.file_read\",        # File reading (read-only)\n    \"strands_tools.file_write.file_write\",      # File writing (requires consent)\n    \"strands_tools.calculator.calculator\",      # Math calculations (SymPy-based)\n    \"strands_tools.current_time.current_time\",  # Date/time (read-only)\n}\n</code></pre></p> <p>Capability Checking (<code>capability/checker.py</code>): <pre><code>def check_python_tools(spec: Spec) -&gt; list[UnsupportedFeature]:\n    \"\"\"Check if Python tools are in allowlist.\"\"\"\n    issues = []\n\n    for tool in spec.tools.python:\n        callable_path = tool.callable\n        if callable_path not in ALLOWED_PYTHON_CALLABLES:\n            issues.append(UnsupportedFeature(\n                category=\"tools.python\",\n                feature=callable_path,\n                remediation=f\"Use allowlisted tool. Allowed: {ALLOWED_PYTHON_CALLABLES}\",\n                severity=\"high\"\n            ))\n\n    return issues\n</code></pre></p> <p>User Consent for file_write (<code>strands_tools.file_write</code>): <pre><code>def file_write(tool: dict[str, Any], **kwargs: Any) -&gt; dict[str, Any]:\n    \"\"\"Write file with user consent (unless bypassed).\"\"\"\n    tool_input = tool.get(\"input\", {})\n    file_path = tool_input.get(\"file_path\")\n    content = tool_input.get(\"content\")\n\n    # Check bypass flag\n    if not os.environ.get(\"BYPASS_TOOL_CONSENT\"):\n        # Prompt for consent\n        print(f\"File write requested: {file_path}\")\n        print(f\"Content preview: {content[:100]}...\")\n        response = input(\"Allow? (y/N): \")\n\n        if response.lower() != \"y\":\n            return {\n                \"toolUseId\": tool.get(\"toolUseId\"),\n                \"status\": \"error\",\n                \"content\": [{\"text\": \"User denied file write\"}]\n            }\n\n    # Write file\n    Path(file_path).write_text(content)\n    return {\"toolUseId\": tool.get(\"toolUseId\"), \"status\": \"success\", ...}\n</code></pre></p> <p>Bypass for Automation (CLI flag): <pre><code># Interactive mode (default)\nstrands run workflow.yaml\n# Prompts for file_write consent\n\n# CI/CD mode (bypass consent)\nstrands run workflow.yaml --bypass-tool-consent\n# Sets BYPASS_TOOL_CONSENT=true, skips prompts\n</code></pre></p> <p>What's Allowed: - <code>strands_tools.http_request</code> - HTTP requests (subject to SSRF protection) - <code>strands_tools.file_read</code> - Read files (read-only) - <code>strands_tools.file_write</code> - Write files (requires consent) - <code>strands_tools.calculator</code> - Mathematical calculations - <code>strands_tools.current_time</code> - Get current date/time</p> <p>What's Blocked: - <code>os.system</code>, <code>subprocess.run</code> - Command execution - <code>eval</code>, <code>exec</code>, <code>compile</code> - Code evaluation - <code>open</code>, <code>shutil.rmtree</code> - Direct file operations - <code>socket</code>, <code>urllib</code> - Direct network access - Any callable not in allowlist</p> <p>Security Tests (<code>tests/test_capability.py</code>): <pre><code>def test_capability_blocks_disallowed_python_tool():\n    \"\"\"Capability checker blocks disallowed Python callables.\"\"\"\n    spec = create_spec(\n        tools={\"python\": [{\"callable\": \"os.system\"}]}\n    )\n    report = check_capability(spec)\n    assert not report.supported\n    assert any(\"os.system\" in issue.feature for issue in report.issues)\n</code></pre></p>"},{"location":"explanation/security-model/#best-practices_3","title":"Best Practices","text":"<p>\u2705 Safe Tool Usage: <pre><code># HTTP requests\ntools:\n  python:\n    - callable: \"strands_tools.http_request.http_request\"\n\n# File reading\ntools:\n  python:\n    - callable: \"strands_tools.file_read.file_read\"\n</code></pre></p> <p>\u2705 CI/CD with Bypass (after review): <pre><code># Review spec for dangerous tools\ngrep -E \"file_write|system|exec\" workflow.yaml\n\n# Run with bypass only after review\nstrands run workflow.yaml --bypass-tool-consent --force\n</code></pre></p> <p>\u274c Unsafe Patterns (will trigger EX_UNSUPPORTED): <pre><code># Arbitrary code execution\ntools:\n  python:\n    - callable: \"os.system\"\n\n# Direct file operations\ntools:\n  python:\n    - callable: \"open\"\n</code></pre></p>"},{"location":"explanation/security-model/#audit-logging","title":"Audit Logging","text":"<p>All security violations are logged with structured fields for SIEM integration.</p>"},{"location":"explanation/security-model/#log-format","title":"Log Format","text":"<p>JSON Structured Logs (<code>STRANDS_LOG_FORMAT=json</code>): <pre><code>{\n  \"event\": \"http_url_blocked\",\n  \"violation_type\": \"ssrf_attempt\",\n  \"blocked_url\": \"http://169.254.169.254/latest/\",\n  \"matched_pattern\": \"^https?://169\\\\.254\\\\.169\\\\.254.*$\",\n  \"timestamp\": \"2025-11-09T05:03:46Z\",\n  \"level\": \"warning\",\n  \"spec_file\": \"/path/to/workflow.yaml\",\n  \"user\": \"alice\"\n}\n</code></pre></p>"},{"location":"explanation/security-model/#violation-types","title":"Violation Types","text":"Event Violation Type Severity Action <code>template_security_violation</code> <code>unsafe_operation</code> High Block template rendering <code>http_url_blocked</code> <code>ssrf_attempt</code> High Block HTTP executor creation <code>artifact_path_blocked</code> <code>path_traversal</code> High Block artifact write <code>tool_blocked</code> <code>disallowed_callable</code> Critical Exit with EX_UNSUPPORTED"},{"location":"explanation/security-model/#integration-with-siem","title":"Integration with SIEM","text":"<p>Export to CloudWatch Logs (AWS): <pre><code># Configure log group\nexport STRANDS_LOG_GROUP=\"/aws/strands-cli/security\"\n\n# Run with CloudWatch export\nstrands run workflow.yaml --log-cloudwatch\n</code></pre></p> <p>Export to S3 (archival): <pre><code># Configure S3 bucket\nexport STRANDS_LOG_S3_BUCKET=\"security-audit-logs\"\n\n# Run with S3 export\nstrands run workflow.yaml --log-s3\n</code></pre></p> <p>Query with CloudWatch Insights: <pre><code>fields @timestamp, event, violation_type, blocked_url\n| filter event = \"http_url_blocked\"\n| sort @timestamp desc\n| limit 100\n</code></pre></p>"},{"location":"explanation/security-model/#security-best-practices","title":"Security Best Practices","text":""},{"location":"explanation/security-model/#development","title":"Development","text":"<p>\u2705 Test with Restricted Settings: <pre><code># Block all except specific domains\nexport STRANDS_HTTP_ALLOWED_DOMAINS='[\"^http://localhost\", \"^https://httpbin.org\"]'\n\n# Run workflow\nstrands run workflow.yaml\n</code></pre></p> <p>\u2705 Use Interactive Mode for file_write: <pre><code># Default behavior (prompts for consent)\nstrands run workflow.yaml\n</code></pre></p> <p>\u2705 Review Logs for Violations: <pre><code># Enable JSON logging\nexport STRANDS_LOG_FORMAT=json\nexport STRANDS_LOG_LEVEL=WARNING\n\n# Run and filter security events\nstrands run workflow.yaml 2&gt;&amp;1 | jq 'select(.event | contains(\"blocked\"))'\n</code></pre></p>"},{"location":"explanation/security-model/#production","title":"Production","text":"<p>\u2705 Enforce Strict Allowlist: <pre><code># Only allow trusted domains\nexport STRANDS_HTTP_ALLOWED_DOMAINS='[\"^https://api\\\\.openai\\\\.com\", \"^https://api\\\\.anthropic\\\\.com\"]'\n</code></pre></p> <p>\u2705 Add Custom Blocklist: <pre><code># Block internal infrastructure\nexport STRANDS_HTTP_BLOCKED_PATTERNS='[\"^https://.*\\\\.internal\\\\.company\\\\.com\", \"^https://admin\\\\..*\"]'\n</code></pre></p> <p>\u2705 Review Specs Before Execution: <pre><code># Validate schema\nstrands validate untrusted-spec.yaml\n\n# Check for dangerous tools\ngrep -E \"file_write|http_request|os\\\\.system\" untrusted-spec.yaml\n\n# Review template expressions\ngrep -E \"\\\\{\\\\{.*__class__.*\\\\}\\\\}\" untrusted-spec.yaml\n</code></pre></p> <p>\u2705 Use <code>--bypass-tool-consent</code> Only After Review: <pre><code># ONLY for reviewed specs in CI/CD\nstrands run reviewed-spec.yaml --bypass-tool-consent --force\n</code></pre></p> <p>\u274c Never Use <code>--bypass-tool-consent</code> for Untrusted Specs: <pre><code># DANGEROUS: Untrusted spec with consent bypass\nstrands run untrusted-spec.yaml --bypass-tool-consent  # DON'T DO THIS\n</code></pre></p>"},{"location":"explanation/security-model/#cicd","title":"CI/CD","text":"<p>\u2705 Isolated Execution Environment: <pre><code># GitHub Actions example\njobs:\n  run-workflow:\n    runs-on: ubuntu-latest\n    container:\n      image: python:3.12-slim\n      options: --read-only --tmpfs /tmp  # Read-only filesystem\n    steps:\n      - name: Run workflow\n        run: strands run workflow.yaml --bypass-tool-consent\n</code></pre></p> <p>\u2705 Limit Network Access: <pre><code># Docker Compose example\nservices:\n  strands-cli:\n    image: strands-cli:latest\n    networks:\n      - restricted  # Custom network with egress filtering\n    environment:\n      STRANDS_HTTP_ALLOWED_DOMAINS: '[\"^https://api\\\\.openai\\\\.com\"]'\n</code></pre></p> <p>\u2705 Monitor Security Events: <pre><code># GitHub Actions example\n- name: Check for security violations\n  run: |\n    strands run workflow.yaml 2&gt;&amp;1 | tee logs.json\n    if grep -q \"violation_type\" logs.json; then\n      echo \"Security violations detected!\"\n      exit 1\n    fi\n</code></pre></p>"},{"location":"explanation/security-model/#future-enhancements","title":"Future Enhancements","text":""},{"location":"explanation/security-model/#planned-security-features","title":"Planned Security Features","text":"<ol> <li>Content Security Policy for HTTP responses</li> <li>Validate <code>Content-Type</code> headers</li> <li>Enforce size limits</li> <li> <p>Block binary responses (unless expected)</p> </li> <li> <p>MCP Server Sandboxing</p> </li> <li>Isolate MCP processes (chroot, Docker)</li> <li>Allowlist MCP executables</li> <li> <p>Resource limits (CPU, memory, network)</p> </li> <li> <p>Rate Limiting</p> </li> <li>Enforce budget limits (prevent runaway costs)</li> <li>Per-provider rate limits</li> <li> <p>Circuit breaker for failing services</p> </li> <li> <p>Secrets Manager Integration</p> </li> <li>AWS Secrets Manager / SSM support</li> <li>HashiCorp Vault integration</li> <li> <p>Encrypted secrets in specs</p> </li> <li> <p>Python Tool Sandboxing</p> </li> <li>Chroot/jail for file operations</li> <li>Network access restrictions</li> <li> <p>Syscall filtering (seccomp)</p> </li> <li> <p>Symlink Policy Refinement</p> </li> <li>Allow symlinks within <code>output_dir</code> (after validation)</li> <li>Detect symlink loops</li> <li>Prevent time-of-check-time-of-use (TOCTOU) attacks</li> </ol>"},{"location":"explanation/security-model/#summary","title":"Summary","text":"<p>Strands CLI implements defense-in-depth security:</p> <ol> <li>Template Sandboxing: Jinja2 SandboxedEnvironment prevents RCE</li> <li>SSRF Prevention: URL validation blocks localhost, metadata, private IPs</li> <li>Path Security: Multi-layer checks prevent traversal and overwrite</li> <li>Tool Allowlisting: Strict callable restrictions prevent arbitrary code execution</li> <li>Audit Logging: Structured security events for SIEM integration</li> </ol> <p>Security Posture: - \u2705 Threat model: Untrusted workflow specs - \u2705 Attack surface: Templates, HTTP, paths, tools - \u2705 Security controls: Multi-layer validation, sandboxing, allowlisting - \u2705 Audit trail: Structured logging of all violations</p> <p>Best Practices: - Review specs before execution (especially from untrusted sources) - Use allowlist/blocklist environment variables for production - Enable structured logging for security monitoring - Use <code>--bypass-tool-consent</code> only for reviewed specs in CI/CD - Monitor audit logs for security violations</p> <p>Next Steps: See Architecture Overview, Pattern Philosophy, Design Decisions, and Performance Optimizations for more details.</p>"},{"location":"howto/budgets/","title":"How to Manage Budgets","text":"<p>This guide shows you how to configure and use token budgets, time limits, and step limits in Strands workflows to prevent runaway costs and execution.</p>"},{"location":"howto/budgets/#why-budgets-matter","title":"Why Budgets Matter","text":"<p>Without budgets, workflows can: - Consume excessive tokens and incur high costs - Run indefinitely in loops or long chains - Timeout unpredictably without clear limits</p> <p>Budgets provide: - Cost control - Hard limits on token usage - Time bounds - Maximum execution duration - Safety - Prevent infinite loops in graph/evaluator patterns</p>"},{"location":"howto/budgets/#budget-types","title":"Budget Types","text":"<p>Strands supports three types of budgets:</p> <ol> <li>Token Budget (<code>max_tokens</code>) - Total tokens across all LLM calls</li> <li>Time Budget (<code>max_duration_s</code>) - Maximum execution time in seconds</li> <li>Step Budget (<code>max_steps</code>) - Maximum workflow steps/iterations</li> </ol>"},{"location":"howto/budgets/#configuring-budgets","title":"Configuring Budgets","text":""},{"location":"howto/budgets/#runtime-level-budgets","title":"Runtime-Level Budgets","text":"<p>Set global budgets for entire workflow:</p> <pre><code>version: 0\nname: budget-demo\nruntime:\n  provider: openai\n  model_id: gpt-4o-mini\n  budgets:\n    max_tokens: 100000      # 100K token limit\n    max_duration_s: 300     # 5 minute timeout\n    max_steps: 50           # Max 50 steps/iterations\n\nagents:\n  assistant:\n    prompt: \"You are a helpful assistant\"\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: assistant\n        prompt: \"Hello!\"\n</code></pre>"},{"location":"howto/budgets/#pattern-level-budgets","title":"Pattern-Level Budgets","text":"<p>Override budgets for specific patterns:</p> <pre><code>runtime:\n  provider: openai\n  model_id: gpt-4o-mini\n  budgets:\n    max_tokens: 200000  # Global budget\n\npattern:\n  type: evaluator_optimizer\n  config:\n    producer: writer\n    evaluator:\n      agent: critic\n      input: \"Evaluate: {{ draft }}\"\n    accept:\n      min_score: 85\n      max_iters: 3  # Pattern-specific iteration limit\n</code></pre>"},{"location":"howto/budgets/#token-budgets","title":"Token Budgets","text":""},{"location":"howto/budgets/#setting-token-limits","title":"Setting Token Limits","text":"<p>Token budgets are cumulative across all LLM calls:</p> <pre><code>runtime:\n  budgets:\n    max_tokens: 50000  # Total tokens (input + output)\n</code></pre> <p>What counts toward budget: - Input tokens (prompts, context, tool results) - Output tokens (agent responses) - All steps/iterations in the workflow</p> <p>What doesn't count: - Schema validation - Template rendering - Non-LLM tool execution</p>"},{"location":"howto/budgets/#recommended-token-budgets","title":"Recommended Token Budgets","text":"Workflow Type Recommended Budget Reasoning Single-step 10,000 One agent call Short chain (3-5 steps) 50,000 Multiple calls with context Medium workflow (5-10 steps) 100,000 DAG with parallel branches Long research (10+ steps) 200,000 Extended chains with tools Evaluator-optimizer 150,000 Iterative refinement loops Graph with loops 300,000 Conditional branches, iterations"},{"location":"howto/budgets/#example-research-workflow","title":"Example: Research Workflow","text":"<pre><code>runtime:\n  provider: openai\n  model_id: gpt-4o-mini\n  budgets:\n    max_tokens: 100000  # Sufficient for ~10 research steps\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: researcher\n        prompt: \"Research {{ topic }}\"\n\n      - agent_id: researcher\n        prompt: \"Analyze: {{ steps[0].response }}\"\n\n      - agent_id: writer\n        prompt: \"Write report on: {{ steps[1].response }}\"\n</code></pre>"},{"location":"howto/budgets/#time-budgets","title":"Time Budgets","text":""},{"location":"howto/budgets/#setting-time-limits","title":"Setting Time Limits","text":"<p>Time budgets enforce maximum execution duration:</p> <pre><code>runtime:\n  budgets:\n    max_duration_s: 600  # 10 minute timeout\n</code></pre> <p>What counts toward budget: - Total workflow execution time - LLM API calls (including retries) - Tool execution time - Template rendering and processing</p> <p>Timeout behavior: - Workflow stops gracefully at budget exceeded - Partial results returned if available - Exit code indicates budget exceeded</p>"},{"location":"howto/budgets/#recommended-time-budgets","title":"Recommended Time Budgets","text":"Workflow Type Recommended Timeout Reasoning Single-step 30s Quick single call Short chain 120s Few sequential calls Medium workflow 300s Parallel execution Long research 600s Extended processing Tool-heavy 900s External API calls"},{"location":"howto/budgets/#example-api-integration","title":"Example: API Integration","text":"<pre><code>runtime:\n  provider: openai\n  model_id: gpt-4o-mini\n  budgets:\n    max_duration_s: 180  # 3 minutes for API calls\n\ntools:\n  http_executors:\n    - id: github_api\n      base_url: https://api.github.com\n      endpoints:\n        - path: /repos/{owner}/{repo}\n          method: GET\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: researcher\n        prompt: \"Fetch repo data for tensorflow/tensorflow\"\n</code></pre>"},{"location":"howto/budgets/#step-budgets","title":"Step Budgets","text":""},{"location":"howto/budgets/#setting-step-limits","title":"Setting Step Limits","text":"<p>Step budgets limit workflow iterations:</p> <pre><code>runtime:\n  budgets:\n    max_steps: 100  # Maximum 100 steps/iterations\n</code></pre> <p>What counts as a step: - Chain: Each step in <code>steps</code> array - Workflow: Each task execution - Parallel: Each branch step - Routing: Classifier + all route steps - Evaluator-Optimizer: Each iteration (producer + evaluator) - Graph: Each node execution - Orchestrator-Workers: Each worker task + orchestrator rounds</p>"},{"location":"howto/budgets/#example-graph-with-loops","title":"Example: Graph with Loops","text":"<pre><code>runtime:\n  provider: openai\n  model_id: gpt-4o-mini\n  budgets:\n    max_steps: 20  # Prevent infinite loops\n\npattern:\n  type: graph\n  config:\n    max_iterations: 10  # Additional graph-specific limit\n    nodes:\n      analyze:\n        agent: analyst\n        input: \"Analyze {{ input }}\"\n\n      decide:\n        agent: decider\n        input: \"Continue? {{ nodes.analyze.response }}\"\n\n    edges:\n      - from: START\n        to: analyze\n\n      - from: analyze\n        to: decide\n\n      - from: decide\n        to: analyze\n        condition: \"nodes.decide.response contains 'continue'\"\n\n      - from: decide\n        to: END\n        condition: \"nodes.decide.response contains 'done'\"\n</code></pre>"},{"location":"howto/budgets/#budget-enforcement","title":"Budget Enforcement","text":""},{"location":"howto/budgets/#how-budgets-are-enforced","title":"How Budgets Are Enforced","text":"<p>Budgets are checked: - Before each step: Check if budget already exceeded - After each LLM call: Update cumulative usage - At pattern boundaries: Validate within pattern limits</p>"},{"location":"howto/budgets/#budget-exceeded-behavior","title":"Budget Exceeded Behavior","text":"<p>When budget exceeded: 1. Workflow stops immediately 2. Partial results returned (if any) 3. Error message indicates which budget exceeded 4. Exit code: <code>EX_RUNTIME</code> (10)</p>"},{"location":"howto/budgets/#example-error-messages","title":"Example Error Messages","text":"<p>Token budget: <pre><code>Error: Token budget exceeded\n  Used: 105,432 tokens\n  Limit: 100,000 tokens\n  Overage: 5,432 tokens\n</code></pre></p> <p>Time budget: <pre><code>Error: Time budget exceeded\n  Duration: 325s\n  Limit: 300s\n  Overage: 25s\n</code></pre></p> <p>Step budget: <pre><code>Error: Step budget exceeded\n  Steps: 52\n  Limit: 50\n  Overage: 2 steps\n</code></pre></p>"},{"location":"howto/budgets/#pattern-specific-considerations","title":"Pattern-Specific Considerations","text":""},{"location":"howto/budgets/#chain-pattern","title":"Chain Pattern","text":"<pre><code>runtime:\n  budgets:\n    max_steps: 10  # Limits total chain steps\n\npattern:\n  type: chain\n  config:\n    steps:  # Each step counts toward budget\n      - agent_id: step1\n        prompt: \"...\"\n      - agent_id: step2\n        prompt: \"...\"\n</code></pre>"},{"location":"howto/budgets/#evaluator-optimizer-pattern","title":"Evaluator-Optimizer Pattern","text":"<pre><code>runtime:\n  budgets:\n    max_steps: 20  # Each iteration = 2 steps (producer + evaluator)\n\npattern:\n  type: evaluator_optimizer\n  config:\n    accept:\n      max_iters: 5  # Pattern-specific iteration limit\n</code></pre> <p>Budget = <code>max_iters * 2</code> (producer + evaluator per iteration)</p>"},{"location":"howto/budgets/#graph-pattern","title":"Graph Pattern","text":"<pre><code>runtime:\n  budgets:\n    max_steps: 50  # Each node execution counts\n\npattern:\n  type: graph\n  config:\n    max_iterations: 20  # Additional graph limit\n</code></pre> <p>Effective limit = <code>min(max_steps, max_iterations)</code></p>"},{"location":"howto/budgets/#orchestrator-workers-pattern","title":"Orchestrator-Workers Pattern","text":"<pre><code>runtime:\n  budgets:\n    max_steps: 100\n\npattern:\n  type: orchestrator_workers\n  config:\n    orchestrator:\n      limits:\n        max_workers: 5\n        max_rounds: 3\n</code></pre> <p>Budget = orchestrator steps + (workers * rounds)</p>"},{"location":"howto/budgets/#best-practices","title":"Best Practices","text":""},{"location":"howto/budgets/#1-start-conservative","title":"1. Start Conservative","text":"<p>Begin with tight budgets during development:</p> <pre><code>runtime:\n  budgets:\n    max_tokens: 10000\n    max_duration_s: 60\n    max_steps: 10\n</code></pre> <p>Increase as needed based on actual usage.</p>"},{"location":"howto/budgets/#2-monitor-usage","title":"2. Monitor Usage","text":"<p>Enable debug mode to see budget consumption:</p> <pre><code>strands run workflow.yaml --debug\n</code></pre> <p>Debug logs show: - Tokens per step - Cumulative usage - Time elapsed - Steps executed</p>"},{"location":"howto/budgets/#3-use-multiple-budgets","title":"3. Use Multiple Budgets","text":"<p>Combine budgets for comprehensive control:</p> <pre><code>runtime:\n  budgets:\n    max_tokens: 100000   # Cost control\n    max_duration_s: 300  # Time limit\n    max_steps: 50        # Loop prevention\n</code></pre> <p>All budgets enforced; first exceeded stops workflow.</p>"},{"location":"howto/budgets/#4-set-pattern-specific-limits","title":"4. Set Pattern-Specific Limits","text":"<pre><code>pattern:\n  type: evaluator_optimizer\n  config:\n    accept:\n      max_iters: 3  # Specific to pattern\n</code></pre> <p>Use pattern config for fine-grained control.</p>"},{"location":"howto/budgets/#5-production-vs-development","title":"5. Production vs Development","text":"<p>Development: <pre><code>runtime:\n  budgets:\n    max_tokens: 50000\n    max_duration_s: 120\n</code></pre></p> <p>Production: <pre><code>runtime:\n  budgets:\n    max_tokens: 200000\n    max_duration_s: 600\n    max_steps: 100\n</code></pre></p>"},{"location":"howto/budgets/#calculating-required-budgets","title":"Calculating Required Budgets","text":""},{"location":"howto/budgets/#token-estimation","title":"Token Estimation","text":"<p>Estimate tokens needed:</p> <ol> <li>Count steps: How many LLM calls?</li> <li>Estimate per-step: ~2,000-5,000 tokens per call (input + output)</li> <li>Add buffer: Multiply by 1.5-2x for safety</li> <li>Add context growth: Later steps have more context</li> </ol> <p>Example: - 10-step chain - ~3,000 tokens/step average - Context growth: +500 tokens/step - Total: <code>10 * 3000 + (10 * 500) = 35,000 tokens</code> - With 2x buffer: <code>70,000 tokens</code></p>"},{"location":"howto/budgets/#time-estimation","title":"Time Estimation","text":"<p>Estimate duration needed:</p> <ol> <li>LLM latency: ~2-5s per call</li> <li>Tool execution: ~1-10s per tool call</li> <li>Network latency: ~0.5-2s overhead</li> <li>Add buffer: 2-3x for retries and variance</li> </ol> <p>Example: - 5 LLM calls * 3s = 15s - 2 API calls * 5s = 10s - Total: 25s - With 3x buffer: 75s</p>"},{"location":"howto/budgets/#troubleshooting","title":"Troubleshooting","text":""},{"location":"howto/budgets/#budget-exceeded-too-early","title":"Budget Exceeded Too Early","text":"<p>Problem: Workflow hits budget before completing</p> <p>Solutions: 1. Increase budget: <code>max_tokens: 200000</code> 2. Reduce context: Use compaction 3. Simplify prompts: Shorter instructions 4. Use cheaper model: <code>gpt-4o-mini</code> instead of <code>gpt-4o</code></p>"},{"location":"howto/budgets/#budget-never-reached","title":"Budget Never Reached","text":"<p>Problem: Budget set too high, wasting potential</p> <p>Solutions: 1. Review actual usage in debug logs 2. Reduce budget to 1.5x actual usage 3. Set appropriate limits per workflow type</p>"},{"location":"howto/budgets/#infinite-loop-detection","title":"Infinite Loop Detection","text":"<p>Problem: Graph or evaluator pattern loops forever</p> <p>Solution: Set strict step limit:</p> <pre><code>runtime:\n  budgets:\n    max_steps: 20  # Force termination\n\npattern:\n  type: graph\n  config:\n    max_iterations: 10\n</code></pre>"},{"location":"howto/budgets/#example-complete-budget-configuration","title":"Example: Complete Budget Configuration","text":"<pre><code>version: 0\nname: production-workflow\ndescription: Demonstrates complete budget management\n\nruntime:\n  provider: openai\n  model_id: gpt-4o-mini\n\n  # Comprehensive budget controls\n  budgets:\n    max_tokens: 150000      # ~15-20 agent calls\n    max_duration_s: 600     # 10 minute timeout\n    max_steps: 30           # Max 30 workflow steps\n\n  # Retry strategy\n  failure_policy:\n    retries: 2\n    backoff: exponential\n\nagents:\n  researcher:\n    prompt: \"You research topics thoroughly\"\n\n  writer:\n    prompt: \"You write clear reports\"\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: researcher\n        prompt: \"Research {{ topic }}\"\n\n      - agent_id: researcher\n        prompt: \"Deep dive: {{ steps[0].response }}\"\n\n      - agent_id: writer\n        prompt: \"Write report: {{ steps[1].response }}\"\n\ninputs:\n  topic:\n    type: string\n    default: \"quantum computing\"\n</code></pre> <p>Run with monitoring:</p> <pre><code>strands run production-workflow.yaml --debug --verbose\n</code></pre>"},{"location":"howto/budgets/#see-also","title":"See Also","text":"<ul> <li>Context Management - Optimize token usage with compaction</li> <li>Schema Reference - Complete runtime options</li> <li>Telemetry - Monitor budget consumption</li> </ul>"},{"location":"howto/context-management/","title":"How to Manage Context","text":"<p>This guide shows you how to manage conversation context in Strands workflows using presets, notes, JIT tools, and context compaction.</p>"},{"location":"howto/context-management/#understanding-context-management","title":"Understanding Context Management","text":"<p>Context management controls how much conversation history agents retain and how efficiently that memory is used. Without management, long workflows can:</p> <ul> <li>Exceed model context limits</li> <li>Incur excessive costs from repeated long contexts</li> <li>Lose important information when history is truncated</li> </ul> <p>Strands provides four context management features:</p> <ol> <li>Presets - Pre-configured settings for common scenarios</li> <li>Compaction - Automatic summarization when context grows too large</li> <li>Notes - Persistent structured memory across workflow steps</li> <li>JIT Retrieval - On-demand tools to fetch specific information</li> </ol>"},{"location":"howto/context-management/#using-presets","title":"Using Presets","text":"<p>Presets provide battle-tested configurations optimized for different workflow types.</p>"},{"location":"howto/context-management/#available-presets","title":"Available Presets","text":"Preset Best For Compaction Notes Max Context <code>minimal</code> Short workflows (1-3 steps) Disabled No Full <code>balanced</code> Most workflows (3-10 steps) At 100K tokens No Medium <code>long_run</code> Research, multi-step (10+ steps) At 80K tokens Yes (20 notes) Large <code>interactive</code> Chat, conversational At 50K tokens No Moderate"},{"location":"howto/context-management/#applying-a-preset","title":"Applying a Preset","text":"<pre><code>runtime:\n  provider: openai\n  model_id: gpt-4o-mini\n  preset: balanced  # Automatic context management\n</code></pre> <p>That's it! The preset configures: - When to trigger compaction - How much context to preserve - What gets summarized vs. kept verbatim</p>"},{"location":"howto/context-management/#preset-details","title":"Preset Details","text":""},{"location":"howto/context-management/#minimal","title":"Minimal","text":"<pre><code># Automatically configured when preset: minimal\ncontext_policy:\n  compaction:\n    enabled: false\n</code></pre> <p>Use for: - Simple single-agent tasks - When you want full control - Testing and development</p>"},{"location":"howto/context-management/#balanced-recommended","title":"Balanced (Recommended)","text":"<pre><code># Automatically configured when preset: balanced\ncontext_policy:\n  compaction:\n    enabled: true\n    when_tokens_over: 100000\n    summary_ratio: 0.35\n    preserve_recent_messages: 12\n</code></pre> <p>Use for: - General-purpose workflows - 3-10 step chains - Moderate context requirements</p>"},{"location":"howto/context-management/#long-run","title":"Long Run","text":"<pre><code># Automatically configured when preset: long_run\ncontext_policy:\n  compaction:\n    enabled: true\n    when_tokens_over: 80000\n    summary_ratio: 0.40\n    preserve_recent_messages: 20\n  notes:\n    file: artifacts/notes.md\n    include_last: 20\n    format: markdown\n  retrieval:\n    jit_tools:\n      - grep\n      - search\n      - head\n      - tail\n</code></pre> <p>Use for: - Research workflows - Multi-agent collaboration - Long-running processes - Cross-step continuity</p>"},{"location":"howto/context-management/#interactive","title":"Interactive","text":"<pre><code># Automatically configured when preset: interactive\ncontext_policy:\n  compaction:\n    enabled: true\n    when_tokens_over: 50000\n    summary_ratio: 0.30\n    preserve_recent_messages: 16\n</code></pre> <p>Use for: - Chat interfaces - Conversational agents - Frequent exchanges</p>"},{"location":"howto/context-management/#custom-context-policies","title":"Custom Context Policies","text":"<p>For fine-grained control, configure <code>context_policy</code> directly:</p> <pre><code>runtime:\n  provider: openai\n  model_id: gpt-4o-mini\n\ncontext_policy:\n  compaction:\n    enabled: true\n    when_tokens_over: 80000\n    summary_ratio: 0.35\n    preserve_recent_messages: 15\n    summarization_model: gpt-4o-mini  # Optional: cheaper model for summaries\n\n  notes:\n    file: ./artifacts/workflow-notes.md\n    include_last: 10\n    format: markdown\n\n  retrieval:\n    jit_tools:\n      - grep\n      - head\n      - tail\n</code></pre>"},{"location":"howto/context-management/#compaction-configuration","title":"Compaction Configuration","text":"<p>Control when and how context is summarized:</p> <pre><code>context_policy:\n  compaction:\n    enabled: true                     # Turn on automatic compaction\n    when_tokens_over: 100000          # Trigger at this token count\n    summary_ratio: 0.35               # Keep 35% of content as summary\n    preserve_recent_messages: 12      # Always keep last 12 messages verbatim\n    summarization_model: gpt-4o-mini  # Optional: use cheaper model\n</code></pre> <p>How it works:</p> <ol> <li>Workflow tracks cumulative tokens after each step</li> <li>When tokens exceed <code>when_tokens_over</code>, compaction triggers</li> <li>Older messages are summarized (except tool calls, which are preserved)</li> <li>Recent messages (controlled by <code>preserve_recent_messages</code>) are kept intact</li> <li>Summary replaces older messages, reducing total tokens by ~65%</li> </ol> <p>Token calculation example:</p> <ul> <li>Original context: 120,000 tokens</li> <li>Compaction triggered at: 100,000</li> <li>After compaction: ~78,000 tokens</li> <li>Summary of old messages: ~42,000 (35% of 120K)</li> <li>Recent messages preserved: ~36,000</li> </ul>"},{"location":"howto/context-management/#using-a-cheaper-summarization-model","title":"Using a Cheaper Summarization Model","text":"<p>Save costs by using a smaller model for summarization:</p> <pre><code>context_policy:\n  compaction:\n    enabled: true\n    when_tokens_over: 80000\n    summarization_model: gpt-4o-mini  # Use mini for summaries, main model for work\n</code></pre> <p>This is especially valuable when your main workflow uses expensive models like GPT-4o or Claude Opus.</p>"},{"location":"howto/context-management/#structured-notes","title":"Structured Notes","text":"<p>Notes provide persistent memory across workflow steps, stored in a Markdown file with timestamps and agent attribution.</p>"},{"location":"howto/context-management/#basic-configuration","title":"Basic Configuration","text":"<pre><code>context_policy:\n  notes:\n    file: ./artifacts/workflow-notes.md\n    include_last: 10\n    format: markdown\n</code></pre>"},{"location":"howto/context-management/#how-notes-work","title":"How Notes Work","text":"<p>After each step, Strands appends a note entry:</p> <pre><code>## [2025-11-09T14:32:00Z] \u2014 Agent: researcher (Step 1)\n- Input: Analyze customer reviews for sentiment\n- Tools used: http_request, file_read\n- Outcome: Positive sentiment (0.82 score), 247 reviews analyzed\n</code></pre> <p>On subsequent steps, the last N notes are injected into agent context:</p> <pre><code>System: Previous Workflow Steps\n[Last 10 note entries appear here]\n\nUser: [Current step prompt]\n</code></pre>"},{"location":"howto/context-management/#example-workflow-with-notes","title":"Example Workflow with Notes","text":"<pre><code>version: 0\nname: research-with-memory\nruntime:\n  provider: openai\n  model_id: gpt-4o-mini\n\ncontext_policy:\n  notes:\n    file: ./artifacts/research-notes.md\n    include_last: 5\n\nagents:\n  researcher:\n    prompt: |\n      You are a research assistant. Analyze the given topic.\n      Review \"Previous Workflow Steps\" to avoid repeating work.\n\n  synthesizer:\n    prompt: |\n      You synthesize findings from research.\n      Use \"Previous Workflow Steps\" to see what was already discovered.\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent: researcher\n        input: \"Research {{ topic }}\"\n\n      - agent: researcher\n        input: \"Find additional sources on {{ topic }}\"\n\n      - agent: synthesizer\n        input: \"Synthesize findings from previous research\"\n\ninputs:\n  values:\n    topic: \"AI ethics in healthcare\"\n</code></pre>"},{"location":"howto/context-management/#notes-across-sessions","title":"Notes Across Sessions","text":"<p>Notes persist to disk, enabling multi-session workflows:</p> <p>Session 1: <pre><code>strands run research.yaml --var topic=\"climate change\"\n# Creates artifacts/research-notes.md with findings\n</code></pre></p> <p>Session 2 (days later): <pre><code>strands run research.yaml --var topic=\"renewable energy\"\n# Loads previous notes, maintaining continuity\n</code></pre></p>"},{"location":"howto/context-management/#notes-file-format","title":"Notes File Format","text":"<p>The notes file is human-readable Markdown:</p> <pre><code>## [2025-11-09T10:15:00Z] \u2014 Agent: researcher (Step 1)\n- Input: Research climate change impacts\n- Tools used: None\n- Outcome: Identified 5 major impact areas: sea level, temperature, ecosystems, agriculture, health\n\n## [2025-11-09T10:16:23Z] \u2014 Agent: researcher (Step 2)\n- Input: Find additional sources on climate change\n- Tools used: http_request\n- Outcome: Retrieved 12 peer-reviewed papers from nature.com, science.org\n\n## [2025-11-09T10:17:45Z] \u2014 Agent: synthesizer (Step 3)\n- Input: Synthesize findings from previous research\n- Tools used: None\n- Outcome: Created comprehensive synthesis covering all 5 impact areas with citations\n</code></pre> <p>You can review this file to understand what the workflow accomplished.</p>"},{"location":"howto/context-management/#jit-retrieval-tools","title":"JIT Retrieval Tools","text":"<p>JIT (Just-In-Time) tools let agents fetch specific information on demand instead of loading everything into context upfront.</p>"},{"location":"howto/context-management/#configuration","title":"Configuration","text":"<pre><code>context_policy:\n  retrieval:\n    jit_tools:\n      - grep      # Search files for patterns\n      - search    # Full-text search\n      - head      # Read start of files\n      - tail      # Read end of files\n</code></pre>"},{"location":"howto/context-management/#how-jit-tools-work","title":"How JIT Tools Work","text":"<p>Instead of: <pre><code># Bad: Load entire codebase into context\nagents:\n  analyst:\n    prompt: |\n      Here are all 50,000 lines of code:\n      {{ entire_codebase }}\n\n      Now find the bug.\n</code></pre></p> <p>Do this: <pre><code># Good: Agent uses grep to find relevant code\nagents:\n  analyst:\n    prompt: |\n      You can search the codebase using the grep tool.\n      Find code related to authentication errors.\n\ncontext_policy:\n  retrieval:\n    jit_tools:\n      - grep\n</code></pre></p> <p>The agent will invoke <code>grep</code> with search patterns as needed:</p> <pre><code>Agent: [Uses grep tool to search for \"authentication\"]\ngrep result: Found 3 files with \"authentication\"\nAgent: [Reads specific files]\nAgent: Found the bug in auth.py line 42\n</code></pre>"},{"location":"howto/context-management/#available-jit-tools","title":"Available JIT Tools","text":"Tool Purpose Example <code>grep</code> Search files for text patterns Find all TODO comments <code>search</code> Full-text search in files Locate specific function definitions <code>head</code> Read first N lines of file Check file headers <code>tail</code> Read last N lines of file View log file endings"},{"location":"howto/context-management/#example-code-analysis-with-jit","title":"Example: Code Analysis with JIT","text":"<pre><code>version: 0\nname: code-analyzer\nruntime:\n  provider: openai\n  model_id: gpt-4o-mini\n\ncontext_policy:\n  retrieval:\n    jit_tools:\n      - grep\n      - head\n      - tail\n\nagents:\n  analyzer:\n    prompt: |\n      You analyze code for bugs and improvements.\n      Use the available tools to search and inspect files:\n      - grep: Search for patterns\n      - head: Check file starts\n      - tail: Check file ends\n\n      Do NOT try to read entire files into context.\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent: analyzer\n        input: \"Find potential security issues in the authentication code\"\n</code></pre>"},{"location":"howto/context-management/#combining-features","title":"Combining Features","text":"<p>The most powerful context management combines all features:</p> <pre><code>version: 0\nname: comprehensive-research\nruntime:\n  provider: openai\n  model_id: gpt-4o-mini\n  preset: long_run  # Enables compaction, notes, and JIT tools\n\nagents:\n  researcher:\n    prompt: |\n      You are a research assistant with access to:\n      1. Previous workflow steps (from notes)\n      2. Search tools (grep, head, tail)\n      3. Summarized conversation history (via compaction)\n\n      Use these efficiently:\n      - Check notes to avoid repeating work\n      - Use grep to find specific information\n      - Rely on summarized context for broad understanding\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent: researcher\n        input: \"Phase 1: Research {{ topic }}\"\n\n      - agent: researcher\n        input: \"Phase 2: Deep dive into findings from Phase 1\"\n\n      - agent: researcher\n        input: \"Phase 3: Synthesize comprehensive report\"\n</code></pre> <p>This workflow: - Uses <code>long_run</code> preset for optimal long-running performance - Maintains notes for cross-step continuity - Compacts context automatically when it exceeds 80K tokens - Provides JIT tools for targeted information retrieval - Preserves recent messages for immediate context</p>"},{"location":"howto/context-management/#best-practices","title":"Best Practices","text":""},{"location":"howto/context-management/#1-choose-the-right-preset","title":"1. Choose the Right Preset","text":"<p>Start with presets, customize only when needed:</p> <pre><code># Good: Use preset for common case\nruntime:\n  preset: balanced\n\n# Only customize if you have specific requirements\ncontext_policy:\n  compaction:\n    when_tokens_over: 120000  # Custom threshold\n</code></pre>"},{"location":"howto/context-management/#2-monitor-token-usage","title":"2. Monitor Token Usage","text":"<p>Use debug mode to see when compaction triggers:</p> <pre><code>strands run workflow.yaml --debug\n</code></pre> <p>Look for log entries: <pre><code>context_compaction_triggered: tokens=103450 threshold=100000\ncontext_compacted: before=103450 after=68230 reduction=34%\n</code></pre></p>"},{"location":"howto/context-management/#3-set-appropriate-thresholds","title":"3. Set Appropriate Thresholds","text":"<p>Balance cost vs. information retention:</p> <ul> <li>Conservative (keep more context): <code>when_tokens_over: 120000</code></li> <li>Aggressive (save costs): <code>when_tokens_over: 60000</code></li> <li>Balanced: <code>when_tokens_over: 100000</code> (default)</li> </ul>"},{"location":"howto/context-management/#4-use-notes-for-critical-information","title":"4. Use Notes for Critical Information","text":"<p>Notes are never compacted, making them ideal for:</p> <ul> <li>Key decisions and their rationale</li> <li>Important findings that must persist</li> <li>Cross-step dependencies</li> <li>Session-spanning workflows</li> </ul>"},{"location":"howto/context-management/#5-combine-with-budgets","title":"5. Combine with Budgets","text":"<p>Prevent runaway costs:</p> <pre><code>runtime:\n  preset: long_run\n  budgets:\n    max_tokens: 200000  # Hard limit across entire workflow\n\ncontext_policy:\n  compaction:\n    when_tokens_over: 100000  # Compact at 50% of budget\n</code></pre>"},{"location":"howto/context-management/#troubleshooting","title":"Troubleshooting","text":""},{"location":"howto/context-management/#context-still-exceeds-model-limits","title":"Context Still Exceeds Model Limits","text":"<p>Symptom: Errors about context window exceeded</p> <p>Solutions:</p> <ol> <li> <p>Lower <code>when_tokens_over</code> threshold:    <pre><code>context_policy:\n  compaction:\n    when_tokens_over: 60000  # More aggressive compaction\n</code></pre></p> </li> <li> <p>Increase <code>summary_ratio</code> (more aggressive summarization):    <pre><code>context_policy:\n  compaction:\n    summary_ratio: 0.25  # Keep only 25% (was 35%)\n</code></pre></p> </li> <li> <p>Reduce <code>preserve_recent_messages</code>:    <pre><code>context_policy:\n  compaction:\n    preserve_recent_messages: 8  # Keep fewer recent messages\n</code></pre></p> </li> </ol>"},{"location":"howto/context-management/#important-information-lost-in-summaries","title":"Important Information Lost in Summaries","text":"<p>Symptom: Agent \"forgets\" critical details from earlier steps</p> <p>Solutions:</p> <ol> <li> <p>Increase <code>preserve_recent_messages</code>:    <pre><code>context_policy:\n  compaction:\n    preserve_recent_messages: 20  # Keep more verbatim\n</code></pre></p> </li> <li> <p>Use notes for critical information:    <pre><code>context_policy:\n  notes:\n    file: ./artifacts/notes.md\n    include_last: 15  # More note context\n</code></pre></p> </li> <li> <p>Raise compaction threshold:    <pre><code>context_policy:\n  compaction:\n    when_tokens_over: 120000  # Delay compaction\n</code></pre></p> </li> </ol>"},{"location":"howto/context-management/#notes-file-growing-too-large","title":"Notes File Growing Too Large","text":"<p>Symptom: Notes file becomes difficult to read or parse</p> <p>Solutions:</p> <ol> <li> <p>Reduce <code>include_last</code>:    <pre><code>context_policy:\n  notes:\n    include_last: 5  # Only inject last 5 notes\n</code></pre></p> </li> <li> <p>Archive old notes between major workflow phases:    <pre><code>mv artifacts/notes.md artifacts/notes-archive-2025-11-09.md\n# Start fresh notes file\n</code></pre></p> </li> </ol>"},{"location":"howto/context-management/#compaction-happening-too-often","title":"Compaction Happening Too Often","text":"<p>Symptom: Excessive compaction in short workflows</p> <p>Solutions:</p> <ol> <li> <p>Use <code>minimal</code> or <code>balanced</code> preset instead of <code>long_run</code>:    <pre><code>runtime:\n  preset: balanced  # Higher threshold\n</code></pre></p> </li> <li> <p>Increase threshold:    <pre><code>context_policy:\n  compaction:\n    when_tokens_over: 150000  # Less frequent compaction\n</code></pre></p> </li> </ol>"},{"location":"howto/context-management/#see-also","title":"See Also","text":"<ul> <li>Budgets - Token and time limits</li> <li>Running Workflows - Execution options</li> <li>Telemetry - Monitoring context usage</li> </ul>"},{"location":"howto/develop-tools/","title":"Native Tools Development Guide","text":"<p>This guide explains how to develop native tools for the Strands CLI using the registry-based auto-discovery system.</p>"},{"location":"howto/develop-tools/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Architecture Overview</li> <li>Your First Tool: Echo</li> <li>TOOL_SPEC Format</li> <li>ToolResult Contract</li> <li>Advanced Example: python_exec</li> <li>Testing Your Tool</li> <li>Using Tools in Workflows</li> <li>Registry Mechanics</li> </ol>"},{"location":"howto/develop-tools/#architecture-overview","title":"Architecture Overview","text":"<p>The Strands CLI uses a registry-based auto-discovery system for native tools. Tools are automatically discovered and registered at runtime without manual configuration.</p>"},{"location":"howto/develop-tools/#key-components","title":"Key Components","text":"<ul> <li>Tool Modules: Python files in <code>src/strands_cli/tools/</code> that export <code>TOOL_SPEC</code></li> <li>Registry: <code>src/strands_cli/tools/registry.py</code> - scans and registers tools on first import</li> <li>Capability Checker: <code>src/strands_cli/capability/checker.py</code> - validates tool usage against allowlist</li> <li>Tool Adapter: <code>src/strands_cli/runtime/tools.py</code> - loads and executes tools during workflow runs</li> </ul>"},{"location":"howto/develop-tools/#auto-discovery-flow","title":"Auto-Discovery Flow","text":"<pre><code>1. CLI starts \u2192 imports strands_cli.tools\n2. ToolRegistry.__new__() \u2192 singleton instantiation\n3. _discover_tools() \u2192 scans src/strands_cli/tools/*.py\n4. For each .py file:\n   - Import module\n   - Check for TOOL_SPEC export\n   - Validate TOOL_SPEC.name exists\n   - Register ToolInfo(id, module_path, description)\n5. Tools available via get_registry().list_all()\n</code></pre>"},{"location":"howto/develop-tools/#directory-structure","title":"Directory Structure","text":"<pre><code>src/strands_cli/tools/\n\u251c\u2500\u2500 __init__.py           # Exports get_registry()\n\u251c\u2500\u2500 registry.py           # Auto-discovery logic\n\u2514\u2500\u2500 python_exec.py        # Example native tool\n</code></pre>"},{"location":"howto/develop-tools/#your-first-tool-echo","title":"Your First Tool: Echo","text":"<p>Let's build a simple <code>echo</code> tool that returns the input message unchanged.</p>"},{"location":"howto/develop-tools/#step-1-create-the-tool-module","title":"Step 1: Create the Tool Module","text":"<p>Create <code>src/strands_cli/tools/echo.py</code>:</p> <pre><code>\"\"\"Echo tool - returns input message unchanged.\n\nSimple example demonstrating the minimal native tool pattern.\n\"\"\"\n\nfrom typing import Any\n\n\n# Tool Specification (required for auto-discovery)\nTOOL_SPEC = {\n    \"name\": \"echo\",\n    \"description\": \"Returns the input message unchanged\",\n    \"inputSchema\": {\n        \"json\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"message\": {\n                    \"type\": \"string\",\n                    \"description\": \"Message to echo back\"\n                }\n            },\n            \"required\": [\"message\"]\n        }\n    }\n}\n\n\ndef echo(tool: dict[str, Any], **kwargs: Any) -&gt; dict[str, Any]:\n    \"\"\"Echo tool implementation.\n\n    Args:\n        tool: Tool invocation object with:\n            - toolUseId: Unique identifier for this invocation\n            - input: Dict containing the input parameters\n        **kwargs: Additional arguments (unused but required for signature)\n\n    Returns:\n        ToolResult dict with:\n            - toolUseId: Echo back the invocation ID\n            - status: \"success\" or \"error\"\n            - content: List of content blocks (text or other formats)\n    \"\"\"\n    tool_use_id = tool.get(\"toolUseId\", \"\")\n    tool_input = tool.get(\"input\", {})\n    message = tool_input.get(\"message\", \"\")\n\n    if not message:\n        return {\n            \"toolUseId\": tool_use_id,\n            \"status\": \"error\",\n            \"content\": [{\"text\": \"No message provided\"}]\n        }\n\n    return {\n        \"toolUseId\": tool_use_id,\n        \"status\": \"success\",\n        \"content\": [{\"text\": message}]\n    }\n</code></pre>"},{"location":"howto/develop-tools/#step-2-verify-auto-discovery","title":"Step 2: Verify Auto-Discovery","text":"<p>The tool is automatically discovered when the registry initializes. Verify it works:</p> <pre><code>uv run python -c \"from strands_cli.tools import get_registry; print([t.id for t in get_registry().list_all()])\"\n# Should output: ['python_exec', 'echo']\n</code></pre>"},{"location":"howto/develop-tools/#step-3-use-in-a-workflow","title":"Step 3: Use in a Workflow","text":"<p>Create <code>examples/echo-demo.yaml</code>:</p> <pre><code>version: 0\nname: echo-demo\ndescription: Test the echo native tool\n\nruntime:\n  provider: ollama\n  model_id: llama3.2:3b\n  host: http://localhost:11434\n\nagents:\n  assistant:\n    prompt: |\n      You are a helpful assistant. When asked to echo a message,\n      use the echo tool to return it unchanged.\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent: assistant\n        input: \"Echo this message: Hello, World!\"\n\ntools:\n  python:\n    - echo  # Short ID format (auto-resolved by registry)\n\noutputs:\n  artifacts:\n    - path: ./echo-result.txt\n      from: \"{{ last_response }}\"\n</code></pre> <p>Run it:</p> <pre><code>uv run strands run examples/echo-demo.yaml --force\n</code></pre>"},{"location":"howto/develop-tools/#tool_spec-format","title":"TOOL_SPEC Format","text":"<p>The <code>TOOL_SPEC</code> dictionary follows the Strands SDK module-based pattern and must contain:</p>"},{"location":"howto/develop-tools/#required-fields","title":"Required Fields","text":"<pre><code>TOOL_SPEC = {\n    \"name\": str,           # Tool identifier (must match function name)\n    \"description\": str,    # Human-readable description\n    \"inputSchema\": dict    # JSON Schema defining input parameters\n}\n</code></pre>"},{"location":"howto/develop-tools/#input-schema-structure","title":"Input Schema Structure","text":"<p>The <code>inputSchema</code> must follow this format:</p> <pre><code>\"inputSchema\": {\n    \"json\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"param_name\": {\n                \"type\": \"string|number|integer|boolean|array|object\",\n                \"description\": \"Parameter description\",\n                # Optional:\n                \"default\": value,\n                \"enum\": [allowed_values],\n                \"minimum\": number,\n                \"maximum\": number,\n                \"items\": {...}  # For array types\n            }\n        },\n        \"required\": [\"param1\", \"param2\"]  # List of required parameter names\n    }\n}\n</code></pre>"},{"location":"howto/develop-tools/#complete-example","title":"Complete Example","text":"<pre><code>TOOL_SPEC = {\n    \"name\": \"calculator\",\n    \"description\": \"Perform arithmetic calculations\",\n    \"inputSchema\": {\n        \"json\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"operation\": {\n                    \"type\": \"string\",\n                    \"description\": \"Arithmetic operation to perform\",\n                    \"enum\": [\"add\", \"subtract\", \"multiply\", \"divide\"]\n                },\n                \"a\": {\n                    \"type\": \"number\",\n                    \"description\": \"First operand\"\n                },\n                \"b\": {\n                    \"type\": \"number\",\n                    \"description\": \"Second operand\"\n                },\n                \"precision\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Number of decimal places\",\n                    \"default\": 2,\n                    \"minimum\": 0,\n                    \"maximum\": 10\n                }\n            },\n            \"required\": [\"operation\", \"a\", \"b\"]\n        }\n    }\n}\n</code></pre>"},{"location":"howto/develop-tools/#toolresult-contract","title":"ToolResult Contract","text":"<p>All tool functions must return a dictionary following this standard format:</p>"},{"location":"howto/develop-tools/#success-response","title":"Success Response","text":"<pre><code>{\n    \"toolUseId\": str,      # Echo back the invocation ID\n    \"status\": \"success\",   # Indicates successful execution\n    \"content\": [           # List of content blocks\n        {\"text\": str},     # Text content (most common)\n        # or:\n        {\"json\": dict},    # JSON content\n        {\"image\": bytes},  # Binary content\n    ]\n}\n</code></pre>"},{"location":"howto/develop-tools/#error-response","title":"Error Response","text":"<pre><code>{\n    \"toolUseId\": str,      # Echo back the invocation ID\n    \"status\": \"error\",     # Indicates failure\n    \"content\": [\n        {\"text\": str}      # Error message\n    ]\n}\n</code></pre>"},{"location":"howto/develop-tools/#guidelines","title":"Guidelines","text":"<ol> <li>Always include <code>toolUseId</code>: Extract from <code>tool.get(\"toolUseId\", \"\")</code> and echo it back</li> <li>Use descriptive error messages: Help users understand what went wrong</li> <li>Return text content by default: Most tools return <code>{\"text\": result}</code></li> <li>Handle missing inputs gracefully: Validate inputs and return errors, don't raise exceptions</li> <li>Catch all exceptions: Wrap execution logic in try/except and return error responses</li> </ol>"},{"location":"howto/develop-tools/#example-with-error-handling","title":"Example with Error Handling","text":"<pre><code>def my_tool(tool: dict[str, Any], **kwargs: Any) -&gt; dict[str, Any]:\n    tool_use_id = tool.get(\"toolUseId\", \"\")\n    tool_input = tool.get(\"input\", {})\n\n    # Validate required parameters\n    required_param = tool_input.get(\"required_param\")\n    if not required_param:\n        return {\n            \"toolUseId\": tool_use_id,\n            \"status\": \"error\",\n            \"content\": [{\"text\": \"Missing required parameter: required_param\"}]\n        }\n\n    try:\n        # Execute tool logic\n        result = perform_operation(required_param)\n\n        return {\n            \"toolUseId\": tool_use_id,\n            \"status\": \"success\",\n            \"content\": [{\"text\": str(result)}]\n        }\n\n    except ValueError as e:\n        return {\n            \"toolUseId\": tool_use_id,\n            \"status\": \"error\",\n            \"content\": [{\"text\": f\"Invalid input: {e}\"}]\n        }\n\n    except Exception as e:\n        return {\n            \"toolUseId\": tool_use_id,\n            \"status\": \"error\",\n            \"content\": [{\"text\": f\"Execution failed: {type(e).__name__}: {e}\"}]\n        }\n</code></pre>"},{"location":"howto/develop-tools/#advanced-example-python_exec","title":"Advanced Example: python_exec","text":"<p>The <code>python_exec</code> tool demonstrates advanced patterns including security restrictions, output capture, and comprehensive error handling.</p>"},{"location":"howto/develop-tools/#full-implementation","title":"Full Implementation","text":"<pre><code>\"\"\"Python code execution tool (Strands SDK module-based pattern).\n\nExecute Python code safely with restricted builtins and stdout capture.\nMVP implementation - production version should add proper sandboxing.\n\"\"\"\n\nimport io\nfrom contextlib import redirect_stdout\nfrom typing import Any\n\n# Tool Specification (Strands SDK standard)\nTOOL_SPEC = {\n    \"name\": \"python_exec\",\n    \"description\": \"Execute Python code and return results (MVP - simple version with restricted builtins)\",\n    \"inputSchema\": {\n        \"json\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"code\": {\"type\": \"string\", \"description\": \"Python code to execute\"},\n                \"timeout\": {\n                    \"type\": \"integer\",\n                    \"default\": 5,\n                    \"description\": \"Timeout in seconds (not enforced in MVP)\",\n                },\n            },\n            \"required\": [\"code\"],\n        }\n    },\n}\n\n\ndef python_exec(tool: dict[str, Any], **kwargs: Any) -&gt; dict[str, Any]:\n    \"\"\"Execute Python code with restricted builtins and stdout capture.\n\n    MVP Implementation:\n    - Uses exec() with restricted globals\n    - Captures stdout via StringIO\n    - Returns result or error\n\n    Security Limitations (MVP):\n    - No proper sandboxing (subprocess/docker)\n    - No resource limits (memory, CPU)\n    - No timeout enforcement\n    - Limited builtin allowlist\n    - No AST parsing for dangerous operations\n\n    Production version should address all security limitations.\n\n    Args:\n        tool: Tool invocation object with toolUseId and input\n        **kwargs: Additional arguments (unused)\n\n    Returns:\n        ToolResult dict with status and content\n    \"\"\"\n    tool_use_id = tool.get(\"toolUseId\", \"\")\n    tool_input = tool.get(\"input\", {})\n    code = tool_input.get(\"code\", \"\")\n\n    if not code:\n        return {\n            \"toolUseId\": tool_use_id,\n            \"status\": \"error\",\n            \"content\": [{\"text\": \"No code provided\"}],\n        }\n\n    try:\n        # Capture stdout\n        output = io.StringIO()\n\n        with redirect_stdout(output):\n            # Restricted globals - only safe builtins\n            restricted_globals = {\n                \"__builtins__\": {\n                    # Type constructors\n                    \"int\": int,\n                    \"float\": float,\n                    \"str\": str,\n                    \"bool\": bool,\n                    \"list\": list,\n                    \"dict\": dict,\n                    \"tuple\": tuple,\n                    \"set\": set,\n                    # Utilities\n                    \"len\": len,\n                    \"range\": range,\n                    \"enumerate\": enumerate,\n                    \"zip\": zip,\n                    \"sum\": sum,\n                    \"min\": min,\n                    \"max\": max,\n                    \"abs\": abs,\n                    \"round\": round,\n                    \"sorted\": sorted,\n                    \"reversed\": reversed,\n                    # Output\n                    \"print\": print,\n                    # Type checking\n                    \"isinstance\": isinstance,\n                    \"type\": type,\n                }\n            }\n\n            # Execute code with restricted environment\n            exec(code, restricted_globals)\n\n        # Get captured output\n        result = output.getvalue()\n\n        return {\n            \"toolUseId\": tool_use_id,\n            \"status\": \"success\",\n            \"content\": [{\"text\": result if result else \"Code executed successfully (no output)\"}],\n        }\n\n    except Exception as e:\n        return {\n            \"toolUseId\": tool_use_id,\n            \"status\": \"error\",\n            \"content\": [{\"text\": f\"Execution failed: {type(e).__name__}: {e!s}\"}],\n        }\n</code></pre>"},{"location":"howto/develop-tools/#key-patterns-demonstrated","title":"Key Patterns Demonstrated","text":"<ol> <li>Output Capture: Using <code>io.StringIO()</code> and <code>redirect_stdout()</code> to capture printed output</li> <li>Security Restrictions: Custom <code>__builtins__</code> dict to limit available functions</li> <li>Comprehensive Error Handling: Catching all exceptions and returning structured errors</li> <li>Documentation: Clear docstrings explaining security limitations</li> <li>Type Hints: Full type annotations for better IDE support and type checking</li> </ol>"},{"location":"howto/develop-tools/#testing-your-tool","title":"Testing Your Tool","text":"<p>Every native tool should have comprehensive tests. Here's the pattern used for <code>python_exec</code>.</p>"},{"location":"howto/develop-tools/#test-file-structure","title":"Test File Structure","text":"<p>Create <code>tests/test_echo.py</code>:</p> <pre><code>\"\"\"Unit tests for echo native tool.\"\"\"\n\nimport pytest\n\n\nclass TestEchoTool:\n    \"\"\"Tests for the echo tool.\"\"\"\n\n    def test_echo_success(self) -&gt; None:\n        \"\"\"Test successful echo operation.\"\"\"\n        from strands_cli.tools.echo import echo\n\n        tool = {\n            \"toolUseId\": \"test-123\",\n            \"input\": {\"message\": \"Hello, World!\"}\n        }\n\n        result = echo(tool)\n\n        assert result[\"toolUseId\"] == \"test-123\"\n        assert result[\"status\"] == \"success\"\n        assert len(result[\"content\"]) == 1\n        assert result[\"content\"][0][\"text\"] == \"Hello, World!\"\n\n    def test_echo_empty_message(self) -&gt; None:\n        \"\"\"Test echo with empty message returns error.\"\"\"\n        from strands_cli.tools.echo import echo\n\n        tool = {\n            \"toolUseId\": \"test-456\",\n            \"input\": {\"message\": \"\"}\n        }\n\n        result = echo(tool)\n\n        assert result[\"toolUseId\"] == \"test-456\"\n        assert result[\"status\"] == \"error\"\n        assert \"No message provided\" in result[\"content\"][0][\"text\"]\n\n    def test_echo_missing_input(self) -&gt; None:\n        \"\"\"Test echo with missing input dict.\"\"\"\n        from strands_cli.tools.echo import echo\n\n        tool = {\n            \"toolUseId\": \"test-789\",\n            \"input\": {}\n        }\n\n        result = echo(tool)\n\n        assert result[\"status\"] == \"error\"\n\n    def test_echo_tool_spec_format(self) -&gt; None:\n        \"\"\"Test that TOOL_SPEC has required fields.\"\"\"\n        from strands_cli.tools.echo import TOOL_SPEC\n\n        assert \"name\" in TOOL_SPEC\n        assert TOOL_SPEC[\"name\"] == \"echo\"\n        assert \"description\" in TOOL_SPEC\n        assert \"inputSchema\" in TOOL_SPEC\n        assert \"json\" in TOOL_SPEC[\"inputSchema\"]\n\n        schema = TOOL_SPEC[\"inputSchema\"][\"json\"]\n        assert \"properties\" in schema\n        assert \"message\" in schema[\"properties\"]\n        assert schema[\"required\"] == [\"message\"]\n</code></pre>"},{"location":"howto/develop-tools/#integration-test-pattern","title":"Integration Test Pattern","text":"<p>Create <code>tests/test_echo_integration.py</code>:</p> <pre><code>\"\"\"Integration tests for echo tool in workflows.\"\"\"\n\nfrom pathlib import Path\n\nimport pytest\n\nfrom strands_cli.loader import load_spec\n\n\nclass TestEchoIntegration:\n    \"\"\"Integration tests for echo tool.\"\"\"\n\n    def test_echo_in_spec_validation(self, tmp_path: Path) -&gt; None:\n        \"\"\"Test that echo tool passes capability validation.\"\"\"\n        from strands_cli.capability import check_capability\n\n        spec_content = \"\"\"\nversion: 0\nname: echo-validation-test\ndescription: Test echo tool validation\n\nruntime:\n  provider: ollama\n  model_id: llama3.2:3b\n  host: http://localhost:11434\n\nagents:\n  assistant:\n    prompt: \"Test assistant\"\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent: assistant\n        input: \"Test\"\n\ntools:\n  python:\n    - echo\n\noutputs:\n  artifacts:\n    - path: result.txt\n      from: \"{{ last_response }}\"\n\"\"\"\n        spec_file = tmp_path / \"echo_test.yaml\"\n        spec_file.write_text(spec_content)\n\n        spec = load_spec(str(spec_file))\n        report = check_capability(spec)\n\n        # Should be supported (no issues)\n        assert report.supported is True\n        assert len(report.issues) == 0\n\n    @pytest.mark.asyncio\n    async def test_echo_in_chain_workflow(\n        self, tmp_path: Path, mock_create_model: None\n    ) -&gt; None:\n        \"\"\"Test echo tool in a chain workflow.\"\"\"\n        spec_content = \"\"\"\nversion: 0\nname: echo-chain-test\ndescription: Test echo in chain pattern\n\nruntime:\n  provider: ollama\n  model_id: llama3.2:3b\n  host: http://localhost:11434\n\nagents:\n  assistant:\n    prompt: \"Use the echo tool\"\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent: assistant\n        input: \"Echo: Test message\"\n\ntools:\n  python:\n    - echo\n\noutputs:\n  artifacts:\n    - path: result.txt\n      from: \"{{ last_response }}\"\n\"\"\"\n        spec_file = tmp_path / \"echo_chain.yaml\"\n        spec_file.write_text(spec_content)\n\n        spec = load_spec(str(spec_file))\n\n        from strands_cli.exec.chain import run_chain\n        result = await run_chain(spec, {})\n\n        assert result is not None\n        assert result.last_response is not None\n</code></pre>"},{"location":"howto/develop-tools/#run-tests","title":"Run Tests","text":"<pre><code># Run all tests for echo tool\nuv run pytest tests/test_echo.py -v\n\n# Run with coverage\nuv run pytest tests/test_echo.py --cov=src/strands_cli/tools/echo --cov-report=term-missing\n\n# Run integration tests\nuv run pytest tests/test_echo_integration.py -v\n</code></pre>"},{"location":"howto/develop-tools/#using-tools-in-workflows","title":"Using Tools in Workflows","text":""},{"location":"howto/develop-tools/#short-id-format-recommended","title":"Short ID Format (Recommended)","text":"<p>The simplest way to use a native tool:</p> <pre><code>tools:\n  python:\n    - echo          # Auto-resolved to strands_cli.tools.echo\n    - python_exec   # Auto-resolved to strands_cli.tools.python_exec\n</code></pre>"},{"location":"howto/develop-tools/#full-path-format","title":"Full Path Format","text":"<p>For explicit imports:</p> <pre><code>tools:\n  python:\n    - strands_cli.tools.echo\n    - strands_cli.tools.python_exec\n</code></pre>"},{"location":"howto/develop-tools/#legacy-format-backward-compatible","title":"Legacy Format (Backward Compatible)","text":"<p>Old format still works via registry resolution:</p> <pre><code>tools:\n  python:\n    - strands_tools.echo          # Resolves to strands_cli.tools.echo\n    - strands_tools.python_exec   # Resolves to strands_cli.tools.python_exec\n</code></pre>"},{"location":"howto/develop-tools/#complete-workflow-example","title":"Complete Workflow Example","text":"<pre><code>version: 0\nname: multi-tool-demo\ndescription: Demonstrate multiple native tools\n\nruntime:\n  provider: openai\n  model_id: gpt-4o-mini\n\nagents:\n  assistant:\n    prompt: |\n      You are a helpful assistant with access to multiple tools.\n      Use the echo tool to repeat messages, and python_exec to perform calculations.\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent: assistant\n        input: |\n          First, echo this message: \"Starting workflow\"\n          Then calculate the factorial of 5 using Python.\n\ntools:\n  python:\n    - echo        # Native echo tool\n    - python_exec # Native Python execution tool\n\noutputs:\n  artifacts:\n    - path: ./workflow-result.txt\n      from: \"{{ last_response }}\"\n</code></pre> <p>Run it:</p> <pre><code>uv run strands run examples/multi-tool-demo.yaml --force\n</code></pre>"},{"location":"howto/develop-tools/#registry-mechanics","title":"Registry Mechanics","text":""},{"location":"howto/develop-tools/#how-auto-discovery-works","title":"How Auto-Discovery Works","text":"<p>The <code>ToolRegistry</code> class uses a singleton pattern and discovers tools on first instantiation:</p> <pre><code># From src/strands_cli/tools/registry.py\n\nclass ToolRegistry:\n    \"\"\"Simple singleton registry for native tools.\"\"\"\n\n    _instance: \"ToolRegistry | None\" = None\n    _tools: dict[str, ToolInfo]\n\n    def __new__(cls) -&gt; \"ToolRegistry\":\n        \"\"\"Singleton pattern - ensures only one registry instance exists.\"\"\"\n        if cls._instance is None:\n            cls._instance = super().__new__(cls)\n            cls._instance._tools = {}\n            cls._instance._discover_tools()  # Auto-discovery happens here\n        return cls._instance\n</code></pre>"},{"location":"howto/develop-tools/#discovery-process","title":"Discovery Process","text":"<pre><code>def _discover_tools(self) -&gt; None:\n    \"\"\"Auto-discover tools from strands_cli.tools module.\"\"\"\n    tools_dir = Path(__file__).parent\n\n    # Scan all .py files (skip __init__, registry, etc.)\n    for _importer, module_name, _is_pkg in pkgutil.iter_modules([str(tools_dir)]):\n        if module_name.startswith(\"_\") or module_name == \"registry\":\n            continue\n\n        try:\n            module = importlib.import_module(f\"strands_cli.tools.{module_name}\")\n\n            # Check for TOOL_SPEC (Strands SDK pattern)\n            if not hasattr(module, \"TOOL_SPEC\"):\n                logger.warning(\"Tool module missing TOOL_SPEC, skipping\", module_name=module_name)\n                continue\n\n            spec = module.TOOL_SPEC\n\n            # Validate TOOL_SPEC has required fields\n            if not isinstance(spec, dict) or \"name\" not in spec:\n                logger.warning(\"Tool module has invalid TOOL_SPEC (missing 'name'), skipping\")\n                continue\n\n            tool_id = spec[\"name\"]\n\n            # Register tool\n            tool_info = ToolInfo(\n                id=tool_id,\n                module_path=f\"strands_cli.tools.{module_name}\",\n                description=spec.get(\"description\", \"\")\n            )\n            self._tools[tool_id] = tool_info\n\n        except Exception as e:\n            logger.warning(\"Failed to import tool module, skipping\", error=str(e))\n</code></pre>"},{"location":"howto/develop-tools/#toolinfo-structure","title":"ToolInfo Structure","text":"<pre><code>@dataclass\nclass ToolInfo:\n    \"\"\"Minimal tool metadata for discovery.\"\"\"\n\n    id: str                # Tool identifier (e.g., \"echo\")\n    module_path: str       # Full import path (e.g., \"strands_cli.tools.echo\")\n    description: str       # Tool description from TOOL_SPEC\n\n    @property\n    def import_path(self) -&gt; str:\n        \"\"\"Full import path for loading.\"\"\"\n        return self.module_path\n\n    @property\n    def legacy_path(self) -&gt; str:\n        \"\"\"Backward-compatible 'strands_tools.*' path.\"\"\"\n        return f\"strands_tools.{self.id}.{self.id}\"\n\n    @property\n    def legacy_short(self) -&gt; str:\n        \"\"\"Old short format.\"\"\"\n        return f\"strands_tools.{self.id}\"\n</code></pre>"},{"location":"howto/develop-tools/#resolution-strategy","title":"Resolution Strategy","text":"<p>The registry supports multiple input formats for backward compatibility:</p> <pre><code>def resolve(self, user_input: str) -&gt; str | None:\n    \"\"\"Resolve user input to canonical import path.\n\n    Supports:\n    - Direct ID: \"echo\" \u2192 \"strands_cli.tools.echo\"\n    - Legacy short: \"strands_tools.echo\" \u2192 \"strands_cli.tools.echo\"\n    - Legacy full: \"strands_tools.echo.echo\" \u2192 \"strands_cli.tools.echo\"\n    \"\"\"\n    # Direct ID lookup\n    if user_input in self._tools:\n        return self._tools[user_input].import_path\n\n    # Legacy format: \"strands_tools.X\" or \"strands_tools.X.X\"\n    if user_input.startswith(\"strands_tools.\"):\n        parts = user_input.split(\".\")\n        tool_id = parts[1] if len(parts) &gt;= 2 else None\n        if tool_id and tool_id in self._tools:\n            return self._tools[tool_id].import_path\n\n    return None\n</code></pre>"},{"location":"howto/develop-tools/#allowlist-generation","title":"Allowlist Generation","text":"<p>The registry provides an allowlist for capability checking:</p> <pre><code>def get_allowlist(self) -&gt; set[str]:\n    \"\"\"Generate complete allowlist for capability checker.\n\n    Returns all valid import formats for all discovered tools:\n    - Short ID: \"echo\"\n    - New format: \"strands_cli.tools.echo\"\n    - Legacy full: \"strands_tools.echo.echo\"\n    - Legacy short: \"strands_tools.echo\"\n    \"\"\"\n    allowlist = set()\n    for tool in self._tools.values():\n        allowlist.add(tool.id)\n        allowlist.add(tool.import_path)\n        allowlist.add(tool.legacy_path)\n        allowlist.add(tool.legacy_short)\n    return allowlist\n</code></pre>"},{"location":"howto/develop-tools/#hybrid-allowlist-in-capability-checker","title":"Hybrid Allowlist in Capability Checker","text":"<p>The capability checker combines hardcoded legacy tools with registry-discovered tools:</p> <pre><code># From src/strands_cli/capability/checker.py\n\nfrom strands_cli.tools import get_registry\n\n# Hardcoded legacy allowlist\nALLOWED_PYTHON_CALLABLES = {\n    \"strands_tools.http_request.http_request\",\n    \"strands_tools.file_read.file_read\",\n    \"strands_tools.file_write.file_write\",\n    \"strands_tools.calculator.calculator\",\n    \"strands_tools.current_time.current_time\",\n    # ... old format variants\n}\n\n# Combine with registry allowlist\nregistry = get_registry()\nallowed = ALLOWED_PYTHON_CALLABLES | registry.get_allowlist()\n\n# Validate tool against combined allowlist\nif tool.callable not in allowed:\n    issues.append(\n        CapabilityIssue(\n            pointer=f\"/tools/python/{i}/callable\",\n            reason=f\"Python callable '{tool.callable}' not in allowlist\",\n            remediation=\"Use an allowed tool or add to registry\"\n        )\n    )\n</code></pre>"},{"location":"howto/develop-tools/#accessing-the-registry","title":"Accessing the Registry","text":"<pre><code>from strands_cli.tools import get_registry\n\n# Get registry instance\nregistry = get_registry()\n\n# List all discovered tools\nall_tools = registry.list_all()\nfor tool in all_tools:\n    print(f\"{tool.id}: {tool.description}\")\n\n# Get specific tool\ntool_info = registry.get(\"echo\")\nif tool_info:\n    print(f\"Import path: {tool_info.import_path}\")\n\n# Resolve user input\ncanonical_path = registry.resolve(\"strands_tools.echo\")\n# Returns: \"strands_cli.tools.echo\"\n\n# Get allowlist for validation\nallowlist = registry.get_allowlist()\n# Returns: {\"echo\", \"strands_cli.tools.echo\", \"strands_tools.echo\", ...}\n</code></pre>"},{"location":"howto/develop-tools/#summary","title":"Summary","text":"<p>Native tools in Strands CLI follow a simple pattern:</p> <ol> <li>Create a Python module in <code>src/strands_cli/tools/</code></li> <li>Export a <code>TOOL_SPEC</code> dictionary with <code>name</code>, <code>description</code>, and <code>inputSchema</code></li> <li>Implement a function matching <code>TOOL_SPEC[\"name\"]</code> that returns a ToolResult dict</li> <li>Test with unit tests and integration tests</li> <li>Use in workflows via short ID, full path, or legacy format</li> </ol> <p>The registry handles auto-discovery, resolution, and backward compatibility automatically. No manual registration required!</p>"},{"location":"howto/hitl/","title":"Human-in-the-Loop (HITL) Workflows","text":"<p>Learn how to add human approval gates and interactive decision points to your workflows using Human-in-the-Loop (HITL) steps.</p>"},{"location":"howto/hitl/#overview","title":"Overview","text":"<p>HITL steps allow you to pause workflow execution for:</p> <ul> <li>Approval Gates: Review agent outputs before expensive next steps</li> <li>Quality Control: Human validation of generated content</li> <li>Interactive Workflows: User-guided decision making</li> <li>Debugging: Inspect intermediate results during development</li> <li>Compliance: Human oversight for regulated processes</li> </ul> <p>HITL integrates seamlessly with session management for automatic save/resume.</p>"},{"location":"howto/hitl/#basic-hitl-step","title":"Basic HITL Step","text":""},{"location":"howto/hitl/#simple-approval-gate","title":"Simple Approval Gate","text":"<pre><code>pattern:\n  type: chain\n  config:\n    steps:\n      - agent: generator\n        input: \"Generate content about {{ topic }}\"\n\n      # HITL approval gate\n      - type: hitl\n        prompt: \"Review the generated content. Approve to continue?\"\n        context_display: \"{{ steps[0].response }}\"\n\n      - agent: publisher\n        input: \"Publish: {{ steps[0].response }}\"\n</code></pre>"},{"location":"howto/hitl/#hitl-step-properties","title":"HITL Step Properties","text":"Property Required Description <code>type</code> Yes Must be <code>\"hitl\"</code> <code>prompt</code> Yes Message displayed to user requesting input <code>context_display</code> No Context to show user (supports templates) <code>default</code> No Default response if user provides empty input <code>timeout_seconds</code> No Time before expiration (0 = no timeout, not enforced in Phase 1)"},{"location":"howto/hitl/#cli-workflow","title":"CLI Workflow","text":""},{"location":"howto/hitl/#step-1-run-workflow","title":"Step 1: Run Workflow","text":"<pre><code>uv run strands run workflow.yaml --var topic=\"AI Safety\"\n\n# Output:\n# Running workflow: approval-workflow\n# Session ID: a1b2c3d4-e5f6-7890-abcd-ef1234567890\n# Step 1/3: generator - COMPLETE\n#\n# \ud83e\udd1d HUMAN INPUT REQUIRED\n#\n# Review the generated content. Approve to continue?\n#\n# \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n# \u2503 Context for Review                                       \u2503\n# \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n# \u2502 [Generated content displayed here]                       \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n#\n# Session ID: a1b2c3d4-e5f6-7890-abcd-ef1234567890\n# Resume with: strands run --resume a1b2c3d4-e5f6-7890-abcd-ef1234567890 --hitl-response 'your response'\n#\n# Exit code: 19 (EX_HITL_PAUSE)\n</code></pre>"},{"location":"howto/hitl/#step-2-review-context","title":"Step 2: Review Context","text":"<p>Examine the displayed context and decide on your response:</p> <ul> <li>Approve: <code>\"approved\"</code>, <code>\"yes\"</code>, <code>\"proceed\"</code>, etc.</li> <li>Request changes: Provide specific feedback</li> <li>Reject: <code>\"rejected\"</code>, <code>\"no\"</code>, etc.</li> </ul>"},{"location":"howto/hitl/#step-3-resume-with-response","title":"Step 3: Resume with Response","text":"<pre><code># Approve and continue\nuv run strands run --resume a1b2c3d4 --hitl-response \"approved\"\n\n# Or provide feedback\nuv run strands run --resume a1b2c3d4 --hitl-response \"Please focus more on safety considerations\"\n\n# Output:\n# Resuming session: a1b2c3d4...\n# Skipping completed step 0: generator\n# HITL response received: approved\n# Step 3/3: publisher - EXECUTING\n# \u2713 Workflow complete\n</code></pre>"},{"location":"howto/hitl/#template-access","title":"Template Access","text":"<p>Access HITL responses in subsequent steps using <code>{{ steps[n].response }}</code>:</p> <pre><code>pattern:\n  type: chain\n  config:\n    steps:\n      - agent: writer\n        input: \"Write article about {{ topic }}\"\n\n      - type: hitl\n        prompt: \"Review article. Approve or provide feedback?\"\n        context_display: \"{{ steps[0].response }}\"\n\n      - agent: editor\n        input: |\n          User review: {{ steps[1].response }}\n\n          {% if steps[1].response == 'approved' %}\n          Finalize this article for publication:\n          {{ steps[0].response }}\n          {% else %}\n          Revise the article based on this feedback:\n          {{ steps[1].response }}\n\n          Original article:\n          {{ steps[0].response }}\n          {% endif %}\n</code></pre> <p>Template variables in HITL context:</p> <ul> <li><code>{{ steps[n].response }}</code> - Previous step outputs</li> <li><code>{{ last_response }}</code> - Most recent agent response</li> <li><code>{{ variables.* }}</code> - User-provided variables</li> <li>Any custom variables from inputs</li> </ul>"},{"location":"howto/hitl/#examples","title":"Examples","text":""},{"location":"howto/hitl/#example-1-research-approval","title":"Example 1: Research Approval","text":"<pre><code>version: 0\nname: \"research-approval\"\ndescription: \"Research workflow with approval gate\"\n\nruntime:\n  provider: openai\n  model_id: gpt-4o-mini\n\nagents:\n  researcher:\n    prompt: \"Research the given topic thoroughly.\"\n\n  analyst:\n    prompt: \"Analyze research findings.\"\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent: researcher\n        input: \"Research: {{ topic }}\"\n\n      - type: hitl\n        prompt: |\n          Review the research findings.\n          Respond 'approved' to proceed, or provide feedback.\n        context_display: |\n          ## Research Findings\n          {{ steps[0].response }}\n        default: \"approved\"\n\n      - agent: analyst\n        input: |\n          User: {{ steps[1].response }}\n          {% if steps[1].response == 'approved' %}\n          Analyze: {{ steps[0].response }}\n          {% else %}\n          Address this feedback: {{ steps[1].response }}\n          Research: {{ steps[0].response }}\n          {% endif %}\n</code></pre> <p>Usage: <pre><code># Run\nuv run strands run research-approval.yaml --var topic=\"Quantum Computing\"\n\n# Resume with approval\nuv run strands run --resume &lt;session-id&gt; --hitl-response \"approved\"\n\n# Or with feedback\nuv run strands run --resume &lt;session-id&gt; --hitl-response \"Add more recent sources\"\n</code></pre></p>"},{"location":"howto/hitl/#example-2-multi-gate-workflow","title":"Example 2: Multi-Gate Workflow","text":"<pre><code>pattern:\n  type: chain\n  config:\n    steps:\n      # Step 1: Generate draft\n      - agent: writer\n        input: \"Write draft about {{ topic }}\"\n\n      # Gate 1: Content review\n      - type: hitl\n        prompt: \"Review draft content (approve/revise/reject)\"\n        context_display: \"{{ steps[0].response }}\"\n\n      # Step 2: Revise or continue\n      - agent: writer\n        input: |\n          {% if steps[1].response == 'revise' %}\n          Revise draft based on feedback\n          {% elif steps[1].response == 'approve' %}\n          Finalize draft: {{ steps[0].response }}\n          {% endif %}\n\n      # Gate 2: Final approval\n      - type: hitl\n        prompt: \"Final approval for publication (yes/no)\"\n        context_display: \"{{ steps[2].response }}\"\n\n      # Step 3: Publish\n      - agent: publisher\n        input: |\n          {% if steps[3].response == 'yes' %}\n          Publish: {{ steps[2].response }}\n          {% else %}\n          Archive without publishing\n          {% endif %}\n</code></pre>"},{"location":"howto/hitl/#example-3-debug-inspection","title":"Example 3: Debug Inspection","text":"<pre><code>pattern:\n  type: chain\n  config:\n    steps:\n      - agent: data_processor\n        input: \"Process dataset: {{ data_path }}\"\n\n      # Debug checkpoint\n      - type: hitl\n        prompt: \"Inspect processing results. Continue or abort?\"\n        context_display: |\n          ## Processing Results\n          {{ steps[0].response }}\n\n          ## Debug Info\n          Dataset: {{ data_path }}\n          Timestamp: {{ steps[0].timestamp }}\n\n      - agent: analyzer\n        input: \"Analyze: {{ steps[0].response }}\"\n</code></pre>"},{"location":"howto/hitl/#example-4-multi-stage-business-proposal","title":"Example 4: Multi-Stage Business Proposal","text":"<p>A sophisticated workflow with multiple HITL approval gates for executive and CFO review:</p> <pre><code>version: 0\nname: \"hitl-business-proposal\"\ndescription: \"Chain workflow with 2 HITL approval gates for business proposal review\"\n\nruntime:\n  provider: openai\n  model_id: gpt-5-nano\n  budgets:\n    max_tokens: 15000\n\nagents:\n  market_analyst:\n    prompt: |\n      You are a senior market analyst with expertise in competitive analysis.\n      Provide detailed, data-driven market analysis with clear insights.\n\n  financial_analyst:\n    prompt: |\n      You are a financial analyst specializing in business case development.\n      Create comprehensive financial projections and ROI analysis.\n\n  strategist:\n    prompt: |\n      You are a business strategist who synthesizes market and financial data\n      into actionable strategic recommendations.\n\npattern:\n  type: chain\n  config:\n    steps:\n      # Step 1: Market Analysis\n      - agent: market_analyst\n        input: |\n          Conduct market analysis for:\n          Business: {{ business_concept }}\n          Market: {{ target_market }}\n          Geography: {{ geographic_scope }}\n\n      # Step 2: Executive Review Gate\n      - type: hitl\n        prompt: |\n          **EXECUTIVE REVIEW REQUIRED**\n\n          Review market analysis. You may:\n          - Type 'approved' to proceed to financial analysis\n          - Provide feedback for revisions\n          - Type 'reject' to halt the proposal\n        context_display: |\n          ## Market Analysis Report\n          {{ steps[0].response }}\n\n          **Decision Options:**\n          - \u2705 approved - Proceed to financial analysis\n          - \ud83d\udcdd [feedback] - Request revisions\n          - \u274c reject - Stop proposal\n        default: \"approved\"\n        timeout_seconds: 7200  # 2 hours\n\n      # Step 3: Financial Analysis (conditional)\n      - agent: financial_analyst\n        input: |\n          {% if steps[1].response == 'reject' %}\n          Rejected. Summarize why this opportunity is not viable.\n          {% elif steps[1].response == 'approved' %}\n          Develop financial model based on approved analysis:\n          {{ steps[0].response }}\n          {% else %}\n          Revise analysis addressing: {{ steps[1].response }}\n          Original: {{ steps[0].response }}\n          {% endif %}\n\n      # Step 4: CFO Review Gate\n      - type: hitl\n        prompt: |\n          **CFO REVIEW REQUIRED**\n\n          Review financial analysis and projections.\n        context_display: |\n          ## Financial Analysis Report\n          {{ steps[2].response }}\n\n          **Decision Options:**\n          - \u2705 approved - Proceed to strategy\n          - \ud83d\udcdd [feedback] - Request adjustments\n          - \u274c reject - Insufficient financial case\n        default: \"approved\"\n        timeout_seconds: 7200\n\n      # Step 5: Strategic Recommendations\n      - agent: strategist\n        input: |\n          {% if steps[3].response == 'reject' %}\n          Financial rejected. Explain why this doesn't meet criteria.\n          {% elif steps[3].response == 'approved' %}\n          Synthesize into strategic recommendations:\n          Market: {{ steps[0].response }}\n          Financial: {{ steps[2].response }}\n          {% else %}\n          Adjust recommendations per CFO feedback:\n          {{ steps[3].response }}\n          {% endif %}\n\noutputs:\n  artifacts:\n    - path: \"./business-proposal.md\"\n      from: |\n        # Business Proposal: {{ business_concept }}\n\n        **Status:** Approved for Execution\n\n        ## 1. Market Analysis\n        {{ steps[0].response }}\n\n        ### Executive Review: {{ steps[1].response }}\n\n        ## 2. Financial Analysis\n        {{ steps[2].response }}\n\n        ### CFO Review: {{ steps[3].response }}\n\n        ## 3. Strategic Recommendations\n        {{ steps[4].response }}\n\n        ## Approval Chain\n        | Stage | Reviewer | Decision |\n        |-------|----------|----------|\n        | Market | Executive | {{ steps[1].response }} |\n        | Financial | CFO | {{ steps[3].response }} |\n</code></pre> <p>Usage: <pre><code># Run workflow\nuv run strands run chain-hitl-business-proposal-openai.yaml \\\n  --var business_concept=\"AI Customer Service Platform\" \\\n  --var target_market=\"Mid-market B2B SaaS\" \\\n  --var geographic_scope=\"North America\"\n\n# Output shows session ID and first HITL gate\n# Session ID: abc123...\n\n# Executive approval\nuv run strands run --resume abc123 --hitl-response \"approved\"\n\n# CFO approval (second gate)\nuv run strands run --resume abc123 --hitl-response \"approved\"\n\n# Or provide feedback at any gate\nuv run strands run --resume abc123 \\\n  --hitl-response \"Please use more conservative revenue projections\"\n</code></pre></p> <p>Key Features: - Multi-stakeholder: Executive \u2192 CFO \u2192 Strategy team review - Conditional logic: Different prompts based on approval/rejection - Rich context: Formatted decision options in <code>context_display</code> - Structured output: Complete proposal with approval chain summary - Resume workflow: Each gate creates a resume point with full context</p>"},{"location":"howto/hitl/#session-integration","title":"Session Integration","text":""},{"location":"howto/hitl/#automatic-session-saving","title":"Automatic Session Saving","text":"<p>When a HITL step is encountered:</p> <ol> <li>Current state saved: All completed steps, outputs, and token usage</li> <li>Session marked as PAUSED: Status updated in session metadata</li> <li>Workflow exits: Exit code 19 (EX_HITL_PAUSE)</li> <li>User notified: Prompt, context, and resume instructions displayed</li> </ol>"},{"location":"howto/hitl/#session-state","title":"Session State","text":"<pre><code>{\n  \"metadata\": {\n    \"session_id\": \"abc123...\",\n    \"status\": \"paused\",\n    \"workflow_name\": \"approval-workflow\"\n  },\n  \"pattern_state\": {\n    \"current_step\": 1,\n    \"step_history\": [\n      {\n        \"index\": 0,\n        \"agent\": \"generator\",\n        \"response\": \"Generated content...\",\n        \"tokens_estimated\": 1500\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"howto/hitl/#resume-behavior","title":"Resume Behavior","text":"<p>When resuming with <code>--resume</code> and <code>--hitl-response</code>:</p> <ol> <li>Session loaded: State restored from disk</li> <li>HITL response recorded: User input saved in step history</li> <li>Skip completed work: Jump to next step after HITL</li> <li>Context updated: HITL response available as <code>{{ steps[1].response }}</code></li> <li>Execution continues: Remaining steps execute with full context</li> </ol>"},{"location":"howto/hitl/#best-practices","title":"Best Practices","text":""},{"location":"howto/hitl/#1-clear-prompts","title":"1. Clear Prompts","text":"<p>Write specific, actionable prompts:</p> <p>\u2705 Good: <pre><code>prompt: \"Review the API design. Respond 'approved' if complete, or list missing endpoints.\"\n</code></pre></p> <p>\u274c Avoid: <pre><code>prompt: \"Check this\"\n</code></pre></p>"},{"location":"howto/hitl/#2-provide-context","title":"2. Provide Context","text":"<p>Always use <code>context_display</code> to show what to review:</p> <pre><code>- type: hitl\n  prompt: \"Review analysis quality\"\n  context_display: |\n    ## Analysis Results\n    {{ steps[0].response }}\n\n    ## Metrics\n    Token usage: {{ steps[0].tokens }}\n    Duration: {{ steps[0].duration }}\n</code></pre>"},{"location":"howto/hitl/#3-use-default-responses","title":"3. Use Default Responses","text":"<p>Provide safe defaults for non-critical approvals:</p> <pre><code>- type: hitl\n  prompt: \"Approve to continue (default: yes)\"\n  default: \"yes\"\n  timeout_seconds: 300  # 5 minutes\n</code></pre>"},{"location":"howto/hitl/#4-document-expected-responses","title":"4. Document Expected Responses","text":"<p>Add comments or include options in prompt:</p> <pre><code>- type: hitl\n  prompt: |\n    Select deployment environment:\n    - production\n    - staging\n    - development\n  context_display: \"{{ deployment_plan }}\"\n</code></pre>"},{"location":"howto/hitl/#5-handle-different-responses","title":"5. Handle Different Responses","text":"<p>Use Jinja2 conditionals in subsequent steps:</p> <pre><code>- agent: deployer\n  input: |\n    {% if steps[1].response == 'production' %}\n    Deploy to production with validation\n    {% elif steps[1].response == 'staging' %}\n    Deploy to staging for testing\n    {% else %}\n    Deploy to development for debugging\n    {% endif %}\n</code></pre>"},{"location":"howto/hitl/#6-save-session-id","title":"6. Save Session ID","text":"<p>Keep track of session IDs for later resumption:</p> <pre><code># Save to file\nuv run strands run workflow.yaml | tee session.log\nSESSION_ID=$(grep \"Session ID:\" session.log | awk '{print $3}')\n\n# Resume later\nuv run strands run --resume $SESSION_ID --hitl-response \"approved\"\n</code></pre>"},{"location":"howto/hitl/#7-use-sessions-list","title":"7. Use Sessions List","text":"<p>View all pending HITL sessions:</p> <pre><code># List paused sessions\nuv run strands sessions list --status paused\n\n# Show details\nuv run strands sessions show &lt;session-id&gt;\n</code></pre>"},{"location":"howto/hitl/#limitations-phase-1","title":"Limitations (Phase 1)","text":""},{"location":"howto/hitl/#current-constraints","title":"Current Constraints","text":"<ul> <li>Chain pattern only: HITL only supported in chain workflows</li> <li>CLI-based interaction: Must use <code>--resume</code> and <code>--hitl-response</code> flags</li> <li>No timeout enforcement: <code>timeout_seconds</code> parsed but not enforced</li> <li>No validation: Response validation not implemented yet</li> <li>No multi-user: Single-user approval only</li> </ul>"},{"location":"howto/hitl/#workarounds","title":"Workarounds","text":"<p>For other patterns: Convert to chain or wait for Phase 2 multi-pattern support</p> <p>For interactive mode: Use <code>--hitl-response</code> with a wrapper script:</p> <pre><code>#!/bin/bash\n# hitl-interactive.sh - Wrapper for interactive HITL\n\nSESSION_ID=$1\n\necho \"Enter your response:\"\nread USER_RESPONSE\n\nuv run strands run --resume $SESSION_ID --hitl-response \"$USER_RESPONSE\"\n</code></pre>"},{"location":"howto/hitl/#troubleshooting","title":"Troubleshooting","text":""},{"location":"howto/hitl/#hitl-response-required-error","title":"HITL Response Required Error","text":"<pre><code>uv run strands run --resume abc123\n# Error: Session is waiting for HITL response.\n# Resume with: strands run --resume &lt;session-id&gt; --hitl-response 'your response'\n</code></pre> <p>Solution: Provide <code>--hitl-response</code> flag when resuming from HITL pause.</p>"},{"location":"howto/hitl/#hitl-response-without-resume","title":"HITL Response Without Resume","text":"<pre><code>uv run strands run workflow.yaml --hitl-response \"approved\"\n# Error: --hitl-response requires --resume &lt;session-id&gt;\n</code></pre> <p>Solution: <code>--hitl-response</code> only valid when resuming a paused session.</p>"},{"location":"howto/hitl/#empty-hitl-response","title":"Empty HITL Response","text":"<p>If you provide empty string:</p> <pre><code>uv run strands run --resume abc123 --hitl-response \"\"\n</code></pre> <p>Behavior: Empty string recorded as response (default not applied in Phase 1).</p> <p>Workaround: Explicitly provide default value if that's your intent.</p>"},{"location":"howto/hitl/#phase-1-status","title":"Phase 1 Status","text":"<p>\u2705 Implemented: - HITL step type in chain pattern - Automatic session pause on HITL step - Exit code 19 (EX_HITL_PAUSE) - CLI flags: <code>--hitl-response</code> - Template access: <code>{{ steps[n].response }}</code> - Context display with templates - Session integration (save/resume) - Example workflow: <code>chain-hitl-approval-demo.yaml</code></p> <p>\ud83d\udd1c Coming in Phase 2: - Multi-pattern support (workflow, parallel, routing, graph, etc.) - Timeout enforcement - Response validation with regex patterns - Conditional HITL skipping - Interactive CLI mode (inline prompts)</p> <p>\ud83d\udd1c Coming in Phase 3: - Programmatic API for custom handlers - Multi-user approval workflows - HITL history and audit trails - Web UI integration hooks - Webhook notifications</p>"},{"location":"howto/hitl/#next-steps","title":"Next Steps","text":"<ul> <li>Try the example: Run <code>chain-hitl-approval-demo.yaml</code> from the examples directory</li> <li>Read the plan: HITL.md - Complete implementation roadmap</li> <li>Session management: Session Management Guide</li> <li>Chain pattern: Workflow Manual</li> </ul>"},{"location":"howto/hitl/#related-documentation","title":"Related Documentation","text":"<ul> <li>HITL Implementation Plan - Complete HITL roadmap</li> <li>Session Management - Session persistence guide</li> <li>Workflow Manual - Workflow spec reference</li> <li>Exit Codes - CLI exit code meanings</li> <li>Examples - More workflow examples</li> </ul>"},{"location":"howto/run-workflows/","title":"How to Run Workflows","text":"<p>This guide shows you how to execute Strands workflows with various options and configurations.</p>"},{"location":"howto/run-workflows/#basic-execution","title":"Basic Execution","text":"<p>Run a workflow with default settings:</p> <pre><code>strands run workflow.yaml\n</code></pre> <p>The workflow will execute and display output in the console.</p>"},{"location":"howto/run-workflows/#command-line-options","title":"Command-Line Options","text":""},{"location":"howto/run-workflows/#variable-overrides","title":"Variable Overrides","text":"<p>Override variables defined in your workflow:</p> <pre><code>strands run workflow.yaml --var topic=\"Machine Learning\" --var format=\"markdown\"\n</code></pre> <p>Variables are substituted using Jinja2 templates in your workflow:</p> <pre><code>pattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: writer\n        prompt: \"Write about {{ topic }} in {{ format }} format\"\n</code></pre>"},{"location":"howto/run-workflows/#debug-and-verbose-output","title":"Debug and Verbose Output","text":"<p>Enable detailed logging to troubleshoot issues:</p> <pre><code># Debug mode with verbose output\nstrands run workflow.yaml --debug --verbose\n\n# Debug only\nstrands run workflow.yaml --debug\n\n# Verbose only\nstrands run workflow.yaml --verbose\n</code></pre> <p>Debug mode shows: - Detailed execution traces - Agent invocations and responses - Context management operations - Tool calls and results</p>"},{"location":"howto/run-workflows/#artifact-output","title":"Artifact Output","text":"<p>Specify where to save workflow artifacts:</p> <pre><code># Save to specific directory\nstrands run workflow.yaml --artifacts-dir ./output\n\n# Default is current directory\nstrands run workflow.yaml\n</code></pre> <p>Artifacts include: - Final workflow results - Intermediate step outputs (if configured) - Telemetry traces (if enabled) - Execution metadata</p>"},{"location":"howto/run-workflows/#telemetry-tracing","title":"Telemetry Tracing","text":"<p>Enable OpenTelemetry tracing:</p> <pre><code># Export trace to artifacts\nstrands run workflow.yaml --trace\n\n# Trace is saved as artifacts/trace_&lt;timestamp&gt;.json\n</code></pre>"},{"location":"howto/run-workflows/#working-with-different-providers","title":"Working with Different Providers","text":""},{"location":"howto/run-workflows/#aws-bedrock","title":"AWS Bedrock","text":"<pre><code># Using default Bedrock configuration\nstrands run workflow-bedrock.yaml\n\n# Override region\nexport STRANDS_AWS_REGION=us-west-2\nstrands run workflow-bedrock.yaml\n\n# Override model\nexport STRANDS_BEDROCK_MODEL_ID=anthropic.claude-3-opus-20240229-v1:0\nstrands run workflow-bedrock.yaml\n</code></pre>"},{"location":"howto/run-workflows/#ollama","title":"Ollama","text":"<pre><code># Ensure Ollama is running\nollama serve\n\n# Run workflow\nstrands run workflow-ollama.yaml\n\n# Custom Ollama host\nexport OLLAMA_HOST=http://custom-host:11434\nstrands run workflow-ollama.yaml\n</code></pre>"},{"location":"howto/run-workflows/#openai","title":"OpenAI","text":"<pre><code># Set API key\nexport OPENAI_API_KEY=sk-...\n\n# Run workflow\nstrands run workflow-openai.yaml\n</code></pre>"},{"location":"howto/run-workflows/#execution-patterns","title":"Execution Patterns","text":""},{"location":"howto/run-workflows/#chain-pattern","title":"Chain Pattern","text":"<p>Sequential steps with context threading:</p> <pre><code>strands run examples/chain-3-step-research.yaml\n</code></pre> <p>Output shows each step executing in order with results passed to next step.</p>"},{"location":"howto/run-workflows/#workflow-pattern-dag","title":"Workflow Pattern (DAG)","text":"<p>Parallel task execution with dependencies:</p> <pre><code>strands run examples/workflow-parallel-research.yaml\n</code></pre> <p>Tasks run concurrently where dependencies allow, then merge results.</p>"},{"location":"howto/run-workflows/#routing-pattern","title":"Routing Pattern","text":"<p>Dynamic agent selection:</p> <pre><code>strands run examples/routing-task-classification.yaml\n</code></pre> <p>The router agent selects the appropriate specialist based on input.</p>"},{"location":"howto/run-workflows/#parallel-pattern","title":"Parallel Pattern","text":"<p>Concurrent branch execution:</p> <pre><code>strands run examples/parallel-simple-2-branches.yaml\n</code></pre> <p>All branches run simultaneously with optional reduce step.</p>"},{"location":"howto/run-workflows/#evaluator-optimizer-pattern","title":"Evaluator-Optimizer Pattern","text":"<p>Iterative refinement:</p> <pre><code>strands run examples/evaluator-optimizer-writing.yaml\n</code></pre> <p>Content is refined until quality criteria are met.</p>"},{"location":"howto/run-workflows/#orchestrator-workers-pattern","title":"Orchestrator-Workers Pattern","text":"<p>Dynamic task delegation:</p> <pre><code>strands run examples/orchestrator-research-swarm.yaml\n</code></pre> <p>Orchestrator decomposes work and delegates to worker pool.</p>"},{"location":"howto/run-workflows/#graph-pattern","title":"Graph Pattern","text":"<p>State machine with conditionals:</p> <pre><code>strands run examples/graph-decision-tree.yaml\n</code></pre> <p>Execution follows conditional paths and loops.</p>"},{"location":"howto/run-workflows/#output-customization","title":"Output Customization","text":""},{"location":"howto/run-workflows/#controlling-console-output","title":"Controlling Console Output","text":"<pre><code># Minimal output\nstrands run workflow.yaml\n\n# Verbose with step-by-step details\nstrands run workflow.yaml --verbose\n\n# Debug with full traces\nstrands run workflow.yaml --debug --verbose\n</code></pre>"},{"location":"howto/run-workflows/#artifact-configuration","title":"Artifact Configuration","text":"<p>In your workflow, configure artifact outputs:</p> <pre><code>artifacts:\n  - path: result.txt\n    content: \"{{ last_response }}\"\n  - path: trace.json\n    content: \"{{ $TRACE }}\"\n    format: json\n</code></pre> <p>Then run:</p> <pre><code>strands run workflow.yaml --artifacts-dir ./output\n</code></pre> <p>Results appear in: - <code>./output/result.txt</code> - <code>./output/trace.json</code></p>"},{"location":"howto/run-workflows/#error-handling","title":"Error Handling","text":""},{"location":"howto/run-workflows/#understanding-exit-codes","title":"Understanding Exit Codes","text":"<p>Strands uses specific exit codes for different error types:</p> <pre><code>strands run workflow.yaml\necho $?  # Check exit code\n</code></pre> <p>Exit codes: - <code>0</code>: Success - <code>2</code>: Invalid CLI usage - <code>3</code>: Schema validation failed - <code>10</code>: Runtime error (provider, model, tool) - <code>12</code>: File I/O error - <code>18</code>: Unsupported feature - <code>70</code>: Unexpected error</p>"},{"location":"howto/run-workflows/#handling-runtime-errors","title":"Handling Runtime Errors","text":"<p>If a workflow fails during execution:</p> <pre><code># Run with debug to see detailed error\nstrands run workflow.yaml --debug --verbose\n</code></pre> <p>Common runtime errors: - Provider errors: Check credentials, region, model availability - Tool errors: Verify tool configuration and permissions - Timeout errors: Increase timeout in runtime config - Budget exceeded: Adjust token/time budgets</p>"},{"location":"howto/run-workflows/#performance-optimization","title":"Performance Optimization","text":""},{"location":"howto/run-workflows/#agent-caching","title":"Agent Caching","text":"<p>Strands automatically caches agents with identical configurations. In multi-step workflows, this provides 90% overhead reduction.</p> <p>No configuration needed - works automatically.</p>"},{"location":"howto/run-workflows/#model-client-pooling","title":"Model Client Pooling","text":"<p>Model clients are automatically pooled and reused across steps. This reduces connection overhead for Bedrock, Ollama, and OpenAI.</p>"},{"location":"howto/run-workflows/#context-management","title":"Context Management","text":"<p>Use presets to optimize context handling:</p> <pre><code>runtime:\n  provider: bedrock\n  model: anthropic.claude-3-sonnet-20240229-v1:0\n  preset: balanced  # Options: minimal, balanced, long_run, interactive\n</code></pre> <p>Presets control: - Maximum context size - Compaction strategy - Note retention - Memory management</p>"},{"location":"howto/run-workflows/#advanced-execution","title":"Advanced Execution","text":""},{"location":"howto/run-workflows/#using-presets","title":"Using Presets","text":"<p>Presets provide pre-configured context management:</p> <pre><code># Minimal context (fastest, lowest cost)\nstrands run workflow.yaml  # Uses minimal by default\n\n# Balanced (good for most cases)\n# Set in workflow: preset: balanced\n\n# Long-running research (maximum context retention)\n# Set in workflow: preset: long_run\n\n# Interactive chat (conversational style)\n# Set in workflow: preset: interactive\n</code></pre>"},{"location":"howto/run-workflows/#environment-variable-configuration","title":"Environment Variable Configuration","text":"<p>Set defaults via environment:</p> <pre><code># AWS Bedrock\nexport STRANDS_AWS_REGION=us-east-1\nexport STRANDS_BEDROCK_MODEL_ID=anthropic.claude-3-sonnet-20240229-v1:0\n\n# Debug\nexport STRANDS_DEBUG=true\nexport STRANDS_VERBOSE=true\n\n# Paths\nexport STRANDS_CONFIG_DIR=~/.config/strands\n\n# Telemetry\nexport STRANDS_MAX_TRACE_SPANS=5000\n\n# Run workflow\nstrands run workflow.yaml\n</code></pre>"},{"location":"howto/run-workflows/#batch-execution","title":"Batch Execution","text":"<p>Run multiple workflows:</p> <pre><code># Bash\nfor workflow in workflows/*.yaml; do\n  echo \"Running $workflow\"\n  strands run \"$workflow\"\ndone\n\n# PowerShell\nGet-ChildItem workflows/*.yaml | ForEach-Object {\n  Write-Host \"Running $($_.Name)\"\n  strands run $_.FullName\n}\n</code></pre>"},{"location":"howto/run-workflows/#cicd-integration","title":"CI/CD Integration","text":"<p>Run workflows in continuous integration:</p> <pre><code># .github/workflows/execute.yml\nname: Execute Workflows\non: [push]\n\njobs:\n  run:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.12'\n      - name: Install Strands\n        run: pip install strands-cli\n      - name: Run workflow\n        env:\n          AWS_REGION: us-east-1\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n        run: strands run workflow.yaml --artifacts-dir ./results\n      - name: Upload artifacts\n        uses: actions/upload-artifact@v3\n        with:\n          name: workflow-results\n          path: ./results\n</code></pre>"},{"location":"howto/run-workflows/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"howto/run-workflows/#enable-telemetry","title":"Enable Telemetry","text":"<p>Configure OpenTelemetry in your workflow:</p> <pre><code>telemetry:\n  enabled: true\n  otlp:\n    endpoint: http://localhost:4318\n    protocol: http\n  console:\n    enabled: true\n  artifacts:\n    enabled: true\n</code></pre> <p>Then run:</p> <pre><code>strands run workflow.yaml\n</code></pre> <p>Traces export to: - OTLP collector (if configured) - Console output (if enabled) - Artifact files (if enabled)</p>"},{"location":"howto/run-workflows/#pii-redaction","title":"PII Redaction","text":"<p>Enable automatic PII scrubbing:</p> <pre><code>telemetry:\n  enabled: true\n  redaction:\n    enabled: true\n    patterns:\n      - email\n      - credit_card\n      - ssn\n      - phone\n</code></pre>"},{"location":"howto/run-workflows/#troubleshooting","title":"Troubleshooting","text":""},{"location":"howto/run-workflows/#workflow-not-starting","title":"Workflow Not Starting","text":"<p>Check validation:</p> <pre><code>strands validate workflow.yaml\nstrands plan workflow.yaml\n</code></pre>"},{"location":"howto/run-workflows/#provider-connection-issues","title":"Provider Connection Issues","text":"<p>Verify credentials and connectivity:</p> <pre><code># Bedrock - test AWS credentials\naws sts get-caller-identity\n\n# Ollama - test connectivity\ncurl http://localhost:11434/api/tags\n\n# OpenAI - verify API key\necho $OPENAI_API_KEY\n</code></pre>"},{"location":"howto/run-workflows/#performance-issues","title":"Performance Issues","text":"<p>Enable profiling:</p> <pre><code>strands run workflow.yaml --debug --verbose\n</code></pre> <p>Check for: - Excessive context sizes - Inefficient prompts - Large tool outputs - Network latency</p>"},{"location":"howto/run-workflows/#getting-help","title":"Getting Help","text":"<p>If issues persist:</p> <ol> <li>Run with <code>--debug --verbose</code> for detailed logs</li> <li>Check the troubleshooting guide</li> <li>Review exit codes reference</li> <li>Check GitHub issues for similar problems</li> </ol>"},{"location":"howto/run-workflows/#see-also","title":"See Also","text":"<ul> <li>Validate Workflows - Pre-execution validation</li> <li>Context Management - Optimize context handling</li> <li>Telemetry - Observability and tracing</li> <li>CLI Reference - Complete command documentation</li> </ul>"},{"location":"howto/secrets/","title":"How to Manage Secrets and Environment Variables","text":"<p>This guide shows you how to securely manage secrets, API keys, and environment variables in Strands workflows.</p>"},{"location":"howto/secrets/#environment-variable-secrets","title":"Environment Variable Secrets","text":"<p>The current MVP supports secrets from environment variables using <code>source: env</code>.</p>"},{"location":"howto/secrets/#basic-usage","title":"Basic Usage","text":"<pre><code>version: 0\nname: secure-workflow\nruntime:\n  provider: openai\n  model_id: gpt-4o-mini\n\nenv:\n  secrets:\n    - name: OPENAI_API_KEY\n      source: env\n      description: \"OpenAI API key\"\n\nagents:\n  assistant:\n    prompt: \"You are a helpful assistant\"\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: assistant\n        prompt: \"Hello!\"\n</code></pre> <p>Set the environment variable before running:</p> <pre><code>export OPENAI_API_KEY=\"sk-...\"\nstrands run workflow.yaml\n</code></pre>"},{"location":"howto/secrets/#referencing-secrets","title":"Referencing Secrets","text":"<p>Use secrets in templates with <code>{{ secrets.NAME }}</code>:</p> <pre><code>tools:\n  http_executors:\n    - id: github_api\n      base_url: https://api.github.com\n      headers:\n        Authorization: \"Bearer {{ secrets.GITHUB_TOKEN }}\"\n      endpoints:\n        - path: /user\n          method: GET\n\nenv:\n  secrets:\n    - name: GITHUB_TOKEN\n      source: env\n      description: \"GitHub personal access token\"\n</code></pre>"},{"location":"howto/secrets/#multiple-secrets","title":"Multiple Secrets","text":"<pre><code>env:\n  secrets:\n    - name: API_KEY\n      source: env\n      description: \"Primary API key\"\n\n    - name: DATABASE_URL\n      source: env\n      description: \"Database connection string\"\n\n    - name: AWS_ACCESS_KEY_ID\n      source: env\n      description: \"AWS access key\"\n\n    - name: AWS_SECRET_ACCESS_KEY\n      source: env\n      description: \"AWS secret key\"\n</code></pre>"},{"location":"howto/secrets/#best-practices","title":"Best Practices","text":""},{"location":"howto/secrets/#1-never-hardcode-secrets","title":"1. Never Hardcode Secrets","text":"<p>\u274c Don't do this:</p> <pre><code>tools:\n  http_executors:\n    - id: api\n      headers:\n        X-API-Key: \"hardcoded-secret-key-123\"  # NEVER DO THIS\n</code></pre> <p>\u2705 Do this instead:</p> <pre><code>tools:\n  http_executors:\n    - id: api\n      headers:\n        X-API-Key: \"{{ secrets.API_KEY }}\"\n\nenv:\n  secrets:\n    - name: API_KEY\n      source: env\n</code></pre>"},{"location":"howto/secrets/#2-use-env-files-locally","title":"2. Use .env Files Locally","text":"<p>Create <code>.env</code> file (add to <code>.gitignore</code>):</p> <pre><code># .env\nOPENAI_API_KEY=sk-proj-...\nGITHUB_TOKEN=ghp_...\nDATABASE_URL=postgresql://user:pass@localhost/db\n</code></pre> <p>Load with your shell or tool:</p> <pre><code># PowerShell\nGet-Content .env | ForEach-Object {\n  $parts = $_ -split '=', 2\n  [Environment]::SetEnvironmentVariable($parts[0], $parts[1], \"Process\")\n}\nstrands run workflow.yaml\n\n# Bash\nexport $(cat .env | xargs)\nstrands run workflow.yaml\n\n# Or use dotenv tool\ndotenv run -- strands run workflow.yaml\n</code></pre>"},{"location":"howto/secrets/#3-document-required-secrets","title":"3. Document Required Secrets","text":"<p>Add clear descriptions:</p> <pre><code>env:\n  secrets:\n    - name: OPENAI_API_KEY\n      source: env\n      description: |\n        OpenAI API key (get from https://platform.openai.com/api-keys)\n        Format: sk-proj-...\n\n    - name: GITHUB_TOKEN\n      source: env\n      description: |\n        GitHub personal access token with 'repo' scope\n        Generate at: https://github.com/settings/tokens\n</code></pre>"},{"location":"howto/secrets/#4-validate-secrets-early","title":"4. Validate Secrets Early","text":"<p>Check secrets exist before workflow runs:</p> <pre><code># PowerShell\nif (-not $env:OPENAI_API_KEY) {\n  Write-Error \"OPENAI_API_KEY not set\"\n  exit 1\n}\nstrands run workflow.yaml\n\n# Bash\nif [ -z \"$OPENAI_API_KEY\" ]; then\n  echo \"Error: OPENAI_API_KEY not set\"\n  exit 1\nfi\nstrands run workflow.yaml\n</code></pre>"},{"location":"howto/secrets/#5-use-secret-scoping","title":"5. Use Secret Scoping","text":"<p>Only declare secrets you actually use:</p> <pre><code># Only declare what you need\nenv:\n  secrets:\n    - name: API_KEY\n      source: env\n\n# Don't declare unused secrets\n</code></pre>"},{"location":"howto/secrets/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"howto/secrets/#github-actions","title":"GitHub Actions","text":"<p>Store secrets in GitHub repository settings, then:</p> <pre><code># .github/workflows/workflow.yml\nname: Run Workflow\non: [push]\n\njobs:\n  run:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.12'\n\n      - name: Install Strands CLI\n        run: pip install strands-cli\n\n      - name: Run workflow\n        env:\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        run: strands run workflow.yaml\n</code></pre>"},{"location":"howto/secrets/#gitlab-ci","title":"GitLab CI","text":"<pre><code># .gitlab-ci.yml\nrun_workflow:\n  image: python:3.12\n  script:\n    - pip install strands-cli\n    - strands run workflow.yaml\n  variables:\n    OPENAI_API_KEY: $OPENAI_API_KEY\n    GITHUB_TOKEN: $GITHUB_TOKEN\n</code></pre> <p>Configure secrets in GitLab CI/CD settings.</p>"},{"location":"howto/secrets/#docker","title":"Docker","text":"<pre><code># Dockerfile\nFROM python:3.12\nRUN pip install strands-cli\nCOPY workflow.yaml .\nCMD [\"strands\", \"run\", \"workflow.yaml\"]\n</code></pre> <p>Run with secrets:</p> <pre><code>docker run -e OPENAI_API_KEY=$OPENAI_API_KEY my-workflow\n</code></pre>"},{"location":"howto/secrets/#common-secret-patterns","title":"Common Secret Patterns","text":""},{"location":"howto/secrets/#aws-credentials","title":"AWS Credentials","text":"<pre><code>env:\n  secrets:\n    - name: AWS_ACCESS_KEY_ID\n      source: env\n      description: \"AWS access key ID\"\n\n    - name: AWS_SECRET_ACCESS_KEY\n      source: env\n      description: \"AWS secret access key\"\n\n    - name: AWS_REGION\n      source: env\n      description: \"AWS region (e.g., us-east-1)\"\n</code></pre> <p>For Bedrock workflows, these are used automatically.</p>"},{"location":"howto/secrets/#api-authentication","title":"API Authentication","text":"<pre><code>env:\n  secrets:\n    - name: API_KEY\n      source: env\n\ntools:\n  http_executors:\n    - id: api\n      base_url: https://api.example.com\n      headers:\n        X-API-Key: \"{{ secrets.API_KEY }}\"\n</code></pre>"},{"location":"howto/secrets/#database-connections","title":"Database Connections","text":"<pre><code>env:\n  secrets:\n    - name: DATABASE_URL\n      source: env\n      description: \"Format: postgresql://user:pass@host:port/db\"\n\n# Use in tools or runtime config\n</code></pre>"},{"location":"howto/secrets/#oauth-tokens","title":"OAuth Tokens","text":"<pre><code>env:\n  secrets:\n    - name: OAUTH_TOKEN\n      source: env\n\ntools:\n  http_executors:\n    - id: api\n      base_url: https://api.example.com\n      auth:\n        type: bearer\n        token: \"{{ secrets.OAUTH_TOKEN }}\"\n</code></pre>"},{"location":"howto/secrets/#security-considerations","title":"Security Considerations","text":""},{"location":"howto/secrets/#pii-redaction","title":"PII Redaction","text":"<p>Enable PII redaction for traces and logs:</p> <pre><code>telemetry:\n  redact:\n    tool_inputs: true\n    tool_outputs: true\n</code></pre> <p>This prevents secrets from appearing in telemetry data.</p>"},{"location":"howto/secrets/#secret-validation","title":"Secret Validation","text":"<p>Secrets are validated at runtime:</p> <ul> <li>Missing secrets cause immediate failure</li> <li>No default values (fail fast if not set)</li> <li>Clear error messages indicate which secret is missing</li> </ul>"},{"location":"howto/secrets/#scope-limitation","title":"Scope Limitation","text":"<p>Secrets are only available: - Within the workflow execution - For template rendering - Not exposed to agents directly - Redacted from traces (when PII redaction enabled)</p>"},{"location":"howto/secrets/#future-aws-secrets-manager","title":"Future: AWS Secrets Manager","text":"<p>Future versions will support AWS Secrets Manager:</p> <pre><code># Future syntax (not yet implemented)\nenv:\n  secrets:\n    - name: API_KEY\n      source: aws_secrets_manager\n      secret_id: \"prod/api/key\"\n      region: \"us-east-1\"\n</code></pre> <p>And AWS Systems Manager Parameter Store:</p> <pre><code># Future syntax (not yet implemented)\nenv:\n  secrets:\n    - name: DATABASE_URL\n      source: aws_ssm\n      parameter_name: \"/app/database/url\"\n      region: \"us-east-1\"\n</code></pre>"},{"location":"howto/secrets/#troubleshooting","title":"Troubleshooting","text":""},{"location":"howto/secrets/#secret-not-found","title":"Secret Not Found","text":"<p>Error: <code>Secret 'API_KEY' not found in environment</code></p> <p>Fix: Set the environment variable:</p> <pre><code>export API_KEY=\"your-key-here\"\n</code></pre>"},{"location":"howto/secrets/#secret-empty","title":"Secret Empty","text":"<p>Error: <code>Secret 'API_KEY' is empty</code></p> <p>Fix: Ensure variable has a value:</p> <pre><code>echo $API_KEY  # Should show value\nexport API_KEY=\"actual-value\"\n</code></pre>"},{"location":"howto/secrets/#template-rendering-error","title":"Template Rendering Error","text":"<p>Error: <code>Failed to render template: 'secrets' is undefined</code></p> <p>Fix: Declare secret in spec:</p> <pre><code>env:\n  secrets:\n    - name: API_KEY\n      source: env\n</code></pre>"},{"location":"howto/secrets/#secret-exposed-in-logs","title":"Secret Exposed in Logs","text":"<p>Fix: Enable PII redaction:</p> <pre><code>telemetry:\n  redact:\n    tool_inputs: true\n    tool_outputs: true\n</code></pre>"},{"location":"howto/secrets/#example-complete-secure-workflow","title":"Example: Complete Secure Workflow","text":"<pre><code>version: 0\nname: secure-api-workflow\ndescription: Demonstrates secure secret management\n\nruntime:\n  provider: openai\n  model_id: gpt-4o-mini\n\n# Declare all required secrets\nenv:\n  secrets:\n    - name: OPENAI_API_KEY\n      source: env\n      description: \"OpenAI API key for LLM calls\"\n\n    - name: GITHUB_TOKEN\n      source: env\n      description: \"GitHub PAT for API access\"\n\n    - name: SLACK_WEBHOOK\n      source: env\n      description: \"Slack webhook URL for notifications\"\n\n# Enable PII redaction\ntelemetry:\n  redact:\n    tool_inputs: true\n    tool_outputs: true\n\nagents:\n  researcher:\n    prompt: \"You research GitHub repositories\"\n\n# Use secrets in tools\ntools:\n  http_executors:\n    - id: github\n      base_url: https://api.github.com\n      headers:\n        Authorization: \"Bearer {{ secrets.GITHUB_TOKEN }}\"\n      endpoints:\n        - path: /repos/{owner}/{repo}\n          method: GET\n\n    - id: slack\n      base_url: \"{{ secrets.SLACK_WEBHOOK }}\"\n      endpoints:\n        - path: \"\"\n          method: POST\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: researcher\n        prompt: \"Get info about tensorflow/tensorflow repo\"\n\n      - agent_id: researcher\n        prompt: \"Send summary to Slack\"\n</code></pre> <p>Run securely:</p> <pre><code># Load secrets from .env\nexport $(cat .env | xargs)\n\n# Verify secrets are set\necho \"Checking secrets...\"\ntest -n \"$OPENAI_API_KEY\" &amp;&amp; echo \"\u2713 OPENAI_API_KEY set\"\ntest -n \"$GITHUB_TOKEN\" &amp;&amp; echo \"\u2713 GITHUB_TOKEN set\"\ntest -n \"$SLACK_WEBHOOK\" &amp;&amp; echo \"\u2713 SLACK_WEBHOOK set\"\n\n# Run workflow\nstrands run secure-api-workflow.yaml --trace\n</code></pre>"},{"location":"howto/secrets/#see-also","title":"See Also","text":"<ul> <li>Tools Guide - Using secrets in HTTP executors</li> <li>Security Model - Security architecture</li> <li>Environment Variables Reference - All env vars</li> </ul>"},{"location":"howto/session-management/","title":"Session Management","text":"<p>Learn how to manage workflow sessions for crash recovery and long-running workflows.</p>"},{"location":"howto/session-management/#overview","title":"Overview","text":"<p>Strands CLI automatically saves workflow execution state (sessions) to enable:</p> <ul> <li>Crash Recovery: Resume workflows after failures without re-executing completed steps</li> <li>Cost Optimization: Avoid re-running expensive LLM calls</li> <li>Long-Running Workflows: Pause and resume multi-hour workflows across CLI sessions</li> <li>Debugging: Inspect workflow state between steps</li> </ul> <p>Sessions are enabled by default and stored in <code>~/.strands/sessions/</code>.</p>"},{"location":"howto/session-management/#basic-session-usage","title":"Basic Session Usage","text":""},{"location":"howto/session-management/#run-with-session-saving-default","title":"Run with Session Saving (Default)","text":"<pre><code># Sessions are automatically saved\nuv run strands run workflow.yaml\n\n# Output includes session ID:\n# Session ID: a1b2c3d4-e5f6-7890-abcd-ef1234567890\n# Running workflow: my-workflow\n# ...\n</code></pre>"},{"location":"howto/session-management/#resume-from-session","title":"Resume from Session","text":"<pre><code># Resume from checkpoint after crash or manual interruption\nuv run strands run --resume a1b2c3d4-e5f6-7890-abcd-ef1234567890\n\n# Output shows skip behavior:\n# Resuming session: a1b2c3d4...\n# Skipping completed step 0: researcher\n# Skipping completed step 1: analyst\n# Executing step 2: writer\n# ...\n</code></pre>"},{"location":"howto/session-management/#disable-session-saving","title":"Disable Session Saving","text":"<pre><code># Run without creating a session\nuv run strands run workflow.yaml --no-save-session\n</code></pre>"},{"location":"howto/session-management/#session-management-commands","title":"Session Management Commands","text":""},{"location":"howto/session-management/#list-sessions","title":"List Sessions","text":"<pre><code># List all sessions\nuv run strands sessions list\n\n# Output (table format):\n# \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n# \u2503 Session ID     \u2503 Workflow       \u2503 Pattern \u2503 Status    \u2503 Updated    \u2503\n# \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n# \u2502 a1b2c3d4...    \u2502 research-chain \u2502 chain   \u2502 running   \u2502 2025-11-09 \u2502\n# \u2502 e5f6g7h8...    \u2502 analysis-dag   \u2502 workflow\u2502 completed \u2502 2025-11-08 \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"howto/session-management/#filter-sessions-by-status","title":"Filter Sessions by Status","text":"<pre><code># Show only running sessions\nuv run strands sessions list --status running\n\n# Show only completed sessions\nuv run strands sessions list --status completed\n\n# Show failed sessions\nuv run strands sessions list --status failed\n\n# Valid statuses: running, paused, completed, failed\n</code></pre>"},{"location":"howto/session-management/#show-session-details","title":"Show Session Details","text":"<pre><code># Display detailed session information\nuv run strands sessions show a1b2c3d4-e5f6-7890-abcd-ef1234567890\n\n# Output (panel format):\n# \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n# \u2503 Session a1b2c3d4...                                    \u2503\n# \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n# \u2502 Session ID: a1b2c3d4-e5f6-7890-abcd-ef1234567890       \u2502\n# \u2502 Workflow: research-chain                               \u2502\n# \u2502 Pattern: chain                                         \u2502\n# \u2502 Status: running                                        \u2502\n# \u2502 Created: 2025-11-09T10:00:00Z                          \u2502\n# \u2502 Updated: 2025-11-09T10:15:00Z                          \u2502\n# \u2502                                                        \u2502\n# \u2502 Variables:                                             \u2502\n# \u2502 {                                                      \u2502\n# \u2502   \"topic\": \"AI agents\",                                \u2502\n# \u2502   \"format\": \"markdown\"                                 \u2502\n# \u2502 }                                                      \u2502\n# \u2502                                                        \u2502\n# \u2502 Token Usage:                                           \u2502\n# \u2502   Total: 5000                                          \u2502\n# \u2502   Input: 3000                                          \u2502\n# \u2502   Output: 2000                                         \u2502\n# \u2502                                                        \u2502\n# \u2502 Pattern State:                                         \u2502\n# \u2502 {                                                      \u2502\n# \u2502   \"current_step\": 2,                                   \u2502\n# \u2502   \"step_history\": [...]                                \u2502\n# \u2502 }                                                      \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"howto/session-management/#delete-sessions","title":"Delete Sessions","text":"<pre><code># Delete a session (with confirmation prompt)\nuv run strands sessions delete a1b2c3d4-e5f6-7890-abcd-ef1234567890\n\n# Prompt:\n# Delete session a1b2c3d4...? [y/N]:\n\n# Skip confirmation with --force\nuv run strands sessions delete a1b2c3d4-e5f6-7890-abcd-ef1234567890 --force\n</code></pre>"},{"location":"howto/session-management/#how-session-resume-works","title":"How Session Resume Works","text":""},{"location":"howto/session-management/#checkpointing","title":"Checkpointing","text":"<p>After each step/task/branch completes, the CLI saves:</p> <ol> <li>Execution State: Current position, completed work, pending work</li> <li>Step/Task Outputs: Full responses from completed steps</li> <li>Token Usage: Cumulative token counts by agent</li> <li>Agent Conversations: Full message history via Strands SDK</li> <li>Spec Snapshot: Original workflow spec for validation</li> </ol>"},{"location":"howto/session-management/#resume-behavior","title":"Resume Behavior","text":"<p>When you resume a session:</p> <ol> <li>Load Session State: CLI loads saved execution state</li> <li>Validate Spec: Warns if workflow spec has changed (but allows execution)</li> <li>Skip Completed Work: Jumps to first incomplete step/task/branch</li> <li>Restore Agent Context: Agents remember previous conversation turns</li> <li>Continue Execution: Executes remaining work with full context</li> </ol>"},{"location":"howto/session-management/#example-3-step-chain-resume","title":"Example: 3-Step Chain Resume","text":"<p>Initial Run: <pre><code>uv run strands run chain-3-step.yaml --var topic=\"AI\"\n\n# Output:\n# Session ID: abc123...\n# Step 1/3: researcher - COMPLETE (2000 tokens)\n# Step 2/3: analyst - COMPLETE (3000 tokens)\n# [Crash or Ctrl+C]\n</code></pre></p> <p>Resume: <pre><code>uv run strands run --resume abc123\n\n# Output:\n# Resuming session: abc123...\n# Skipping completed step 0: researcher\n# Skipping completed step 1: analyst\n# Step 3/3: writer - EXECUTING\n# \u2713 Workflow complete\n# Total tokens: 8000 (5000 from resumed session + 3000 new)\n</code></pre></p>"},{"location":"howto/session-management/#session-storage","title":"Session Storage","text":""},{"location":"howto/session-management/#directory-structure","title":"Directory Structure","text":"<pre><code>~/.strands/sessions/\n\u2514\u2500\u2500 session_a1b2c3d4-e5f6-7890-abcd-ef1234567890/\n    \u251c\u2500\u2500 session.json              # Metadata, variables, token usage\n    \u251c\u2500\u2500 pattern_state.json        # Execution state (pattern-specific)\n    \u251c\u2500\u2500 spec_snapshot.yaml        # Original workflow spec\n    \u2514\u2500\u2500 agents/                   # Strands SDK agent sessions\n        \u251c\u2500\u2500 researcher/\n        \u2502   \u251c\u2500\u2500 agent.json        # Agent state (key-value store)\n        \u2502   \u2514\u2500\u2500 messages/\n        \u2502       \u251c\u2500\u2500 message_0.json\n        \u2502       \u2514\u2500\u2500 message_1.json\n        \u2514\u2500\u2500 analyst/\n            \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"howto/session-management/#file-descriptions","title":"File Descriptions","text":"<ul> <li><code>session.json</code>: Core session metadata (ID, name, status, timestamps, variables, runtime config, token usage, artifacts written)</li> <li><code>pattern_state.json</code>: Pattern-specific execution state:</li> <li>Chain: <code>current_step</code>, <code>step_history</code></li> <li>Workflow: <code>completed_tasks</code>, <code>task_outputs</code></li> <li>Parallel: <code>completed_branches</code>, <code>branch_outputs</code></li> <li>(Other patterns in Phase 3)</li> <li><code>spec_snapshot.yaml</code>: Original workflow spec for hash validation</li> <li><code>agents/&lt;agent_id&gt;/</code>: Strands SDK agent session directory with conversation history</li> </ul>"},{"location":"howto/session-management/#supported-patterns","title":"Supported Patterns","text":""},{"location":"howto/session-management/#phase-2-current","title":"Phase 2 (Current)","text":"<ul> <li>\u2705 Chain: Resume from any step</li> <li>Skips completed steps</li> <li>Restores step outputs in template context: <code>{{ steps[n].response }}</code></li> <li>Preserves agent conversation history</li> </ul>"},{"location":"howto/session-management/#phase-3-planned","title":"Phase 3 (Planned)","text":"<ul> <li>\ud83d\udd1c Workflow: Multi-task DAG resume</li> <li>Tracks completed vs pending tasks</li> <li>Restores task outputs: <code>{{ tasks.&lt;id&gt;.response }}</code></li> <li> <p>Resolves dependencies on resume</p> </li> <li> <p>\ud83d\udd1c Parallel: Branch completion tracking</p> </li> <li>Skips completed branches</li> <li>Re-executes failed branches</li> <li> <p>Restores reduce step state</p> </li> <li> <p>\ud83d\udd1c Routing: Router decision preservation</p> </li> <li>Caches router agent choice</li> <li>Skips router execution on resume</li> <li> <p>Continues with selected agent</p> </li> <li> <p>\ud83d\udd1c Evaluator-Optimizer: Iteration state restoration</p> </li> <li>Preserves iteration history</li> <li>Continues from last iteration</li> <li> <p>Maintains quality gate state</p> </li> <li> <p>\ud83d\udd1c Orchestrator-Workers: Round state tracking</p> </li> <li>Tracks completed rounds</li> <li>Restores worker outputs</li> <li> <p>Preserves orchestrator decisions</p> </li> <li> <p>\ud83d\udd1c Graph: Node history and cycle detection</p> </li> <li>Restores node transition history</li> <li>Preserves iteration counts</li> <li>Continues from current node</li> </ul>"},{"location":"howto/session-management/#spec-change-detection","title":"Spec Change Detection","text":""},{"location":"howto/session-management/#hash-validation","title":"Hash Validation","text":"<p>The CLI computes a SHA256 hash of your workflow spec when creating a session. On resume, it re-hashes the spec and compares:</p> <pre><code># If spec changed:\n# \u26a0 Warning: Spec file has changed since session creation\n# Original: abc123de...\n# Current:  def456gh...\n# Continuing with execution...\n</code></pre>"},{"location":"howto/session-management/#behavior","title":"Behavior","text":"<ul> <li>No Hash Match: Warning logged, but execution continues (allows spec fixes)</li> <li>Recommendation: Only resume with unchanged specs for consistent behavior</li> <li>Use Case: Helpful for fixing typos in prompts or adding missing outputs</li> </ul>"},{"location":"howto/session-management/#advanced-use-cases","title":"Advanced Use Cases","text":""},{"location":"howto/session-management/#manual-session-cleanup","title":"Manual Session Cleanup","text":"<pre><code># List old sessions\nuv run strands sessions list\n\n# Delete completed sessions older than 7 days\nfor session_id in $(strands sessions list --status completed | tail -n +3 | awk '{print $1}'); do\n  uv run strands sessions delete $session_id --force\ndone\n</code></pre>"},{"location":"howto/session-management/#session-inspection-for-debugging","title":"Session Inspection for Debugging","text":"<pre><code># Show detailed session state\nuv run strands sessions show &lt;session-id&gt;\n\n# Manually inspect files\ncat ~/.strands/sessions/session_&lt;uuid&gt;/pattern_state.json | jq .\n\n# View agent conversation\ncat ~/.strands/sessions/session_&lt;uuid&gt;/agents/researcher/messages/message_0.json | jq .\n</code></pre>"},{"location":"howto/session-management/#resume-with-variable-overrides","title":"Resume with Variable Overrides","text":"<p>Not supported in Phase 2: Resume uses original session variables. Variable overrides are ignored.</p> <p>Workaround: Modify <code>session.json</code> manually before resuming (advanced users only).</p>"},{"location":"howto/session-management/#troubleshooting","title":"Troubleshooting","text":""},{"location":"howto/session-management/#session-not-found","title":"Session Not Found","text":"<pre><code>uv run strands run --resume invalid-id\n\n# Error: Session not found: invalid-id\n# Exit code: 2 (EX_USAGE)\n</code></pre> <p>Solution: List sessions with <code>strands sessions list</code> to find valid IDs.</p>"},{"location":"howto/session-management/#session-already-completed","title":"Session Already Completed","text":"<pre><code>uv run strands run --resume &lt;completed-session-id&gt;\n\n# Error: Session already completed: &lt;session-id&gt;\n# Exit code: 2 (EX_USAGE)\n</code></pre> <p>Solution: Completed sessions cannot be resumed. Start a new execution instead.</p>"},{"location":"howto/session-management/#spec-hash-mismatch","title":"Spec Hash Mismatch","text":"<pre><code># Warning: Spec file has changed since session creation\n</code></pre> <p>Solution: If intentional (e.g., fixing typos), ignore warning. If accidental, restore original spec from <code>spec_snapshot.yaml</code>.</p>"},{"location":"howto/session-management/#session-corruption","title":"Session Corruption","text":"<p>Symptoms: JSON parse errors, missing files in session directory</p> <p>Solution: Delete corrupted session and re-run workflow: <pre><code>uv run strands sessions delete &lt;session-id&gt; --force\nuv run strands run workflow.yaml\n</code></pre></p>"},{"location":"howto/session-management/#best-practices","title":"Best Practices","text":"<ol> <li>Monitor Session IDs: Save session IDs from CLI output for later resumption</li> <li>Clean Up Regularly: Delete old completed sessions to save disk space</li> <li>Use Stable Specs: Avoid modifying specs mid-execution for consistent behavior</li> <li>Backup Critical Sessions: Copy session directories before manual edits</li> <li>Leverage --force: Use <code>--force</code> flag for automated cleanup scripts</li> </ol>"},{"location":"howto/session-management/#limitations-v0120-phase-2","title":"Limitations (v0.12.0 - Phase 2)","text":"<ul> <li>Single Pattern Support: Only chain pattern supports resume (Phase 3 adds other patterns)</li> <li>File Storage Only: Sessions stored locally in <code>~/.strands/sessions/</code> (cloud storage in Phase 4)</li> <li>No Concurrent Safety: File locking not implemented yet (Phase 4)</li> <li>Manual Cleanup: No automatic session expiration (Phase 4)</li> <li>No Auto-Resume: Must manually specify <code>--resume</code> flag (Phase 4 adds <code>--auto-resume</code>)</li> <li>No Variable Override on Resume: Resume uses original session variables (Phase 3+)</li> </ul>"},{"location":"howto/session-management/#next-steps","title":"Next Steps","text":"<ul> <li>Phase 3: Multi-pattern resume for all 7 workflow patterns</li> <li>Phase 4: S3 storage, file locking, auto-cleanup, auto-resume on failure</li> <li>Phase 11: \u2705 COMPLETE - Human-in-the-loop with approval gates (See HITL Guide)</li> </ul>"},{"location":"howto/session-management/#session-architecture","title":"Session Architecture","text":""},{"location":"howto/session-management/#storage-structure","title":"Storage Structure","text":"<p>Sessions are stored in <code>~/.strands/sessions/</code> with the following structure:</p> <pre><code>~/.strands/sessions/session_&lt;uuid&gt;/\n\u251c\u2500\u2500 session.json              # Metadata, variables, runtime config, token usage\n\u251c\u2500\u2500 pattern_state.json        # Pattern-specific execution state\n\u251c\u2500\u2500 spec_snapshot.yaml        # Original workflow spec for validation\n\u2514\u2500\u2500 agents/                   # Strands SDK agent sessions\n    \u251c\u2500\u2500 &lt;agent_id&gt;/\n    \u2502   \u251c\u2500\u2500 agent.json        # Agent state (key-value store)\n    \u2502   \u2514\u2500\u2500 messages/\n    \u2502       \u2514\u2500\u2500 message_*.json # Conversation history\n</code></pre>"},{"location":"howto/session-management/#session-state-components","title":"Session State Components","text":"<p>Each session captures:</p> <ul> <li>Metadata: Session ID, workflow name, pattern type, status, timestamps</li> <li>Variables: User-provided variables from <code>--var</code> flags</li> <li>Runtime Config: Provider, model ID, region, and other runtime settings</li> <li>Pattern State: Pattern-specific execution state (current step, completed tasks, etc.)</li> <li>Token Usage: Cumulative token counts by agent for cost tracking</li> <li>Agent Sessions: Full conversation history managed by Strands SDK FileSessionManager</li> <li>Artifacts: List of output files already written</li> </ul>"},{"location":"howto/session-management/#checkpointing-behavior","title":"Checkpointing Behavior","text":"<p>The CLI automatically checkpoints after each significant execution milestone:</p> <ul> <li>Chain: After each step completes</li> <li>Workflow: After each task completes</li> <li>Parallel: After each branch completes</li> <li>Routing: After router decision and selected agent execution</li> <li>Evaluator-Optimizer: After each iteration</li> <li>Orchestrator-Workers: After each round and reduce step</li> <li>Graph: After each node transition</li> </ul>"},{"location":"howto/session-management/#roadmap","title":"Roadmap","text":"<p>Current (v0.12.0 - Phase 2): - \u2705 Chain pattern resume - \u2705 File-based storage - \u2705 Session management CLI</p> <p>Upcoming (Phase 3): - \ud83d\udd1c Multi-pattern resume (workflow, parallel, routing, evaluator-optimizer, orchestrator-workers, graph) - \ud83d\udd1c Variable override on resume</p> <p>Future (Phase 4): - \ud83d\udd1c File locking for concurrent execution safety - \ud83d\udd1c Automatic session cleanup and expiration - \ud83d\udd1c Auto-resume on failure flag - \ud83d\udd1c Performance optimizations (lazy loading)</p>"},{"location":"howto/session-management/#related-documentation","title":"Related Documentation","text":"<ul> <li>Session API Reference - Pydantic models and repository API</li> <li>Workflow Manual - Workflow spec reference</li> <li>Exit Codes - CLI exit code meanings</li> </ul>"},{"location":"howto/telemetry/","title":"How to Use Telemetry and Observability","text":"<p>This guide shows you how to enable OpenTelemetry tracing, export traces, enable debug logging, and redact PII in Strands workflows.</p>"},{"location":"howto/telemetry/#quick-start","title":"Quick Start","text":""},{"location":"howto/telemetry/#enable-trace-export","title":"Enable Trace Export","text":"<p>Add <code>--trace</code> flag to export the execution trace:</p> <pre><code>strands run workflow.yaml --trace\n</code></pre> <p>This creates <code>artifacts/&lt;workflow-name&gt;-trace.json</code> with complete execution details.</p>"},{"location":"howto/telemetry/#enable-debug-logging","title":"Enable Debug Logging","text":"<p>Use <code>--debug</code> for detailed structured logs:</p> <pre><code>strands run workflow.yaml --debug\n</code></pre> <p>Debug mode shows: - Variable resolution - Template rendering - Agent invocations - Tool executions - Context management operations</p>"},{"location":"howto/telemetry/#enable-verbose-output","title":"Enable Verbose Output","text":"<p>Add <code>--verbose</code> for more console output:</p> <pre><code>strands run workflow.yaml --verbose --debug\n</code></pre>"},{"location":"howto/telemetry/#opentelemetry-configuration","title":"OpenTelemetry Configuration","text":""},{"location":"howto/telemetry/#otlp-export-to-collector","title":"OTLP Export to Collector","text":"<p>Configure OTLP export in your workflow spec:</p> <pre><code>version: 0\nname: my-workflow\nruntime:\n  provider: openai\n  model_id: gpt-4o-mini\n\ntelemetry:\n  otel:\n    endpoint: \"http://localhost:4318/v1/traces\"\n    service_name: \"my-workflow\"\n    sample_ratio: 1.0\n\nagents:\n  analyst:\n    prompt: \"Analyze the data\"\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: analyst\n        prompt: \"Analyze {{ topic }}\"\n</code></pre>"},{"location":"howto/telemetry/#otlp-endpoints","title":"OTLP Endpoints","text":"<p>Common collector endpoints:</p> Platform Endpoint Jaeger <code>http://localhost:4318/v1/traces</code> Zipkin <code>http://localhost:9411/api/v2/spans</code> Honeycomb <code>https://api.honeycomb.io/v1/traces</code> New Relic <code>https://otlp.nr-data.net/v1/traces</code> Datadog <code>http://localhost:4318/v1/traces</code>"},{"location":"howto/telemetry/#environment-variables","title":"Environment Variables","text":"<p>Override telemetry settings via environment:</p> <pre><code>export OTEL_EXPORTER_OTLP_ENDPOINT=\"http://localhost:4318/v1/traces\"\nexport OTEL_SERVICE_NAME=\"production-workflow\"\nexport STRANDS_DEBUG=true\n</code></pre>"},{"location":"howto/telemetry/#trace-artifacts","title":"Trace Artifacts","text":""},{"location":"howto/telemetry/#using-trace-variable","title":"Using <code>{{ $TRACE }}</code> Variable","text":"<p>Include trace in workflow artifacts:</p> <pre><code>outputs:\n  artifacts:\n    - path: \"./artifacts/trace.json\"\n      from: \"{{ $TRACE }}\"\n</code></pre> <p>This renders the complete execution trace as JSON.</p>"},{"location":"howto/telemetry/#trace-structure","title":"Trace Structure","text":"<p>Trace JSON contains:</p> <pre><code>{\n  \"trace_id\": \"unique-trace-id\",\n  \"spec_name\": \"workflow-name\",\n  \"pattern\": \"chain\",\n  \"duration_ms\": 3421,\n  \"spans\": [\n    {\n      \"name\": \"execute.chain\",\n      \"span_id\": \"span-id\",\n      \"start_time\": \"2025-11-09T10:30:00Z\",\n      \"end_time\": \"2025-11-09T10:30:03Z\",\n      \"attributes\": {\n        \"spec.name\": \"workflow-name\",\n        \"pattern.type\": \"chain\",\n        \"runtime.provider\": \"openai\"\n      },\n      \"events\": [\n        {\n          \"name\": \"step_start\",\n          \"timestamp\": \"2025-11-09T10:30:00Z\",\n          \"attributes\": {\"step.index\": 0}\n        }\n      ],\n      \"status\": \"OK\"\n    }\n  ]\n}\n</code></pre>"},{"location":"howto/telemetry/#analyzing-traces","title":"Analyzing Traces","text":"<p>Use trace data to:</p> <ul> <li>Debug workflow execution issues</li> <li>Identify performance bottlenecks</li> <li>Track token usage per step</li> <li>Monitor error rates</li> <li>Audit LLM interactions</li> </ul>"},{"location":"howto/telemetry/#pii-redaction","title":"PII Redaction","text":""},{"location":"howto/telemetry/#enable-redaction","title":"Enable Redaction","text":"<p>Protect sensitive data in traces:</p> <pre><code>telemetry:\n  redact:\n    tool_inputs: true\n    tool_outputs: true\n</code></pre>"},{"location":"howto/telemetry/#built-in-pii-patterns","title":"Built-in PII Patterns","text":"<p>Automatically redacts:</p> <ul> <li>Email addresses: <code>user@example.com</code> \u2192 <code>***REDACTED***</code></li> <li>Credit cards: <code>4111-1111-1111-1111</code> \u2192 <code>***REDACTED***</code></li> <li>SSN: <code>123-45-6789</code> \u2192 <code>***REDACTED***</code></li> <li>Phone numbers: <code>555-123-4567</code> \u2192 <code>***REDACTED***</code></li> <li>API keys: <code>sk_live_abc123...</code> \u2192 <code>***REDACTED***</code></li> </ul>"},{"location":"howto/telemetry/#custom-redaction-patterns","title":"Custom Redaction Patterns","text":"<p>Add domain-specific patterns:</p> <pre><code>telemetry:\n  redact:\n    tool_inputs: true\n    tool_outputs: true\n    custom_patterns:\n      # AWS Access Keys\n      - \"\\\\b(A3T[A-Z0-9]|AKIA|AGPA|AIDA|AROA|AIPA|ANPA|ANVA|ASIA)[A-Z0-9]{16}\\\\b\"\n      # GitHub Tokens\n      - \"\\\\bghp_[A-Za-z0-9]{36}\\\\b\"\n      # Custom internal IDs\n      - \"\\\\bINT-[0-9]{8}\\\\b\"\n</code></pre> <p>Patterns use Python regex syntax.</p>"},{"location":"howto/telemetry/#debug-logging","title":"Debug Logging","text":""},{"location":"howto/telemetry/#enable-debug-mode","title":"Enable Debug Mode","text":"<pre><code>strands run workflow.yaml --debug\n</code></pre> <p>Debug logs show:</p> <pre><code>{\n  \"event\": \"variable_resolution\",\n  \"timestamp\": \"2025-11-09T10:30:00Z\",\n  \"variables\": {\n    \"topic\": \"AI safety\",\n    \"format\": \"markdown\"\n  }\n}\n\n{\n  \"event\": \"template_render\",\n  \"timestamp\": \"2025-11-09T10:30:00Z\",\n  \"template\": \"Analyze {{ topic }}\",\n  \"result\": \"Analyze AI safety\"\n}\n\n{\n  \"event\": \"agent_invoke\",\n  \"timestamp\": \"2025-11-09T10:30:01Z\",\n  \"agent_id\": \"analyst\",\n  \"prompt\": \"Analyze AI safety\",\n  \"model\": \"gpt-4o-mini\"\n}\n\n{\n  \"event\": \"llm_response\",\n  \"timestamp\": \"2025-11-09T10:30:03Z\",\n  \"tokens_used\": 1234,\n  \"response_length\": 567\n}\n</code></pre>"},{"location":"howto/telemetry/#debug-with-verbose","title":"Debug with Verbose","text":"<p>Combine for maximum visibility:</p> <pre><code>strands run workflow.yaml --debug --verbose\n</code></pre> <p>Shows both structured JSON logs and human-readable console output.</p>"},{"location":"howto/telemetry/#span-hierarchy","title":"Span Hierarchy","text":"<p>Strands emits structured spans for all workflow patterns:</p>"},{"location":"howto/telemetry/#chain-pattern","title":"Chain Pattern","text":"<pre><code>execute.chain\n\u251c\u2500\u2500 step.0\n\u2502   \u251c\u2500\u2500 agent.invoke\n\u2502   \u2502   \u251c\u2500\u2500 llm.request\n\u2502   \u2502   \u2514\u2500\u2500 tool.http_request\n\u2502   \u2514\u2500\u2500 template.render\n\u2514\u2500\u2500 step.1\n    \u2514\u2500\u2500 agent.invoke\n</code></pre>"},{"location":"howto/telemetry/#workflow-pattern-dag","title":"Workflow Pattern (DAG)","text":"<pre><code>execute.workflow\n\u251c\u2500\u2500 task.overview\n\u2502   \u2514\u2500\u2500 agent.invoke\n\u251c\u2500\u2500 task.technical (parallel)\n\u2502   \u2514\u2500\u2500 agent.invoke\n\u2514\u2500\u2500 task.business (parallel)\n    \u2514\u2500\u2500 agent.invoke\n</code></pre>"},{"location":"howto/telemetry/#parallel-pattern","title":"Parallel Pattern","text":"<pre><code>execute.parallel\n\u251c\u2500\u2500 branch.technical\n\u2502   \u2514\u2500\u2500 step.0\n\u2502       \u2514\u2500\u2500 agent.invoke\n\u251c\u2500\u2500 branch.business\n\u2502   \u2514\u2500\u2500 step.0\n\u2502       \u2514\u2500\u2500 agent.invoke\n\u2514\u2500\u2500 reduce\n    \u2514\u2500\u2500 agent.invoke\n</code></pre>"},{"location":"howto/telemetry/#best-practices","title":"Best Practices","text":""},{"location":"howto/telemetry/#production-deployments","title":"Production Deployments","text":"<ol> <li>Use OTLP endpoint for centralized trace collection</li> <li>Set appropriate sample_ratio (e.g., 0.1 for 10% sampling)</li> <li>Enable PII redaction for sensitive data</li> <li>Monitor trace storage - high volume can be costly</li> </ol> <p>Example production config:</p> <pre><code>telemetry:\n  otel:\n    endpoint: \"https://otlp.company.com/v1/traces\"\n    service_name: \"production-workflow\"\n    sample_ratio: 0.1\n  redact:\n    tool_inputs: true\n    tool_outputs: true\n</code></pre>"},{"location":"howto/telemetry/#development-workflows","title":"Development Workflows","text":"<ol> <li>Use --trace flag for quick exports</li> <li>Enable --debug for troubleshooting</li> <li>Use console exporter for local testing</li> <li>Keep sample_ratio at 1.0 to capture everything</li> </ol> <p>Example development config:</p> <pre><code>telemetry:\n  otel:\n    exporter: console\n    sample_ratio: 1.0\n</code></pre>"},{"location":"howto/telemetry/#troubleshooting-with-traces","title":"Troubleshooting with Traces","text":"<ol> <li>Check span hierarchy for execution flow</li> <li>Review span attributes for configuration</li> <li>Examine span events for timing details</li> <li>Filter by error.type to find failures</li> </ol>"},{"location":"howto/telemetry/#performance-analysis","title":"Performance Analysis","text":"<p>Use trace data to identify:</p> <ul> <li>Long-running steps: High <code>duration_ms</code> in step spans</li> <li>Token usage: <code>tokens.total</code> attributes</li> <li>Retry patterns: Multiple <code>llm.request</code> spans</li> <li>Tool performance: <code>tool.*</code> span durations</li> </ul>"},{"location":"howto/telemetry/#common-use-cases","title":"Common Use Cases","text":""},{"location":"howto/telemetry/#debugging-failed-workflows","title":"Debugging Failed Workflows","text":"<pre><code># Run with full tracing and debug logging\nstrands run workflow.yaml --trace --debug --verbose\n\n# Check artifacts/workflow-trace.json for error details\ncat artifacts/workflow-trace.json | jq '.spans[] | select(.status == \"ERROR\")'\n</code></pre>"},{"location":"howto/telemetry/#monitoring-production-workflows","title":"Monitoring Production Workflows","text":"<pre><code># Send to centralized collector\ntelemetry:\n  otel:\n    endpoint: \"https://otlp.company.com/v1/traces\"\n    service_name: \"production-workflow\"\n    sample_ratio: 0.1  # Sample 10%\n  redact:\n    tool_inputs: true\n    tool_outputs: true\n</code></pre>"},{"location":"howto/telemetry/#local-development-testing","title":"Local Development Testing","text":"<pre><code># Console output for quick inspection\nstrands run workflow.yaml --debug\n\n# Or use console exporter in spec\ntelemetry:\n  otel:\n    exporter: console\n</code></pre>"},{"location":"howto/telemetry/#see-also","title":"See Also","text":"<ul> <li>Environment Reference - Environment variables</li> <li>Schema Reference - Complete telemetry configuration</li> <li>Security Model</li> </ul>"},{"location":"howto/tools/","title":"How to Work with Tools","text":"<p>This guide shows you how to use tools in Strands workflows, including HTTP executors, Python tools, and file operations.</p>"},{"location":"howto/tools/#tool-types","title":"Tool Types","text":"<p>Strands supports three types of tools:</p> <ol> <li>Python Tools - Native Python functions (allowlisted)</li> <li>HTTP Executors - REST API integrations</li> <li>MCP Servers - Model Context Protocol integrations</li> </ol>"},{"location":"howto/tools/#python-tools","title":"Python Tools","text":""},{"location":"howto/tools/#allowlisted-python-tools","title":"Allowlisted Python Tools","text":"<p>For security, only allowlisted Python callables can be used:</p> <p>Legacy Tools: - <code>strands_tools.http_request</code> - Make HTTP requests - <code>strands_tools.file_read</code> - Read files (with consent) - <code>strands_tools.file_write</code> - Write files (with consent)</p> <p>Native Tools (auto-discovered): - <code>python_exec</code> - Execute Python code in sandbox - Plus any custom tools in <code>src/strands_cli/tools/</code></p>"},{"location":"howto/tools/#using-python-tools","title":"Using Python Tools","text":"<pre><code>version: 0\nname: python-tools-demo\nruntime:\n  provider: openai\n  model_id: gpt-4o-mini\n\nagents:\n  coder:\n    prompt: \"You write and execute Python code to solve problems.\"\n\ntools:\n  python:\n    - python_exec\n    - strands_tools.http_request\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: coder\n        prompt: \"Calculate the first 10 Fibonacci numbers using Python\"\n</code></pre>"},{"location":"howto/tools/#python-execution-tool","title":"Python Execution Tool","text":"<p>The <code>python_exec</code> tool runs Python code in a controlled environment:</p> <pre><code>tools:\n  python:\n    - python_exec\n</code></pre> <p>Agent can request code execution:</p> <pre><code># Agent provides this as tool input\n{\n  \"code\": \"result = sum(range(1, 101))\\nprint(result)\",\n  \"timeout\": 5\n}\n\n# Tool returns\n{\n  \"stdout\": \"5050\",\n  \"stderr\": \"\",\n  \"exit_code\": 0\n}\n</code></pre> <p>Security: Code runs in subprocess with timeout and no network access.</p>"},{"location":"howto/tools/#file-operations","title":"File Operations","text":"<p>Read files with consent:</p> <pre><code>tools:\n  python:\n    - strands_tools.file_read\n\nenv:\n  filesystem:\n    read_paths:\n      - path: ./data\n        consent: true\n      - path: ./config.yaml\n        consent: true\n</code></pre> <p>Write files with consent:</p> <pre><code>tools:\n  python:\n    - strands_tools.file_write\n\nenv:\n  filesystem:\n    write_paths:\n      - path: ./output\n        consent: true\n</code></pre>"},{"location":"howto/tools/#http-executors","title":"HTTP Executors","text":""},{"location":"howto/tools/#basic-http-tool","title":"Basic HTTP Tool","text":"<p>Make REST API calls:</p> <pre><code>version: 0\nname: http-demo\nruntime:\n  provider: openai\n  model_id: gpt-4o-mini\n\nagents:\n  researcher:\n    prompt: \"You research information using APIs.\"\n\ntools:\n  http_executors:\n    - id: github_api\n      base_url: https://api.github.com\n      description: \"GitHub REST API\"\n      endpoints:\n        - path: /repos/{owner}/{repo}\n          method: GET\n          description: \"Get repository information\"\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: researcher\n        prompt: \"Get info about the tensorflow/tensorflow repository\"\n</code></pre>"},{"location":"howto/tools/#http-executor-configuration","title":"HTTP Executor Configuration","text":"<pre><code>tools:\n  http_executors:\n    - id: my_api\n      base_url: https://api.example.com\n      description: \"Example API\"\n\n      # Optional: Headers\n      headers:\n        Accept: application/json\n        User-Agent: Strands-CLI/0.2.0\n\n      # Optional: Authentication\n      auth:\n        type: bearer\n        token: \"{{ secrets.api_token }}\"\n\n      # Endpoints\n      endpoints:\n        - path: /users/{id}\n          method: GET\n          description: \"Get user by ID\"\n\n        - path: /users\n          method: POST\n          description: \"Create new user\"\n          body_schema:\n            type: object\n            properties:\n              name:\n                type: string\n              email:\n                type: string\n</code></pre>"},{"location":"howto/tools/#authentication-types","title":"Authentication Types","text":"<p>Bearer Token:</p> <pre><code>tools:\n  http_executors:\n    - id: api\n      base_url: https://api.example.com\n      auth:\n        type: bearer\n        token: \"{{ secrets.api_token }}\"\n</code></pre> <p>Basic Auth:</p> <pre><code>tools:\n  http_executors:\n    - id: api\n      base_url: https://api.example.com\n      auth:\n        type: basic\n        username: \"{{ secrets.api_user }}\"\n        password: \"{{ secrets.api_pass }}\"\n</code></pre> <p>API Key:</p> <pre><code>tools:\n  http_executors:\n    - id: api\n      base_url: https://api.example.com\n      headers:\n        X-API-Key: \"{{ secrets.api_key }}\"\n</code></pre>"},{"location":"howto/tools/#path-parameters","title":"Path Parameters","text":"<p>Use <code>{param}</code> syntax for dynamic paths:</p> <pre><code>tools:\n  http_executors:\n    - id: github\n      base_url: https://api.github.com\n      endpoints:\n        - path: /repos/{owner}/{repo}/issues/{issue_number}\n          method: GET\n          description: \"Get issue details\"\n</code></pre> <p>Agent provides parameters:</p> <pre><code>{\n  \"owner\": \"tensorflow\",\n  \"repo\": \"tensorflow\",\n  \"issue_number\": 12345\n}\n</code></pre>"},{"location":"howto/tools/#request-bodies","title":"Request Bodies","text":"<p>Define schema for POST/PUT requests:</p> <pre><code>tools:\n  http_executors:\n    - id: api\n      base_url: https://api.example.com\n      endpoints:\n        - path: /comments\n          method: POST\n          description: \"Create comment\"\n          body_schema:\n            type: object\n            properties:\n              text:\n                type: string\n                description: \"Comment text\"\n              author:\n                type: string\n                description: \"Author name\"\n            required: [text, author]\n</code></pre>"},{"location":"howto/tools/#mcp-server-integration","title":"MCP Server Integration","text":""},{"location":"howto/tools/#enable-mcp-servers","title":"Enable MCP Servers","text":"<p>Use Model Context Protocol servers:</p> <pre><code>version: 0\nname: mcp-demo\nruntime:\n  provider: openai\n  model_id: gpt-4o-mini\n\nagents:\n  analyst:\n    prompt: \"You analyze files using MCP tools.\"\n\ntools:\n  mcp_servers:\n    filesystem:\n      command: npx\n      args:\n        - -y\n        - \"@modelcontextprotocol/server-filesystem\"\n        - /path/to/allowed/directory\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: analyst\n        prompt: \"List files in the directory and read README.md\"\n</code></pre>"},{"location":"howto/tools/#multiple-mcp-servers","title":"Multiple MCP Servers","text":"<pre><code>tools:\n  mcp_servers:\n    filesystem:\n      command: npx\n      args: [\"-y\", \"@modelcontextprotocol/server-filesystem\", \"./data\"]\n\n    sqlite:\n      command: npx\n      args: [\"-y\", \"@modelcontextprotocol/server-sqlite\", \"./db.sqlite\"]\n\n    github:\n      command: npx\n      args: [\"-y\", \"@modelcontextprotocol/server-github\"]\n      env:\n        GITHUB_TOKEN: \"{{ secrets.github_token }}\"\n</code></pre>"},{"location":"howto/tools/#mcp-tool-usage","title":"MCP Tool Usage","text":"<p>MCP servers expose tools that agents can call:</p> <pre><code># MCP filesystem server provides:\n# - read_file(path)\n# - write_file(path, content)\n# - list_directory(path)\n# - search_files(pattern)\n\n# Agent can use these tools automatically\npattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: analyst\n        prompt: |\n          Read the file 'config.yaml' and analyze its structure.\n          List all JSON files in the current directory.\n</code></pre>"},{"location":"howto/tools/#tool-security","title":"Tool Security","text":""},{"location":"howto/tools/#allowlisting","title":"Allowlisting","text":"<p>Only allowlisted Python callables are permitted:</p> <pre><code># Allowed (built-in)\n- python_exec\n- strands_tools.http_request\n- strands_tools.file_read\n- strands_tools.file_write\n\n# Not allowed (will fail validation)\n- os.system\n- subprocess.run\n- eval\n- exec\n</code></pre>"},{"location":"howto/tools/#file-access-control","title":"File Access Control","text":"<p>Require explicit consent for file operations:</p> <pre><code>env:\n  filesystem:\n    read_paths:\n      - path: ./data\n        consent: true  # Explicit consent required\n\n    write_paths:\n      - path: ./output\n        consent: true\n</code></pre>"},{"location":"howto/tools/#http-security","title":"HTTP Security","text":"<p>SSRF Prevention: HTTP executors validate URLs against: - No private IP ranges (10.x, 192.168.x, 127.x) - No file:// or other dangerous schemes - Only http:// and https:// allowed</p> <p>Path Traversal Prevention: Paths are sanitized to prevent <code>../</code> attacks.</p>"},{"location":"howto/tools/#common-patterns","title":"Common Patterns","text":""},{"location":"howto/tools/#api-integration","title":"API Integration","text":"<pre><code>tools:\n  http_executors:\n    - id: weather_api\n      base_url: https://api.weather.com\n      headers:\n        X-API-Key: \"{{ secrets.weather_key }}\"\n      endpoints:\n        - path: /current/{city}\n          method: GET\n          description: \"Get current weather\"\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: assistant\n        prompt: \"What's the weather in {{ city }}?\"\n</code></pre>"},{"location":"howto/tools/#file-analysis","title":"File Analysis","text":"<pre><code>tools:\n  python:\n    - strands_tools.file_read\n\nenv:\n  filesystem:\n    read_paths:\n      - path: ./logs\n        consent: true\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: analyst\n        prompt: \"Read error.log and summarize the errors\"\n</code></pre>"},{"location":"howto/tools/#code-execution","title":"Code Execution","text":"<pre><code>tools:\n  python:\n    - python_exec\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: coder\n        prompt: |\n          Write Python code to:\n          1. Generate 100 random numbers\n          2. Calculate mean and standard deviation\n          3. Print results\n</code></pre>"},{"location":"howto/tools/#multi-tool-workflow","title":"Multi-Tool Workflow","text":"<pre><code>tools:\n  python:\n    - python_exec\n    - strands_tools.http_request\n\n  http_executors:\n    - id: github_api\n      base_url: https://api.github.com\n      endpoints:\n        - path: /repos/{owner}/{repo}\n          method: GET\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: researcher\n        prompt: \"Fetch tensorflow repo info from GitHub\"\n\n      - agent_id: analyst\n        prompt: |\n          Analyze this data using Python:\n          {{ steps[0].response }}\n\n          Calculate repository age in days.\n</code></pre>"},{"location":"howto/tools/#tool-override-per-agent","title":"Tool Override per Agent","text":"<p>Override tools for specific agents:</p> <pre><code>agents:\n  analyst:\n    prompt: \"You analyze data\"\n    tools:\n      - python_exec  # Only this tool for this agent\n\n  researcher:\n    prompt: \"You research information\"\n    tools:\n      - strands_tools.http_request\n\n# Global tools (used by agents without tool overrides)\ntools:\n  python:\n    - python_exec\n    - strands_tools.file_read\n</code></pre>"},{"location":"howto/tools/#developing-custom-native-tools","title":"Developing Custom Native Tools","text":"<p>Create new tools in <code>src/strands_cli/tools/</code>:</p> <pre><code># src/strands_cli/tools/my_tool.py\nfrom typing import Any\n\nTOOL_SPEC = {\n    \"name\": \"my_tool\",\n    \"description\": \"Does something useful\",\n    \"inputSchema\": {\n        \"json\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"param\": {\n                    \"type\": \"string\",\n                    \"description\": \"Parameter description\"\n                }\n            },\n            \"required\": [\"param\"]\n        }\n    }\n}\n\ndef my_tool(tool: dict[str, Any], **kwargs: Any) -&gt; dict[str, Any]:\n    tool_use_id = tool.get(\"toolUseId\", \"\")\n    tool_input = tool.get(\"input\", {})\n    param = tool_input.get(\"param\", \"\")\n\n    # Process...\n    result = f\"Processed: {param}\"\n\n    return {\n        \"toolUseId\": tool_use_id,\n        \"status\": \"success\",\n        \"content\": [{\"text\": result}]\n    }\n</code></pre> <p>Tool is auto-discovered and available as <code>my_tool</code> in workflows.</p> <p>See Tool Development Guide for complete documentation.</p>"},{"location":"howto/tools/#troubleshooting","title":"Troubleshooting","text":""},{"location":"howto/tools/#tool-not-found","title":"Tool Not Found","text":"<p>Error: <code>Tool 'my_tool' not in allowlist</code></p> <p>Fix: Ensure tool is: 1. In allowlist (legacy tools or native tools with TOOL_SPEC) 2. Correctly referenced in workflow (check spelling) 3. Exported with TOOL_SPEC (for native tools)</p>"},{"location":"howto/tools/#http-executor-fails","title":"HTTP Executor Fails","text":"<p>Error: <code>HTTP request failed: 403 Forbidden</code></p> <p>Fix: Check: 1. Authentication credentials are correct 2. Headers are properly configured 3. Endpoint path matches API documentation 4. Base URL is correct (no trailing slash issues)</p>"},{"location":"howto/tools/#mcp-server-wont-start","title":"MCP Server Won't Start","text":"<p>Error: <code>Failed to start MCP server: command not found</code></p> <p>Fix: 1. Ensure command is installed (<code>npx</code>, <code>python</code>, etc.) 2. Check MCP server package is available 3. Verify environment variables are set 4. Check file paths are absolute</p>"},{"location":"howto/tools/#file-access-denied","title":"File Access Denied","text":"<p>Error: <code>File access denied: ./data/file.txt</code></p> <p>Fix: Add explicit consent:</p> <pre><code>env:\n  filesystem:\n    read_paths:\n      - path: ./data\n        consent: true\n</code></pre>"},{"location":"howto/tools/#see-also","title":"See Also","text":"<ul> <li>Tool Development Guide</li> <li>Security Model</li> <li>Secrets Management</li> <li>Spec Reference: Tools</li> </ul>"},{"location":"howto/validate-workflows/","title":"How to Validate Workflows","text":"<p>This guide shows you how to validate your Strands workflow specifications before execution.</p>"},{"location":"howto/validate-workflows/#basic-validation","title":"Basic Validation","text":"<p>Use the <code>validate</code> command to check your workflow against the JSON Schema:</p> <pre><code>strands validate workflow.yaml\n</code></pre> <p>If validation succeeds, you'll see:</p> <pre><code>\u2713 Workflow validation successful\n</code></pre>"},{"location":"howto/validate-workflows/#understanding-validation-errors","title":"Understanding Validation Errors","text":"<p>When validation fails, Strands provides detailed error messages with JSONPointer paths to help you locate the issue.</p>"},{"location":"howto/validate-workflows/#example-missing-required-field","title":"Example: Missing Required Field","text":"<pre><code>strands validate workflow.yaml\n</code></pre> <p>Error output:</p> <pre><code>\u2717 Schema validation failed:\n  /runtime/provider: 'provider' is a required property\n</code></pre> <p>Fix: Add the missing <code>provider</code> field to your runtime configuration:</p> <pre><code>runtime:\n  provider: bedrock\n  model: anthropic.claude-3-sonnet-20240229-v1:0\n</code></pre>"},{"location":"howto/validate-workflows/#example-invalid-pattern-type","title":"Example: Invalid Pattern Type","text":"<p>Error output:</p> <pre><code>\u2717 Schema validation failed:\n  /pattern/type: 'invalid_pattern' is not one of ['chain', 'workflow', 'routing', 'parallel', 'evaluator_optimizer', 'orchestrator_workers', 'graph']\n</code></pre> <p>Fix: Use a valid pattern type:</p> <pre><code>pattern:\n  type: chain\n</code></pre>"},{"location":"howto/validate-workflows/#example-invalid-property-type","title":"Example: Invalid Property Type","text":"<p>Error output:</p> <pre><code>\u2717 Schema validation failed:\n  /runtime/timeout: 'not-a-number' is not of type 'number'\n</code></pre> <p>Fix: Provide a numeric value:</p> <pre><code>runtime:\n  timeout: 300\n</code></pre>"},{"location":"howto/validate-workflows/#common-validation-issues","title":"Common Validation Issues","text":""},{"location":"howto/validate-workflows/#missing-pattern-configuration","title":"Missing Pattern Configuration","text":"<p>Each pattern requires specific configuration. For example, the chain pattern requires a <code>steps</code> array:</p> <pre><code>pattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: step1\n        prompt: \"First step\"\n</code></pre>"},{"location":"howto/validate-workflows/#invalid-agent-references","title":"Invalid Agent References","text":"<p>When using routing or workflow patterns, ensure all referenced agent IDs exist:</p> <pre><code>agents:\n  - id: analyzer\n    system: \"You analyze input\"\n\npattern:\n  type: routing\n  config:\n    routes:\n      - condition: \"input.type == 'analysis'\"\n        agent_id: analyzer  # Must match an agent ID above\n</code></pre>"},{"location":"howto/validate-workflows/#malformed-yaml-syntax","title":"Malformed YAML Syntax","text":"<p>If your YAML is malformed, you'll see a parsing error:</p> <pre><code>\u2717 Failed to load workflow: YAML parsing error at line 15, column 3\n</code></pre> <p>Fix: Check for: - Proper indentation (use spaces, not tabs) - Missing colons after keys - Unmatched quotes - Invalid escape sequences</p>"},{"location":"howto/validate-workflows/#validation-best-practices","title":"Validation Best Practices","text":""},{"location":"howto/validate-workflows/#1-validate-early-and-often","title":"1. Validate Early and Often","text":"<p>Validate your workflow during development:</p> <pre><code># Validate after each change\nstrands validate workflow.yaml\n</code></pre>"},{"location":"howto/validate-workflows/#2-use-the-plan-command","title":"2. Use the Plan Command","text":"<p>The <code>plan</code> command performs validation and shows the execution plan:</p> <pre><code>strands plan workflow.yaml\n</code></pre> <p>This helps you: - Verify validation passes - Understand execution order - Check variable substitution - Preview the workflow structure</p>"},{"location":"howto/validate-workflows/#3-check-for-unsupported-features","title":"3. Check for Unsupported Features","text":"<p>Some workflows may validate but use unsupported features. Use the capability checker:</p> <pre><code>strands run workflow.yaml\n</code></pre> <p>If unsupported features are detected, you'll get exit code 18 and a detailed report.</p>"},{"location":"howto/validate-workflows/#4-validate-with-variable-substitution","title":"4. Validate with Variable Substitution","text":"<p>If your workflow uses template variables, validate with actual values:</p> <pre><code>strands validate workflow.yaml --var topic=\"AI\" --var format=\"markdown\"\n</code></pre> <p>This ensures variable substitution doesn't break the schema.</p>"},{"location":"howto/validate-workflows/#advanced-validation","title":"Advanced Validation","text":""},{"location":"howto/validate-workflows/#custom-schema-validation","title":"Custom Schema Validation","text":"<p>You can validate against the schema directly using standard tools:</p> <pre><code># Using Python jsonschema\npython -c \"\nimport json\nimport yaml\nfrom jsonschema import validate\n\nwith open('workflow.yaml') as f:\n    workflow = yaml.safe_load(f)\n\nwith open('src/strands_cli/schema/strands-workflow.schema.json') as f:\n    schema = json.load(f)\n\nvalidate(workflow, schema)\nprint('Valid!')\n\"\n</code></pre>"},{"location":"howto/validate-workflows/#validation-in-cicd","title":"Validation in CI/CD","text":"<p>Add validation to your continuous integration pipeline:</p> <pre><code># .github/workflows/validate.yml\nname: Validate Workflows\non: [push, pull_request]\n\njobs:\n  validate:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.12'\n      - name: Install Strands CLI\n        run: pip install strands-cli\n      - name: Validate all workflows\n        run: |\n          for workflow in workflows/*.yaml; do\n            echo \"Validating $workflow\"\n            strands validate \"$workflow\"\n          done\n</code></pre>"},{"location":"howto/validate-workflows/#pre-commit-hook","title":"Pre-commit Hook","text":"<p>Validate workflows before committing:</p> <pre><code># .pre-commit-config.yaml\nrepos:\n  - repo: local\n    hooks:\n      - id: validate-strands\n        name: Validate Strands Workflows\n        entry: strands validate\n        language: system\n        files: '\\.yaml$'\n        pass_filenames: true\n</code></pre>"},{"location":"howto/validate-workflows/#troubleshooting","title":"Troubleshooting","text":""},{"location":"howto/validate-workflows/#jsonpointer-paths","title":"JSONPointer Paths","text":"<p>Error messages use JSONPointer notation to indicate where errors occur:</p> <ul> <li><code>/runtime/provider</code> \u2192 Root level <code>runtime</code> object, <code>provider</code> field</li> <li><code>/agents/0/system</code> \u2192 First agent in <code>agents</code> array, <code>system</code> field</li> <li><code>/pattern/config/steps/2/prompt</code> \u2192 Third step in chain, <code>prompt</code> field</li> </ul>"},{"location":"howto/validate-workflows/#schema-version-compatibility","title":"Schema Version Compatibility","text":"<p>Ensure your workflow schema version matches the CLI version:</p> <pre><code>schema: https://raw.githubusercontent.com/ThomasRohde/strands-cli/main/src/strands_cli/schema/strands-workflow.schema.json\n</code></pre>"},{"location":"howto/validate-workflows/#getting-help","title":"Getting Help","text":"<p>If validation errors are unclear:</p> <ol> <li>Check the Schema Reference for field documentation</li> <li>Review examples for pattern-specific templates</li> <li>Run with <code>--debug --verbose</code> for detailed error information</li> <li>Consult the troubleshooting guide</li> </ol>"},{"location":"howto/validate-workflows/#exit-codes","title":"Exit Codes","text":"<p>The <code>validate</code> command uses these exit codes:</p> <ul> <li><code>0</code> (EX_OK): Validation successful</li> <li><code>2</code> (EX_USAGE): Invalid CLI usage (missing file, bad arguments)</li> <li><code>3</code> (EX_SCHEMA): Schema validation failed</li> <li><code>70</code> (EX_UNKNOWN): Unexpected error</li> </ul>"},{"location":"howto/validate-workflows/#see-also","title":"See Also","text":"<ul> <li>Running Workflows - Execute validated workflows</li> <li>Schema Reference - Complete schema documentation</li> <li>CLI Reference - All CLI commands and options</li> </ul>"},{"location":"howto/patterns/chain/","title":"Chain Pattern","text":"<p>The Chain pattern executes a series of steps sequentially, where each step can access the results of previous steps. This is ideal for workflows that require ordered processing with context passing.</p>"},{"location":"howto/patterns/chain/#when-to-use","title":"When to Use","text":"<p>Use the Chain pattern when you need to:</p> <ul> <li>Execute steps in a specific order</li> <li>Pass results from one step to the next</li> <li>Build upon previous step outputs</li> <li>Implement multi-stage processing pipelines</li> <li>Maintain conversation context across steps</li> </ul>"},{"location":"howto/patterns/chain/#basic-example","title":"Basic Example","text":"<pre><code>version: 0\nname: simple-chain\ndescription: Three-step research workflow\n\nruntime:\n  provider: bedrock\n  model: anthropic.claude-3-sonnet-20240229-v1:0\n\nagents:\n  - id: researcher\n    system: \"You are a research assistant providing factual information.\"\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: researcher\n        prompt: \"Research the topic: {{ topic }}. List 3-5 key points.\"\n\n      - agent_id: researcher\n        prompt: |\n          Based on this research:\n          {{ steps[0].response }}\n\n          Analyze the most important point in detail.\n\n      - agent_id: researcher\n        prompt: |\n          Previous research: {{ steps[0].response }}\n          Analysis: {{ steps[1].response }}\n\n          Write a 2-paragraph summary combining both insights.\n\ninputs:\n  topic:\n    type: string\n    description: \"Research topic\"\n    default: \"artificial intelligence\"\n</code></pre>"},{"location":"howto/patterns/chain/#accessing-step-results","title":"Accessing Step Results","text":""},{"location":"howto/patterns/chain/#last-response","title":"Last Response","text":"<p>Access the most recent step output:</p> <pre><code>prompt: \"Summarize this: {{ last_response }}\"\n</code></pre>"},{"location":"howto/patterns/chain/#specific-steps","title":"Specific Steps","text":"<p>Access any previous step by index (0-based):</p> <pre><code># First step\nprompt: \"Build on this: {{ steps[0].response }}\"\n\n# Second step\nprompt: \"Compare {{ steps[0].response }} with {{ steps[1].response }}\"\n</code></pre>"},{"location":"howto/patterns/chain/#all-steps","title":"All Steps","text":"<p>Iterate over all previous steps:</p> <pre><code>prompt: |\n  Review all previous outputs:\n  {% for step in steps %}\n  Step {{ loop.index }}: {{ step.response }}\n  {% endfor %}\n</code></pre>"},{"location":"howto/patterns/chain/#context-threading","title":"Context Threading","text":"<p>The Chain pattern automatically threads context through steps:</p> <ol> <li>Step 1 executes with initial input</li> <li>Step 2 has access to Step 1's response via <code>steps[0].response</code></li> <li>Step 3 has access to both previous steps via <code>steps[0]</code> and <code>steps[1]</code></li> <li>And so on...</li> </ol>"},{"location":"howto/patterns/chain/#example-research-to-report","title":"Example: Research to Report","text":"<pre><code>pattern:\n  type: chain\n  config:\n    steps:\n      # Step 1: Gather information\n      - agent_id: researcher\n        prompt: \"Find key facts about {{ topic }}\"\n\n      # Step 2: Analyze (uses Step 1)\n      - agent_id: analyst\n        prompt: |\n          Given these facts:\n          {{ steps[0].response }}\n\n          Identify the 3 most important insights.\n\n      # Step 3: Write report (uses Steps 1 and 2)\n      - agent_id: writer\n        prompt: |\n          Facts: {{ steps[0].response }}\n          Insights: {{ steps[1].response }}\n\n          Write a comprehensive report for {{ audience }}.\n</code></pre>"},{"location":"howto/patterns/chain/#using-multiple-agents","title":"Using Multiple Agents","text":"<p>You can use different agents for different steps:</p> <pre><code>agents:\n  - id: researcher\n    system: \"You research topics thoroughly and cite sources.\"\n\n  - id: analyst\n    system: \"You analyze data and identify patterns.\"\n\n  - id: writer\n    system: \"You write clear, engaging content.\"\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: researcher\n        prompt: \"Research {{ topic }}\"\n\n      - agent_id: analyst\n        prompt: \"Analyze: {{ last_response }}\"\n\n      - agent_id: writer\n        prompt: \"Write a report based on: {{ last_response }}\"\n</code></pre>"},{"location":"howto/patterns/chain/#advanced-features","title":"Advanced Features","text":""},{"location":"howto/patterns/chain/#step-level-variables","title":"Step-Level Variables","text":"<p>Define variables specific to each step:</p> <pre><code>steps:\n  - agent_id: researcher\n    prompt: \"Research {{ topic }} with focus on {{ focus }}\"\n    vars:\n      focus: \"technical details\"\n\n  - agent_id: researcher\n    prompt: \"Research {{ topic }} with focus on {{ focus }}\"\n    vars:\n      focus: \"business implications\"\n</code></pre>"},{"location":"howto/patterns/chain/#conditional-content","title":"Conditional Content","text":"<p>Use Jinja2 conditionals in prompts:</p> <pre><code>steps:\n  - agent_id: writer\n    prompt: |\n      {% if steps|length &gt; 0 %}\n      Previous context: {{ last_response }}\n      {% endif %}\n\n      Write about {{ topic }}.\n</code></pre>"},{"location":"howto/patterns/chain/#truncating-long-responses","title":"Truncating Long Responses","text":"<p>Use Jinja2 filters to manage context size:</p> <pre><code>steps:\n  - agent_id: summarizer\n    prompt: |\n      Summarize this (showing first 200 chars):\n      {{ steps[0].response | truncate(200) }}\n</code></pre>"},{"location":"howto/patterns/chain/#error-handling","title":"Error Handling","text":""},{"location":"howto/patterns/chain/#retry-configuration","title":"Retry Configuration","text":"<p>Configure retries at the runtime level:</p> <pre><code>runtime:\n  provider: bedrock\n  model: anthropic.claude-3-sonnet-20240229-v1:0\n  failure_policy:\n    retries: 3\n    backoff: exponential\n</code></pre> <p>If a step fails, it will retry up to 3 times with exponential backoff before failing the entire chain.</p>"},{"location":"howto/patterns/chain/#budget-limits","title":"Budget Limits","text":"<p>Prevent runaway chains:</p> <pre><code>runtime:\n  budgets:\n    max_steps: 10          # Maximum chain steps\n    max_tokens: 100000     # Maximum total tokens\n    max_duration_s: 300    # Maximum 5 minutes\n</code></pre>"},{"location":"howto/patterns/chain/#output-artifacts","title":"Output Artifacts","text":"<p>Save chain results to files:</p> <pre><code>outputs:\n  artifacts:\n    - path: \"research_report.md\"\n      content: |\n        # {{ topic }}\n\n        ## Research\n        {{ steps[0].response }}\n\n        ## Analysis\n        {{ steps[1].response }}\n\n        ## Summary\n        {{ steps[2].response }}\n</code></pre>"},{"location":"howto/patterns/chain/#best-practices","title":"Best Practices","text":""},{"location":"howto/patterns/chain/#1-keep-steps-focused","title":"1. Keep Steps Focused","text":"<p>Each step should have a clear, single purpose:</p> <pre><code># Good - clear purpose per step\nsteps:\n  - agent_id: researcher\n    prompt: \"Find 5 sources about {{ topic }}\"\n  - agent_id: analyst\n    prompt: \"Analyze credibility of sources: {{ last_response }}\"\n  - agent_id: writer\n    prompt: \"Synthesize findings: {{ last_response }}\"\n\n# Avoid - too much in one step\nsteps:\n  - agent_id: do_everything\n    prompt: \"Research, analyze, and write a complete report\"\n</code></pre>"},{"location":"howto/patterns/chain/#2-manage-context-size","title":"2. Manage Context Size","text":"<p>Long chains can accumulate large context. Use strategies to manage this:</p> <pre><code># Truncate earlier steps\nprompt: |\n  Early research (truncated): {{ steps[0].response | truncate(100) }}\n  Recent analysis: {{ steps[-1].response }}\n\n# Reference only what you need\nprompt: |\n  Key insight from step 2: {{ steps[1].response }}\n  Write a conclusion.\n</code></pre>"},{"location":"howto/patterns/chain/#3-use-descriptive-prompts","title":"3. Use Descriptive Prompts","text":"<p>Make step purposes clear:</p> <pre><code>steps:\n  - agent_id: researcher\n    prompt: |\n      # Research Phase\n      Find authoritative sources about {{ topic }}.\n      Focus on recent publications (last 2 years).\n\n  - agent_id: analyst\n    prompt: |\n      # Analysis Phase\n      Review these sources: {{ last_response }}\n      Identify consensus and controversies.\n</code></pre>"},{"location":"howto/patterns/chain/#4-validate-inputs","title":"4. Validate Inputs","text":"<p>Use input constraints:</p> <pre><code>inputs:\n  topic:\n    type: string\n    description: \"Research topic\"\n\n  depth:\n    type: string\n    enum: [\"shallow\", \"medium\", \"deep\"]\n    default: \"medium\"\n</code></pre>"},{"location":"howto/patterns/chain/#5-monitor-token-usage","title":"5. Monitor Token Usage","text":"<p>Enable telemetry to track token consumption:</p> <pre><code>telemetry:\n  enabled: true\n  console:\n    enabled: true\n</code></pre> <p>Then run with trace:</p> <pre><code>strands run workflow.yaml --trace\n</code></pre>"},{"location":"howto/patterns/chain/#common-patterns","title":"Common Patterns","text":""},{"location":"howto/patterns/chain/#research-analyze-report","title":"Research \u2192 Analyze \u2192 Report","text":"<pre><code>steps:\n  - agent_id: researcher\n    prompt: \"Gather information about {{ topic }}\"\n  - agent_id: analyst\n    prompt: \"Analyze: {{ last_response }}\"\n  - agent_id: writer\n    prompt: \"Write report: {{ last_response }}\"\n</code></pre>"},{"location":"howto/patterns/chain/#iterative-refinement","title":"Iterative Refinement","text":"<pre><code>steps:\n  - agent_id: writer\n    prompt: \"Write initial draft about {{ topic }}\"\n  - agent_id: editor\n    prompt: \"Improve this draft: {{ last_response }}\"\n  - agent_id: editor\n    prompt: \"Polish final version: {{ last_response }}\"\n</code></pre>"},{"location":"howto/patterns/chain/#multi-format-output","title":"Multi-Format Output","text":"<pre><code>steps:\n  - agent_id: writer\n    prompt: \"Write content about {{ topic }}\"\n  - agent_id: formatter\n    prompt: \"Convert to markdown: {{ last_response }}\"\n  - agent_id: formatter\n    prompt: \"Create HTML version: {{ steps[0].response }}\"\n</code></pre>"},{"location":"howto/patterns/chain/#performance-considerations","title":"Performance Considerations","text":""},{"location":"howto/patterns/chain/#agent-caching","title":"Agent Caching","text":"<p>Strands automatically caches agents with identical configurations. If all steps use the same agent, only one agent is built:</p> <pre><code>agents:\n  - id: researcher\n    system: \"You are a researcher\"\n\nsteps:\n  - agent_id: researcher  # Agent built here\n    prompt: \"Step 1\"\n  - agent_id: researcher  # Cached - no rebuild\n    prompt: \"Step 2\"\n  - agent_id: researcher  # Cached - no rebuild\n    prompt: \"Step 3\"\n</code></pre> <p>This provides ~90% overhead reduction.</p>"},{"location":"howto/patterns/chain/#parallel-vs-chain","title":"Parallel vs. Chain","text":"<p>If steps are independent, consider the Parallel pattern instead:</p> <pre><code># Chain (sequential) - 30 seconds total\nsteps:\n  - agent_id: researcher\n    prompt: \"Research A\"  # 10s\n  - agent_id: researcher\n    prompt: \"Research B\"  # 10s\n  - agent_id: researcher\n    prompt: \"Research C\"  # 10s\n\n# Parallel (concurrent) - 10 seconds total\nbranches:\n  - id: a\n    agent_id: researcher\n    prompt: \"Research A\"  # 10s\n  - id: b\n    agent_id: researcher\n    prompt: \"Research B\"  # 10s (concurrent)\n  - id: c\n    agent_id: researcher\n    prompt: \"Research C\"  # 10s (concurrent)\n</code></pre>"},{"location":"howto/patterns/chain/#troubleshooting","title":"Troubleshooting","text":""},{"location":"howto/patterns/chain/#chain-not-progressing","title":"Chain Not Progressing","text":"<p>Check budget limits:</p> <pre><code>strands run workflow.yaml --debug --verbose\n</code></pre> <p>Look for: <pre><code>Budget exceeded: max_steps (5) reached\n</code></pre></p>"},{"location":"howto/patterns/chain/#context-too-large","title":"Context Too Large","text":"<p>Reduce context accumulation:</p> <pre><code># Use truncate filter\nprompt: \"{{ steps[0].response | truncate(200) }}\"\n\n# Reference only recent steps\nprompt: \"{{ steps[-1].response }}\"\n\n# Adjust max_tokens per agent\nagents:\n  - id: researcher\n    max_tokens: 500  # Limit response size\n</code></pre>"},{"location":"howto/patterns/chain/#steps-failing","title":"Steps Failing","text":"<p>Enable retry logic:</p> <pre><code>runtime:\n  failure_policy:\n    retries: 3\n    backoff: exponential\n</code></pre>"},{"location":"howto/patterns/chain/#examples","title":"Examples","text":"<p>Complete examples in the repository:</p> <ul> <li><code>examples/chain-3-step-research.yaml</code> - Basic three-step chain</li> <li><code>examples/single-agent-chain-bedrock.yaml</code> - Bedrock provider</li> <li><code>examples/single-agent-chain-ollama.yaml</code> - Ollama provider</li> <li><code>examples/single-agent-chain-openai.yaml</code> - OpenAI provider</li> </ul>"},{"location":"howto/patterns/chain/#see-also","title":"See Also","text":"<ul> <li>Workflow Pattern - For DAG-based parallel execution</li> <li>Parallel Pattern - For concurrent independent tasks</li> <li>Graph Pattern - For conditional control flow</li> <li>Run Workflows - Execution guide</li> <li>Context Management - Managing chain context</li> </ul>"},{"location":"howto/patterns/evaluator-optimizer/","title":"Evaluator-Optimizer Pattern","text":"<p>The Evaluator-Optimizer pattern implements iterative refinement through a producer-evaluator-optimizer loop. A producer generates initial output, an evaluator scores it against quality criteria, and if the score is below threshold, the producer revises the output based on feedback. This continues until quality criteria are met or maximum iterations are reached.</p>"},{"location":"howto/patterns/evaluator-optimizer/#when-to-use","title":"When to Use","text":"<p>Use the Evaluator-Optimizer pattern when you need to:</p> <ul> <li>Ensure output meets specific quality standards</li> <li>Implement iterative refinement workflows</li> <li>Generate content that improves through feedback</li> <li>Enforce quality gates before accepting results</li> <li>Implement code review or content review cycles</li> </ul>"},{"location":"howto/patterns/evaluator-optimizer/#basic-example","title":"Basic Example","text":"<pre><code>version: 0\nname: simple-evaluator-optimizer\ndescription: Iterative content refinement\n\nruntime:\n  provider: bedrock\n  model: anthropic.claude-3-sonnet-20240229-v1:0\n\nagents:\n  - id: writer\n    system: \"You are an expert writer. Create clear, engaging content.\"\n\n  - id: critic\n    system: |\n      You are a critical editor. Evaluate content quality.\n      Respond with JSON: {\"score\": 0-100, \"issues\": [...], \"fixes\": [...]}\n\npattern:\n  type: evaluator_optimizer\n  config:\n    producer: writer\n\n    evaluator:\n      agent: critic\n      input: |\n        Evaluate this draft:\n        {{ draft }}\n\n        Return JSON with score (0-100), issues array, and fixes array.\n\n    accept:\n      min_score: 85\n      max_iters: 3\n\ninputs:\n  topic:\n    type: string\n    description: \"Content topic\"\n    default: \"artificial intelligence\"\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#pattern-components","title":"Pattern Components","text":""},{"location":"howto/patterns/evaluator-optimizer/#producer-agent","title":"Producer Agent","text":"<p>The producer generates initial output and revisions:</p> <pre><code>agents:\n  - id: writer\n    system: |\n      You are a content writer.\n      Write a blog post about the given topic.\n\nconfig:\n  producer: writer  # Agent that produces drafts\n</code></pre> <p>The producer is invoked initially, then again for each revision iteration.</p>"},{"location":"howto/patterns/evaluator-optimizer/#evaluator-configuration","title":"Evaluator Configuration","text":"<p>The evaluator scores output quality:</p> <pre><code>evaluator:\n  agent: critic                    # Agent that evaluates quality\n  input: |                         # Template for evaluation\n    Evaluate this draft:\n    {{ draft }}\n\n    Score 0-100 based on:\n    - Clarity\n    - Accuracy\n    - Engagement\n    - Structure\n\n    Return JSON: {\"score\": 85, \"issues\": [...], \"fixes\": [...]}\n</code></pre> <p>Critical: Evaluator must return valid JSON with <code>score</code> field (0-100).</p>"},{"location":"howto/patterns/evaluator-optimizer/#acceptance-criteria","title":"Acceptance Criteria","text":"<p>Define when to accept output:</p> <pre><code>accept:\n  min_score: 85      # Minimum score to accept (0-100)\n  max_iters: 3       # Maximum revision iterations\n</code></pre> <p>Workflow stops when either: - Score meets <code>min_score</code> threshold - <code>max_iters</code> iterations reached</p>"},{"location":"howto/patterns/evaluator-optimizer/#revision-prompt","title":"Revision Prompt","text":""},{"location":"howto/patterns/evaluator-optimizer/#default-revision-behavior","title":"Default Revision Behavior","text":"<p>Without a custom revision prompt, Strands uses a generic template:</p> <pre><code># Default behavior\nconfig:\n  producer: writer\n  evaluator: {...}\n  accept: {...}\n  # No revise_prompt - uses default\n</code></pre> <p>Default template includes: - Current draft - Evaluation score - Issues identified - Suggested fixes</p>"},{"location":"howto/patterns/evaluator-optimizer/#custom-revision-prompt","title":"Custom Revision Prompt","text":"<p>Provide domain-specific revision guidance:</p> <pre><code>config:\n  producer: writer\n  evaluator: {...}\n  accept: {...}\n\n  revise_prompt: |\n    Your previous draft scored {{ evaluation.score }}/100.\n\n    Issues identified:\n    {% for issue in evaluation.issues %}\n    - {{ issue }}\n    {% endfor %}\n\n    Suggested fixes:\n    {% for fix in evaluation.fixes %}\n    - {{ fix }}\n    {% endfor %}\n\n    Revise the draft to address ALL issues.\n    Maintain the original topic and style.\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#accessing-evaluation-results","title":"Accessing Evaluation Results","text":"<p>Available variables in revision prompt:</p> <pre><code>revise_prompt: |\n  Score: {{ evaluation.score }}\n  Iteration: {{ iteration }}\n\n  Issues: {{ evaluation.issues | join(', ') }}\n  Fixes: {{ evaluation.fixes | join(', ') }}\n\n  Previous draft:\n  {{ draft }}\n\n  Please revise.\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#iteration-workflow","title":"Iteration Workflow","text":""},{"location":"howto/patterns/evaluator-optimizer/#execution-flow","title":"Execution Flow","text":"<pre><code>1. Producer generates initial draft\n2. Evaluator scores draft\n3. If score &gt;= min_score \u2192 Accept and finish\n4. If score &lt; min_score \u2192 Producer revises based on feedback\n5. Repeat steps 2-4 until accepted or max_iters reached\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#example-execution","title":"Example Execution","text":"<pre><code>accept:\n  min_score: 85\n  max_iters: 3\n</code></pre> <p>Timeline: <pre><code>Iteration 1:\n  Producer \u2192 Draft v1\n  Evaluator \u2192 Score: 65 (below threshold)\n\nIteration 2:\n  Producer \u2192 Draft v2 (revised)\n  Evaluator \u2192 Score: 78 (below threshold)\n\nIteration 3:\n  Producer \u2192 Draft v3 (revised)\n  Evaluator \u2192 Score: 87 (above threshold)\n  Result: Accept draft v3\n</code></pre></p> <p>If max_iters reached without meeting min_score: <pre><code>Iteration 3:\n  Producer \u2192 Draft v3 (revised)\n  Evaluator \u2192 Score: 82 (below threshold)\n  Result: Accept draft v3 (max iterations reached)\n</code></pre></p>"},{"location":"howto/patterns/evaluator-optimizer/#accessing-results","title":"Accessing Results","text":""},{"location":"howto/patterns/evaluator-optimizer/#final-output","title":"Final Output","text":"<p>The accepted draft is available as <code>last_response</code>:</p> <pre><code>outputs:\n  artifacts:\n    - path: \"final_output.md\"\n      content: \"{{ last_response }}\"\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#iteration-history","title":"Iteration History","text":"<p>Access evaluation metadata:</p> <pre><code>outputs:\n  artifacts:\n    - path: \"review_report.md\"\n      content: |\n        # Review Report\n\n        **Final Score**: {{ evaluation.score }}\n        **Iterations**: {{ iteration }}\n        **Accepted**: {{ evaluation.score &gt;= 85 }}\n\n        ## Final Output\n        {{ last_response }}\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#advanced-features","title":"Advanced Features","text":""},{"location":"howto/patterns/evaluator-optimizer/#different-models-for-different-roles","title":"Different Models for Different Roles","text":"<p>Use specialized models:</p> <pre><code>agents:\n  - id: fast_writer\n    model: anthropic.claude-3-haiku-20240307-v1:0\n    system: \"Fast content generation\"\n\n  - id: critical_evaluator\n    model: anthropic.claude-3-opus-20240229-v1:0\n    system: \"Thorough quality evaluation\"\n\nconfig:\n  producer: fast_writer\n  evaluator:\n    agent: critical_evaluator\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#complex-evaluation-criteria","title":"Complex Evaluation Criteria","text":"<p>Multiple quality dimensions:</p> <pre><code>evaluator:\n  agent: critic\n  input: |\n    Evaluate on multiple dimensions:\n\n    Draft: {{ draft }}\n\n    Score each dimension 0-100:\n    1. Technical accuracy\n    2. Clarity and readability\n    3. Completeness\n    4. Code quality (if applicable)\n\n    Return JSON:\n    {\n      \"score\": &lt;average of all dimensions&gt;,\n      \"technical\": &lt;score&gt;,\n      \"clarity\": &lt;score&gt;,\n      \"completeness\": &lt;score&gt;,\n      \"code_quality\": &lt;score&gt;,\n      \"issues\": [...],\n      \"fixes\": [...]\n    }\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#iteration-aware-revision","title":"Iteration-Aware Revision","text":"<p>Adjust guidance based on iteration count:</p> <pre><code>revise_prompt: |\n  Revision {{ iteration }} of {{ max_iters }}\n  Current score: {{ evaluation.score }}/{{ min_score }} required\n\n  {% if iteration == 1 %}\n  First revision: Focus on major issues first.\n  {% elif iteration == 2 %}\n  Second revision: Address remaining issues thoroughly.\n  {% else %}\n  Final revision: Make targeted improvements to meet threshold.\n  {% endif %}\n\n  Issues: {{ evaluation.issues | join(', ') }}\n  Fixes: {{ evaluation.fixes | join(', ') }}\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#error-handling","title":"Error Handling","text":""},{"location":"howto/patterns/evaluator-optimizer/#evaluator-returning-invalid-json","title":"Evaluator Returning Invalid JSON","text":"<p>If evaluator returns invalid JSON, the workflow fails:</p> <pre><code>Error: Evaluator response is not valid JSON\nExpected: {\"score\": 85, \"issues\": [...], \"fixes\": [...]}\nReceived: \"The content is good quality\"\n</code></pre> <p>Fix: Enforce JSON output in evaluator system prompt.</p>"},{"location":"howto/patterns/evaluator-optimizer/#quality-never-reached","title":"Quality Never Reached","text":"<p>If min_score is never reached:</p> <pre><code>accept:\n  min_score: 95    # Very high threshold\n  max_iters: 3\n</code></pre> <p>Result: Workflow completes with best available draft after 3 iterations.</p>"},{"location":"howto/patterns/evaluator-optimizer/#budget-limits","title":"Budget Limits","text":"<p>Prevent excessive iteration:</p> <pre><code>runtime:\n  budgets:\n    max_steps: 10          # Limit total iterations\n    max_tokens: 100000     # Limit total tokens\n    max_duration_s: 600    # Maximum 10 minutes\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#best-practices","title":"Best Practices","text":""},{"location":"howto/patterns/evaluator-optimizer/#1-set-realistic-thresholds","title":"1. Set Realistic Thresholds","text":"<p>Balance quality and iteration count:</p> <pre><code># Good - achievable threshold\naccept:\n  min_score: 85\n  max_iters: 3\n\n# Avoid - unrealistic threshold\naccept:\n  min_score: 99  # May never reach\n  max_iters: 10  # Too many iterations\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#2-provide-specific-evaluation-criteria","title":"2. Provide Specific Evaluation Criteria","text":"<p>Clear criteria lead to better feedback:</p> <pre><code># Good - specific criteria\nevaluator:\n  agent: critic\n  input: |\n    Evaluate based on:\n    1. Code correctness (no bugs)\n    2. Type hints (complete coverage)\n    3. Docstrings (all functions documented)\n    4. Error handling (comprehensive)\n\n# Avoid - vague criteria\nevaluator:\n  agent: critic\n  input: \"Is this code good? Score it.\"\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#3-use-structured-feedback","title":"3. Use Structured Feedback","text":"<p>Request actionable fixes:</p> <pre><code>evaluator:\n  agent: critic\n  input: |\n    Return JSON with:\n    {\n      \"score\": &lt;0-100&gt;,\n      \"issues\": [\"Specific issue 1\", \"Specific issue 2\"],\n      \"fixes\": [\"How to fix issue 1\", \"How to fix issue 2\"]\n    }\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#4-monitor-iteration-progress","title":"4. Monitor Iteration Progress","text":"<p>Track improvement across iterations:</p> <pre><code>outputs:\n  artifacts:\n    - path: \"iteration_log.md\"\n      content: |\n        # Iteration Log\n\n        **Iterations Used**: {{ iteration }}\n        **Final Score**: {{ evaluation.score }}\n        **Target Score**: 85\n\n        Improvement achieved: {{ evaluation.score &gt;= 85 }}\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#5-handle-edge-cases","title":"5. Handle Edge Cases","text":"<p>Ensure evaluator handles all inputs:</p> <pre><code>evaluator:\n  agent: critic\n  input: |\n    Evaluate: {{ draft }}\n\n    If draft is empty or invalid, return:\n    {\"score\": 0, \"issues\": [\"Empty draft\"], \"fixes\": [\"Generate content\"]}\n\n    Otherwise evaluate normally.\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#common-patterns","title":"Common Patterns","text":""},{"location":"howto/patterns/evaluator-optimizer/#code-quality-refinement","title":"Code Quality Refinement","text":"<pre><code>config:\n  producer: coder\n\n  evaluator:\n    agent: reviewer\n    input: |\n      Review this code: {{ draft }}\n\n      Check:\n      1. Correctness\n      2. Type hints\n      3. Docstrings\n      4. Error handling\n      5. Performance\n\n      Return JSON with score and detailed feedback.\n\n  accept:\n    min_score: 85\n    max_iters: 4\n\n  revise_prompt: |\n    Code review score: {{ evaluation.score }}/100\n\n    Issues: {{ evaluation.issues | join('\\n- ') }}\n    Fixes: {{ evaluation.fixes | join('\\n- ') }}\n\n    Revise the code to address ALL issues.\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#content-writing-refinement","title":"Content Writing Refinement","text":"<pre><code>config:\n  producer: writer\n\n  evaluator:\n    agent: editor\n    input: |\n      Edit this content: {{ draft }}\n\n      Evaluate:\n      1. Grammar and spelling\n      2. Clarity and flow\n      3. Engagement\n      4. Structure\n\n      Return JSON with score and feedback.\n\n  accept:\n    min_score: 90\n    max_iters: 3\n\n  revise_prompt: |\n    Editorial feedback ({{ evaluation.score }}/100):\n\n    Issues found:\n    {% for issue in evaluation.issues %}\n    - {{ issue }}\n    {% endfor %}\n\n    Please revise to address these issues while maintaining voice and style.\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#design-review-cycle","title":"Design Review Cycle","text":"<pre><code>config:\n  producer: designer\n\n  evaluator:\n    agent: design_critic\n    input: |\n      Review this design: {{ draft }}\n\n      Criteria:\n      1. Usability\n      2. Accessibility\n      3. Visual hierarchy\n      4. Consistency\n\n      Return JSON score and recommendations.\n\n  accept:\n    min_score: 80\n    max_iters: 5\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#performance-considerations","title":"Performance Considerations","text":""},{"location":"howto/patterns/evaluator-optimizer/#iteration-overhead","title":"Iteration Overhead","text":"<p>Each iteration adds time:</p> <pre><code>Total time = Initial draft + (Iterations \u00d7 (Evaluation + Revision))\n           \u2248 3s + (N \u00d7 (2s + 3s))\n           \u2248 3s + (N \u00d7 5s)\n</code></pre> <p>Balance quality vs. time by setting appropriate <code>max_iters</code>.</p>"},{"location":"howto/patterns/evaluator-optimizer/#agent-caching","title":"Agent Caching","text":"<p>Producer and evaluator agents are cached:</p> <pre><code># Agent built once, reused for all iterations\nproducer: writer     # Built on first iteration\nevaluator:\n  agent: critic      # Built on first evaluation\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#troubleshooting","title":"Troubleshooting","text":""},{"location":"howto/patterns/evaluator-optimizer/#evaluator-not-returning-json","title":"Evaluator Not Returning JSON","text":"<p>Check evaluator output:</p> <pre><code>strands run workflow.yaml --debug --verbose\n</code></pre> <p>Look for: <pre><code>Evaluator response: \"This is good content, score is 85\"\nError: Invalid JSON from evaluator\n</code></pre></p> <p>Fix: Enforce JSON-only output in system prompt.</p>"},{"location":"howto/patterns/evaluator-optimizer/#score-not-improving","title":"Score Not Improving","text":"<p>If score plateaus:</p> <pre><code>Iteration 1: Score 60\nIteration 2: Score 62\nIteration 3: Score 63\n</code></pre> <p>Possible causes: - Vague evaluation criteria - Insufficient revision guidance - Unrealistic target score</p>"},{"location":"howto/patterns/evaluator-optimizer/#max-iterations-reached","title":"Max Iterations Reached","text":"<p>If workflow always hits max_iters:</p> <pre><code># Lower threshold or increase iterations\naccept:\n  min_score: 80      # Was 95\n  max_iters: 5       # Was 3\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#evaluator-optimizer-vs-other-patterns","title":"Evaluator-Optimizer vs. Other Patterns","text":""},{"location":"howto/patterns/evaluator-optimizer/#vs-chain","title":"vs. Chain","text":"<p>Evaluator-Optimizer has quality gates, Chain doesn't:</p> <pre><code># Evaluator-Optimizer: Iterates until quality threshold\npattern:\n  type: evaluator_optimizer\n  config:\n    accept:\n      min_score: 85  # Must meet threshold\n\n# Chain: Executes steps once\npattern:\n  type: chain\n  config:\n    steps: [...]  # No quality feedback loop\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#vs-graph-with-loops","title":"vs. Graph with Loops","text":"<p>Evaluator-Optimizer has structured evaluation, Graph has custom conditions:</p> <pre><code># Evaluator-Optimizer: Built-in quality scoring\npattern:\n  type: evaluator_optimizer\n  config:\n    evaluator: {...}\n    accept: {...}\n\n# Graph: Custom loop logic\npattern:\n  type: graph\n  config:\n    nodes:\n      generate: {...}\n      check: {...}\n    edges:\n      - from: check\n        choose:\n          - when: \"{{ custom_condition }}\"\n            to: generate  # Loop back\n</code></pre>"},{"location":"howto/patterns/evaluator-optimizer/#examples","title":"Examples","text":"<p>Complete examples in the repository:</p> <ul> <li><code>examples/evaluator-optimizer-writing-openai.yaml</code> - Content refinement</li> <li><code>examples/evaluator-optimizer-code-review-openai.yaml</code> - Code quality</li> <li><code>examples/evaluator-optimizer-writing-ollama.yaml</code> - Local model refinement</li> </ul>"},{"location":"howto/patterns/evaluator-optimizer/#see-also","title":"See Also","text":"<ul> <li>Chain Pattern - For sequential execution</li> <li>Graph Pattern - For custom control flow</li> <li>Run Workflows - Execution guide</li> <li>Budgets - Implementing budget and quality constraints</li> </ul>"},{"location":"howto/patterns/graph/","title":"Graph Pattern","text":"<p>The Graph pattern implements state machines with explicit control flow using nodes and conditional edges. Unlike other patterns, Graph gives you complete control over execution order through JMESPath conditions, enabling loops, branching, and complex decision trees. This is ideal for workflows requiring dynamic routing based on runtime conditions.</p>"},{"location":"howto/patterns/graph/#when-to-use","title":"When to Use","text":"<p>Use the Graph pattern when you need to:</p> <ul> <li>Implement complex conditional logic and branching</li> <li>Create loops with exit conditions</li> <li>Build state machines with multiple execution paths</li> <li>Make routing decisions based on node outputs</li> <li>Implement decision trees or approval workflows</li> <li>Handle dynamic workflows that vary based on runtime data</li> </ul>"},{"location":"howto/patterns/graph/#basic-example","title":"Basic Example","text":"<pre><code>version: 0\nname: simple-graph\ndescription: Basic graph with conditional routing\n\nruntime:\n  provider: bedrock\n  model: anthropic.claude-3-sonnet-20240229-v1:0\n\nagents:\n  - id: classifier\n    system: \"You classify input and provide category in your response.\"\n\n  - id: handler_a\n    system: \"You handle category A requests.\"\n\n  - id: handler_b\n    system: \"You handle category B requests.\"\n\npattern:\n  type: graph\n  config:\n    max_iterations: 5  # Prevent infinite loops\n\n    nodes:\n      classify:\n        agent: classifier\n        input: \"Classify this request: {{ request }}\"\n\n      handle_a:\n        agent: handler_a\n\n      handle_b:\n        agent: handler_b\n\n    edges:\n      - from: classify\n        choose:\n          - when: \"{{ 'category a' in nodes.classify.response.lower() }}\"\n            to: handle_a\n          - when: \"{{ 'category b' in nodes.classify.response.lower() }}\"\n            to: handle_b\n\ninputs:\n  request:\n    type: string\n    description: \"User request\"\n    default: \"I need help with category A\"\n</code></pre>"},{"location":"howto/patterns/graph/#graph-components","title":"Graph Components","text":""},{"location":"howto/patterns/graph/#nodes","title":"Nodes","text":"<p>Nodes represent execution states:</p> <pre><code>nodes:\n  node_id:\n    agent: agent_id\n    input: \"{{ template }}\"  # Optional, uses default if omitted\n</code></pre> <p>Each node executes an agent invocation. The first node defined becomes the start node unless <code>start_node</code> is specified.</p>"},{"location":"howto/patterns/graph/#edges","title":"Edges","text":"<p>Edges define transitions between nodes:</p> <pre><code>edges:\n  - from: source_node\n    choose:\n      - when: \"{{ condition_1 }}\"\n        to: target_node_1\n      - when: \"{{ condition_2 }}\"\n        to: target_node_2\n      - when: else\n        to: default_node\n</code></pre> <p>Edges use JMESPath conditions to determine next node.</p>"},{"location":"howto/patterns/graph/#start-node","title":"Start Node","text":"<p>Explicitly set the starting node:</p> <pre><code>config:\n  start_node: intake  # Start here instead of first defined node\n\n  nodes:\n    intake: {...}\n    process: {...}\n</code></pre>"},{"location":"howto/patterns/graph/#conditional-edges","title":"Conditional Edges","text":""},{"location":"howto/patterns/graph/#simple-conditions","title":"Simple Conditions","text":"<p>Check for text in node responses:</p> <pre><code>edges:\n  - from: analyze\n    choose:\n      - when: \"{{ 'approved' in nodes.analyze.response.lower() }}\"\n        to: proceed\n      - when: \"{{ 'rejected' in nodes.analyze.response.lower() }}\"\n        to: reject\n</code></pre>"},{"location":"howto/patterns/graph/#numeric-comparisons","title":"Numeric Comparisons","text":"<p>Compare numeric values:</p> <pre><code>edges:\n  - from: validate\n    choose:\n      - when: \"{{ 'amount: 50' in nodes.validate.response }}\"\n        to: auto_approve\n      - when: \"{{ 'amount: 500' in nodes.validate.response }}\"\n        to: manager_review\n      - when: else\n        to: director_review\n</code></pre>"},{"location":"howto/patterns/graph/#multiple-conditions","title":"Multiple Conditions","text":"<p>Combine conditions with AND/OR:</p> <pre><code>edges:\n  - from: classify\n    choose:\n      - when: \"{{ 'urgent' in nodes.classify.response and 'premium' in nodes.classify.response }}\"\n        to: fast_track\n      - when: \"{{ 'urgent' in nodes.classify.response }}\"\n        to: standard_urgent\n      - when: else\n        to: normal_queue\n</code></pre>"},{"location":"howto/patterns/graph/#else-clause","title":"Else Clause","text":"<p>Always provide a fallback:</p> <pre><code>edges:\n  - from: node_a\n    choose:\n      - when: \"{{ condition_1 }}\"\n        to: node_b\n      - when: \"{{ condition_2 }}\"\n        to: node_c\n      - when: else  # Required for complete coverage\n        to: default_node\n</code></pre>"},{"location":"howto/patterns/graph/#accessing-node-results","title":"Accessing Node Results","text":""},{"location":"howto/patterns/graph/#specific-node-outputs","title":"Specific Node Outputs","text":"<p>Access any completed node by ID:</p> <pre><code>nodes:\n  analyze:\n    agent: analyst\n    input: |\n      Previous classification:\n      {{ nodes.classify.response }}\n\n      Perform detailed analysis.\n</code></pre>"},{"location":"howto/patterns/graph/#node-metadata","title":"Node Metadata","text":"<p>Access node execution status:</p> <pre><code>outputs:\n  artifacts:\n    - path: \"execution_log.md\"\n      content: |\n        ## Execution Path\n\n        {% if nodes.classify %}\n        Classification: {{ nodes.classify.response }}\n        {% endif %}\n\n        {% if nodes.approve %}\n        Approval: {{ nodes.approve.response }}\n        {% endif %}\n</code></pre>"},{"location":"howto/patterns/graph/#terminal-node","title":"Terminal Node","text":"<p>Access the final node reached:</p> <pre><code>outputs:\n  artifacts:\n    - path: \"result.md\"\n      content: |\n        **Terminal Node**: {{ terminal_node }}\n        **Total Steps**: {{ total_steps }}\n\n        {{ last_response }}\n</code></pre>"},{"location":"howto/patterns/graph/#loops-and-cycles","title":"Loops and Cycles","text":""},{"location":"howto/patterns/graph/#implementing-loops","title":"Implementing Loops","text":"<p>Create cycles by routing back to previous nodes:</p> <pre><code>nodes:\n  generate:\n    agent: generator\n    input: \"Generate content for {{ topic }}\"\n\n  check:\n    agent: validator\n    input: |\n      Validate: {{ nodes.generate.response }}\n\n      Respond with \"valid\" or \"invalid\"\n\nedges:\n  - from: generate\n    to: check\n\n  - from: check\n    choose:\n      - when: \"{{ 'invalid' in nodes.check.response.lower() }}\"\n        to: generate  # Loop back\n      - when: else\n        to: done  # Exit loop\n\n  done:\n    agent: finalizer\n</code></pre>"},{"location":"howto/patterns/graph/#maximum-iterations","title":"Maximum Iterations","text":"<p>Prevent infinite loops:</p> <pre><code>config:\n  max_iterations: 10  # Maximum node executions\n\n  nodes: {...}\n  edges: {...}\n</code></pre> <p>After <code>max_iterations</code>, execution stops at current node.</p>"},{"location":"howto/patterns/graph/#loop-counters","title":"Loop Counters","text":"<p>Track iteration count in conditions:</p> <pre><code>edges:\n  - from: process\n    choose:\n      - when: \"{{ iteration &lt; 5 and 'retry' in nodes.process.response }}\"\n        to: process  # Loop with limit\n      - when: else\n        to: complete\n</code></pre>"},{"location":"howto/patterns/graph/#terminal-nodes","title":"Terminal Nodes","text":""},{"location":"howto/patterns/graph/#implicit-terminal-nodes","title":"Implicit Terminal Nodes","text":"<p>Nodes with no outgoing edges are terminal:</p> <pre><code>nodes:\n  start:\n    agent: processor\n\n  finish:\n    agent: finalizer\n\nedges:\n  - from: start\n    to: finish\n\n  # finish has no outgoing edges = terminal node\n</code></pre>"},{"location":"howto/patterns/graph/#multiple-terminal-nodes","title":"Multiple Terminal Nodes","text":"<p>Different paths can end at different terminals:</p> <pre><code>nodes:\n  classify: {...}\n  approve: {...}\n  reject: {...}\n\nedges:\n  - from: classify\n    choose:\n      - when: \"{{ 'accept' in nodes.classify.response }}\"\n        to: approve  # Terminal\n      - when: else\n        to: reject   # Terminal\n\n  # Both approve and reject are terminal nodes\n</code></pre>"},{"location":"howto/patterns/graph/#advanced-features","title":"Advanced Features","text":""},{"location":"howto/patterns/graph/#multi-path-workflows","title":"Multi-Path Workflows","text":"<p>Complex branching logic:</p> <pre><code>nodes:\n  intake: {...}\n  technical: {...}\n  billing: {...}\n  general: {...}\n  escalate: {...}\n\nedges:\n  # Initial routing\n  - from: intake\n    choose:\n      - when: \"{{ 'technical' in nodes.intake.response }}\"\n        to: technical\n      - when: \"{{ 'billing' in nodes.intake.response }}\"\n        to: billing\n      - when: else\n        to: general\n\n  # Escalation from technical\n  - from: technical\n    choose:\n      - when: \"{{ 'high priority' in nodes.intake.response }}\"\n        to: escalate\n      # Else: terminal\n\n  # Escalation from billing\n  - from: billing\n    choose:\n      - when: \"{{ 'high priority' in nodes.intake.response }}\"\n        to: escalate\n      # Else: terminal\n\n  # escalate is terminal\n</code></pre>"},{"location":"howto/patterns/graph/#decision-trees","title":"Decision Trees","text":"<p>Hierarchical decision-making:</p> <pre><code>nodes:\n  validate: {...}\n  auto_approve: {...}\n  manager: {...}\n  director: {...}\n  reject: {...}\n\nedges:\n  - from: validate\n    choose:\n      - when: \"{{ 'invalid' in nodes.validate.response }}\"\n        to: reject\n      - when: \"{{ 'amount: 50' in nodes.validate.response }}\"\n        to: auto_approve\n      - when: \"{{ 'amount: 500' in nodes.validate.response }}\"\n        to: manager\n      - when: else\n        to: director\n\n  - from: manager\n    choose:\n      - when: \"{{ 'approve' in nodes.manager.response }}\"\n        to: director\n      - when: else\n        to: reject\n</code></pre>"},{"location":"howto/patterns/graph/#retry-logic","title":"Retry Logic","text":"<p>Implement automatic retries:</p> <pre><code>nodes:\n  execute:\n    agent: executor\n    input: \"Perform operation: {{ task }}\"\n\n  verify:\n    agent: verifier\n    input: \"Verify: {{ nodes.execute.response }}\"\n\n  retry_check:\n    agent: checker\n    input: |\n      Attempts: {{ retry_count | default(0) }}\n      Max retries: 3\n\n      Can retry? {{ retry_count | default(0) &lt; 3 }}\n\nedges:\n  - from: execute\n    to: verify\n\n  - from: verify\n    choose:\n      - when: \"{{ 'success' in nodes.verify.response }}\"\n        to: complete\n      - when: else\n        to: execute  # Retry (limited by max_iterations)\n</code></pre>"},{"location":"howto/patterns/graph/#error-handling","title":"Error Handling","text":""},{"location":"howto/patterns/graph/#node-failure","title":"Node Failure","text":"<p>If a node fails: - Execution stops at that node - Workflow exits with error - No outgoing edges are followed</p>"},{"location":"howto/patterns/graph/#cycle-detection","title":"Cycle Detection","text":"<p>Strands detects infinite cycles:</p> <pre><code># This would be detected as a cycle\nedges:\n  - from: node_a\n    to: node_b\n  - from: node_b\n    to: node_a  # Unconditional cycle = error\n</code></pre> <p>Use conditional edges to avoid infinite cycles.</p>"},{"location":"howto/patterns/graph/#budget-limits","title":"Budget Limits","text":"<p>Prevent runaway graphs:</p> <pre><code>runtime:\n  budgets:\n    max_steps: 20          # Maximum total nodes\n    max_tokens: 100000     # Maximum total tokens\n    max_duration_s: 600    # Maximum 10 minutes\n\npattern:\n  type: graph\n  config:\n    max_iterations: 10  # Additional graph-specific limit\n</code></pre>"},{"location":"howto/patterns/graph/#output-artifacts","title":"Output Artifacts","text":""},{"location":"howto/patterns/graph/#using-node-results","title":"Using Node Results","text":"<p>Access specific nodes in artifacts:</p> <pre><code>outputs:\n  artifacts:\n    - path: \"decision_log.md\"\n      content: |\n        # Decision Log\n\n        ## Initial Classification\n        {{ nodes.classify.response }}\n\n        {% if nodes.technical %}\n        ## Technical Resolution\n        {{ nodes.technical.response }}\n        {% endif %}\n\n        {% if nodes.escalate %}\n        ## Escalation\n        {{ nodes.escalate.response }}\n        {% endif %}\n\n        ## Final Decision\n        Terminal Node: {{ terminal_node }}\n</code></pre>"},{"location":"howto/patterns/graph/#execution-trace","title":"Execution Trace","text":"<p>Include execution path:</p> <pre><code>outputs:\n  artifacts:\n    - path: \"trace.md\"\n      content: |\n        # Execution Trace\n\n        **Total Steps**: {{ total_steps }}\n        **Terminal Node**: {{ terminal_node }}\n\n        ## Nodes Executed\n        {% for node_id, node in nodes.items() %}\n        - {{ node_id }}: {{ node.status }}\n        {% endfor %}\n\n        ## Final Output\n        {{ last_response }}\n</code></pre>"},{"location":"howto/patterns/graph/#best-practices","title":"Best Practices","text":""},{"location":"howto/patterns/graph/#1-always-provide-else-clauses","title":"1. Always Provide Else Clauses","text":"<p>Ensure all paths are covered:</p> <pre><code># Good - complete coverage\nedges:\n  - from: classify\n    choose:\n      - when: \"{{ condition_1 }}\"\n        to: path1\n      - when: \"{{ condition_2 }}\"\n        to: path2\n      - when: else\n        to: default_path\n\n# Avoid - missing else clause\nedges:\n  - from: classify\n    choose:\n      - when: \"{{ condition }}\"\n        to: path1\n      # Missing else = error if condition false\n</code></pre>"},{"location":"howto/patterns/graph/#2-set-reasonable-max_iterations","title":"2. Set Reasonable max_iterations","text":"<p>Prevent infinite loops:</p> <pre><code># Good - reasonable limit\nconfig:\n  max_iterations: 10  # Allows some loops but prevents runaway\n\n# Avoid - too permissive\nconfig:\n  max_iterations: 1000  # Could run forever\n</code></pre>"},{"location":"howto/patterns/graph/#3-use-descriptive-node-names","title":"3. Use Descriptive Node Names","text":"<p>Make graph structure clear:</p> <pre><code># Good - clear purpose\nnodes:\n  validate_input:\n    agent: validator\n  auto_approve:\n    agent: approver\n  manager_review:\n    agent: manager\n\n# Avoid - generic names\nnodes:\n  node1: {...}\n  node2: {...}\n  node3: {...}\n</code></pre>"},{"location":"howto/patterns/graph/#4-document-complex-logic","title":"4. Document Complex Logic","text":"<p>Use comments for complex conditions:</p> <pre><code>edges:\n  - from: validate\n    choose:\n      # Auto-approve for amounts under $100\n      - when: \"{{ 'amount: 50' in nodes.validate.response }}\"\n        to: auto_approve\n\n      # Manager review for $100-$5000\n      - when: \"{{ 'amount: 500' in nodes.validate.response }}\"\n        to: manager\n\n      # Director approval for &gt; $5000\n      - when: else\n        to: director\n</code></pre>"},{"location":"howto/patterns/graph/#5-test-all-paths","title":"5. Test All Paths","text":"<p>Validate all execution paths:</p> <pre><code># Test different inputs to cover all paths\nstrands run graph.yaml --var input=\"approve\"\nstrands run graph.yaml --var input=\"reject\"\nstrands run graph.yaml --var input=\"escalate\"\n</code></pre>"},{"location":"howto/patterns/graph/#common-patterns","title":"Common Patterns","text":""},{"location":"howto/patterns/graph/#approval-workflow","title":"Approval Workflow","text":"<pre><code>nodes:\n  validate:\n    agent: validator\n  auto_approve:\n    agent: approver\n  manager:\n    agent: manager_agent\n  director:\n    agent: director_agent\n  reject:\n    agent: rejector\n\nedges:\n  - from: validate\n    choose:\n      - when: \"{{ 'invalid' in nodes.validate.response }}\"\n        to: reject\n      - when: \"{{ 'low amount' in nodes.validate.response }}\"\n        to: auto_approve\n      - when: \"{{ 'medium amount' in nodes.validate.response }}\"\n        to: manager\n      - when: else\n        to: director\n\n  - from: manager\n    choose:\n      - when: \"{{ 'approve' in nodes.manager.response }}\"\n        to: director\n      - when: else\n        to: reject\n</code></pre>"},{"location":"howto/patterns/graph/#state-machine","title":"State Machine","text":"<pre><code>nodes:\n  intake: {...}\n  process: {...}\n  verify: {...}\n  complete: {...}\n  retry: {...}\n\nedges:\n  - from: intake\n    to: process\n\n  - from: process\n    to: verify\n\n  - from: verify\n    choose:\n      - when: \"{{ 'success' in nodes.verify.response }}\"\n        to: complete\n      - when: \"{{ retry_count | default(0) &lt; 3 }}\"\n        to: process  # Retry\n      - when: else\n        to: complete  # Give up\n</code></pre>"},{"location":"howto/patterns/graph/#conditional-loop","title":"Conditional Loop","text":"<pre><code>nodes:\n  generate:\n    agent: generator\n  evaluate:\n    agent: evaluator\n  refine:\n    agent: refiner\n  finalize:\n    agent: finalizer\n\nedges:\n  - from: generate\n    to: evaluate\n\n  - from: evaluate\n    choose:\n      - when: \"{{ 'score: 90' in nodes.evaluate.response or 'score: 95' in nodes.evaluate.response }}\"\n        to: finalize  # Good enough\n      - when: \"{{ iteration &lt; 5 }}\"\n        to: generate  # Try again\n      - when: else\n        to: finalize  # Max iterations\n</code></pre>"},{"location":"howto/patterns/graph/#performance-considerations","title":"Performance Considerations","text":""},{"location":"howto/patterns/graph/#execution-overhead","title":"Execution Overhead","text":"<p>Graph pattern has minimal overhead per node:</p> <pre><code>Total time = Sum of node execution times\n</code></pre> <p>No scheduling overhead like Workflow pattern.</p>"},{"location":"howto/patterns/graph/#agent-caching","title":"Agent Caching","text":"<p>Agents are cached across nodes:</p> <pre><code>agents:\n  - id: processor\n    system: \"Process requests\"\n\nnodes:\n  step1:\n    agent: processor  # Agent built\n  step2:\n    agent: processor  # Cached\n  step3:\n    agent: processor  # Cached\n</code></pre>"},{"location":"howto/patterns/graph/#optimal-path-length","title":"Optimal Path Length","text":"<p>Shorter paths are faster:</p> <pre><code># Fast - direct path to terminal\nclassify \u2192 handle \u2192 complete (3 nodes)\n\n# Slower - long path with loops\nclassify \u2192 process \u2192 verify \u2192 refine \u2192 verify \u2192 refine \u2192 complete (7 nodes)\n</code></pre>"},{"location":"howto/patterns/graph/#troubleshooting","title":"Troubleshooting","text":""},{"location":"howto/patterns/graph/#graph-not-progressing","title":"Graph Not Progressing","text":"<p>Check for missing edges:</p> <pre><code>strands validate workflow.yaml\n</code></pre> <p>Look for: <pre><code>Node 'node_id' has no outgoing edges and condition not met\n</code></pre></p>"},{"location":"howto/patterns/graph/#infinite-loop-detected","title":"Infinite Loop Detected","text":"<p>If max_iterations is reached:</p> <pre><code>strands run workflow.yaml --debug --verbose\n</code></pre> <p>Look for: <pre><code>Max iterations (10) reached\nCurrent node: process\nExecution stopped\n</code></pre></p>"},{"location":"howto/patterns/graph/#condition-never-true","title":"Condition Never True","text":"<p>Debug condition evaluation:</p> <pre><code># Add debug node to check values\nnodes:\n  debug:\n    agent: debugger\n    input: |\n      Check condition:\n      Response: {{ nodes.classify.response }}\n      Contains 'approve': {{ 'approve' in nodes.classify.response.lower() }}\n</code></pre>"},{"location":"howto/patterns/graph/#wrong-path-taken","title":"Wrong Path Taken","text":"<p>Verify condition logic:</p> <pre><code>edges:\n  - from: classify\n    choose:\n      # Check exact condition matching\n      - when: \"{{ 'category a' in nodes.classify.response.lower() }}\"\n        to: handle_a\n      - when: \"{{ 'category b' in nodes.classify.response.lower() }}\"\n        to: handle_b\n      - when: else\n        to: default  # Add else to catch mismatches\n</code></pre>"},{"location":"howto/patterns/graph/#graph-vs-other-patterns","title":"Graph vs. Other Patterns","text":""},{"location":"howto/patterns/graph/#graph-vs-routing","title":"Graph vs. Routing","text":"<p>Graph has explicit conditions, Routing uses AI classification:</p> <pre><code># Graph: Explicit conditions\npattern:\n  type: graph\n  config:\n    edges:\n      - from: classify\n        choose:\n          - when: \"{{ 'technical' in nodes.classify.response }}\"\n            to: tech_handler\n\n# Routing: AI-based classification\npattern:\n  type: routing\n  config:\n    router:\n      agent: classifier  # AI decides route\n</code></pre>"},{"location":"howto/patterns/graph/#graph-vs-workflow","title":"Graph vs. Workflow","text":"<p>Graph has conditional flow, Workflow has fixed DAG:</p> <pre><code># Graph: Conditional routing\nedges:\n  - from: analyze\n    choose:\n      - when: \"{{ condition }}\"\n        to: path_a  # Dynamic choice\n      - when: else\n        to: path_b\n\n# Workflow: Fixed dependencies\ntasks:\n  - id: task1\n  - id: task2\n    deps: [task1]  # Always follows task1\n</code></pre>"},{"location":"howto/patterns/graph/#graph-vs-chain","title":"Graph vs. Chain","text":"<p>Graph supports branching, Chain is linear:</p> <pre><code># Graph: Multiple paths\nedges:\n  - from: classify\n    choose:\n      - when: \"{{ condition_a }}\"\n        to: handler_a\n      - when: \"{{ condition_b }}\"\n        to: handler_b\n\n# Chain: Single path\nsteps:\n  - agent_id: step1\n  - agent_id: step2  # Always follows step1\n</code></pre>"},{"location":"howto/patterns/graph/#examples","title":"Examples","text":"<p>Complete examples in the repository:</p> <ul> <li><code>examples/graph-decision-tree-openai.yaml</code> - Multi-level decision tree</li> <li><code>examples/graph-state-machine-openai.yaml</code> - State machine with loops</li> <li><code>examples/graph-iterative-refinement-openai.yaml</code> - Conditional refinement loop</li> </ul>"},{"location":"howto/patterns/graph/#see-also","title":"See Also","text":"<ul> <li>Routing Pattern - For AI-based routing</li> <li>Workflow Pattern - For DAG execution</li> <li>Chain Pattern - For sequential execution</li> <li>Run Workflows - Execution guide</li> </ul>"},{"location":"howto/patterns/orchestrator-workers/","title":"Orchestrator-Workers Pattern","text":"<p>The Orchestrator-Workers pattern implements dynamic task delegation where an orchestrator agent breaks down complex work into subtasks, delegates them to worker agents running in parallel, aggregates results, and optionally produces a final writeup. This is ideal for research swarms, data processing pipelines, and collaborative multi-agent workflows.</p>"},{"location":"howto/patterns/orchestrator-workers/#when-to-use","title":"When to Use","text":"<p>Use the Orchestrator-Workers pattern when you need to:</p> <ul> <li>Break down complex tasks into parallel subtasks dynamically</li> <li>Delegate work to specialized worker agents</li> <li>Process large datasets with distributed workers</li> <li>Aggregate results from multiple concurrent workers</li> <li>Implement research swarms or collaborative agent teams</li> <li>Scale work distribution based on task complexity</li> </ul>"},{"location":"howto/patterns/orchestrator-workers/#basic-example","title":"Basic Example","text":"<pre><code>version: 0\nname: simple-orchestrator\ndescription: Research swarm with dynamic task delegation\n\nruntime:\n  provider: bedrock\n  model: anthropic.claude-3-sonnet-20240229-v1:0\n\nagents:\n  - id: orchestrator\n    system: |\n      You break down research topics into specific subtasks.\n      Respond with JSON array: [{\"task\": \"subtask 1\"}, {\"task\": \"subtask 2\"}]\n\n  - id: researcher\n    system: \"You are a research specialist. Conduct thorough research.\"\n\n  - id: synthesizer\n    system: \"You aggregate research from multiple sources.\"\n\npattern:\n  type: orchestrator_workers\n  config:\n    orchestrator:\n      agent: orchestrator\n      limits:\n        max_workers: 3\n        max_rounds: 1\n\n    worker_template:\n      agent: researcher\n\n    reduce:\n      agent: synthesizer\n      input: \"Aggregate findings from all workers\"\n\ninputs:\n  topic:\n    type: string\n    description: \"Research topic\"\n    default: \"artificial intelligence\"\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#pattern-components","title":"Pattern Components","text":""},{"location":"howto/patterns/orchestrator-workers/#orchestrator-configuration","title":"Orchestrator Configuration","text":"<p>The orchestrator creates tasks for workers:</p> <pre><code>orchestrator:\n  agent: orchestrator\n  limits:\n    max_workers: 3   # Maximum concurrent workers\n    max_rounds: 1    # Maximum delegation rounds\n</code></pre> <p>Critical: Orchestrator must return JSON array of tasks:</p> <pre><code>[\n  {\"task\": \"Research technical aspects\"},\n  {\"task\": \"Research business implications\"},\n  {\"task\": \"Research ethical considerations\"}\n]\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#worker-template","title":"Worker Template","text":"<p>Defines how workers execute tasks:</p> <pre><code>worker_template:\n  agent: researcher\n  tools: []  # Optional: Tools available to workers\n</code></pre> <p>Each task from the orchestrator spawns a worker using this template.</p>"},{"location":"howto/patterns/orchestrator-workers/#reduce-step","title":"Reduce Step","text":"<p>Aggregates worker results:</p> <pre><code>reduce:\n  agent: synthesizer\n  input: |\n    Synthesize findings from {{ workers | length }} workers:\n\n    {% for worker in workers %}\n    Worker {{ loop.index }}: {{ worker.response }}\n    {% endfor %}\n</code></pre> <p>The reduce step executes after all workers complete.</p>"},{"location":"howto/patterns/orchestrator-workers/#writeup-step-optional","title":"Writeup Step (Optional)","text":"<p>Creates final report from aggregated results:</p> <pre><code>writeup:\n  agent: writer\n  input: |\n    Synthesis: {{ reduce_response }}\n\n    Create executive summary report.\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#orchestrator-output","title":"Orchestrator Output","text":""},{"location":"howto/patterns/orchestrator-workers/#task-array-format","title":"Task Array Format","text":"<p>Orchestrator must return JSON array:</p> <pre><code># Valid orchestrator output\n[\n  {\"task\": \"Research aspect 1\"},\n  {\"task\": \"Research aspect 2\"},\n  {\"task\": \"Research aspect 3\"}\n]\n</code></pre> <p>Each object must have a <code>task</code> field. Additional fields are passed to workers.</p>"},{"location":"howto/patterns/orchestrator-workers/#dynamic-task-count","title":"Dynamic Task Count","text":"<p>Orchestrator determines how many workers to spawn:</p> <pre><code># Orchestrator can create 1-10 tasks dynamically\n[\n  {\"task\": \"Task 1\"},\n  {\"task\": \"Task 2\"}\n  # ... up to max_workers tasks\n]\n</code></pre> <p>The <code>max_workers</code> limit controls maximum concurrent workers.</p>"},{"location":"howto/patterns/orchestrator-workers/#task-metadata","title":"Task Metadata","text":"<p>Include additional metadata in tasks:</p> <pre><code># Orchestrator output with metadata\n[\n  {\"task\": \"Research A\", \"priority\": \"high\", \"depth\": \"detailed\"},\n  {\"task\": \"Research B\", \"priority\": \"medium\", \"depth\": \"brief\"}\n]\n</code></pre> <p>Workers can access metadata in their prompts.</p>"},{"location":"howto/patterns/orchestrator-workers/#worker-execution","title":"Worker Execution","text":""},{"location":"howto/patterns/orchestrator-workers/#worker-input-template","title":"Worker Input Template","text":"<p>Workers receive orchestrator tasks:</p> <pre><code>worker_template:\n  agent: researcher\n  # Implicit input: \"{{ task }}\"\n</code></pre> <p>Default worker input is the <code>task</code> field from orchestrator output.</p>"},{"location":"howto/patterns/orchestrator-workers/#custom-worker-input","title":"Custom Worker Input","text":"<p>Customize worker prompts:</p> <pre><code>orchestrator:\n  agent: orchestrator\n  task_prompt_template: |\n    Assigned task: {{ task }}\n    Priority: {{ priority | default('normal') }}\n\n    Execute this research task thoroughly.\n</code></pre> <p>Access task metadata in template.</p>"},{"location":"howto/patterns/orchestrator-workers/#worker-tools","title":"Worker Tools","text":"<p>Provide tools to workers:</p> <pre><code>worker_template:\n  agent: researcher\n  tools:\n    - http_executors  # Enable web research\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#accessing-results","title":"Accessing Results","text":""},{"location":"howto/patterns/orchestrator-workers/#workers-array","title":"Workers Array","text":"<p>Access all worker results in reduce step:</p> <pre><code>reduce:\n  agent: synthesizer\n  input: |\n    Findings from {{ workers | length }} workers:\n\n    {% for worker in workers %}\n    Worker {{ loop.index }}:\n    Task: {{ worker.task }}\n    Result: {{ worker.response }}\n    {% endfor %}\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#reduce-response","title":"Reduce Response","text":"<p>Access aggregated results in writeup:</p> <pre><code>writeup:\n  agent: writer\n  input: |\n    Aggregated findings:\n    {{ reduce_response }}\n\n    Create final report.\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#worker-metadata","title":"Worker Metadata","text":"<p>Access worker task metadata:</p> <pre><code>reduce:\n  agent: synthesizer\n  input: |\n    {% for worker in workers %}\n    Task: {{ worker.task }}\n    Priority: {{ worker.priority }}\n    Result: {{ worker.response }}\n    {% endfor %}\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#multi-round-delegation","title":"Multi-Round Delegation","text":""},{"location":"howto/patterns/orchestrator-workers/#multiple-rounds","title":"Multiple Rounds","text":"<p>Orchestrator can delegate multiple times:</p> <pre><code>orchestrator:\n  agent: orchestrator\n  limits:\n    max_workers: 3\n    max_rounds: 2  # Two delegation rounds\n</code></pre> <p>Round 1 workers complete, then Round 2 workers execute.</p>"},{"location":"howto/patterns/orchestrator-workers/#round-aware-orchestration","title":"Round-Aware Orchestration","text":"<p>Orchestrator sees previous round results:</p> <pre><code>agents:\n  - id: orchestrator\n    system: |\n      Round 1: Break down topic into subtasks\n      Round 2: Based on results, identify gaps and create follow-up tasks\n\n      Respond with JSON array of tasks.\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#accessing-round-results","title":"Accessing Round Results","text":"<p>In reduce step, access all rounds:</p> <pre><code>reduce:\n  agent: synthesizer\n  input: |\n    Round 1 workers: {{ round_1_workers | length }}\n    Round 2 workers: {{ round_2_workers | length }}\n\n    All findings:\n    {% for worker in workers %}\n    {{ worker.response }}\n    {% endfor %}\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#advanced-features","title":"Advanced Features","text":""},{"location":"howto/patterns/orchestrator-workers/#limiting-concurrency","title":"Limiting Concurrency","text":"<p>Control parallel worker execution:</p> <pre><code>orchestrator:\n  agent: orchestrator\n  limits:\n    max_workers: 5  # Process max 5 tasks concurrently\n</code></pre> <p>If orchestrator creates 10 tasks and max_workers=5, workers execute in batches of 5.</p>"},{"location":"howto/patterns/orchestrator-workers/#dynamic-orchestration","title":"Dynamic Orchestration","text":"<p>Orchestrator adapts based on input:</p> <pre><code>agents:\n  - id: orchestrator\n    system: |\n      Analyze topic complexity: {{ topic }}\n\n      For simple topics: Create 2-3 tasks\n      For complex topics: Create 4-6 tasks\n\n      Return JSON array of tasks.\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#specialized-workers","title":"Specialized Workers","text":"<p>Use different worker types:</p> <pre><code>agents:\n  - id: technical_researcher\n    system: \"Technical research specialist\"\n\n  - id: business_researcher\n    system: \"Business analysis specialist\"\n\nworker_template:\n  agent: \"{{ worker_type | default('technical_researcher') }}\"\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#error-handling","title":"Error Handling","text":""},{"location":"howto/patterns/orchestrator-workers/#worker-failure","title":"Worker Failure","text":"<p>If a worker fails: - Other workers continue executing - Failed worker excluded from reduce step - Workflow succeeds with partial results</p>"},{"location":"howto/patterns/orchestrator-workers/#orchestrator-failure","title":"Orchestrator Failure","text":"<p>If orchestrator returns invalid JSON:</p> <pre><code>Error: Orchestrator response is not valid JSON\nExpected: [{\"task\": \"...\"}, ...]\nReceived: \"Create three research tasks\"\n</code></pre> <p>Fix: Enforce JSON output in orchestrator system prompt.</p>"},{"location":"howto/patterns/orchestrator-workers/#budget-limits","title":"Budget Limits","text":"<p>Prevent runaway orchestration:</p> <pre><code>runtime:\n  budgets:\n    max_steps: 50          # Maximum total steps\n    max_tokens: 200000     # Maximum total tokens\n    max_duration_s: 600    # Maximum 10 minutes\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#output-artifacts","title":"Output Artifacts","text":""},{"location":"howto/patterns/orchestrator-workers/#using-writeup","title":"Using Writeup","text":"<p>Save final report:</p> <pre><code>outputs:\n  artifacts:\n    - path: \"final_report.md\"\n      content: \"{{ last_response }}\"  # From writeup step\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#using-reduce","title":"Using Reduce","text":"<p>Save aggregated results:</p> <pre><code>outputs:\n  artifacts:\n    - path: \"aggregated_findings.md\"\n      content: \"{{ reduce_response }}\"\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#using-worker-results","title":"Using Worker Results","text":"<p>Access individual worker outputs:</p> <pre><code>outputs:\n  artifacts:\n    - path: \"all_findings.md\"\n      content: |\n        # Research Findings\n\n        {% for worker in workers %}\n        ## Worker {{ loop.index }}\n        Task: {{ worker.task }}\n\n        {{ worker.response }}\n        {% endfor %}\n\n        ## Synthesis\n        {{ reduce_response }}\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#best-practices","title":"Best Practices","text":""},{"location":"howto/patterns/orchestrator-workers/#1-clear-orchestrator-instructions","title":"1. Clear Orchestrator Instructions","text":"<p>Provide explicit task breakdown guidance:</p> <pre><code>agents:\n  - id: orchestrator\n    system: |\n      You are a research orchestrator.\n\n      Break down \"{{ topic }}\" into {{ num_perspectives }} distinct subtasks.\n      Each subtask should focus on a different aspect or perspective.\n\n      Respond with ONLY a JSON array:\n      [{\"task\": \"Research aspect 1\"}, {\"task\": \"Research aspect 2\"}, ...]\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#2-validate-orchestrator-output","title":"2. Validate Orchestrator Output","text":"<p>Ensure orchestrator returns valid JSON array:</p> <pre><code># Good - valid JSON array\n[\n  {\"task\": \"Research technical aspects\"},\n  {\"task\": \"Research business aspects\"}\n]\n\n# Bad - invalid format\n\"Create tasks for technical and business research\"\n\n# Bad - not an array\n{\"task\": \"Research everything\"}\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#3-set-appropriate-worker-limits","title":"3. Set Appropriate Worker Limits","text":"<p>Balance speed and resource usage:</p> <pre><code># For I/O-bound tasks (research, web scraping)\nlimits:\n  max_workers: 10  # Higher concurrency acceptable\n\n# For compute-intensive tasks\nlimits:\n  max_workers: 3   # Lower to avoid overload\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#4-use-reduce-for-aggregation","title":"4. Use Reduce for Aggregation","text":"<p>Always include reduce step for synthesis:</p> <pre><code># Good - synthesized output\nconfig:\n  orchestrator: {...}\n  worker_template: {...}\n  reduce:\n    agent: synthesizer\n    input: \"Aggregate all findings\"\n\n# Avoid - no synthesis\nconfig:\n  orchestrator: {...}\n  worker_template: {...}\n  # Missing reduce step\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#5-monitor-worker-distribution","title":"5. Monitor Worker Distribution","text":"<p>Track task distribution:</p> <pre><code>reduce:\n  agent: synthesizer\n  input: |\n    Workers spawned: {{ workers | length }}\n    Max workers: {{ max_workers }}\n    Rounds: {{ round_count }}\n\n    Findings: ...\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#common-patterns","title":"Common Patterns","text":""},{"location":"howto/patterns/orchestrator-workers/#research-swarm","title":"Research Swarm","text":"<pre><code>orchestrator:\n  agent: research_planner\n  limits:\n    max_workers: 3\n    max_rounds: 1\n\nworker_template:\n  agent: researcher\n  tools:\n    - http_executors\n\nreduce:\n  agent: synthesizer\n  input: \"Synthesize all research findings\"\n\nwriteup:\n  agent: report_writer\n  input: \"Create executive summary from synthesis\"\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#data-processing-pipeline","title":"Data Processing Pipeline","text":"<pre><code>orchestrator:\n  agent: task_planner\n  limits:\n    max_workers: 5\n    max_rounds: 1\n\nworker_template:\n  agent: data_analyst\n\nreduce:\n  agent: aggregator\n  input: \"Aggregate analysis from all workers\"\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#parallel-code-review","title":"Parallel Code Review","text":"<pre><code>orchestrator:\n  agent: code_splitter\n  limits:\n    max_workers: 4\n    max_rounds: 1\n\nworker_template:\n  agent: code_reviewer\n\nreduce:\n  agent: review_aggregator\n  input: \"Consolidate all code review findings\"\n\nwriteup:\n  agent: summary_writer\n  input: \"Create review summary with action items\"\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#performance-considerations","title":"Performance Considerations","text":""},{"location":"howto/patterns/orchestrator-workers/#orchestrator-overhead","title":"Orchestrator Overhead","text":"<p>The orchestrator adds one initial invocation:</p> <pre><code>Total time = Orchestrator time + Max(worker times) + Reduce time + Writeup time\n           \u2248 2s + Worker execution + 2s + 2s\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#worker-parallelism","title":"Worker Parallelism","text":"<p>Workers execute in parallel up to max_workers:</p> <pre><code># 6 tasks, max_workers=3\nBatch 1: Workers 1, 2, 3 (parallel) - 10s\nBatch 2: Workers 4, 5, 6 (parallel) - 10s\nTotal: 20s\n\n# 6 tasks, max_workers=6\nAll workers (parallel) - 10s\nTotal: 10s\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#agent-caching","title":"Agent Caching","text":"<p>Workers use cached agents:</p> <pre><code>worker_template:\n  agent: researcher  # Agent built once, reused for all workers\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#troubleshooting","title":"Troubleshooting","text":""},{"location":"howto/patterns/orchestrator-workers/#orchestrator-not-returning-json","title":"Orchestrator Not Returning JSON","text":"<p>Check orchestrator output:</p> <pre><code>strands run workflow.yaml --debug --verbose\n</code></pre> <p>Look for: <pre><code>Orchestrator response: \"Break this into three tasks\"\nError: Invalid JSON from orchestrator\n</code></pre></p> <p>Fix: Enforce JSON-only output in system prompt.</p>"},{"location":"howto/patterns/orchestrator-workers/#too-many-workers-created","title":"Too Many Workers Created","text":"<p>If orchestrator creates more tasks than expected:</p> <pre><code>orchestrator:\n  limits:\n    max_workers: 3  # Hard limit on concurrent workers\n</code></pre> <p>Workers beyond limit queue and execute in batches.</p>"},{"location":"howto/patterns/orchestrator-workers/#workers-not-completing","title":"Workers Not Completing","text":"<p>Enable debug logging:</p> <pre><code>strands run workflow.yaml --debug --verbose\n</code></pre> <p>Look for: <pre><code>Worker 1: Completed\nWorker 2: Failed - &lt;error&gt;\nWorker 3: Completed\n</code></pre></p> <p>Failed workers are excluded from reduce step.</p>"},{"location":"howto/patterns/orchestrator-workers/#reduce-step-failing","title":"Reduce Step Failing","text":"<p>Ensure at least one worker succeeds:</p> <pre><code>Reduce step requires at least one successful worker\nAll workers failed - reduce step skipped\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#orchestrator-workers-vs-other-patterns","title":"Orchestrator-Workers vs. Other Patterns","text":""},{"location":"howto/patterns/orchestrator-workers/#vs-parallel","title":"vs. Parallel","text":"<p>Orchestrator-Workers has dynamic task creation, Parallel has static branches:</p> <pre><code># Orchestrator-Workers: Dynamic tasks\npattern:\n  type: orchestrator_workers\n  config:\n    orchestrator:\n      agent: planner  # AI creates tasks dynamically\n\n# Parallel: Static branches\npattern:\n  type: parallel\n  config:\n    branches:\n      - id: branch1  # Predefined branches\n      - id: branch2\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#vs-workflow","title":"vs. Workflow","text":"<p>Orchestrator-Workers delegates dynamically, Workflow has fixed DAG:</p> <pre><code># Orchestrator-Workers: Dynamic delegation\npattern:\n  type: orchestrator_workers\n  config:\n    orchestrator:\n      agent: planner  # Creates tasks at runtime\n\n# Workflow: Fixed tasks\npattern:\n  type: workflow\n  config:\n    tasks:\n      - id: task1   # Predefined tasks\n      - id: task2\n</code></pre>"},{"location":"howto/patterns/orchestrator-workers/#examples","title":"Examples","text":"<p>Complete examples in the repository:</p> <ul> <li><code>examples/orchestrator-research-swarm-openai.yaml</code> - Research team collaboration</li> <li><code>examples/orchestrator-data-processing-openai.yaml</code> - Data processing pipeline</li> <li><code>examples/orchestrator-minimal-openai.yaml</code> - Basic orchestrator pattern</li> </ul>"},{"location":"howto/patterns/orchestrator-workers/#see-also","title":"See Also","text":"<ul> <li>Parallel Pattern - For static concurrent branches</li> <li>Workflow Pattern - For DAG-based execution</li> <li>Chain Pattern - For sequential execution</li> <li>Run Workflows - Execution guide</li> </ul>"},{"location":"howto/patterns/parallel/","title":"Parallel Pattern","text":"<p>The Parallel pattern executes multiple independent branches concurrently, with an optional reduce step to aggregate results. This is ideal for scenarios where you need to perform similar operations on different data or gather multiple perspectives simultaneously.</p>"},{"location":"howto/patterns/parallel/#when-to-use","title":"When to Use","text":"<p>Use the Parallel pattern when you need to:</p> <ul> <li>Execute independent tasks concurrently for faster completion</li> <li>Gather multiple perspectives or analyses simultaneously</li> <li>Process different data sources in parallel</li> <li>Perform the same operation on multiple inputs</li> <li>Aggregate concurrent results into a single output</li> </ul>"},{"location":"howto/patterns/parallel/#basic-example","title":"Basic Example","text":"<pre><code>version: 0\nname: simple-parallel\ndescription: Parallel research on two aspects\n\nruntime:\n  provider: bedrock\n  model: anthropic.claude-3-sonnet-20240229-v1:0\n\nagents:\n  - id: researcher\n    system: \"You are a research assistant providing factual information.\"\n\npattern:\n  type: parallel\n  config:\n    branches:\n      - id: technical\n        steps:\n          - agent: researcher\n            input: \"Research technical aspects of {{ topic }}\"\n\n      - id: business\n        steps:\n          - agent: researcher\n            input: \"Research business aspects of {{ topic }}\"\n\ninputs:\n  topic:\n    type: string\n    description: \"Research topic\"\n    default: \"artificial intelligence\"\n</code></pre>"},{"location":"howto/patterns/parallel/#branch-configuration","title":"Branch Configuration","text":""},{"location":"howto/patterns/parallel/#simple-branches","title":"Simple Branches","text":"<p>Each branch executes independently:</p> <pre><code>branches:\n  - id: branch1\n    steps:\n      - agent: researcher\n        input: \"Research aspect 1\"\n\n  - id: branch2\n    steps:\n      - agent: researcher\n        input: \"Research aspect 2\"\n\n  - id: branch3\n    steps:\n      - agent: researcher\n        input: \"Research aspect 3\"\n</code></pre> <p>All branches start simultaneously.</p>"},{"location":"howto/patterns/parallel/#multi-step-branches","title":"Multi-Step Branches","text":"<p>Branches can have multiple sequential steps:</p> <pre><code>branches:\n  - id: comprehensive_research\n    steps:\n      - agent: researcher\n        input: \"Gather data about {{ topic }}\"\n\n      - agent: analyst\n        input: |\n          Data: {{ last_response }}\n\n          Analyze key points.\n\n      - agent: writer\n        input: |\n          Analysis: {{ last_response }}\n\n          Write summary.\n</code></pre> <p>Within a branch, steps execute sequentially. Across branches, execution is concurrent.</p>"},{"location":"howto/patterns/parallel/#accessing-branch-results","title":"Accessing Branch Results","text":""},{"location":"howto/patterns/parallel/#specific-branch-outputs","title":"Specific Branch Outputs","text":"<p>Access any branch result by its ID:</p> <pre><code># In reduce step or artifacts\ncontent: |\n  Technical: {{ branches.technical.response }}\n  Business: {{ branches.business.response }}\n</code></pre>"},{"location":"howto/patterns/parallel/#branch-metadata","title":"Branch Metadata","text":"<p>Access branch status and metadata:</p> <pre><code>content: |\n  ## Technical Research\n  Status: {{ branches.technical.status }}\n  {{ branches.technical.response }}\n</code></pre>"},{"location":"howto/patterns/parallel/#iterating-over-branches","title":"Iterating Over Branches","text":"<p>Loop through all branch results:</p> <pre><code>content: |\n  # All Research Findings\n\n  {% for branch_id, branch in branches.items() %}\n  ## {{ branch_id | title }}\n  {{ branch.response }}\n  {% endfor %}\n</code></pre>"},{"location":"howto/patterns/parallel/#reduce-step","title":"Reduce Step","text":""},{"location":"howto/patterns/parallel/#basic-reduction","title":"Basic Reduction","text":"<p>Aggregate all branch results:</p> <pre><code>pattern:\n  type: parallel\n  config:\n    branches:\n      - id: aspect1\n        steps: [...]\n\n      - id: aspect2\n        steps: [...]\n\n      - id: aspect3\n        steps: [...]\n\n    reduce:\n      agent: synthesizer\n      input: |\n        Synthesize these findings:\n\n        Aspect 1: {{ branches.aspect1.response }}\n        Aspect 2: {{ branches.aspect2.response }}\n        Aspect 3: {{ branches.aspect3.response }}\n</code></pre> <p>The reduce step executes after all branches complete.</p>"},{"location":"howto/patterns/parallel/#accessing-all-branches-in-reduce","title":"Accessing All Branches in Reduce","text":"<p>Use template iteration:</p> <pre><code>reduce:\n  agent: synthesizer\n  input: |\n    Combine all research perspectives:\n\n    {% for branch_id, branch in branches.items() %}\n    {{ branch_id }}: {{ branch.response }}\n    {% endfor %}\n\n    Create unified analysis.\n</code></pre>"},{"location":"howto/patterns/parallel/#workers-array","title":"Workers Array","text":"<p>Access branch results as an array:</p> <pre><code>reduce:\n  agent: synthesizer\n  input: |\n    Findings from {{ workers | length }} branches:\n\n    {% for worker in workers %}\n    Branch {{ loop.index }}: {{ worker.response }}\n    {% endfor %}\n</code></pre>"},{"location":"howto/patterns/parallel/#advanced-features","title":"Advanced Features","text":""},{"location":"howto/patterns/parallel/#different-agents-per-branch","title":"Different Agents Per Branch","text":"<p>Assign specialized agents to different branches:</p> <pre><code>agents:\n  - id: tech_expert\n    system: \"You are a technical expert.\"\n\n  - id: business_analyst\n    system: \"You are a business analyst.\"\n\n  - id: market_researcher\n    system: \"You are a market researcher.\"\n\n  - id: synthesizer\n    system: \"You synthesize multiple perspectives.\"\n\nbranches:\n  - id: technical\n    steps:\n      - agent: tech_expert\n        input: \"Technical analysis of {{ topic }}\"\n\n  - id: business\n    steps:\n      - agent: business_analyst\n        input: \"Business analysis of {{ topic }}\"\n\n  - id: market\n    steps:\n      - agent: market_researcher\n        input: \"Market analysis of {{ topic }}\"\n\nreduce:\n  agent: synthesizer\n  input: \"Synthesize all analyses\"\n</code></pre>"},{"location":"howto/patterns/parallel/#branch-specific-variables","title":"Branch-Specific Variables","text":"<p>Pass different variables to different branches:</p> <pre><code>branches:\n  - id: detailed\n    steps:\n      - agent: researcher\n        input: \"Research {{ topic }}\"\n        vars:\n          depth: \"comprehensive\"\n          max_length: 1000\n\n  - id: summary\n    steps:\n      - agent: researcher\n        input: \"Research {{ topic }}\"\n        vars:\n          depth: \"brief\"\n          max_length: 200\n</code></pre>"},{"location":"howto/patterns/parallel/#conditional-content-in-branches","title":"Conditional Content in Branches","text":"<p>Use Jinja2 conditionals:</p> <pre><code>branches:\n  - id: analysis\n    steps:\n      - agent: analyst\n        input: |\n          {% if include_technical %}\n          Include technical details for {{ topic }}\n          {% else %}\n          Provide high-level overview of {{ topic }}\n          {% endif %}\n</code></pre>"},{"location":"howto/patterns/parallel/#without-reduce-step","title":"Without Reduce Step","text":""},{"location":"howto/patterns/parallel/#parallel-execution-only","title":"Parallel Execution Only","text":"<p>Omit the reduce step to run branches without aggregation:</p> <pre><code>pattern:\n  type: parallel\n  config:\n    branches:\n      - id: branch1\n        steps: [...]\n\n      - id: branch2\n        steps: [...]\n\n    # No reduce step - just parallel execution\n</code></pre> <p>The <code>last_response</code> will be from the last branch to complete (non-deterministic).</p>"},{"location":"howto/patterns/parallel/#accessing-results","title":"Accessing Results","text":"<p>Use branch-specific outputs in artifacts:</p> <pre><code>outputs:\n  artifacts:\n    - path: \"technical_report.md\"\n      content: \"{{ branches.technical.response }}\"\n\n    - path: \"business_report.md\"\n      content: \"{{ branches.business.response }}\"\n\n    - path: \"combined_report.md\"\n      content: |\n        # Combined Report\n\n        ## Technical\n        {{ branches.technical.response }}\n\n        ## Business\n        {{ branches.business.response }}\n</code></pre>"},{"location":"howto/patterns/parallel/#error-handling","title":"Error Handling","text":""},{"location":"howto/patterns/parallel/#branch-failure-behavior","title":"Branch Failure Behavior","text":"<p>If a branch fails: - Other branches continue executing - Failed branch is excluded from reduce step - Workflow succeeds with partial results (unless all branches fail)</p>"},{"location":"howto/patterns/parallel/#retry-configuration","title":"Retry Configuration","text":"<p>Configure retries at the runtime level:</p> <pre><code>runtime:\n  provider: bedrock\n  model: anthropic.claude-3-sonnet-20240229-v1:0\n  failure_policy:\n    retries: 3\n    backoff: exponential\n</code></pre> <p>Each step in each branch gets retry attempts.</p>"},{"location":"howto/patterns/parallel/#budget-limits","title":"Budget Limits","text":"<p>Prevent runaway parallel workflows:</p> <pre><code>runtime:\n  budgets:\n    max_steps: 20           # Maximum steps across all branches\n    max_tokens: 100000      # Maximum total tokens\n    max_duration_s: 600     # Maximum 10 minutes\n</code></pre>"},{"location":"howto/patterns/parallel/#output-artifacts","title":"Output Artifacts","text":""},{"location":"howto/patterns/parallel/#using-branch-results","title":"Using Branch Results","text":"<p>Save individual branch outputs:</p> <pre><code>outputs:\n  artifacts:\n    - path: \"{{ topic }}_technical.md\"\n      content: \"{{ branches.technical.response }}\"\n\n    - path: \"{{ topic }}_business.md\"\n      content: \"{{ branches.business.response }}\"\n</code></pre>"},{"location":"howto/patterns/parallel/#using-reduced-result","title":"Using Reduced Result","text":"<p>Save the synthesized output:</p> <pre><code>outputs:\n  artifacts:\n    - path: \"{{ topic }}_synthesis.md\"\n      content: \"{{ last_response }}\"  # From reduce step\n</code></pre>"},{"location":"howto/patterns/parallel/#combined-artifacts","title":"Combined Artifacts","text":"<p>Include both individual and synthesized results:</p> <pre><code>outputs:\n  artifacts:\n    - path: \"complete_analysis.md\"\n      content: |\n        # {{ topic | title }} Analysis\n\n        ## Technical Perspective\n        {{ branches.technical.response }}\n\n        ## Business Perspective\n        {{ branches.business.response }}\n\n        ## Market Perspective\n        {{ branches.market.response }}\n\n        ## Synthesis\n        {{ last_response }}\n</code></pre>"},{"location":"howto/patterns/parallel/#best-practices","title":"Best Practices","text":""},{"location":"howto/patterns/parallel/#1-ensure-branch-independence","title":"1. Ensure Branch Independence","text":"<p>Branches should not depend on each other's results:</p> <pre><code># Good - independent branches\nbranches:\n  - id: source1\n    steps:\n      - agent: researcher\n        input: \"Research source 1 about {{ topic }}\"\n\n  - id: source2\n    steps:\n      - agent: researcher\n        input: \"Research source 2 about {{ topic }}\"\n\n# Avoid - branch2 depends on branch1 (use Workflow pattern instead)\nbranches:\n  - id: research\n    steps:\n      - agent: researcher\n        input: \"Research {{ topic }}\"\n\n  - id: analysis\n    steps:\n      - agent: analyst\n        input: \"Analyze {{ branches.research.response }}\"  # Won't work!\n</code></pre> <p>If branches need to share results, use the Workflow pattern instead.</p>"},{"location":"howto/patterns/parallel/#2-use-descriptive-branch-ids","title":"2. Use Descriptive Branch IDs","text":"<p>Make branch IDs meaningful:</p> <pre><code># Good - clear purpose\nbranches:\n  - id: academic_perspective\n  - id: industry_perspective\n  - id: regulatory_perspective\n\n# Avoid - generic IDs\nbranches:\n  - id: branch1\n  - id: branch2\n  - id: branch3\n</code></pre>"},{"location":"howto/patterns/parallel/#3-balance-branch-count","title":"3. Balance Branch Count","text":"<p>More branches = faster completion but higher resource usage:</p> <pre><code># Fast but resource-intensive (10 concurrent API calls)\nbranches:\n  - id: perspective1\n  - id: perspective2\n  # ... 10 total branches\n\n# Slower but more conservative (3 concurrent API calls)\nbranches:\n  - id: perspective1\n  - id: perspective2\n  - id: perspective3\n</code></pre> <p>Consider your provider's rate limits and costs.</p>"},{"location":"howto/patterns/parallel/#4-use-reduce-for-aggregation","title":"4. Use Reduce for Aggregation","text":"<p>Always use a reduce step when you need unified output:</p> <pre><code># Good - synthesized output\nconfig:\n  branches: [...]\n  reduce:\n    agent: synthesizer\n    input: \"Combine all findings\"\n\n# Avoid - no synthesis (just multiple independent outputs)\nconfig:\n  branches: [...]\n  # Missing reduce step\n</code></pre>"},{"location":"howto/patterns/parallel/#5-handle-variable-branch-counts","title":"5. Handle Variable Branch Counts","text":"<p>Use iteration to handle dynamic branch counts:</p> <pre><code>reduce:\n  agent: synthesizer\n  input: |\n    Synthesize findings from {{ branches | length }} branches:\n\n    {% for branch_id, branch in branches.items() %}\n    {{ branch_id }}: {{ branch.response }}\n    {% endfor %}\n</code></pre>"},{"location":"howto/patterns/parallel/#common-patterns","title":"Common Patterns","text":""},{"location":"howto/patterns/parallel/#multi-perspective-analysis","title":"Multi-Perspective Analysis","text":"<pre><code>branches:\n  - id: academic\n    steps:\n      - agent: academic_researcher\n        input: \"Academic perspective on {{ topic }}\"\n\n  - id: industry\n    steps:\n      - agent: industry_analyst\n        input: \"Industry perspective on {{ topic }}\"\n\n  - id: regulatory\n    steps:\n      - agent: regulatory_expert\n        input: \"Regulatory perspective on {{ topic }}\"\n\nreduce:\n  agent: synthesizer\n  input: \"Synthesize all three perspectives\"\n</code></pre>"},{"location":"howto/patterns/parallel/#data-source-aggregation","title":"Data Source Aggregation","text":"<pre><code>branches:\n  - id: database1\n    steps:\n      - agent: data_analyst\n        input: \"Analyze data from source 1\"\n\n  - id: database2\n    steps:\n      - agent: data_analyst\n        input: \"Analyze data from source 2\"\n\n  - id: api_data\n    steps:\n      - agent: data_analyst\n        input: \"Analyze data from API\"\n\nreduce:\n  agent: aggregator\n  input: \"Aggregate all data sources\"\n</code></pre>"},{"location":"howto/patterns/parallel/#competitive-analysis","title":"Competitive Analysis","text":"<pre><code>branches:\n  - id: competitor_a\n    steps:\n      - agent: analyst\n        input: \"Analyze competitor A's strategy\"\n\n  - id: competitor_b\n    steps:\n      - agent: analyst\n        input: \"Analyze competitor B's strategy\"\n\n  - id: competitor_c\n    steps:\n      - agent: analyst\n        input: \"Analyze competitor C's strategy\"\n\nreduce:\n  agent: strategist\n  input: \"Compare all competitors and recommend strategy\"\n</code></pre>"},{"location":"howto/patterns/parallel/#performance-considerations","title":"Performance Considerations","text":""},{"location":"howto/patterns/parallel/#parallel-speedup","title":"Parallel Speedup","text":"<p>Parallel pattern provides linear speedup for independent tasks:</p> <pre><code># Sequential (Chain): 30 seconds total\npattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: researcher\n        prompt: \"Research A\"  # 10s\n      - agent_id: researcher\n        prompt: \"Research B\"  # 10s\n      - agent_id: researcher\n        prompt: \"Research C\"  # 10s\n\n# Parallel: 10 seconds total (3x speedup)\npattern:\n  type: parallel\n  config:\n    branches:\n      - id: a\n        steps:\n          - agent: researcher\n            input: \"Research A\"  # 10s (concurrent)\n      - id: b\n        steps:\n          - agent: researcher\n            input: \"Research B\"  # 10s (concurrent)\n      - id: c\n        steps:\n          - agent: researcher\n            input: \"Research C\"  # 10s (concurrent)\n</code></pre>"},{"location":"howto/patterns/parallel/#agent-caching","title":"Agent Caching","text":"<p>Strands caches agents across branches:</p> <pre><code>agents:\n  - id: researcher\n    system: \"You are a researcher\"\n\nbranches:\n  - id: branch1\n    steps:\n      - agent: researcher  # Agent built here\n  - id: branch2\n    steps:\n      - agent: researcher  # Cached - no rebuild\n  - id: branch3\n    steps:\n      - agent: researcher  # Cached - no rebuild\n</code></pre>"},{"location":"howto/patterns/parallel/#reduce-step-overhead","title":"Reduce Step Overhead","text":"<p>The reduce step adds one additional agent invocation:</p> <pre><code>Total time = Max(branch execution times) + Reduce time\n</code></pre> <p>If you don't need synthesis, omit the reduce step.</p>"},{"location":"howto/patterns/parallel/#troubleshooting","title":"Troubleshooting","text":""},{"location":"howto/patterns/parallel/#branches-not-running-concurrently","title":"Branches Not Running Concurrently","text":"<p>Verify you're using the Parallel pattern:</p> <pre><code>strands validate workflow.yaml\n</code></pre> <p>Check pattern type: <pre><code>pattern:\n  type: parallel  # Not chain or workflow\n</code></pre></p>"},{"location":"howto/patterns/parallel/#some-branches-failing","title":"Some Branches Failing","text":"<p>Enable debug logging:</p> <pre><code>strands run workflow.yaml --debug --verbose\n</code></pre> <p>Look for: <pre><code>Branch 'technical' completed successfully\nBranch 'business' failed: &lt;error message&gt;\nBranch 'market' completed successfully\n</code></pre></p> <p>Failed branches are excluded from reduce step.</p>"},{"location":"howto/patterns/parallel/#reduce-step-not-executing","title":"Reduce Step Not Executing","text":"<p>Ensure at least one branch succeeds:</p> <pre><code>Reduce step requires at least one successful branch\nAll branches failed - reduce step skipped\n</code></pre>"},{"location":"howto/patterns/parallel/#variable-branch-results","title":"Variable Branch Results","text":"<p>Branch completion order is non-deterministic. Use branch IDs for consistent access:</p> <pre><code># Good - explicit branch access\ncontent: |\n  Technical: {{ branches.technical.response }}\n  Business: {{ branches.business.response }}\n\n# Avoid - order-dependent access\ncontent: |\n  First: {{ branches[0].response }}  # Which branch is first?\n</code></pre>"},{"location":"howto/patterns/parallel/#parallel-vs-other-patterns","title":"Parallel vs. Other Patterns","text":""},{"location":"howto/patterns/parallel/#parallel-vs-workflow","title":"Parallel vs. Workflow","text":"<p>Use Parallel for independent branches, Workflow for dependencies:</p> <pre><code># Parallel: All branches independent\npattern:\n  type: parallel\n  config:\n    branches:\n      - id: branch1\n        steps: [...]  # No dependencies\n      - id: branch2\n        steps: [...]  # No dependencies\n\n# Workflow: Tasks can depend on each other\npattern:\n  type: workflow\n  config:\n    tasks:\n      - id: task1\n        agent: researcher\n        input: \"Research\"\n      - id: task2\n        agent: analyst\n        deps: [task1]  # Depends on task1\n        input: \"{{ tasks.task1.response }}\"\n</code></pre>"},{"location":"howto/patterns/parallel/#parallel-vs-chain","title":"Parallel vs. Chain","text":"<p>Use Parallel for concurrent execution, Chain for sequential:</p> <pre><code># Parallel: 10 seconds total (concurrent)\npattern:\n  type: parallel\n  config:\n    branches:\n      - id: a\n        steps: [...]  # Runs concurrently\n      - id: b\n        steps: [...]  # Runs concurrently\n\n# Chain: 20 seconds total (sequential)\npattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: researcher\n        prompt: \"Step 1\"  # 10s\n      - agent_id: researcher\n        prompt: \"Step 2\"  # 10s (after step 1)\n</code></pre>"},{"location":"howto/patterns/parallel/#examples","title":"Examples","text":"<p>Complete examples in the repository:</p> <ul> <li><code>examples/parallel-simple-2-branches.yaml</code> - Basic parallel research</li> <li><code>examples/parallel-with-reduce.yaml</code> - Multi-perspective synthesis</li> <li><code>examples/parallel-multi-step-branches.yaml</code> - Complex branch workflows</li> </ul>"},{"location":"howto/patterns/parallel/#see-also","title":"See Also","text":"<ul> <li>Workflow Pattern - For task dependencies</li> <li>Chain Pattern - For sequential execution</li> <li>Orchestrator-Workers Pattern - For dynamic parallel delegation</li> <li>Run Workflows - Execution guide</li> <li>Context Management - Managing branch context</li> </ul>"},{"location":"howto/patterns/routing/","title":"Routing Pattern","text":"<p>The Routing pattern dynamically selects the appropriate execution path based on input classification. A router agent analyzes the input and chooses which route to follow, then executes a sequence of steps specific to that route. This is ideal for scenarios where different inputs require different handling strategies.</p>"},{"location":"howto/patterns/routing/#when-to-use","title":"When to Use","text":"<p>Use the Routing pattern when you need to:</p> <ul> <li>Classify inputs and route to specialized handlers</li> <li>Implement different workflows for different input types</li> <li>Build intelligent dispatching systems (support tickets, task classification)</li> <li>Create multi-path workflows with conditional branching</li> <li>Avoid running unnecessary processing for specific input types</li> </ul>"},{"location":"howto/patterns/routing/#basic-example","title":"Basic Example","text":"<pre><code>version: 0\nname: simple-router\ndescription: Route tasks to appropriate specialists\n\nruntime:\n  provider: bedrock\n  model: anthropic.claude-3-sonnet-20240229-v1:0\n\ninputs:\n  task:\n    type: string\n    description: \"Task description\"\n    default: \"Write a Python function to sort a list\"\n\nagents:\n  - id: classifier\n    system: |\n      You are a task classifier. Analyze tasks and determine their type.\n      Respond with ONLY valid JSON: {\"route\": \"&lt;route_name&gt;\"}\n\n  - id: coder\n    system: \"You are an expert programmer. Write clean, documented code.\"\n\n  - id: writer\n    system: \"You are a technical writer. Create clear documentation.\"\n\n  - id: researcher\n    system: \"You are a researcher. Provide comprehensive information.\"\n\npattern:\n  type: routing\n  config:\n    router:\n      agent: classifier\n      input: |\n        Task: {{ task }}\n\n        Classify as: coding, writing, or research\n      max_retries: 3\n\n    routes:\n      coding:\n        then:\n          - agent: coder\n            input: |\n              Task: {{ task }}\n\n              Implement with code examples and explanations.\n\n      writing:\n        then:\n          - agent: writer\n            input: |\n              Task: {{ task }}\n\n              Create well-structured content.\n\n      research:\n        then:\n          - agent: researcher\n            input: |\n              Task: {{ task }}\n\n              Conduct thorough research.\n</code></pre>"},{"location":"howto/patterns/routing/#router-configuration","title":"Router Configuration","text":""},{"location":"howto/patterns/routing/#router-agent","title":"Router Agent","text":"<p>The router agent analyzes input and selects a route:</p> <pre><code>router:\n  agent: classifier          # Agent that makes routing decision\n  input: \"{{ user_query }}\"  # Input to analyze\n  max_retries: 3             # Retry if JSON parsing fails\n</code></pre> <p>Critical: Router must respond with valid JSON:</p> <pre><code>{\"route\": \"route_name\"}\n</code></pre>"},{"location":"howto/patterns/routing/#router-input-template","title":"Router Input Template","text":"<p>Access workflow inputs in the router prompt:</p> <pre><code>router:\n  agent: classifier\n  input: |\n    User Query: {{ query }}\n    Context: {{ context }}\n    Priority: {{ priority }}\n\n    Classify into: urgent, standard, or low_priority\n</code></pre>"},{"location":"howto/patterns/routing/#route-definitions","title":"Route Definitions","text":""},{"location":"howto/patterns/routing/#basic-route","title":"Basic Route","text":"<p>Each route defines a sequence of steps to execute:</p> <pre><code>routes:\n  technical:\n    then:\n      - agent: tech_specialist\n        input: \"Handle technical issue: {{ input_query }}\"\n</code></pre>"},{"location":"howto/patterns/routing/#multi-step-routes","title":"Multi-Step Routes","text":"<p>Routes can have multiple sequential steps:</p> <pre><code>routes:\n  escalate:\n    then:\n      - agent: analyst\n        input: \"Analyze issue: {{ input_query }}\"\n\n      - agent: manager\n        input: |\n          Analysis: {{ steps[0].response }}\n\n          Provide management response.\n\n      - agent: writer\n        input: |\n          Create formal response based on:\n          {{ steps[1].response }}\n</code></pre>"},{"location":"howto/patterns/routing/#fallback-routes","title":"Fallback Routes","text":"<p>Use <code>when: else</code> for default routing:</p> <pre><code>routes:\n  technical:\n    then: [...]\n\n  billing:\n    then: [...]\n\n  general:\n    when: else  # Catches anything not routed to technical or billing\n    then:\n      - agent: general_support\n        input: \"Handle general inquiry\"\n</code></pre>"},{"location":"howto/patterns/routing/#accessing-router-results","title":"Accessing Router Results","text":""},{"location":"howto/patterns/routing/#router-output","title":"Router Output","text":"<p>Access the routing decision and router response:</p> <pre><code>routes:\n  coding:\n    then:\n      - agent: coder\n        input: |\n          Routed to: {{ router.chosen_route }}\n          Router analysis: {{ router.response }}\n\n          Original task: {{ task }}\n</code></pre>"},{"location":"howto/patterns/routing/#using-in-artifacts","title":"Using in Artifacts","text":"<p>Reference router information in output files:</p> <pre><code>outputs:\n  artifacts:\n    - path: \"./response-{{ router.chosen_route }}.md\"\n      content: |\n        # Response (Route: {{ router.chosen_route }})\n\n        {{ last_response }}\n</code></pre>"},{"location":"howto/patterns/routing/#conditional-routing-with-jmespath","title":"Conditional Routing with JMESPath","text":""},{"location":"howto/patterns/routing/#simple-conditions","title":"Simple Conditions","text":"<p>Use JMESPath expressions for additional routing logic:</p> <pre><code>routes:\n  high_priority:\n    when: \"priority == 'high'\"\n    then:\n      - agent: urgent_handler\n        input: \"Handle urgently\"\n\n  normal:\n    when: else\n    then:\n      - agent: standard_handler\n        input: \"Handle normally\"\n</code></pre>"},{"location":"howto/patterns/routing/#complex-conditions","title":"Complex Conditions","text":"<p>Combine multiple conditions:</p> <pre><code>routes:\n  premium_urgent:\n    when: \"priority == 'high' &amp;&amp; customer_tier == 'premium'\"\n    then: [...]\n\n  standard_urgent:\n    when: \"priority == 'high' &amp;&amp; customer_tier != 'premium'\"\n    then: [...]\n\n  routine:\n    when: else\n    then: [...]\n</code></pre>"},{"location":"howto/patterns/routing/#advanced-features","title":"Advanced Features","text":""},{"location":"howto/patterns/routing/#route-specific-variables","title":"Route-Specific Variables","text":"<p>Pass different variables to different routes:</p> <pre><code>routes:\n  technical:\n    then:\n      - agent: tech_specialist\n        input: \"{{ issue }}\"\n        vars:\n          expertise_level: \"advanced\"\n          include_code: true\n\n  general:\n    then:\n      - agent: general_support\n        input: \"{{ issue }}\"\n        vars:\n          expertise_level: \"beginner\"\n          include_code: false\n</code></pre>"},{"location":"howto/patterns/routing/#accessing-step-results-in-routes","title":"Accessing Step Results in Routes","text":"<p>Reference previous steps within a route:</p> <pre><code>routes:\n  research:\n    then:\n      - agent: researcher\n        input: \"Research {{ topic }}\"\n\n      - agent: analyst\n        input: |\n          Research findings:\n          {{ steps[0].response }}\n\n          Analyze key insights.\n\n      - agent: writer\n        input: |\n          Research: {{ steps[0].response }}\n          Analysis: {{ steps[1].response }}\n\n          Write comprehensive report.\n</code></pre>"},{"location":"howto/patterns/routing/#multiple-agents-in-routes","title":"Multiple Agents in Routes","text":"<p>Different routes can use different agent configurations:</p> <pre><code>agents:\n  - id: classifier\n    system: \"Classify customer queries\"\n\n  - id: faq_bot\n    system: \"Answer common questions briefly\"\n    max_tokens: 200\n\n  - id: tech_expert\n    system: \"Provide detailed technical support\"\n    max_tokens: 1000\n\n  - id: escalation_manager\n    system: \"Handle complex escalations\"\n    max_tokens: 500\n\nroutes:\n  faq:\n    then:\n      - agent: faq_bot\n        input: \"{{ query }}\"\n\n  technical:\n    then:\n      - agent: tech_expert\n        input: \"{{ query }}\"\n      - agent: faq_bot\n        input: \"Summarize: {{ steps[0].response }}\"\n\n  escalate:\n    then:\n      - agent: escalation_manager\n        input: \"{{ query }}\"\n</code></pre>"},{"location":"howto/patterns/routing/#error-handling","title":"Error Handling","text":""},{"location":"howto/patterns/routing/#router-retry-logic","title":"Router Retry Logic","text":"<p>If the router returns invalid JSON, it retries:</p> <pre><code>router:\n  agent: classifier\n  input: \"{{ query }}\"\n  max_retries: 3  # Try up to 3 times to get valid JSON\n</code></pre> <p>After <code>max_retries</code> failures, the workflow exits with an error.</p>"},{"location":"howto/patterns/routing/#route-execution-failures","title":"Route Execution Failures","text":"<p>Configure retry behavior for route steps:</p> <pre><code>runtime:\n  provider: bedrock\n  model: anthropic.claude-3-sonnet-20240229-v1:0\n  failure_policy:\n    retries: 2\n    backoff: exponential\n</code></pre> <p>Each step in the selected route gets retry attempts.</p>"},{"location":"howto/patterns/routing/#budget-limits","title":"Budget Limits","text":"<p>Prevent runaway routing workflows:</p> <pre><code>runtime:\n  budgets:\n    max_steps: 10          # Maximum total steps\n    max_tokens: 50000      # Maximum total tokens\n    max_duration_s: 300    # Maximum 5 minutes\n</code></pre>"},{"location":"howto/patterns/routing/#best-practices","title":"Best Practices","text":""},{"location":"howto/patterns/routing/#1-clear-router-instructions","title":"1. Clear Router Instructions","text":"<p>Provide explicit routing criteria:</p> <pre><code>agents:\n  - id: classifier\n    system: |\n      You are a customer support classifier.\n\n      Available routes:\n      - faq: Simple questions (password resets, account setup)\n      - technical: Complex issues (bugs, errors, performance)\n      - escalate: Urgent issues (security, billing disputes)\n\n      Respond with ONLY valid JSON: {\"route\": \"&lt;route_name&gt;\"}\n</code></pre>"},{"location":"howto/patterns/routing/#2-validate-router-output","title":"2. Validate Router Output","text":"<p>The router MUST return valid JSON with a <code>route</code> field:</p> <pre><code># Good - valid JSON\n{\"route\": \"technical\"}\n\n# Bad - will cause retries\nTechnical support needed\n\n# Bad - invalid JSON\n{route: technical}\n</code></pre> <p>Use <code>max_retries</code> to handle occasional formatting issues.</p>"},{"location":"howto/patterns/routing/#3-design-for-coverage","title":"3. Design for Coverage","text":"<p>Ensure all possible inputs have a route:</p> <pre><code>routes:\n  route1:\n    then: [...]\n\n  route2:\n    then: [...]\n\n  default:\n    when: else  # Catch-all for unmatched cases\n    then:\n      - agent: default_handler\n        input: \"Handle unknown case\"\n</code></pre>"},{"location":"howto/patterns/routing/#4-keep-routes-focused","title":"4. Keep Routes Focused","text":"<p>Each route should handle a specific type of input:</p> <pre><code># Good - clear separation\nroutes:\n  bug_report:\n    then:\n      - agent: bug_analyst\n        input: \"Analyze bug\"\n      - agent: dev_team\n        input: \"Triage: {{ steps[0].response }}\"\n\n  feature_request:\n    then:\n      - agent: product_manager\n        input: \"Evaluate request\"\n\n# Avoid - mixing concerns\nroutes:\n  everything:\n    then:\n      - agent: do_it_all\n        input: \"Handle anything\"\n</code></pre>"},{"location":"howto/patterns/routing/#5-test-router-classification","title":"5. Test Router Classification","text":"<p>Validate router behavior with different inputs:</p> <pre><code># Test different input types\nstrands run router.yaml --var query=\"How do I reset my password?\"\nstrands run router.yaml --var query=\"App crashes on startup\"\nstrands run router.yaml --var query=\"Cancel my subscription\"\n</code></pre>"},{"location":"howto/patterns/routing/#common-patterns","title":"Common Patterns","text":""},{"location":"howto/patterns/routing/#customer-support-routing","title":"Customer Support Routing","text":"<pre><code>router:\n  agent: support_classifier\n  input: \"Customer query: {{ query }}\"\n\nroutes:\n  faq:\n    then:\n      - agent: faq_bot\n        input: \"Answer: {{ query }}\"\n\n  technical:\n    then:\n      - agent: tech_support\n        input: \"Debug: {{ query }}\"\n      - agent: summarizer\n        input: \"Simplify: {{ steps[0].response }}\"\n\n  escalate:\n    then:\n      - agent: manager\n        input: \"Escalate: {{ query }}\"\n</code></pre>"},{"location":"howto/patterns/routing/#content-type-routing","title":"Content Type Routing","text":"<pre><code>router:\n  agent: content_classifier\n  input: \"User request: {{ request }}\"\n\nroutes:\n  code:\n    then:\n      - agent: developer\n        input: \"Write code for: {{ request }}\"\n      - agent: documenter\n        input: \"Document: {{ steps[0].response }}\"\n\n  documentation:\n    then:\n      - agent: technical_writer\n        input: \"Write docs for: {{ request }}\"\n\n  tutorial:\n    then:\n      - agent: educator\n        input: \"Create tutorial for: {{ request }}\"\n</code></pre>"},{"location":"howto/patterns/routing/#priority-based-routing","title":"Priority-Based Routing","text":"<pre><code>router:\n  agent: priority_classifier\n  input: |\n    Task: {{ task }}\n    Deadline: {{ deadline }}\n    Impact: {{ impact }}\n\nroutes:\n  urgent:\n    when: \"priority == 'urgent'\"\n    then:\n      - agent: senior_engineer\n        input: \"Fast-track: {{ task }}\"\n\n  normal:\n    when: \"priority == 'normal'\"\n    then:\n      - agent: engineer\n        input: \"Process: {{ task }}\"\n\n  low:\n    when: else\n    then:\n      - agent: junior_engineer\n        input: \"Queue: {{ task }}\"\n</code></pre>"},{"location":"howto/patterns/routing/#performance-considerations","title":"Performance Considerations","text":""},{"location":"howto/patterns/routing/#router-overhead","title":"Router Overhead","text":"<p>The routing pattern adds one agent invocation for classification:</p> <pre><code>Total time = Router time + Selected route time\n            \u2248 1-3s      + Route execution time\n</code></pre> <p>For simple binary decisions, consider using the Graph pattern with conditions instead.</p>"},{"location":"howto/patterns/routing/#agent-caching","title":"Agent Caching","text":"<p>Strands caches agents across route steps:</p> <pre><code>routes:\n  technical:\n    then:\n      - agent: tech_support  # Agent built\n      - agent: tech_support  # Cached - no rebuild\n      - agent: tech_support  # Cached - no rebuild\n</code></pre>"},{"location":"howto/patterns/routing/#route-execution","title":"Route Execution","text":"<p>Only the selected route executes - other routes are never processed.</p>"},{"location":"howto/patterns/routing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"howto/patterns/routing/#router-returning-invalid-json","title":"Router Returning Invalid JSON","text":"<p>Check router agent output:</p> <pre><code>strands run router.yaml --debug --verbose\n</code></pre> <p>Look for: <pre><code>Router response: \"The task should be routed to technical support\"\nError: Failed to parse router JSON after 3 retries\n</code></pre></p> <p>Fix: Improve router system prompt to enforce JSON output.</p>"},{"location":"howto/patterns/routing/#wrong-route-selected","title":"Wrong Route Selected","text":"<p>Verify router logic with explicit inputs:</p> <pre><code>router:\n  agent: classifier\n  input: |\n    Query: {{ query }}\n\n    Classification criteria:\n    - If contains \"error\" or \"bug\" \u2192 technical\n    - If contains \"billing\" or \"payment\" \u2192 billing\n    - Otherwise \u2192 general\n\n    Respond with JSON: {\"route\": \"&lt;route&gt;\"}\n</code></pre>"},{"location":"howto/patterns/routing/#route-not-found","title":"Route Not Found","text":"<p>Ensure route names match exactly:</p> <pre><code># Router returns\n{\"route\": \"technical\"}\n\n# Routes must have exact match\nroutes:\n  technical:     # \u2713 Matches\n    then: [...]\n\n  Technical:     # \u2717 Case mismatch\n    then: [...]\n</code></pre>"},{"location":"howto/patterns/routing/#steps-within-route-failing","title":"Steps Within Route Failing","text":"<p>Enable debug mode to see route execution:</p> <pre><code>strands run router.yaml --debug --verbose\n</code></pre> <p>Look for: <pre><code>Selected route: technical\nExecuting step 1/3 in route 'technical'\nStep failed: &lt;error&gt;\n</code></pre></p>"},{"location":"howto/patterns/routing/#routing-vs-other-patterns","title":"Routing vs. Other Patterns","text":""},{"location":"howto/patterns/routing/#routing-vs-graph","title":"Routing vs. Graph","text":"<p>Use Routing for dynamic classification, Graph for explicit control flow:</p> <pre><code># Routing: Decision made by AI router\npattern:\n  type: routing\n  config:\n    router:\n      agent: classifier\n      input: \"{{ input }}\"  # AI decides which route\n    routes:\n      route1: [...]\n      route2: [...]\n\n# Graph: Decision based on explicit conditions\npattern:\n  type: graph\n  config:\n    nodes:\n      classify: {...}\n    edges:\n      - from: classify\n        choose:\n          - when: \"{{ 'technical' in nodes.classify.response }}\"\n            to: tech_handler\n          - when: else\n            to: general_handler\n</code></pre>"},{"location":"howto/patterns/routing/#routing-vs-conditional-chain","title":"Routing vs. Conditional Chain","text":"<p>Routing executes different step sequences, Chain executes all steps:</p> <pre><code># Routing: Only selected route executes\npattern:\n  type: routing\n  config:\n    router: {...}\n    routes:\n      route_a:\n        then: [step1, step2]  # OR\n      route_b:\n        then: [step3, step4]  # Only one route runs\n\n# Chain: All steps execute\npattern:\n  type: chain\n  config:\n    steps:\n      - agent: step1\n      - agent: step2  # AND\n      - agent: step3  # All steps run\n</code></pre>"},{"location":"howto/patterns/routing/#examples","title":"Examples","text":"<p>Complete examples in the repository:</p> <ul> <li><code>examples/routing-task-classification.yaml</code> - Task classifier routing to specialists</li> <li><code>examples/routing-customer-support.yaml</code> - Customer support ticket routing</li> <li><code>examples/routing-multi-tool-openai.yaml</code> - Multi-tool routing workflow</li> </ul>"},{"location":"howto/patterns/routing/#see-also","title":"See Also","text":"<ul> <li>Graph Pattern - For explicit conditional control flow</li> <li>Chain Pattern - For sequential execution</li> <li>Workflow Pattern - For parallel task execution</li> <li>Run Workflows - Execution guide</li> </ul>"},{"location":"howto/patterns/workflow/","title":"Workflow Pattern","text":"<p>The Workflow pattern executes tasks as a Directed Acyclic Graph (DAG), enabling parallel execution of independent tasks while respecting dependencies. This is ideal for complex workflows where multiple tasks can run concurrently but some tasks depend on others completing first.</p>"},{"location":"howto/patterns/workflow/#when-to-use","title":"When to Use","text":"<p>Use the Workflow pattern when you need to:</p> <ul> <li>Execute independent tasks concurrently for faster completion</li> <li>Define explicit task dependencies (task B waits for task A)</li> <li>Build complex multi-stage pipelines with parallel branches</li> <li>Optimize execution time by parallelizing independent work</li> <li>Maintain clear task relationships in complex workflows</li> </ul>"},{"location":"howto/patterns/workflow/#basic-example","title":"Basic Example","text":"<pre><code>version: 0\nname: simple-workflow\ndescription: DAG-based research workflow\n\nruntime:\n  provider: bedrock\n  model: anthropic.claude-3-sonnet-20240229-v1:0\n  max_parallel: 2  # Run up to 2 tasks concurrently\n\nagents:\n  - id: researcher\n    system: \"You are a research assistant providing factual information.\"\n\npattern:\n  type: workflow\n  config:\n    tasks:\n      # Root task - no dependencies\n      - id: overview\n        agent: researcher\n        description: \"Get high-level overview\"\n        input: \"Provide a brief overview of {{ topic }}\"\n\n      # Parallel tasks - both depend on overview\n      - id: technical\n        agent: researcher\n        deps: [overview]\n        description: \"Research technical aspects\"\n        input: |\n          Overview: {{ tasks.overview.response }}\n\n          Research the technical details of {{ topic }}\n\n      - id: business\n        agent: researcher\n        deps: [overview]\n        description: \"Research business aspects\"\n        input: |\n          Overview: {{ tasks.overview.response }}\n\n          Research the business implications of {{ topic }}\n\n      # Final task - depends on both parallel tasks\n      - id: synthesis\n        agent: researcher\n        deps: [technical, business]\n        description: \"Synthesize findings\"\n        input: |\n          Technical: {{ tasks.technical.response }}\n          Business: {{ tasks.business.response }}\n\n          Write a comprehensive report.\n\ninputs:\n  topic:\n    type: string\n    description: \"Research topic\"\n    default: \"artificial intelligence\"\n</code></pre>"},{"location":"howto/patterns/workflow/#task-dependencies","title":"Task Dependencies","text":""},{"location":"howto/patterns/workflow/#no-dependencies-root-tasks","title":"No Dependencies (Root Tasks)","text":"<p>Tasks with no <code>deps</code> field execute immediately:</p> <pre><code>tasks:\n  - id: task1\n    agent: researcher\n    input: \"Independent task 1\"\n\n  - id: task2\n    agent: researcher\n    input: \"Independent task 2\"  # Runs concurrently with task1\n</code></pre>"},{"location":"howto/patterns/workflow/#single-dependency","title":"Single Dependency","text":"<p>Task waits for one parent to complete:</p> <pre><code>tasks:\n  - id: research\n    agent: researcher\n    input: \"Gather information\"\n\n  - id: analyze\n    agent: analyst\n    deps: [research]  # Waits for research to complete\n    input: \"Analyze: {{ tasks.research.response }}\"\n</code></pre>"},{"location":"howto/patterns/workflow/#multiple-dependencies","title":"Multiple Dependencies","text":"<p>Task waits for all parents to complete:</p> <pre><code>tasks:\n  - id: source1\n    agent: researcher\n    input: \"Research source 1\"\n\n  - id: source2\n    agent: researcher\n    input: \"Research source 2\"\n\n  - id: synthesis\n    agent: analyst\n    deps: [source1, source2]  # Waits for BOTH to complete\n    input: |\n      Source 1: {{ tasks.source1.response }}\n      Source 2: {{ tasks.source2.response }}\n\n      Synthesize both sources.\n</code></pre>"},{"location":"howto/patterns/workflow/#accessing-task-results","title":"Accessing Task Results","text":""},{"location":"howto/patterns/workflow/#specific-task-outputs","title":"Specific Task Outputs","text":"<p>Access any completed task by its ID:</p> <pre><code># Single task reference\ninput: \"Build on: {{ tasks.overview.response }}\"\n\n# Multiple task references\ninput: |\n  Technical: {{ tasks.technical.response }}\n  Business: {{ tasks.business.response }}\n\n  Combine both perspectives.\n</code></pre>"},{"location":"howto/patterns/workflow/#task-metadata","title":"Task Metadata","text":"<p>Access task status and metadata:</p> <pre><code>outputs:\n  artifacts:\n    - path: \"report.md\"\n      content: |\n        ## Technical Analysis\n        Status: {{ tasks.technical.status }}\n        {{ tasks.technical.response }}\n</code></pre>"},{"location":"howto/patterns/workflow/#iterating-over-tasks","title":"Iterating Over Tasks","text":"<p>Loop through completed tasks:</p> <pre><code>input: |\n  Review all completed tasks:\n  {% for task_id, task in tasks.items() %}\n  {{ task_id }}: {{ task.response | truncate(100) }}\n  {% endfor %}\n</code></pre>"},{"location":"howto/patterns/workflow/#parallel-execution","title":"Parallel Execution","text":""},{"location":"howto/patterns/workflow/#controlling-concurrency","title":"Controlling Concurrency","text":"<p>Limit concurrent task execution:</p> <pre><code>runtime:\n  provider: bedrock\n  model: anthropic.claude-3-sonnet-20240229-v1:0\n  max_parallel: 3  # Maximum 3 tasks running simultaneously\n</code></pre> <p>Without <code>max_parallel</code>, all independent tasks run concurrently.</p>"},{"location":"howto/patterns/workflow/#example-fan-outfan-in","title":"Example: Fan-Out/Fan-In","text":"<pre><code>tasks:\n  # Single source task\n  - id: source\n    agent: researcher\n    input: \"Research {{ topic }}\"\n\n  # Fan-out: Multiple parallel tasks\n  - id: aspect1\n    agent: analyst\n    deps: [source]\n    input: \"Analyze aspect 1: {{ tasks.source.response }}\"\n\n  - id: aspect2\n    agent: analyst\n    deps: [source]\n    input: \"Analyze aspect 2: {{ tasks.source.response }}\"\n\n  - id: aspect3\n    agent: analyst\n    deps: [source]\n    input: \"Analyze aspect 3: {{ tasks.source.response }}\"\n\n  # Fan-in: Single synthesis task\n  - id: synthesis\n    agent: writer\n    deps: [aspect1, aspect2, aspect3]\n    input: |\n      Aspect 1: {{ tasks.aspect1.response }}\n      Aspect 2: {{ tasks.aspect2.response }}\n      Aspect 3: {{ tasks.aspect3.response }}\n\n      Synthesize all aspects.\n</code></pre>"},{"location":"howto/patterns/workflow/#dag-execution-order","title":"DAG Execution Order","text":"<p>The workflow executor:</p> <ol> <li>Identifies root tasks (no dependencies)</li> <li>Executes root tasks (up to <code>max_parallel</code> concurrently)</li> <li>As tasks complete, checks which dependent tasks can now run</li> <li>Continues until all tasks complete</li> </ol>"},{"location":"howto/patterns/workflow/#example-execution-timeline","title":"Example Execution Timeline","text":"<pre><code>tasks:\n  - id: A          # Starts at t=0\n  - id: B          # Starts at t=0 (parallel with A)\n  - id: C\n    deps: [A]      # Starts when A completes\n  - id: D\n    deps: [A, B]   # Starts when BOTH A and B complete\n  - id: E\n    deps: [C, D]   # Starts when BOTH C and D complete\n</code></pre> <p>Timeline: <pre><code>t=0:  A and B start (parallel)\nt=5:  A completes \u2192 C starts\nt=7:  B completes \u2192 D starts (A already done)\nt=10: C completes\nt=12: D completes \u2192 E starts (C and D both done)\nt=15: E completes\n</code></pre></p>"},{"location":"howto/patterns/workflow/#advanced-features","title":"Advanced Features","text":""},{"location":"howto/patterns/workflow/#task-descriptions","title":"Task Descriptions","text":"<p>Provide human-readable descriptions for logging:</p> <pre><code>tasks:\n  - id: research\n    agent: researcher\n    description: \"Gather initial data about the topic\"  # Shown in logs\n    input: \"Research {{ topic }}\"\n</code></pre>"},{"location":"howto/patterns/workflow/#conditional-task-content","title":"Conditional Task Content","text":"<p>Use Jinja2 conditionals in task inputs:</p> <pre><code>tasks:\n  - id: synthesis\n    agent: writer\n    deps: [research, analysis]\n    input: |\n      {% if tasks.research.response | length &gt; 500 %}\n      Research (truncated): {{ tasks.research.response | truncate(200) }}\n      {% else %}\n      Research: {{ tasks.research.response }}\n      {% endif %}\n\n      Analysis: {{ tasks.analysis.response }}\n\n      Write a summary.\n</code></pre>"},{"location":"howto/patterns/workflow/#different-agents-per-task","title":"Different Agents Per Task","text":"<p>Assign specialized agents to different tasks:</p> <pre><code>agents:\n  - id: researcher\n    system: \"You research topics thoroughly.\"\n\n  - id: analyst\n    system: \"You analyze data critically.\"\n\n  - id: writer\n    system: \"You write clear reports.\"\n\ntasks:\n  - id: gather\n    agent: researcher\n    input: \"Research {{ topic }}\"\n\n  - id: analyze\n    agent: analyst\n    deps: [gather]\n    input: \"Analyze: {{ tasks.gather.response }}\"\n\n  - id: report\n    agent: writer\n    deps: [analyze]\n    input: \"Write report: {{ tasks.analyze.response }}\"\n</code></pre>"},{"location":"howto/patterns/workflow/#error-handling","title":"Error Handling","text":""},{"location":"howto/patterns/workflow/#task-failure-behavior","title":"Task Failure Behavior","text":"<p>If a task fails: - Tasks depending on it will not execute - Independent tasks continue executing - Workflow fails with partial results</p>"},{"location":"howto/patterns/workflow/#retry-configuration","title":"Retry Configuration","text":"<p>Configure retries at the runtime level:</p> <pre><code>runtime:\n  provider: bedrock\n  model: anthropic.claude-3-sonnet-20240229-v1:0\n  failure_policy:\n    retries: 3\n    backoff: exponential\n</code></pre> <p>Each task gets up to 3 retry attempts before failing.</p>"},{"location":"howto/patterns/workflow/#budget-limits","title":"Budget Limits","text":"<p>Prevent runaway workflows:</p> <pre><code>runtime:\n  budgets:\n    max_tasks: 20           # Maximum total tasks\n    max_tokens: 100000      # Maximum total tokens\n    max_duration_s: 600     # Maximum 10 minutes\n</code></pre>"},{"location":"howto/patterns/workflow/#output-artifacts","title":"Output Artifacts","text":""},{"location":"howto/patterns/workflow/#accessing-task-results_1","title":"Accessing Task Results","text":"<p>Save workflow results to files:</p> <pre><code>outputs:\n  artifacts:\n    - path: \"research_report.md\"\n      content: |\n        # {{ topic | title }} Report\n\n        ## Overview\n        {{ tasks.overview.response }}\n\n        ## Technical Analysis\n        {{ tasks.technical.response }}\n\n        ## Business Analysis\n        {{ tasks.business.response }}\n\n        ## Synthesis\n        {{ tasks.synthesis.response }}\n</code></pre>"},{"location":"howto/patterns/workflow/#using-last-response","title":"Using Last Response","text":"<p>The <code>last_response</code> variable contains the final task's output:</p> <pre><code>outputs:\n  artifacts:\n    - path: \"summary.txt\"\n      content: \"{{ last_response }}\"\n</code></pre>"},{"location":"howto/patterns/workflow/#best-practices","title":"Best Practices","text":""},{"location":"howto/patterns/workflow/#1-design-for-parallelism","title":"1. Design for Parallelism","text":"<p>Identify independent tasks that can run concurrently:</p> <pre><code># Good - parallel research branches\ntasks:\n  - id: source\n    agent: researcher\n    input: \"Overview of {{ topic }}\"\n\n  - id: tech\n    agent: researcher\n    deps: [source]\n    input: \"Technical aspects\"\n\n  - id: business\n    agent: researcher\n    deps: [source]\n    input: \"Business aspects\"  # Parallel with tech\n\n# Avoid - unnecessary sequential execution\ntasks:\n  - id: step1\n    agent: researcher\n    input: \"Research A\"\n\n  - id: step2\n    agent: researcher\n    deps: [step1]  # Only depends if actually needs step1 output\n    input: \"Research B\"  # If independent, remove deps\n</code></pre>"},{"location":"howto/patterns/workflow/#2-set-appropriate-max_parallel","title":"2. Set Appropriate max_parallel","text":"<p>Balance speed and resource usage:</p> <pre><code># For I/O-bound tasks (API calls, web research)\nruntime:\n  max_parallel: 10  # Higher parallelism acceptable\n\n# For compute-intensive tasks\nruntime:\n  max_parallel: 3   # Lower to avoid overload\n</code></pre>"},{"location":"howto/patterns/workflow/#3-use-descriptive-task-ids","title":"3. Use Descriptive Task IDs","text":"<p>Make task IDs meaningful:</p> <pre><code># Good - clear purpose\ntasks:\n  - id: market_research\n  - id: competitor_analysis\n  - id: swot_synthesis\n\n# Avoid - generic IDs\ntasks:\n  - id: task1\n  - id: task2\n  - id: task3\n</code></pre>"},{"location":"howto/patterns/workflow/#4-validate-dag-structure","title":"4. Validate DAG Structure","text":"<p>Ensure no circular dependencies:</p> <pre><code># Invalid - circular dependency\ntasks:\n  - id: A\n    deps: [B]\n  - id: B\n    deps: [A]  # Error: cycle detected\n</code></pre> <p>Strands validates DAG structure at load time.</p>"},{"location":"howto/patterns/workflow/#5-manage-context-size","title":"5. Manage Context Size","text":"<p>Truncate large task outputs when passing to dependent tasks:</p> <pre><code>tasks:\n  - id: large_research\n    agent: researcher\n    input: \"Comprehensive research on {{ topic }}\"\n\n  - id: summary\n    agent: writer\n    deps: [large_research]\n    input: |\n      Research (truncated):\n      {{ tasks.large_research.response | truncate(500) }}\n\n      Summarize key points.\n</code></pre>"},{"location":"howto/patterns/workflow/#common-patterns","title":"Common Patterns","text":""},{"location":"howto/patterns/workflow/#linear-pipeline-sequential","title":"Linear Pipeline (Sequential)","text":"<pre><code>tasks:\n  - id: collect\n    agent: researcher\n    input: \"Collect data\"\n\n  - id: analyze\n    agent: analyst\n    deps: [collect]\n    input: \"Analyze: {{ tasks.collect.response }}\"\n\n  - id: recommend\n    agent: advisor\n    deps: [analyze]\n    input: \"Recommend: {{ tasks.analyze.response }}\"\n</code></pre>"},{"location":"howto/patterns/workflow/#diamond-pattern","title":"Diamond Pattern","text":"<pre><code>tasks:\n  - id: source\n    agent: researcher\n    input: \"Research {{ topic }}\"\n\n  - id: left\n    agent: analyst\n    deps: [source]\n    input: \"Left analysis\"\n\n  - id: right\n    agent: analyst\n    deps: [source]\n    input: \"Right analysis\"\n\n  - id: merge\n    agent: writer\n    deps: [left, right]\n    input: \"Merge both analyses\"\n</code></pre>"},{"location":"howto/patterns/workflow/#multi-stage-pipeline","title":"Multi-Stage Pipeline","text":"<pre><code>tasks:\n  # Stage 1: Research\n  - id: research1\n    agent: researcher\n    input: \"Research aspect 1\"\n\n  - id: research2\n    agent: researcher\n    input: \"Research aspect 2\"\n\n  # Stage 2: Analysis (depends on all research)\n  - id: analysis1\n    agent: analyst\n    deps: [research1, research2]\n    input: \"Analyze technical\"\n\n  - id: analysis2\n    agent: analyst\n    deps: [research1, research2]\n    input: \"Analyze business\"\n\n  # Stage 3: Synthesis (depends on all analysis)\n  - id: synthesis\n    agent: writer\n    deps: [analysis1, analysis2]\n    input: \"Synthesize all findings\"\n</code></pre>"},{"location":"howto/patterns/workflow/#performance-considerations","title":"Performance Considerations","text":""},{"location":"howto/patterns/workflow/#task-scheduling-overhead","title":"Task Scheduling Overhead","text":"<p>Workflow pattern has scheduling overhead for dependency resolution:</p> <ul> <li>Small workflows (&lt; 5 tasks): Minimal overhead</li> <li>Large workflows (&gt; 20 tasks): ~100-200ms scheduling overhead</li> <li>Consider using Chain pattern for simple sequential workflows</li> </ul>"},{"location":"howto/patterns/workflow/#agent-caching","title":"Agent Caching","text":"<p>Strands automatically caches agents with identical configurations:</p> <pre><code>agents:\n  - id: researcher\n    system: \"You are a researcher\"\n\ntasks:\n  - id: task1\n    agent: researcher  # Agent built here\n  - id: task2\n    agent: researcher  # Cached - no rebuild\n  - id: task3\n    agent: researcher  # Cached - no rebuild\n</code></pre> <p>This provides ~90% overhead reduction for repeated agent use.</p>"},{"location":"howto/patterns/workflow/#optimal-parallelism","title":"Optimal Parallelism","text":"<p>The workflow executor efficiently schedules tasks:</p> <pre><code># Optimal: 3 parallel branches, max_parallel=3\nruntime:\n  max_parallel: 3\n\ntasks:\n  - id: source\n    agent: researcher\n    input: \"Research\"\n  - id: branch1\n    agent: analyst\n    deps: [source]\n    input: \"Branch 1\"\n  - id: branch2\n    agent: analyst\n    deps: [source]\n    input: \"Branch 2\"\n  - id: branch3\n    agent: analyst\n    deps: [source]\n    input: \"Branch 3\"\n</code></pre> <p>All three branches execute concurrently after source completes.</p>"},{"location":"howto/patterns/workflow/#troubleshooting","title":"Troubleshooting","text":""},{"location":"howto/patterns/workflow/#workflow-not-completing","title":"Workflow Not Completing","text":"<p>Check for circular dependencies:</p> <pre><code>strands validate workflow.yaml\n</code></pre> <p>Look for: <pre><code>Validation Error: Circular dependency detected in workflow DAG\n</code></pre></p>"},{"location":"howto/patterns/workflow/#tasks-not-running-in-parallel","title":"Tasks Not Running in Parallel","text":"<p>Verify dependencies are correct:</p> <pre><code># Check that tasks don't have unnecessary deps\ntasks:\n  - id: task1\n    agent: researcher\n    input: \"Independent task 1\"\n\n  - id: task2\n    agent: researcher\n    # No deps = can run parallel with task1\n    input: \"Independent task 2\"\n</code></pre> <p>Enable debug logging:</p> <pre><code>strands run workflow.yaml --debug --verbose\n</code></pre>"},{"location":"howto/patterns/workflow/#budget-exceeded","title":"Budget Exceeded","text":"<p>Increase budget limits or reduce task count:</p> <pre><code>runtime:\n  budgets:\n    max_tasks: 30        # Increase from default\n    max_tokens: 200000   # Increase token budget\n</code></pre>"},{"location":"howto/patterns/workflow/#task-failures","title":"Task Failures","text":"<p>Check task-level errors:</p> <pre><code>strands run workflow.yaml --debug --verbose\n</code></pre> <p>Look for: <pre><code>Task 'task_id' failed: &lt;error message&gt;\nDependent tasks ['dep1', 'dep2'] will not execute\n</code></pre></p>"},{"location":"howto/patterns/workflow/#workflow-vs-other-patterns","title":"Workflow vs. Other Patterns","text":""},{"location":"howto/patterns/workflow/#workflow-vs-chain","title":"Workflow vs. Chain","text":"<p>Use Workflow when tasks can run in parallel:</p> <pre><code># Chain: 30 seconds total (sequential)\npattern:\n  type: chain\n  config:\n    steps:\n      - agent_id: researcher\n        prompt: \"Research A\"  # 10s\n      - agent_id: researcher\n        prompt: \"Research B\"  # 10s\n      - agent_id: researcher\n        prompt: \"Research C\"  # 10s\n\n# Workflow: 10 seconds total (parallel)\npattern:\n  type: workflow\n  config:\n    tasks:\n      - id: research_a\n        agent: researcher\n        input: \"Research A\"  # 10s\n      - id: research_b\n        agent: researcher\n        input: \"Research B\"  # 10s (concurrent)\n      - id: research_c\n        agent: researcher\n        input: \"Research C\"  # 10s (concurrent)\n</code></pre>"},{"location":"howto/patterns/workflow/#workflow-vs-parallel","title":"Workflow vs. Parallel","text":"<p>Workflow supports dependencies, Parallel does not:</p> <pre><code># Workflow: Tasks can depend on each other\npattern:\n  type: workflow\n  config:\n    tasks:\n      - id: source\n        agent: researcher\n        input: \"Research\"\n      - id: analysis\n        agent: analyst\n        deps: [source]  # Waits for source\n        input: \"{{ tasks.source.response }}\"\n\n# Parallel: All branches independent\npattern:\n  type: parallel\n  config:\n    branches:\n      - id: branch1\n        steps: [...]  # No dependencies between branches\n      - id: branch2\n        steps: [...]\n</code></pre> <p>Use Parallel for simpler scenarios with no inter-branch dependencies.</p>"},{"location":"howto/patterns/workflow/#examples","title":"Examples","text":"<p>Complete examples in the repository:</p> <ul> <li><code>examples/workflow-parallel-research.yaml</code> - Fan-out/fan-in research</li> <li><code>examples/workflow-linear-dag.yaml</code> - Sequential pipeline</li> <li><code>examples/multi-task-workflow.yaml</code> - Complex multi-stage workflow</li> </ul>"},{"location":"howto/patterns/workflow/#see-also","title":"See Also","text":"<ul> <li>Chain Pattern - For sequential execution</li> <li>Parallel Pattern - For simpler concurrent execution</li> <li>Graph Pattern - For conditional control flow</li> <li>Run Workflows - Execution guide</li> <li>Context Management - Managing task context</li> </ul>"},{"location":"reference/cli/","title":"CLI Reference","text":"<p>Complete command-line interface reference for Strands CLI.</p>"},{"location":"reference/cli/#installation","title":"Installation","text":"<pre><code># Install with uv\nuv pip install strands-cli\n\n# Verify installation\nstrands version\n</code></pre>"},{"location":"reference/cli/#global-options","title":"Global Options","text":"<p>All commands support the following global options:</p> <ul> <li><code>--debug</code> - Enable debug logging</li> <li><code>--verbose</code> - Enable verbose output</li> <li><code>--help</code> - Show help message and exit</li> </ul>"},{"location":"reference/cli/#commands","title":"Commands","text":""},{"location":"reference/cli/#version","title":"version","text":"<p>Display the current version of Strands CLI.</p> <pre><code>strands version\n</code></pre> <p>Output: Displays the semantic version number (e.g., <code>0.3.0</code>)</p>"},{"location":"reference/cli/#run","title":"run","text":"<p>Execute a workflow specification file.</p> <pre><code>strands run [OPTIONS] SPEC_FILE\n</code></pre> <p>Arguments:</p> <ul> <li><code>SPEC_FILE</code> - Path to the YAML/JSON workflow specification file (optional when using --resume)</li> </ul> <p>Options:</p> <ul> <li><code>--var KEY=VALUE</code> - Override template variables (can be used multiple times)</li> <li><code>--out TEXT</code> - Output directory for artifacts (default: current directory)</li> <li><code>--format [json|text]</code> - Output format for results (default: <code>text</code>)</li> <li><code>--force</code> - Force overwrite existing artifact files</li> <li><code>--trace</code> - Enable trace artifact generation</li> <li><code>--resume SESSION_ID</code> - Resume workflow from saved session (mutually exclusive with SPEC_FILE)</li> <li><code>--save-session / --no-save-session</code> - Enable/disable session saving (default: enabled)</li> <li><code>--debug</code> - Enable debug logging</li> <li><code>--verbose</code> - Enable verbose output</li> </ul> <p>Examples:</p> <pre><code># Basic execution (creates session by default)\nstrands run workflow.yaml\n\n# Resume from saved session\nstrands run --resume a1b2c3d4-e5f6-7890-abcd-ef1234567890\n\n# Disable session saving\nstrands run workflow.yaml --no-save-session\n\n# With variable overrides\nstrands run workflow.yaml --var topic=\"AI\" --var format=\"markdown\"\n\n# Save artifacts to specific directory\nstrands run workflow.yaml --out ./output\n\n# Enable debugging and tracing\nstrands run workflow.yaml --debug --verbose --trace\n\n# JSON output format\nstrands run workflow.yaml --format json\n</code></pre> <p>Session Output:</p> <p>When session saving is enabled (default), the CLI displays the session ID in the output:</p> <pre><code>Session ID: a1b2c3d4-e5f6-7890-abcd-ef1234567890\nRunning workflow: my-workflow\nStep 1/3: researcher - COMPLETE\nStep 2/3: analyst - COMPLETE\nStep 3/3: writer - COMPLETE\n\u2713 Workflow completed successfully\n\nArtifacts written:\n  \u2022 ./output/result.md\n</code></pre> <p>Exit Codes:</p> <ul> <li><code>0</code> - Success</li> <li><code>2</code> - Invalid CLI usage</li> <li><code>3</code> - Schema validation failure</li> <li><code>10</code> - Runtime error (provider/model/tool)</li> <li><code>12</code> - File I/O error</li> <li><code>18</code> - Unsupported feature</li> <li><code>70</code> - Unexpected exception</li> </ul>"},{"location":"reference/cli/#validate","title":"validate","text":"<p>Validate a workflow specification against the JSON Schema.</p> <pre><code>strands validate [OPTIONS] SPEC_FILE\n</code></pre> <p>Arguments:</p> <ul> <li><code>SPEC_FILE</code> - Path to the YAML/JSON workflow specification file (required)</li> </ul> <p>Options:</p> <ul> <li><code>--format [text|json]</code> - Output format (default: <code>text</code>)</li> <li><code>--debug</code> - Enable debug logging</li> </ul> <p>Examples:</p> <pre><code># Validate a workflow\nstrands validate workflow.yaml\n\n# JSON output\nstrands validate workflow.yaml --format json\n</code></pre> <p>Output:</p> <ul> <li>On success: Displays validation success message with workflow details</li> <li>On failure: Shows detailed validation errors with JSONPointer paths</li> </ul>"},{"location":"reference/cli/#plan","title":"plan","text":"<p>Display an execution plan for a workflow without running it.</p> <pre><code>strands plan [OPTIONS] SPEC_FILE\n</code></pre> <p>Arguments:</p> <ul> <li><code>SPEC_FILE</code> - Path to the YAML/JSON workflow specification file (required)</li> </ul> <p>Options:</p> <ul> <li><code>--format [text|json]</code> - Output format (default: <code>text</code>)</li> <li><code>--debug</code> - Enable debug logging</li> </ul> <p>Examples:</p> <pre><code># Show execution plan\nstrands plan workflow.yaml\n\n# JSON format\nstrands plan workflow.yaml --format json\n</code></pre> <p>Output:</p> <p>Displays: - Workflow metadata (name, description, pattern) - Agent configurations - Execution steps/tasks/branches/nodes - Capability compatibility report - Warnings for unsupported features</p>"},{"location":"reference/cli/#explain","title":"explain","text":"<p>Explain a workflow specification in natural language.</p> <pre><code>strands explain [OPTIONS] SPEC_FILE\n</code></pre> <p>Arguments:</p> <ul> <li><code>SPEC_FILE</code> - Path to the YAML/JSON workflow specification file (required)</li> </ul> <p>Options:</p> <ul> <li><code>--debug</code> - Enable debug logging</li> </ul> <p>Examples:</p> <pre><code># Get workflow explanation\nstrands explain workflow.yaml\n</code></pre> <p>Output:</p> <p>Human-readable explanation of: - What the workflow does - Agent roles and configurations - Execution flow - Tool usage - Context management strategy</p>"},{"location":"reference/cli/#list-supported","title":"list-supported","text":"<p>List all supported workflow patterns and features.</p> <pre><code>strands list-supported\n</code></pre> <p>Output:</p> <p>Displays a table of: - Supported workflow patterns (Chain, Workflow, Routing, etc.) - Supported providers (AWS Bedrock, Ollama, OpenAI) - Available features and capabilities</p>"},{"location":"reference/cli/#list-tools","title":"list-tools","text":"<p>List all available native tools.</p> <pre><code>strands list-tools [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--format [text|json]</code> - Output format (default: <code>text</code>)</li> </ul> <p>Examples:</p> <pre><code># List tools\nstrands list-tools\n\n# JSON format\nstrands list-tools --format json\n</code></pre> <p>Output:</p> <p>Displays: - Tool names - Tool descriptions - Input schema specifications - Usage examples</p>"},{"location":"reference/cli/#doctor","title":"doctor","text":"<p>Run system health checks and display configuration.</p> <pre><code>strands doctor\n</code></pre> <p>Output:</p> <p>Displays: - Strands CLI version - Python version - Environment configuration - Provider availability (AWS Bedrock, Ollama, OpenAI) - Tool registry status - Configuration directory - System diagnostics</p>"},{"location":"reference/cli/#sessions","title":"sessions","text":"<p>Manage workflow sessions for crash recovery and resume functionality.</p> <pre><code>strands sessions COMMAND [OPTIONS]\n</code></pre> <p>Subcommands:</p> <ul> <li><code>list</code> - List all saved sessions</li> <li><code>show SESSION_ID</code> - Show detailed session information</li> <li><code>delete SESSION_ID</code> - Delete a saved session</li> </ul>"},{"location":"reference/cli/#sessions-list","title":"sessions list","text":"<p>List all saved workflow sessions.</p> <pre><code>strands sessions list [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--status [running|paused|completed|failed]</code> - Filter sessions by status</li> <li><code>--verbose</code> - Show extended session information</li> </ul> <p>Examples:</p> <pre><code># List all sessions\nstrands sessions list\n\n# Show only running sessions\nstrands sessions list --status running\n\n# Show only completed sessions\nstrands sessions list --status completed\n</code></pre> <p>Output: Rich table with session ID, workflow name, pattern type, status, and last updated timestamp.</p>"},{"location":"reference/cli/#sessions-show","title":"sessions show","text":"<p>Display detailed information about a specific session.</p> <pre><code>strands sessions show SESSION_ID\n</code></pre> <p>Arguments:</p> <ul> <li><code>SESSION_ID</code> - Session ID to inspect (full UUID)</li> </ul> <p>Examples:</p> <pre><code># Show session details\nstrands sessions show a1b2c3d4-e5f6-7890-abcd-ef1234567890\n</code></pre> <p>Output: Panel with complete session metadata including: - Session ID and workflow name - Pattern type and execution status - Created/updated timestamps - Variables and runtime configuration - Token usage breakdown - Pattern-specific execution state</p>"},{"location":"reference/cli/#sessions-delete","title":"sessions delete","text":"<p>Delete a saved workflow session.</p> <pre><code>strands sessions delete [OPTIONS] SESSION_ID\n</code></pre> <p>Arguments:</p> <ul> <li><code>SESSION_ID</code> - Session ID to delete (full UUID)</li> </ul> <p>Options:</p> <ul> <li><code>--force</code> - Skip confirmation prompt</li> </ul> <p>Examples:</p> <pre><code># Delete session (with confirmation)\nstrands sessions delete a1b2c3d4-e5f6-7890-abcd-ef1234567890\n\n# Delete without confirmation\nstrands sessions delete a1b2c3d4-e5f6-7890-abcd-ef1234567890 --force\n</code></pre> <p>Exit Codes:</p> <ul> <li><code>0</code> - Success (session deleted)</li> <li><code>2</code> - Invalid usage (session not found)</li> </ul>"},{"location":"reference/cli/#environment-variables","title":"Environment Variables","text":"<p>See Environment Variables Reference for a complete list of supported environment variables.</p>"},{"location":"reference/cli/#exit-codes","title":"Exit Codes","text":"<p>See Exit Codes Reference for detailed exit code documentation.</p>"},{"location":"reference/cli/#common-workflows","title":"Common Workflows","text":""},{"location":"reference/cli/#development-workflow","title":"Development Workflow","text":"<pre><code># 1. Validate your workflow\nstrands validate workflow.yaml\n\n# 2. Preview execution plan\nstrands plan workflow.yaml\n\n# 3. Run with debugging\nstrands run workflow.yaml --debug --verbose\n\n# 4. Generate trace for analysis\nstrands run workflow.yaml --trace --out ./traces\n</code></pre>"},{"location":"reference/cli/#cicd-integration","title":"CI/CD Integration","text":"<pre><code># Validate in CI pipeline\nstrands validate workflow.yaml --format json || exit 1\n\n# Run workflow with controlled output\nstrands run workflow.yaml --out ./artifacts --force --format json\n</code></pre>"},{"location":"reference/cli/#troubleshooting","title":"Troubleshooting","text":"<pre><code># Check system health\nstrands doctor\n\n# List available tools\nstrands list-tools\n\n# Explain workflow behavior\nstrands explain workflow.yaml\n\n# Run with maximum verbosity\nstrands run workflow.yaml --debug --verbose --trace\n</code></pre>"},{"location":"reference/cli/#see-also","title":"See Also","text":"<ul> <li>Schema Reference - Workflow specification schema</li> <li>Examples - Example workflows</li> <li>Tutorials - Getting started guides</li> </ul>"},{"location":"reference/environment/","title":"Environment Variables Reference","text":"<p>Complete reference for all environment variables used by Strands CLI.</p>"},{"location":"reference/environment/#overview","title":"Overview","text":"<p>Strands CLI uses environment variables for configuration management. All Strands-specific variables use the <code>STRANDS_</code> prefix, following Pydantic Settings conventions.</p>"},{"location":"reference/environment/#configuration-priority","title":"Configuration Priority","text":"<p>Settings cascade in the following order (highest priority first):</p> <ol> <li>Explicit command-line arguments</li> <li>Environment variables (<code>STRANDS_*</code>)</li> <li><code>.env</code> file in current directory</li> <li>Default values</li> </ol>"},{"location":"reference/environment/#env-file-support","title":".env File Support","text":"<p>You can create a <code>.env</code> file in your project directory:</p> <pre><code># .env\nSTRANDS_AWS_REGION=us-west-2\nSTRANDS_BEDROCK_MODEL_ID=anthropic.claude-3-haiku-20240307-v1:0\nSTRANDS_LOG_LEVEL=DEBUG\n</code></pre>"},{"location":"reference/environment/#aws-configuration","title":"AWS Configuration","text":""},{"location":"reference/environment/#strands_aws_region","title":"<code>STRANDS_AWS_REGION</code>","text":"<p>Type: <code>string</code> Default: <code>us-east-1</code> Description: AWS region for Bedrock API calls</p> <p>Usage: <pre><code>export STRANDS_AWS_REGION=us-west-2\nstrands run workflow-bedrock.yaml\n</code></pre></p> <p>Supported regions: Any AWS region with Bedrock availability (e.g., <code>us-east-1</code>, <code>us-west-2</code>, <code>eu-west-1</code>)</p>"},{"location":"reference/environment/#strands_aws_profile","title":"<code>STRANDS_AWS_PROFILE</code>","text":"<p>Type: <code>string</code> Default: <code>None</code> (uses default profile) Description: AWS CLI profile name for credentials</p> <p>Usage: <pre><code>export STRANDS_AWS_PROFILE=bedrock-dev\nstrands run workflow-bedrock.yaml\n</code></pre></p> <p>Note: If not set, uses AWS CLI default credentials chain (environment variables, <code>~/.aws/credentials</code>, IAM roles)</p>"},{"location":"reference/environment/#bedrock-configuration","title":"Bedrock Configuration","text":""},{"location":"reference/environment/#strands_bedrock_model_id","title":"<code>STRANDS_BEDROCK_MODEL_ID</code>","text":"<p>Type: <code>string</code> Default: <code>anthropic.claude-3-sonnet-20240229-v1:0</code> Description: Default Bedrock model ID</p> <p>Usage: <pre><code>export STRANDS_BEDROCK_MODEL_ID=anthropic.claude-3-haiku-20240307-v1:0\nstrands run workflow-bedrock.yaml\n</code></pre></p> <p>Common values: - <code>anthropic.claude-3-opus-20240229-v1:0</code> - Claude 3 Opus (most capable) - <code>anthropic.claude-3-sonnet-20240229-v1:0</code> - Claude 3 Sonnet (balanced) - <code>anthropic.claude-3-haiku-20240307-v1:0</code> - Claude 3 Haiku (fastest)</p>"},{"location":"reference/environment/#workflow-configuration","title":"Workflow Configuration","text":""},{"location":"reference/environment/#strands_workflow_schema_path","title":"<code>STRANDS_WORKFLOW_SCHEMA_PATH</code>","text":"<p>Type: <code>path</code> Default: <code>None</code> (uses bundled schema) Description: Path to custom workflow JSON Schema file</p> <p>Usage: <pre><code>export STRANDS_WORKFLOW_SCHEMA_PATH=/path/to/custom-schema.json\nstrands validate workflow.yaml\n</code></pre></p> <p>Note: Only needed for custom schema validation. Default schema is bundled with the CLI.</p>"},{"location":"reference/environment/#cache-configuration","title":"Cache Configuration","text":""},{"location":"reference/environment/#strands_cache_enabled","title":"<code>STRANDS_CACHE_ENABLED</code>","text":"<p>Type: <code>boolean</code> Default: <code>true</code> Description: Enable/disable agent caching</p> <p>Usage: <pre><code>export STRANDS_CACHE_ENABLED=false\nstrands run workflow.yaml\n</code></pre></p> <p>Impact: Disabling cache will rebuild agents for every step, increasing latency.</p>"},{"location":"reference/environment/#strands_cache_dir","title":"<code>STRANDS_CACHE_DIR</code>","text":"<p>Type: <code>path</code> Default: <code>None</code> (uses system default) Description: Custom cache directory path</p> <p>Usage: <pre><code>export STRANDS_CACHE_DIR=/tmp/strands-cache\nstrands run workflow.yaml\n</code></pre></p>"},{"location":"reference/environment/#observability","title":"Observability","text":""},{"location":"reference/environment/#strands_otel_enabled","title":"<code>STRANDS_OTEL_ENABLED</code>","text":"<p>Type: <code>boolean</code> Default: <code>false</code> Description: Enable OpenTelemetry tracing</p> <p>Usage: <pre><code>export STRANDS_OTEL_ENABLED=true\nexport STRANDS_OTEL_ENDPOINT=http://localhost:4317\nstrands run workflow.yaml\n</code></pre></p> <p>Note: Requires <code>STRANDS_OTEL_ENDPOINT</code> to be set for OTLP export.</p>"},{"location":"reference/environment/#strands_otel_endpoint","title":"<code>STRANDS_OTEL_ENDPOINT</code>","text":"<p>Type: <code>string</code> Default: <code>None</code> Description: OpenTelemetry collector endpoint (OTLP/gRPC)</p> <p>Usage: <pre><code>export STRANDS_OTEL_ENDPOINT=http://localhost:4317\nstrands run workflow.yaml --trace\n</code></pre></p> <p>Common endpoints: - <code>http://localhost:4317</code> - Local OTLP collector (gRPC) - <code>http://localhost:4318</code> - Local OTLP collector (HTTP) - <code>https://api.honeycomb.io:443</code> - Honeycomb - <code>https://otlp.nr-data.net:4317</code> - New Relic</p>"},{"location":"reference/environment/#logging","title":"Logging","text":""},{"location":"reference/environment/#strands_log_level","title":"<code>STRANDS_LOG_LEVEL</code>","text":"<p>Type: <code>string</code> Default: <code>INFO</code> Description: Logging verbosity level</p> <p>Usage: <pre><code>export STRANDS_LOG_LEVEL=DEBUG\nstrands run workflow.yaml\n</code></pre></p> <p>Allowed values: - <code>DEBUG</code> - Verbose debugging output - <code>INFO</code> - General information - <code>WARNING</code> - Warning messages only - <code>ERROR</code> - Error messages only - <code>CRITICAL</code> - Critical errors only</p>"},{"location":"reference/environment/#strands_log_format","title":"<code>STRANDS_LOG_FORMAT</code>","text":"<p>Type: <code>string</code> Default: <code>console</code> Description: Log output format</p> <p>Usage: <pre><code>export STRANDS_LOG_FORMAT=json\nstrands run workflow.yaml\n</code></pre></p> <p>Allowed values: - <code>console</code> - Human-readable console output - <code>json</code> - Structured JSON logs (for log aggregation)</p>"},{"location":"reference/environment/#http-security","title":"HTTP Security","text":""},{"location":"reference/environment/#strands_http_allowed_domains","title":"<code>STRANDS_HTTP_ALLOWED_DOMAINS</code>","text":"<p>Type: <code>list[string]</code> (comma-separated) Default: <code>[]</code> (empty list) Description: Allowed domain patterns for HTTP executor tools (regex)</p> <p>Usage: <pre><code>export STRANDS_HTTP_ALLOWED_DOMAINS=\"api\\.github\\.com,.*\\.amazonaws\\.com\"\nstrands run workflow.yaml\n</code></pre></p> <p>Example: <pre><code># Allow only GitHub API and AWS domains\nexport STRANDS_HTTP_ALLOWED_DOMAINS=\"api\\.github\\.com,.*\\.amazonaws\\.com\"\n</code></pre></p> <p>Security: When set, HTTP executors will only allow requests to matching domains.</p>"},{"location":"reference/environment/#strands_http_blocked_patterns","title":"<code>STRANDS_HTTP_BLOCKED_PATTERNS</code>","text":"<p>Type: <code>list[string]</code> (comma-separated) Default: <code>[]</code> (built-in SSRF protection patterns) Description: Additional blocked URL patterns for HTTP executors (regex)</p> <p>Usage: <pre><code>export STRANDS_HTTP_BLOCKED_PATTERNS=\"169\\.254\\..*,10\\..*\"\nstrands run workflow.yaml\n</code></pre></p> <p>Example: <pre><code># Block internal IP ranges\nexport STRANDS_HTTP_BLOCKED_PATTERNS=\"169\\.254\\..*,10\\..*,192\\.168\\..*\"\n</code></pre></p> <p>Security: Adds extra protection beyond built-in SSRF prevention.</p>"},{"location":"reference/environment/#provider-specific-variables","title":"Provider-Specific Variables","text":""},{"location":"reference/environment/#openai","title":"OpenAI","text":""},{"location":"reference/environment/#openai_api_key","title":"<code>OPENAI_API_KEY</code>","text":"<p>Type: <code>string</code> Default: <code>None</code> (required for OpenAI) Description: OpenAI API key</p> <p>Usage: <pre><code>export OPENAI_API_KEY=sk-...\nstrands run workflow-openai.yaml\n</code></pre></p> <p>Note: This is an OpenAI SDK variable, not a Strands variable.</p>"},{"location":"reference/environment/#telemetry-configuration","title":"Telemetry Configuration","text":""},{"location":"reference/environment/#strands_max_trace_spans","title":"<code>STRANDS_MAX_TRACE_SPANS</code>","text":"<p>Type: <code>integer</code> Default: <code>1000</code> Description: Maximum spans to include in trace artifacts</p> <p>Usage: <pre><code>export STRANDS_MAX_TRACE_SPANS=5000\nstrands run workflow.yaml --trace\n</code></pre></p> <p>Note: Prevents trace files from becoming too large in complex workflows.</p>"},{"location":"reference/environment/#debug-configuration","title":"Debug Configuration","text":""},{"location":"reference/environment/#strands_debug","title":"<code>STRANDS_DEBUG</code>","text":"<p>Type: <code>boolean</code> Default: <code>false</code> Description: Enable debug mode (equivalent to <code>--debug</code> flag)</p> <p>Usage: <pre><code>export STRANDS_DEBUG=true\nstrands run workflow.yaml\n</code></pre></p> <p>Impact: Enables verbose logging and additional diagnostics.</p>"},{"location":"reference/environment/#strands_verbose","title":"<code>STRANDS_VERBOSE</code>","text":"<p>Type: <code>boolean</code> Default: <code>false</code> Description: Enable verbose output (equivalent to <code>--verbose</code> flag)</p> <p>Usage: <pre><code>export STRANDS_VERBOSE=true\nstrands run workflow.yaml\n</code></pre></p>"},{"location":"reference/environment/#configuration-examples","title":"Configuration Examples","text":""},{"location":"reference/environment/#development-environment","title":"Development Environment","text":"<pre><code># .env\nSTRANDS_LOG_LEVEL=DEBUG\nSTRANDS_LOG_FORMAT=console\nSTRANDS_CACHE_ENABLED=true\nSTRANDS_OTEL_ENABLED=true\nSTRANDS_OTEL_ENDPOINT=http://localhost:4317\nSTRANDS_AWS_REGION=us-east-1\n</code></pre>"},{"location":"reference/environment/#production-environment","title":"Production Environment","text":"<pre><code># .env\nSTRANDS_LOG_LEVEL=INFO\nSTRANDS_LOG_FORMAT=json\nSTRANDS_CACHE_ENABLED=true\nSTRANDS_OTEL_ENABLED=true\nSTRANDS_OTEL_ENDPOINT=https://otlp.company.com:4317\nSTRANDS_AWS_REGION=us-west-2\nSTRANDS_AWS_PROFILE=production\nSTRANDS_HTTP_ALLOWED_DOMAINS=\"api\\.company\\.com,.*\\.amazonaws\\.com\"\n</code></pre>"},{"location":"reference/environment/#cicd-environment","title":"CI/CD Environment","text":"<pre><code># GitHub Actions\nSTRANDS_LOG_LEVEL=INFO\nSTRANDS_LOG_FORMAT=json\nSTRANDS_CACHE_ENABLED=false\nSTRANDS_AWS_REGION=us-east-1\n# AWS credentials via OIDC, not environment variables\n</code></pre>"},{"location":"reference/environment/#verification","title":"Verification","text":"<p>Check current configuration with the <code>doctor</code> command:</p> <pre><code>strands doctor\n</code></pre> <p>This will display: - Active environment variable values - Provider availability - Configuration directory - System diagnostics</p>"},{"location":"reference/environment/#see-also","title":"See Also","text":"<ul> <li>CLI Reference - Command-line interface</li> <li>Configuration API - Pydantic Settings models</li> <li>Tutorials: Quickstart</li> </ul>"},{"location":"reference/examples/","title":"Example Workflows","text":"<p>Comprehensive catalog of workflow examples organized by pattern type and use case.</p> <p>Running Examples</p> <p>All examples are in the <code>examples/</code> directory of the repository.</p> <pre><code># Validate before running\nuv run strands validate examples/&lt;file&gt;.yaml\n\n# Run with required variables\nuv run strands run examples/&lt;file&gt;.yaml --var key=value\n\n# Force overwrite artifacts\nuv run strands run examples/&lt;file&gt;.yaml --force\n</code></pre>"},{"location":"reference/examples/#by-pattern-type","title":"By Pattern Type","text":""},{"location":"reference/examples/#chain-pattern","title":"Chain Pattern","text":"<p>Sequential multi-step workflows with context passing.</p> Example Description Provider Key Features chain-3-step-research-openai.yaml Three-step research workflow with context passing OpenAI Sequential steps, <code>steps[n].response</code> references chain-3-step-research.yaml Same as above (Ollama) Ollama Budget limits, temperature control chain-calculator-openai.yaml Multi-step calculation workflow OpenAI Calculator tool, step chaining <p>Learn More: Chain Pattern Guide</p>"},{"location":"reference/examples/#workflow-dag-pattern","title":"Workflow (DAG) Pattern","text":"<p>Task-based workflows with dependency graphs.</p> Example Description Provider Key Features research-workflow-notes-openai.yaml Research with structured notes OpenAI DAG dependencies, notes integration <p>Learn More: Workflow Pattern Guide</p>"},{"location":"reference/examples/#routing-pattern","title":"Routing Pattern","text":"<p>Dynamic agent selection based on classifier decisions.</p> Example Description Provider Key Features routing-customer-support-openai.yaml Customer support ticket routing OpenAI Multi-route classifier, dynamic paths routing-customer-support.yaml Same as above (Ollama) Ollama Cost-effective routing routing-task-classification-openai.yaml Task classification router OpenAI Route selection logic routing-task-classification.yaml Same as above (Ollama) Ollama Budget-friendly routing-multi-tool-openai.yaml Tool selection based on request type OpenAI HTTP executors, dynamic tool routing <p>Learn More: Routing Pattern Guide</p>"},{"location":"reference/examples/#parallel-pattern","title":"Parallel Pattern","text":"<p>Concurrent branch execution with optional reduce step.</p> Example Description Provider Key Features parallel-simple-2-branches.yaml Two-branch parallel execution OpenAI Basic parallel, no reduce parallel-with-reduce.yaml Parallel branches with aggregation OpenAI Reduce step, branch merging parallel-multi-step-branches.yaml Multi-step branches in parallel OpenAI Complex branches, sequential within parallel <p>Learn More: Parallel Pattern Guide</p>"},{"location":"reference/examples/#evaluator-optimizer-pattern","title":"Evaluator-Optimizer Pattern","text":"<p>Iterative refinement with evaluation feedback loops.</p> Example Description Provider Key Features evaluator-optimizer-writing-openai.yaml Content writing with iterative refinement OpenAI Min score threshold, max iterations evaluator-optimizer-writing-ollama.yaml Same as above (Ollama) Ollama Local model refinement evaluator-optimizer-code-review-openai.yaml Code review feedback loop OpenAI JSON scoring, structured feedback evaluator-optimizer-code-review-bedrock.yaml Same as above (Bedrock) Bedrock AWS Claude models <p>Learn More: Evaluator-Optimizer Pattern Guide</p>"},{"location":"reference/examples/#orchestrator-workers-pattern","title":"Orchestrator-Workers Pattern","text":"<p>Orchestrator decomposes tasks, workers execute in parallel.</p> Example Description Provider Key Features orchestrator-minimal-openai.yaml Minimal orchestrator example OpenAI Basic orchestration, worker pool orchestrator-research-swarm-openai.yaml Research team with orchestrator OpenAI Multi-worker coordination, reduce step orchestrator-data-processing-openai.yaml Data processing pipeline OpenAI Parallel workers, aggregation <p>Learn More: Orchestrator-Workers Pattern Guide</p>"},{"location":"reference/examples/#graph-pattern","title":"Graph Pattern","text":"<p>State machines with conditional transitions and loops.</p> Example Description Provider Key Features graph-state-machine-openai.yaml Customer support state machine OpenAI Conditional edges, terminal nodes graph-decision-tree-openai.yaml Approval workflow decision tree OpenAI Multi-path decisions, <code>when</code> conditions graph-iterative-refinement-openai.yaml Code review refinement loop OpenAI Iterative loops, cycle protection <p>Learn More: Graph Pattern Guide</p>"},{"location":"reference/examples/#by-feature","title":"By Feature","text":""},{"location":"reference/examples/#context-management","title":"Context Management","text":"<p>Examples demonstrating Phase 6 context features.</p> Example Description Features context-notes-demo-openai.yaml Structured notes across steps <code>context_policy.notes</code>, note persistence presets-minimal-openai.yaml Minimal context preset <code>context_policy.preset: minimal</code> presets-balanced-openai.yaml Balanced context preset <code>context_policy.preset: balanced</code> presets-long_run-openai.yaml Long-running research preset <code>context_policy.preset: long_run</code> presets-interactive-chat-openai.yaml Interactive chat preset <code>context_policy.preset: interactive</code> <p>Learn More: Context Management Guide</p>"},{"location":"reference/examples/#jit-retrieval-tools","title":"JIT Retrieval Tools","text":"<p>Just-In-Time file system tools for on-demand retrieval.</p> Example Description Tools Used jit-codebase-analysis-openai.yaml Codebase analysis with grep/search <code>grep</code>, <code>search</code> jit-config-audit-openai.yaml Configuration file audit <code>head</code>, <code>tail</code>, <code>grep</code> jit-log-analysis-openai.yaml Log file analysis <code>tail</code>, <code>grep</code> jit-tools-test-openai.yaml JIT tools test suite All JIT tools <p>Learn More: Workflow Spec Reference - JIT Retrieval</p>"},{"location":"reference/examples/#tools-integrations","title":"Tools &amp; Integrations","text":""},{"location":"reference/examples/#http-executors","title":"HTTP Executors","text":"Example Description Integration github-api-example-openai.yaml GitHub API integration GitHub REST API <p>Learn More: Tools Guide</p>"},{"location":"reference/examples/#mcp-servers","title":"MCP Servers","text":"<p>Model Context Protocol server integrations.</p> Example Description MCP Server mcp-simple-openai.yaml Basic MCP integration Generic MCP server mcp-filesystem-openai.yaml Filesystem MCP server <code>@modelcontextprotocol/server-filesystem</code> mcp-multi-server-openai.yaml Multiple MCP servers Multiple servers <p>Learn More: Workflow Manual - Complete MCP specification</p>"},{"location":"reference/examples/#python-tools","title":"Python Tools","text":"Example Description Tools python-exec-demo-openai.yaml Python code execution <code>python_exec</code> native tool <p>Learn More: Develop Tools Guide</p>"},{"location":"reference/examples/#telemetry-observability","title":"Telemetry &amp; Observability","text":"Example Description Features debug-demo-openai.yaml Debug mode with verbose tracing <code>telemetry.otel</code>, debug spans <p>Learn More: Telemetry Guide</p>"},{"location":"reference/examples/#by-provider","title":"By Provider","text":""},{"location":"reference/examples/#openai-examples","title":"OpenAI Examples","text":"<p>All <code>*-openai.yaml</code> examples use OpenAI models (gpt-4o, gpt-4o-mini, gpt-5-nano).</p> <p>Setup: <pre><code>export OPENAI_API_KEY=\"sk-...\"\nuv run strands run examples/&lt;file&gt;-openai.yaml\n</code></pre></p>"},{"location":"reference/examples/#bedrock-examples","title":"Bedrock Examples","text":"<p>All <code>*-bedrock.yaml</code> examples use AWS Bedrock (Claude models).</p> <p>Setup: <pre><code>aws configure  # Set credentials and region\nuv run strands run examples/&lt;file&gt;-bedrock.yaml\n</code></pre></p> <p>Available: - evaluator-optimizer-code-review-bedrock.yaml</p>"},{"location":"reference/examples/#ollama-examples","title":"Ollama Examples","text":"<p>All <code>*-ollama.yaml</code> or non-provider-suffixed examples use Ollama (local models).</p> <p>Setup: <pre><code>ollama serve  # Start Ollama server\nollama pull llama3.2:3b  # Pull model\nuv run strands run examples/&lt;file&gt;.yaml\n</code></pre></p> <p>Available: - chain-3-step-research.yaml - evaluator-optimizer-writing-ollama.yaml - routing-customer-support.yaml - routing-task-classification.yaml - And more...</p>"},{"location":"reference/examples/#special-examples","title":"Special Examples","text":""},{"location":"reference/examples/#backward-compatibility","title":"Backward Compatibility","text":"Example Description Purpose backward-compatibility-test.yaml Tests legacy format compatibility Regression testing"},{"location":"reference/examples/#unsupported-features-exit-code-18","title":"Unsupported Features (Exit Code 18)","text":"<p>Examples demonstrating unsupported MVP features (will fail with explanatory report).</p> Example Description Unsupported Feature multi-agent-unsupported.yaml Multiple agents Multiple agents in same workflow multi-step-unsupported.yaml Multi-step chain Chain with &gt;1 step <p>Learn More: Exit Codes Reference</p>"},{"location":"reference/examples/#example-template","title":"Example Template","text":"<p>Want to create your own? Use this template:</p> <pre><code>version: 0\nname: \"my-workflow\"\ndescription: \"Brief description of what this workflow does\"\ntags: [\"pattern-type\", \"use-case\"]\n\nruntime:\n  provider: openai  # or bedrock, ollama\n  model_id: \"gpt-4o-mini\"\n  temperature: 0.7\n  budgets:\n    max_tokens: 50000\n    max_steps: 100\n\nagents:\n  assistant:\n    prompt: |\n      You are a helpful assistant.\n      Task: {{ task_description }}\n\npattern:\n  type: chain  # or workflow, routing, parallel, evaluator_optimizer, orchestrator_workers, graph\n  config:\n    steps:\n      - agent: assistant\n        input: \"{{ user_input }}\"\n\ninputs:\n  required:\n    user_input: string\n  optional:\n    task_description:\n      type: string\n      default: \"Help the user\"\n\noutputs:\n  artifacts:\n    - path: \"./result.md\"\n      from: \"{{ last_response }}\"\n</code></pre>"},{"location":"reference/examples/#contributing-examples","title":"Contributing Examples","text":"<p>Have a useful workflow? Consider contributing!</p> <ol> <li>Follow the naming convention: <code>&lt;pattern&gt;-&lt;use-case&gt;-&lt;provider&gt;.yaml</code></li> <li>Add clear <code>description</code> and <code>tags</code></li> <li>Include <code>inputs.required</code> documentation</li> <li>Test with <code>strands validate</code> and <code>strands run</code></li> <li>Submit PR with example + entry in this catalog</li> </ol> <p>See: Contributing Guide</p>"},{"location":"reference/examples/#quick-reference","title":"Quick Reference","text":"<p>Pattern Guides: - Chain - Workflow - Routing - Parallel - Evaluator-Optimizer - Orchestrator-Workers - Graph</p> <p>Feature Guides: - Context Management - Telemetry - Tools - Develop Tools</p> <p>Reference: - Complete Workflow Manual - Spec Quick Reference - Exit Codes - Environment Variables</p>"},{"location":"reference/exit-codes/","title":"Exit Codes Reference","text":"<p>Strands CLI follows Unix conventions for exit codes, providing consistent error reporting across different failure modes.</p>"},{"location":"reference/exit-codes/#overview","title":"Overview","text":"<p>Exit codes allow shell scripts and CI/CD pipelines to distinguish between validation errors, runtime failures, and unsupported features programmatically.</p> <p>Best Practice: Always use named constants instead of raw integers:</p> <pre><code>from strands_cli.exit_codes import EX_SCHEMA, EX_OK\nsys.exit(EX_SCHEMA)  # GOOD\nsys.exit(3)  # BAD - unclear meaning\n</code></pre>"},{"location":"reference/exit-codes/#exit-code-categories","title":"Exit Code Categories","text":"Category Range Description Success 0 Successful execution User/Input Errors 2-3 Invalid CLI usage or spec validation failures Runtime Errors 10-19 Provider failures, I/O errors, budget exceeded System Errors 70 Unexpected exceptions"},{"location":"reference/exit-codes/#success-codes","title":"Success Codes","text":""},{"location":"reference/exit-codes/#ex_ok-0","title":"<code>EX_OK</code> (0)","text":"<p>Meaning: Successful execution</p> <p>When returned: - Workflow completed successfully - All validation checks passed - Artifacts written without errors</p> <p>Example: <pre><code>strands run workflow.yaml\necho $?  # Output: 0\n</code></pre></p>"},{"location":"reference/exit-codes/#userinput-error-codes","title":"User/Input Error Codes","text":""},{"location":"reference/exit-codes/#ex_usage-2","title":"<code>EX_USAGE</code> (2)","text":"<p>Meaning: Command-line usage error</p> <p>When returned: - Invalid command-line flags - Missing required arguments - File not found - Invalid output format specified</p> <p>Examples: <pre><code># Missing spec file\nstrands run\n# Exit code: 2\n\n# Invalid format option\nstrands run workflow.yaml --format invalid\n# Exit code: 2\n</code></pre></p> <p>Resolution: - Check command syntax with <code>strands --help</code> - Verify file paths exist - Review available options for each command</p>"},{"location":"reference/exit-codes/#ex_schema-3","title":"<code>EX_SCHEMA</code> (3)","text":"<p>Meaning: JSON Schema validation error</p> <p>When returned: - Workflow spec doesn't conform to <code>strands-workflow.schema.json</code> - Required fields are missing - Invalid data types - Additional properties not allowed</p> <p>Validation details: - Uses JSON Schema Draft 2020-12 - Reports precise error locations using JSONPointer paths - Provides detailed error messages</p> <p>Example: <pre><code>strands validate invalid-workflow.yaml\n# Output:\n# Schema validation error at /runtime/provider: 'invalid_provider' is not valid under any of the given schemas\n# Exit code: 3\n</code></pre></p> <p>Resolution: 1. Run <code>strands validate workflow.yaml</code> to see specific errors 2. Check JSONPointer paths to locate issues 3. Review Schema Reference for valid values 4. Examine example workflows in <code>examples/</code></p>"},{"location":"reference/exit-codes/#runtime-error-codes","title":"Runtime Error Codes","text":""},{"location":"reference/exit-codes/#ex_runtime-10","title":"<code>EX_RUNTIME</code> (10)","text":"<p>Meaning: Provider/model/tool runtime failure</p> <p>When returned: - AWS Bedrock API errors (throttling, invalid credentials) - Ollama connection failures - OpenAI API errors - Tool execution crashes - Model invocation failures</p> <p>Examples: <pre><code># Ollama not running\nstrands run workflow-ollama.yaml\n# Exit code: 10\n\n# Invalid AWS credentials\nstrands run workflow-bedrock.yaml\n# Exit code: 10\n</code></pre></p> <p>Resolution: - Run <code>strands doctor</code> to check system health - Verify provider credentials (AWS, OpenAI API key) - Check Ollama is running (<code>ollama serve</code>) - Review error messages with <code>--debug --verbose</code> - Check provider-specific logs</p>"},{"location":"reference/exit-codes/#ex_io-12","title":"<code>EX_IO</code> (12)","text":"<p>Meaning: Artifact write or I/O error</p> <p>When returned: - Cannot create output directory - Permission denied when writing artifacts - Disk full - Invalid output path</p> <p>Examples: <pre><code># Read-only directory\nstrands run workflow.yaml --out /read-only/\n# Exit code: 12\n\n# Invalid path\nstrands run workflow.yaml --out /invalid/../path\n# Exit code: 12\n</code></pre></p> <p>Resolution: - Check directory permissions - Verify disk space availability - Use valid output paths - Use <code>--force</code> to overwrite existing files (if intended)</p>"},{"location":"reference/exit-codes/#ex_unsupported-18","title":"<code>EX_UNSUPPORTED</code> (18)","text":"<p>Meaning: Feature present in spec but not supported</p> <p>When returned: - Workflow uses features not yet implemented - Capability check detects unsupported patterns - Provider doesn't support requested features</p> <p>Special behavior: When this code is returned, a detailed Markdown remediation report is automatically written to the artifacts directory with: - JSONPointer locations of unsupported features - Reason each feature is unsupported - Specific remediation steps - Minimal working example</p> <p>Example: <pre><code>strands run workflow-with-unsupported.yaml\n# Output:\n# Unsupported features detected. Remediation report: ./remediation_report_YYYYMMDD_HHMMSS.md\n# Exit code: 18\n</code></pre></p> <p>Resolution: 1. Read the generated remediation report 2. Follow suggested remediation steps 3. Use <code>strands list-supported</code> to see available features 4. Modify workflow to use supported alternatives 5. Check for CLI updates</p>"},{"location":"reference/exit-codes/#ex_budget_exceeded-19","title":"<code>EX_BUDGET_EXCEEDED</code> (19)","text":"<p>Meaning: Token budget exhausted during execution</p> <p>When returned: - Cumulative token usage reaches 100% of <code>budgets.max_tokens</code> - Budget enforcement is enabled - Token consumption exceeds configured limits</p> <p>Behavior: - Warning logged at threshold (default 80%) - Automatic context compaction triggered (if enabled) - Workflow aborted to prevent cost overruns</p> <p>Example: <pre><code># workflow.yaml\nbudgets:\n  max_tokens: 10000\n  threshold: 0.8\n</code></pre></p> <pre><code>strands run workflow.yaml\n# Output:\n# Warning: Token budget at 82% (8200/10000)\n# Error: Token budget exceeded (10100/10000) - aborting workflow\n# Exit code: 19\n</code></pre> <p>Resolution: - Increase <code>budgets.max_tokens</code> if legitimate - Enable <code>context_policy.compaction</code> to reduce context - Optimize prompts to use fewer tokens - Split complex workflows into smaller ones - Review token usage with <code>--trace</code></p>"},{"location":"reference/exit-codes/#system-error-codes","title":"System Error Codes","text":""},{"location":"reference/exit-codes/#ex_unknown-70","title":"<code>EX_UNKNOWN</code> (70)","text":"<p>Meaning: Unexpected exception not handled by specific error codes</p> <p>When returned: - Unhandled Python exceptions - Internal CLI bugs - Unexpected edge cases</p> <p>Example: <pre><code>strands run workflow.yaml --debug --verbose\n# Output:\n# Unexpected error: [detailed traceback]\n# Exit code: 70\n</code></pre></p> <p>Resolution: 1. Run with <code>--verbose</code> to see full traceback 2. Check for known issues on GitHub 3. Report the bug with traceback and workflow spec 4. Try updating to latest CLI version</p>"},{"location":"reference/exit-codes/#shell-script-integration","title":"Shell Script Integration","text":""},{"location":"reference/exit-codes/#basic-error-handling","title":"Basic Error Handling","text":"<pre><code>#!/bin/bash\nset -e  # Exit on any error\n\nstrands run workflow.yaml\nif [ $? -eq 0 ]; then\n    echo \"Success!\"\nelse\n    echo \"Workflow failed with code: $?\"\nfi\n</code></pre>"},{"location":"reference/exit-codes/#advanced-error-handling","title":"Advanced Error Handling","text":"<pre><code>#!/bin/bash\n\nstrands run workflow.yaml\nexit_code=$?\n\ncase $exit_code in\n    0)\n        echo \"Workflow completed successfully\"\n        ;;\n    2)\n        echo \"Usage error - check command syntax\"\n        exit 1\n        ;;\n    3)\n        echo \"Schema validation failed - check workflow spec\"\n        exit 1\n        ;;\n    10)\n        echo \"Runtime error - check provider status\"\n        strands doctor\n        exit 1\n        ;;\n    12)\n        echo \"I/O error - check permissions and disk space\"\n        exit 1\n        ;;\n    18)\n        echo \"Unsupported features - see remediation report\"\n        exit 1\n        ;;\n    19)\n        echo \"Token budget exceeded - increase limits or optimize\"\n        exit 1\n        ;;\n    70)\n        echo \"Unexpected error - report as bug\"\n        exit 1\n        ;;\n    *)\n        echo \"Unknown exit code: $exit_code\"\n        exit 1\n        ;;\nesac\n</code></pre>"},{"location":"reference/exit-codes/#cicd-integration","title":"CI/CD Integration","text":"<pre><code># GitHub Actions example\n- name: Validate workflow\n  run: |\n    strands validate workflow.yaml\n    if [ $? -ne 0 ]; then\n      echo \"Validation failed\"\n      exit 1\n    fi\n\n- name: Run workflow\n  run: |\n    strands run workflow.yaml --out ./artifacts\n    exit_code=$?\n    if [ $exit_code -eq 18 ]; then\n      echo \"::warning::Unsupported features detected\"\n      cat ./remediation_report_*.md\n      exit 1\n    elif [ $exit_code -ne 0 ]; then\n      echo \"::error::Workflow failed with exit code $exit_code\"\n      exit 1\n    fi\n</code></pre>"},{"location":"reference/exit-codes/#programmatic-access","title":"Programmatic Access","text":""},{"location":"reference/exit-codes/#python","title":"Python","text":"<pre><code>from strands_cli.exit_codes import (\n    EX_OK,\n    EX_USAGE,\n    EX_SCHEMA,\n    EX_RUNTIME,\n    EX_IO,\n    EX_UNSUPPORTED,\n    EX_BUDGET_EXCEEDED,\n    EX_UNKNOWN,\n)\n\nimport subprocess\n\nresult = subprocess.run(\n    [\"strands\", \"run\", \"workflow.yaml\"],\n    capture_output=True,\n    text=True\n)\n\nif result.returncode == EX_OK:\n    print(\"Success!\")\nelif result.returncode == EX_SCHEMA:\n    print(\"Schema validation failed\")\nelif result.returncode == EX_UNSUPPORTED:\n    print(\"Unsupported features detected\")\n</code></pre>"},{"location":"reference/exit-codes/#see-also","title":"See Also","text":"<ul> <li>CLI Reference - Command-line interface</li> <li>Schema Reference - Workflow specification</li> <li>Troubleshooting Guide - Common issues</li> </ul>"},{"location":"reference/schema/","title":"Schema Reference","text":"<p>Complete JSON Schema reference for Strands workflow specifications.</p>"},{"location":"reference/schema/#overview","title":"Overview","text":"<p>Schema Title: Strands Workflow Spec (v0)</p> <p>Description: Declarative spec for executing agentic workflows (CLI) on AWS Strands SDK. Captures runtime, agents, tools, and Anthropic-style patterns (chain, routing, orchestrator-workers, evaluator-optimizer, graph, workflow).</p> <p>Schema Version: https://json-schema.org/draft/2020-12/schema</p>"},{"location":"reference/schema/#top-level-properties","title":"Top-Level Properties","text":""},{"location":"reference/schema/#version-required","title":"<code>version</code> Required","text":"<p>Type: <code>integer | string</code></p> <p>Spec version. Use 0 initially.</p>"},{"location":"reference/schema/#name-required","title":"<code>name</code> Required","text":"<p>Type: <code>string</code></p> <p>No description available.</p>"},{"location":"reference/schema/#description-optional","title":"<code>description</code> Optional","text":"<p>Type: <code>string</code></p> <p>No description available.</p>"},{"location":"reference/schema/#tags-optional","title":"<code>tags</code> Optional","text":"<p>Type: <code>array</code></p> <p>No description available.</p>"},{"location":"reference/schema/#runtime-required","title":"<code>runtime</code> Required","text":"<p>Type: <code>object</code></p> <p>No description available.</p>"},{"location":"reference/schema/#inputs-optional","title":"<code>inputs</code> Optional","text":"<p>Type: <code>object</code></p> <p>No description available.</p>"},{"location":"reference/schema/#env-optional","title":"<code>env</code> Optional","text":"<p>Type: <code>object</code></p> <p>No description available.</p>"},{"location":"reference/schema/#telemetry-optional","title":"<code>telemetry</code> Optional","text":"<p>Type: <code>object</code></p> <p>No description available.</p>"},{"location":"reference/schema/#context_policy-optional","title":"<code>context_policy</code> Optional","text":"<p>Type: <code>object</code></p> <p>No description available.</p>"},{"location":"reference/schema/#skills-optional","title":"<code>skills</code> Optional","text":"<p>Type: <code>array</code></p> <p>No description available.</p>"},{"location":"reference/schema/#tools-optional","title":"<code>tools</code> Optional","text":"<p>Type: <code>object</code></p> <p>No description available.</p>"},{"location":"reference/schema/#agents-required","title":"<code>agents</code> Required","text":"<p>Type: <code>object</code></p> <p>Map of agent name -&gt; spec</p>"},{"location":"reference/schema/#pattern-required","title":"<code>pattern</code> Required","text":"<p>Type: <code>object</code></p> <p>No description available.</p>"},{"location":"reference/schema/#outputs-optional","title":"<code>outputs</code> Optional","text":"<p>Type: <code>object</code></p> <p>No description available.</p>"},{"location":"reference/schema/#security-optional","title":"<code>security</code> Optional","text":"<p>Type: <code>object</code></p> <p>No description available.</p>"},{"location":"reference/schema/#schema-definitions","title":"Schema Definitions","text":"<p>The schema includes the following reusable definitions in <code>$defs</code>:</p> <ul> <li><code>agentSpec</code></li> <li><code>agents</code></li> <li><code>chainConfig</code></li> <li><code>contextPolicy</code></li> <li><code>env</code></li> <li><code>evaluatorOptimizerConfig</code></li> <li><code>graphConfig</code></li> <li><code>identifier</code></li> <li><code>inference</code></li> <li><code>inputVarMap</code></li> <li><code>inputVarSpec</code></li> <li><code>inputs</code></li> <li><code>nonEmptyString</code></li> <li><code>orchestratorWorkersConfig</code></li> <li><code>outputs</code></li> <li><code>parallelConfig</code></li> <li><code>pattern</code></li> <li><code>routingConfig</code></li> <li><code>runtime</code></li> <li><code>security</code></li> <li><code>skills</code></li> <li><code>step</code></li> <li><code>tag</code></li> <li><code>telemetry</code></li> <li><code>tools</code></li> <li><code>workflowConfig</code></li> </ul>"},{"location":"reference/schema/#see-also","title":"See Also","text":"<ul> <li>CLI Reference - Command-line interface</li> <li>Examples - Example workflows</li> <li>Tutorials - Getting started</li> </ul>"},{"location":"reference/security/","title":"Security Considerations","text":""},{"location":"reference/security/#overview","title":"Overview","text":"<p>Strands CLI executes user-defined workflow specifications that may include templates, HTTP executors, and file operations. This document describes the security measures implemented to protect against common attack vectors when processing potentially untrusted workflow specs.</p> <p>Security Principle: Defense-in-depth for user-editable specifications. All user-controlled inputs (YAML specs, templates, variables) are treated as potentially malicious and validated at multiple layers.</p>"},{"location":"reference/security/#template-security-jinja2-sandboxing","title":"Template Security (Jinja2 Sandboxing)","text":""},{"location":"reference/security/#risk-remote-code-execution-via-template-injection","title":"Risk: Remote Code Execution via Template Injection","text":"<p>Workflow specs use Jinja2 templates for dynamic content rendering in prompts, inputs, and artifact paths. Without proper sandboxing, attackers can exploit template introspection to execute arbitrary Python code.</p> <p>Attack Example: <pre><code>outputs:\n  artifacts:\n    - path: \"output.txt\"\n      from: \"{{ ''.__class__.__mro__[1].__subclasses__()[104].__init__.__globals__['os'].system('malicious_command') }}\"\n</code></pre></p>"},{"location":"reference/security/#mitigation-sandboxed-environment","title":"Mitigation: Sandboxed Environment","text":"<p>Implementation (<code>src/strands_cli/loader/template.py</code>): - Uses <code>jinja2.sandbox.SandboxedEnvironment</code> instead of standard <code>Environment</code> - Explicitly whitelists only safe filters: <code>truncate</code>, <code>tojson</code> - Clears all globals to prevent access to Python builtins - Blocks attribute access to <code>__class__</code>, <code>__mro__</code>, <code>__subclasses__</code>, <code>__globals__</code>, etc.</p> <p>Detection &amp; Logging: <pre><code># Security violations logged at WARNING level\nlogger.warning(\n    \"template_security_violation\",\n    violation_type=\"unsafe_operation\",\n    error=str(e),\n    template_preview=template_str[:100],\n)\n</code></pre></p> <p>What's Allowed: - Variable expansion: <code>{{ variable }}</code> - Whitelisted filters: <code>{{ text | truncate(100) }}</code>, <code>{{ data | tojson }}</code> - Safe attribute access: <code>{{ inputs.topic }}</code> - Whitelisted filters: <code>{{ text | truncate(100) }}</code>, <code>{{ data | tojson }}</code>, <code>{{ topic | title }}</code></p> <p>What's Blocked: - Python introspection: <code>{{ ''.__class__ }}</code> - Builtin functions: <code>{{ eval(...) }}</code>, <code>{{ __import__(...) }}</code> - Non-whitelisted filters: <code>{{ text | upper }}</code> (only <code>truncate</code>, <code>tojson</code>, and <code>title</code> are allowed)</p>"},{"location":"reference/security/#http-executor-security-ssrf-prevention","title":"HTTP Executor Security (SSRF Prevention)","text":""},{"location":"reference/security/#risk-server-side-request-forgery-ssrf","title":"Risk: Server-Side Request Forgery (SSRF)","text":"<p>HTTP executors allow specs to define arbitrary <code>base_url</code> values. Without validation, attackers can target internal services, cloud metadata endpoints, or local files.</p> <p>Attack Example: <pre><code>tools:\n  http_executors:\n    - id: \"metadata-attack\"\n      base_url: \"http://169.254.169.254/latest/meta-data/\"  # AWS metadata\n      timeout: 30\n</code></pre></p>"},{"location":"reference/security/#mitigation-url-validation-with-blocklistallowlist","title":"Mitigation: URL Validation with Blocklist/Allowlist","text":"<p>Implementation (<code>src/strands_cli/types.py</code>, <code>src/strands_cli/config.py</code>):</p>"},{"location":"reference/security/#default-blocked-patterns","title":"Default Blocked Patterns","text":"<p>Enforced for all HTTP executors: - Localhost: <code>127.0.0.1</code>, <code>localhost</code>, <code>[::1]</code> - AWS/Azure metadata: <code>169.254.169.254</code> - Private networks (RFC1918): <code>10.0.0.0/8</code>, <code>172.16.0.0/12</code>, <code>192.168.0.0/16</code> - Non-HTTP protocols: <code>file://</code>, <code>ftp://</code>, <code>gopher://</code></p>"},{"location":"reference/security/#environment-variable-configuration","title":"Environment Variable Configuration","text":"<p>Add custom blocked patterns: <pre><code>export STRANDS_HTTP_BLOCKED_PATTERNS='[\"^https://internal-api\\\\.company\\\\.com\"]'\n</code></pre></p> <p>Enforce allowlist (blocks all URLs except those matching patterns): <pre><code>export STRANDS_HTTP_ALLOWED_DOMAINS='[\"^https://api\\\\.openai\\\\.com\", \"^https://.*\\\\.trusted\\\\.com\"]'\n</code></pre></p> <p>Detection &amp; Logging: <pre><code># SSRF attempts logged at WARNING level\nlogger.warning(\n    \"http_url_blocked\",\n    violation_type=\"ssrf_attempt\",\n    blocked_url=base_url,\n    matched_pattern=pattern,\n)\n</code></pre></p> <p>What's Allowed by Default: - Public HTTPS URLs: <code>https://api.openai.com</code>, <code>https://api.example.com</code> - Public HTTP URLs: <code>http://api.example.com</code> (blocklist-based, not allowlist)</p> <p>What's Blocked: - Localhost/loopback addresses - Private IP ranges - Cloud metadata endpoints - File/FTP/Gopher protocols - Any URL matching <code>STRANDS_HTTP_BLOCKED_PATTERNS</code> - If <code>STRANDS_HTTP_ALLOWED_DOMAINS</code> set: URLs not matching allowlist</p>"},{"location":"reference/security/#artifact-path-security-path-traversal-prevention","title":"Artifact Path Security (Path Traversal Prevention)","text":""},{"location":"reference/security/#risk-path-traversal-and-file-overwrite","title":"Risk: Path Traversal and File Overwrite","text":"<p>Artifact paths can include templates that render user variables. Without validation, attackers can escape the output directory, overwrite system files, or follow symlinks outside the project.</p> <p>Attack Examples: <pre><code>outputs:\n  artifacts:\n    - path: \"{{ malicious }}\"\n      from: \"{{ last_response }}\"\n</code></pre> <pre><code>strands run workflow.yaml --var malicious=\"../../etc/passwd\"\n</code></pre></p>"},{"location":"reference/security/#mitigation-multi-layer-path-validation","title":"Mitigation: Multi-Layer Path Validation","text":"<p>Implementation (<code>src/strands_cli/artifacts/io.py</code>):</p>"},{"location":"reference/security/#1-reject-absolute-paths","title":"1. Reject Absolute Paths","text":"<pre><code>if path_obj.is_absolute():\n    raise ArtifactError(\"Absolute paths not allowed in artifacts\")\n</code></pre>"},{"location":"reference/security/#2-block-path-traversal-components","title":"2. Block Path Traversal (<code>..</code> components)","text":"<pre><code>if \"..\" in path_obj.parts:\n    raise ArtifactError(\"Path traversal not allowed\")\n</code></pre>"},{"location":"reference/security/#3-sanitize-path-components","title":"3. Sanitize Path Components","text":"<p>Each component sanitized with <code>sanitize_filename()</code>: - Removes path separators (<code>/</code>, <code>\\</code>) - Replaces special characters with <code>_</code> - Strips leading/trailing dots and underscores</p>"},{"location":"reference/security/#4-validate-resolved-path","title":"4. Validate Resolved Path","text":"<pre><code>artifact_path.relative_to(output_dir.resolve())  # Raises ValueError if escaped\n</code></pre>"},{"location":"reference/security/#5-block-symlinks-mvp","title":"5. Block Symlinks (MVP)","text":"<pre><code>if artifact_path.is_symlink():\n    raise ArtifactError(\"Symlinks are not allowed for security reasons\")\n</code></pre> <p>Detection &amp; Logging: <pre><code># Path traversal attempts logged at WARNING level\nlogger.warning(\n    \"artifact_path_blocked\",\n    violation_type=\"path_traversal_attempt\",\n    attempted_path=rendered_path,\n    artifact_template=artifact.path,\n)\n</code></pre></p> <p>What's Allowed: - Relative paths: <code>output.txt</code>, <code>reports/summary.md</code> - Nested directories: <code>analysis/data/results.json</code> - Template variables: <code>{{ spec.name }}-report.txt</code></p> <p>What's Blocked: - Absolute paths: <code>/etc/passwd</code>, <code>C:\\Windows\\System32\\config</code> - Path traversal: <code>../../etc/passwd</code>, <code>..\\..\\..\\windows\\hosts</code> - Symlinks (for MVP; may be reconsidered in future releases)</p>"},{"location":"reference/security/#python-tool-security","title":"Python Tool Security","text":""},{"location":"reference/security/#risk-dangerous-file-operations-and-code-execution","title":"Risk: Dangerous File Operations and Code Execution","text":"<p>Python tools can perform file operations and execute code within the workflow environment. The <code>file_write</code> tool, in particular, can modify the filesystem and requires careful usage.</p> <p>Attack Example: <pre><code>tools:\n  python:\n    - callable: \"strands_tools.file_write.file_write\"\n</code></pre> <pre><code># Malicious prompt could attempt to overwrite system files\nstrands run workflow.yaml --var path=\"/etc/passwd\" --var content=\"malicious\"\n</code></pre></p>"},{"location":"reference/security/#mitigation-allowlist-user-consent","title":"Mitigation: Allowlist + User Consent","text":"<p>Implementation (<code>src/strands_cli/capability/checker.py</code>, <code>src/strands_cli/runtime/tools.py</code>):</p>"},{"location":"reference/security/#allowlisted-python-tools","title":"Allowlisted Python Tools","text":"<p>Only the following Python callables are permitted: - <code>strands_tools.http_request.http_request</code> - Make HTTP requests (subject to SSRF protection) - <code>strands_tools.file_read.file_read</code> - Read files (read-only access) - <code>strands_tools.file_write.file_write</code> - Write files (requires consent) - <code>strands_tools.calculator.calculator</code> - Mathematical calculations (SymPy-based) - <code>strands_tools.current_time.current_time</code> - Get current date/time (read-only)</p> <p>Any tool not in this allowlist will trigger exit code 18 with remediation report.</p>"},{"location":"reference/security/#user-consent-for-file_write","title":"User Consent for file_write","text":"<p>The <code>file_write</code> tool includes interactive consent prompts to prevent unintended file modifications. The tool will: 1. Display the target file path and content preview 2. Prompt user to confirm the write operation 3. Allow user to deny (skip) or approve each write</p> <p>Bypassing Consent (Automation Mode):</p> <p>For CI/CD pipelines and automation scenarios, use the <code>--bypass-tool-consent</code> flag:</p> <pre><code>strands run workflow.yaml --bypass-tool-consent\n</code></pre> <p>This sets the <code>BYPASS_TOOL_CONSENT=true</code> environment variable, which the Strands SDK's <code>file_write</code> tool respects.</p> <p>\u26a0\ufe0f Security Warning: Only use <code>--bypass-tool-consent</code> in trusted, controlled environments: - \u2705 CI/CD pipelines with reviewed workflow specs - \u2705 Automated testing with known, safe inputs - \u274c Production workflows processing untrusted user inputs - \u274c Workflows from external/untrusted sources</p>"},{"location":"reference/security/#tool-loading-architecture","title":"Tool Loading Architecture","text":"<p>Two Tool Types (<code>src/strands_cli/runtime/tools.py</code>): 1. @tool decorated functions: Returns function object directly 2. Module-based tools: Returns module with <code>TOOL_SPEC</code> attribute</p> <p>The CLI automatically detects which type and loads appropriately: <pre><code>if hasattr(module, \"TOOL_SPEC\"):\n    return module  # Module-based tool (e.g., file_write)\nelse:\n    return callable_obj  # @tool decorated function\n</code></pre></p> <p>Detection &amp; Logging: <pre><code># Disallowed tool attempts logged at WARNING level\nlogger.warning(\n    \"tool_blocked\",\n    violation_type=\"disallowed_python_callable\",\n    attempted_callable=callable_path,\n    allowlist=ALLOWED_PYTHON_CALLABLES,\n)\n</code></pre></p> <p>What's Allowed: - Allowlisted tools only (see list above) - String format: <code>[\"strands_tools.calculator.calculator\"]</code> - Dict format: <code>[{\"callable\": \"strands_tools.calculator.calculator\"}]</code></p> <p>What's Blocked: - Any Python callable not in allowlist - Arbitrary imports like <code>os.system</code>, <code>subprocess.run</code> - Tools with old path format (migration required)</p>"},{"location":"reference/security/#best-practices","title":"Best Practices","text":"<p>Development/Testing: <pre><code># Interactive mode (prompts for file_write consent)\nstrands run workflow.yaml\n</code></pre></p> <p>Production/CI: <pre><code># Review spec for file_write tool usage first\nstrands validate workflow.yaml\n\n# Run with bypass only after review\nstrands run workflow.yaml --bypass-tool-consent --force\n</code></pre></p> <p>Audit file operations: <pre><code># Enable structured logging to track file_write operations\nexport STRANDS_LOG_LEVEL=INFO\nexport STRANDS_LOG_FORMAT=json\nstrands run workflow.yaml 2&gt;&amp;1 | grep file_write\n</code></pre></p>"},{"location":"reference/security/#audit-logging","title":"Audit Logging","text":"<p>All security violations are logged using <code>structlog</code> with structured fields for analysis:</p>"},{"location":"reference/security/#log-format","title":"Log Format","text":"<pre><code>{\n  \"event\": \"template_security_violation\",\n  \"violation_type\": \"unsafe_operation\",\n  \"error\": \"SecurityError: access to attribute '__class__' of 'str' object is unsafe\",\n  \"template_preview\": \"{{ ''.__class__ }}\",\n  \"timestamp\": \"2025-11-06T05:03:46Z\",\n  \"level\": \"warning\"\n}\n</code></pre>"},{"location":"reference/security/#violation-types","title":"Violation Types","text":"<ul> <li><code>template_security_violation</code>: Template sandbox escape attempt</li> <li><code>http_url_blocked</code>: SSRF attempt (localhost, metadata endpoint, etc.)</li> <li><code>artifact_path_blocked</code>: Path traversal or absolute path attempt</li> <li><code>tool_blocked</code>: Disallowed Python callable attempt</li> </ul>"},{"location":"reference/security/#log-levels","title":"Log Levels","text":"<ul> <li>WARNING: Security policy violation (blocked before execution)</li> <li>ERROR: Unexpected security failure</li> <li>INFO: Normal operations (not security-related)</li> </ul>"},{"location":"reference/security/#configuration-best-practices","title":"Configuration Best Practices","text":""},{"location":"reference/security/#developmenttesting","title":"Development/Testing","text":"<pre><code># Allow localhost for local testing\nexport STRANDS_HTTP_ALLOWED_DOMAINS='[\"^http://localhost\"]'\n\n# Run with interactive file_write consent\nstrands run workflow.yaml\n</code></pre>"},{"location":"reference/security/#production","title":"Production","text":"<pre><code># Enforce strict allowlist\nexport STRANDS_HTTP_ALLOWED_DOMAINS='[\"^https://api\\\\.openai\\\\.com\", \"^https://api\\\\.anthropic\\\\.com\"]'\n\n# Block additional internal patterns\nexport STRANDS_HTTP_BLOCKED_PATTERNS='[\"^https://.*\\\\.internal\\\\.company\\\\.com\"]'\n\n# Review workflow before bypassing tool consent\nstrands validate workflow.yaml\nstrands run workflow.yaml --bypass-tool-consent --force\n\n# Review security logs\nexport STRANDS_LOG_LEVEL=WARNING\nexport STRANDS_LOG_FORMAT=json\n</code></pre>"},{"location":"reference/security/#cicd","title":"CI/CD","text":"<pre><code># Run specs from untrusted sources with maximum restrictions\nexport STRANDS_HTTP_ALLOWED_DOMAINS='[\"^https://api\\\\.trusted\\\\.com\"]'\n\n# Review for dangerous tools\ngrep -E \"file_write|http_request\" workflow.yaml\n\n# Never use --bypass-tool-consent for untrusted specs\n# Never use --force flag (prevent artifact overwrites)\nstrands run untrusted-spec.yaml\n</code></pre>"},{"location":"reference/security/#threat-model","title":"Threat Model","text":""},{"location":"reference/security/#in-scope","title":"In Scope","text":"<ul> <li>User-editable workflow specs: Assumes specs may be malicious (YAML/JSON from untrusted sources)</li> <li>Template injection: Prevents code execution via Jinja2 templates</li> <li>SSRF attacks: Prevents internal network scanning and metadata access</li> <li>Path traversal: Prevents file overwrite and directory escape</li> <li>Data exfiltration: Limits HTTP executor targets via allowlist/blocklist</li> <li>Dangerous tool usage: Allowlist restricts Python callables; file_write requires consent</li> </ul>"},{"location":"reference/security/#out-of-scope-future-work","title":"Out of Scope (Future Work)","text":"<ul> <li>Dependency confusion: Python tool imports are allowlisted but not package-pinned</li> <li>Resource exhaustion: No rate limiting on LLM calls (budgets logged only)</li> <li>Secrets exposure: Env-only secrets assumed secure (Secrets Manager support planned)</li> <li>Supply chain: MCP servers not validated (future hardening needed)</li> <li>File operation sandboxing: file_write can write anywhere writable; no chroot/jail</li> </ul>"},{"location":"reference/security/#security-updates","title":"Security Updates","text":""},{"location":"reference/security/#reporting-vulnerabilities","title":"Reporting Vulnerabilities","text":"<p>Report security issues to: [maintainer contact - TBD]</p>"},{"location":"reference/security/#version-history","title":"Version History","text":"<ul> <li>v0.5.0: Expanded Python tool allowlist (added file_write, calculator, current_time); added --bypass-tool-consent flag; improved tool loading architecture</li> <li>v0.4.0: Initial security hardening (Jinja2 sandbox, HTTP validation, path security)</li> <li>v0.3.0: Multi-agent support (no security hardening)</li> <li>v0.2.0: Single-agent MVP</li> </ul>"},{"location":"reference/security/#future-enhancements","title":"Future Enhancements","text":"<ol> <li>Content Security Policy for HTTP responses (validate Content-Type, size limits)</li> <li>MCP Server Sandboxing (isolate MCP processes, allowlist executables)</li> <li>Rate Limiting (enforce budget limits, prevent runaway costs)</li> <li>Secrets Manager Integration (replace env-only secrets with secure vaults)</li> <li>Python Tool Sandboxing (chroot/jail for file operations, restrict network access)</li> <li>Symlink Policy Refinement (allow symlinks within output_dir after validation)</li> <li>Tool Package Pinning (pin versions of strands_tools dependencies)</li> </ol>"},{"location":"reference/security/#testing","title":"Testing","text":"<p>Security features are covered by comprehensive negative tests:</p> <ul> <li>Template Security: 9 tests blocking introspection, eval, import</li> <li>HTTP Security: 14 tests blocking SSRF vectors and validating env vars</li> <li>Path Security: 7 tests blocking traversal, absolute paths, symlinks</li> <li>Tool Security: 5 tests validating allowlist enforcement and tool loading</li> </ul> <p>Run security tests: <pre><code>uv run pytest tests/test_executor.py::TestTemplateSecurity -v\nuv run pytest tests/test_runtime.py::TestHttpExecutorSecurity -v\nuv run pytest tests/test_executor.py::TestArtifactPathSecurity -v\nuv run pytest tests/test_capability.py::TestCapabilityChecker::test_check_python_tools -v\n</code></pre></p>"},{"location":"reference/security/#summary","title":"Summary","text":"<p>Strands CLI implements defense-in-depth for user-editable workflow specs: 1. Templates \u2192 Sandboxed Jinja2 (no code execution) 2. HTTP Executors \u2192 URL validation (no SSRF) 3. Artifact Paths \u2192 Multi-layer checks (no path traversal) 4. Python Tools \u2192 Allowlist + user consent for dangerous operations 5. Audit Logging \u2192 Structured security events</p> <p>All violations logged at WARNING level with actionable context for operators.</p>"},{"location":"reference/session-api/","title":"Session API Reference","text":"<p>Technical reference for session management data structures and repository API.</p>"},{"location":"reference/session-api/#overview","title":"Overview","text":"<p>The session management system provides persistence for workflow execution state through Pydantic models and repository abstractions. Session persistence enables crash recovery, workflow resume, and cost optimization by skipping completed work.</p> <p>Module: <code>strands_cli.session</code></p> <p>Key Features: - Automatic checkpointing after each step/task/branch completion - Agent conversation history restoration via Strands SDK FileSessionManager - Token usage tracking across resume sessions - Spec change detection with SHA256 hash validation - Pattern-specific execution state serialization</p>"},{"location":"reference/session-api/#data-models","title":"Data Models","text":""},{"location":"reference/session-api/#sessionstatus","title":"SessionStatus","text":"<p>Enumeration of session execution states.</p> <p>Location: <code>src/strands_cli/session/__init__.py</code></p> <pre><code>class SessionStatus(str, Enum):\n    \"\"\"Session execution status.\"\"\"\n    RUNNING = \"running\"      # Workflow currently executing\n    PAUSED = \"paused\"        # Workflow paused for HITL (human-in-the-loop)\n    COMPLETED = \"completed\"  # Workflow finished successfully\n    FAILED = \"failed\"        # Workflow terminated with error\n</code></pre> <p>Usage: <pre><code>from strands_cli.session import SessionStatus\n\nif state.metadata.status == SessionStatus.COMPLETED:\n    print(\"Already finished\")\n</code></pre></p>"},{"location":"reference/session-api/#sessionmetadata","title":"SessionMetadata","text":"<p>Core session metadata and lifecycle information.</p> <p>Location: <code>src/strands_cli/session/__init__.py</code></p> <pre><code>class SessionMetadata(BaseModel):\n    \"\"\"Core session metadata.\"\"\"\n    session_id: str              # UUID (generated by generate_session_id())\n    workflow_name: str           # From spec.name\n    spec_hash: str               # SHA256 of original spec file\n    pattern_type: str            # PatternType enum value (e.g., \"chain\")\n    status: SessionStatus        # Current execution status\n    created_at: str              # ISO 8601 timestamp\n    updated_at: str              # ISO 8601 timestamp (updated on checkpoint)\n    error: str | None = None     # Error message if status == FAILED\n</code></pre> <p>Example: <pre><code>from strands_cli.session import SessionMetadata, SessionStatus\nfrom strands_cli.session.utils import generate_session_id, now_iso8601\n\nmetadata = SessionMetadata(\n    session_id=generate_session_id(),\n    workflow_name=\"research-chain\",\n    spec_hash=\"abc123def456...\",\n    pattern_type=\"chain\",\n    status=SessionStatus.RUNNING,\n    created_at=now_iso8601(),\n    updated_at=now_iso8601(),\n)\n</code></pre></p>"},{"location":"reference/session-api/#tokenusage","title":"TokenUsage","text":"<p>Token usage tracking for cost analysis.</p> <p>Location: <code>src/strands_cli/session/__init__.py</code></p> <pre><code>class TokenUsage(BaseModel):\n    \"\"\"Token usage tracking.\"\"\"\n    total_input_tokens: int = 0         # Cumulative input tokens\n    total_output_tokens: int = 0        # Cumulative output tokens\n    by_agent: dict[str, int] = Field(   # Per-agent token breakdown\n        default_factory=dict\n    )\n</code></pre> <p>Example: <pre><code>from strands_cli.session import TokenUsage\n\nusage = TokenUsage(\n    total_input_tokens=3000,\n    total_output_tokens=2000,\n    by_agent={\n        \"researcher\": 2000,\n        \"analyst\": 3000\n    }\n)\n\nprint(f\"Total tokens: {usage.total_input_tokens + usage.total_output_tokens}\")\n</code></pre></p>"},{"location":"reference/session-api/#sessionstate","title":"SessionState","text":"<p>Complete session state for persistence.</p> <p>Location: <code>src/strands_cli/session/__init__.py</code></p> <pre><code>class SessionState(BaseModel):\n    \"\"\"Complete session state for persistence.\"\"\"\n    metadata: SessionMetadata                   # Session metadata\n    variables: dict[str, str]                   # User-provided variables (--var)\n    runtime_config: dict[str, Any]              # Runtime configuration (provider, model_id, etc.)\n    pattern_state: dict[str, Any]               # Pattern-specific execution state\n    token_usage: TokenUsage                     # Token usage tracking\n    artifacts_written: list[str] = Field(       # Artifacts already written\n        default_factory=list\n    )\n</code></pre> <p>Pattern State Structures:</p> <p>Chain: <pre><code>pattern_state = {\n    \"current_step\": 2,          # Next step to execute (0-indexed)\n    \"step_history\": [\n        {\n            \"index\": 0,\n            \"agent\": \"researcher\",\n            \"response\": \"Research findings...\",\n            \"tokens_estimated\": 2000\n        },\n        {\n            \"index\": 1,\n            \"agent\": \"analyst\",\n            \"response\": \"Analysis...\",\n            \"tokens_estimated\": 3000\n        }\n    ]\n}\n</code></pre></p> <p>Workflow (Phase 3): <pre><code>pattern_state = {\n    \"completed_tasks\": [\"task1\", \"task2\"],\n    \"pending_tasks\": [\"task3\"],\n    \"blocked_tasks\": [\"task4\"],  # Waiting on dependencies\n    \"task_outputs\": {\n        \"task1\": {\"response\": \"...\", \"tokens\": 1000},\n        \"task2\": {\"response\": \"...\", \"tokens\": 1200}\n    }\n}\n</code></pre></p> <p>Example: <pre><code>from strands_cli.session import SessionState, SessionMetadata, SessionStatus, TokenUsage\nfrom strands_cli.session.utils import generate_session_id, now_iso8601\n\nstate = SessionState(\n    metadata=SessionMetadata(\n        session_id=generate_session_id(),\n        workflow_name=\"research-chain\",\n        spec_hash=\"abc123\",\n        pattern_type=\"chain\",\n        status=SessionStatus.RUNNING,\n        created_at=now_iso8601(),\n        updated_at=now_iso8601()\n    ),\n    variables={\"topic\": \"AI agents\", \"format\": \"markdown\"},\n    runtime_config={\n        \"provider\": \"ollama\",\n        \"model_id\": \"llama2\",\n        \"host\": \"http://localhost:11434\"\n    },\n    pattern_state={\n        \"current_step\": 2,\n        \"step_history\": [...]\n    },\n    token_usage=TokenUsage(\n        total_input_tokens=3000,\n        total_output_tokens=2000\n    ),\n    artifacts_written=[\"./output/step1.md\"]\n)\n</code></pre></p>"},{"location":"reference/session-api/#repository-api","title":"Repository API","text":""},{"location":"reference/session-api/#filesessionrepository","title":"FileSessionRepository","text":"<p>File-based session persistence using local filesystem.</p> <p>Location: <code>src/strands_cli/session/file_repository.py</code></p> <pre><code>class FileSessionRepository:\n    \"\"\"File-based session storage using local filesystem.\n\n    Storage structure:\n        {storage_dir}/session_{session_id}/\n        \u251c\u2500\u2500 session.json\n        \u251c\u2500\u2500 pattern_state.json\n        \u251c\u2500\u2500 spec_snapshot.yaml\n        \u2514\u2500\u2500 agents/  # Managed by Strands SDK FileSessionManager\n    \"\"\"\n</code></pre>"},{"location":"reference/session-api/#constructor","title":"Constructor","text":"<pre><code>def __init__(self, storage_dir: Path | None = None):\n    \"\"\"Initialize repository with storage directory.\n\n    Args:\n        storage_dir: Base directory for sessions (default: ~/.strands/sessions)\n    \"\"\"\n</code></pre> <p>Example: <pre><code>from strands_cli.session.file_repository import FileSessionRepository\n\n# Use default directory (~/.strands/sessions)\nrepo = FileSessionRepository()\n\n# Use custom directory\nrepo = FileSessionRepository(storage_dir=Path(\"/tmp/sessions\"))\n</code></pre></p>"},{"location":"reference/session-api/#methods","title":"Methods","text":""},{"location":"reference/session-api/#exists","title":"exists()","text":"<pre><code>def exists(self, session_id: str) -&gt; bool:\n    \"\"\"Check if session exists.\n\n    Args:\n        session_id: Session ID to check\n\n    Returns:\n        True if session directory exists, False otherwise\n    \"\"\"\n</code></pre> <p>Example: <pre><code>if repo.exists(\"abc123\"):\n    print(\"Session found\")\n</code></pre></p>"},{"location":"reference/session-api/#save","title":"save()","text":"<pre><code>def save(self, state: SessionState, spec_content: str) -&gt; None:\n    \"\"\"Save complete session state.\n\n    Args:\n        state: Session state to persist\n        spec_content: Original workflow spec YAML/JSON content\n\n    Side Effects:\n        Creates session directory if not exists\n        Writes session.json, pattern_state.json, spec_snapshot.yaml\n        Logs \"session_saved\" event\n    \"\"\"\n</code></pre> <p>Example: <pre><code>from strands_cli.session import SessionState\nfrom pathlib import Path\n\nstate = SessionState(...)\nspec_content = Path(\"workflow.yaml\").read_text()\n\nrepo.save(state, spec_content)\n# Session saved to ~/.strands/sessions/session_&lt;uuid&gt;/\n</code></pre></p>"},{"location":"reference/session-api/#load","title":"load()","text":"<pre><code>def load(self, session_id: str) -&gt; SessionState | None:\n    \"\"\"Load session state from disk.\n\n    Args:\n        session_id: Session ID to load\n\n    Returns:\n        SessionState if found, None otherwise\n\n    Logs:\n        \"session_loaded\" event if successful\n        \"session_not_found\" warning if missing\n    \"\"\"\n</code></pre> <p>Example: <pre><code>state = repo.load(\"abc123-def456-...\")\nif state:\n    print(f\"Loaded session: {state.metadata.workflow_name}\")\nelse:\n    print(\"Session not found\")\n</code></pre></p>"},{"location":"reference/session-api/#delete","title":"delete()","text":"<pre><code>def delete(self, session_id: str) -&gt; None:\n    \"\"\"Delete session completely.\n\n    Args:\n        session_id: Session ID to delete\n\n    Side Effects:\n        Removes entire session directory (session.json, agents/, etc.)\n        Logs \"session_deleted\" event\n        No-op if session doesn't exist\n    \"\"\"\n</code></pre> <p>Example: <pre><code>repo.delete(\"abc123-def456-...\")\n# Session directory removed\n</code></pre></p>"},{"location":"reference/session-api/#list_sessions","title":"list_sessions()","text":"<pre><code>def list_sessions(self) -&gt; list[SessionMetadata]:\n    \"\"\"List all sessions in storage.\n\n    Returns:\n        List of session metadata objects (one per session)\n\n    Note:\n        Only returns sessions with valid session.json files\n        Corrupt sessions are skipped silently\n    \"\"\"\n</code></pre> <p>Example: <pre><code>sessions = repo.list_sessions()\nfor session in sessions:\n    print(f\"{session.session_id}: {session.workflow_name} ({session.status})\")\n</code></pre></p>"},{"location":"reference/session-api/#get_agents_dir","title":"get_agents_dir()","text":"<pre><code>def get_agents_dir(self, session_id: str) -&gt; Path:\n    \"\"\"Get agents directory for Strands SDK FileSessionManager.\n\n    Args:\n        session_id: Session ID\n\n    Returns:\n        Path to agents directory (may not exist yet)\n\n    Usage:\n        Used by AgentCache to configure Strands SDK session manager\n    \"\"\"\n</code></pre> <p>Example: <pre><code>from strands.session.file_session_manager import FileSessionManager\n\nagents_dir = repo.get_agents_dir(\"abc123\")\nsession_manager = FileSessionManager(\n    session_id=\"abc123_researcher\",\n    storage_dir=str(agents_dir)\n)\n</code></pre></p>"},{"location":"reference/session-api/#utility-functions","title":"Utility Functions","text":""},{"location":"reference/session-api/#generate_session_id","title":"generate_session_id()","text":"<p>Generate unique session identifier.</p> <p>Location: <code>src/strands_cli/session/utils.py</code></p> <pre><code>def generate_session_id() -&gt; str:\n    \"\"\"Generate unique session ID.\n\n    Returns:\n        UUID4 string (e.g., \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\")\n    \"\"\"\n</code></pre> <p>Example: <pre><code>from strands_cli.session.utils import generate_session_id\n\nsession_id = generate_session_id()\nprint(session_id)  # \"f47ac10b-58cc-4372-a567-0e02b2c3d479\"\n</code></pre></p>"},{"location":"reference/session-api/#compute_spec_hash","title":"compute_spec_hash()","text":"<p>Compute SHA256 hash of workflow spec file.</p> <p>Location: <code>src/strands_cli/session/utils.py</code></p> <pre><code>def compute_spec_hash(spec_path: Path) -&gt; str:\n    \"\"\"Compute SHA256 hash of workflow spec.\n\n    Args:\n        spec_path: Path to workflow spec file\n\n    Returns:\n        Hex-encoded SHA256 hash (64 characters)\n\n    Use Case:\n        Detect spec file changes between session creation and resume\n    \"\"\"\n</code></pre> <p>Example: <pre><code>from strands_cli.session.utils import compute_spec_hash\nfrom pathlib import Path\n\nspec_hash = compute_spec_hash(Path(\"workflow.yaml\"))\nprint(spec_hash)  # \"abc123def456...\"\n\n# Later, check if spec changed\ncurrent_hash = compute_spec_hash(Path(\"workflow.yaml\"))\nif current_hash != spec_hash:\n    print(\"Spec file has changed!\")\n</code></pre></p>"},{"location":"reference/session-api/#now_iso8601","title":"now_iso8601()","text":"<p>Get current timestamp in ISO 8601 format.</p> <p>Location: <code>src/strands_cli/session/utils.py</code></p> <pre><code>def now_iso8601() -&gt; str:\n    \"\"\"Get current timestamp in ISO 8601 format.\n\n    Returns:\n        ISO 8601 timestamp string (UTC timezone)\n        Example: \"2025-11-09T10:15:30.123456+00:00\"\n    \"\"\"\n</code></pre> <p>Example: <pre><code>from strands_cli.session.utils import now_iso8601\n\ntimestamp = now_iso8601()\nprint(timestamp)  # \"2025-11-09T14:30:45.678901+00:00\"\n\n# Use in session metadata\nmetadata = SessionMetadata(\n    created_at=now_iso8601(),\n    updated_at=now_iso8601(),\n    # ...\n)\n</code></pre></p>"},{"location":"reference/session-api/#integration-patterns","title":"Integration Patterns","text":""},{"location":"reference/session-api/#creating-a-new-session","title":"Creating a New Session","text":"<pre><code>from strands_cli.session import SessionState, SessionMetadata, SessionStatus, TokenUsage\nfrom strands_cli.session.file_repository import FileSessionRepository\nfrom strands_cli.session.utils import generate_session_id, compute_spec_hash, now_iso8601\nfrom pathlib import Path\n\n# 1. Generate session ID\nsession_id = generate_session_id()\n\n# 2. Compute spec hash\nspec_path = Path(\"workflow.yaml\")\nspec_hash = compute_spec_hash(spec_path)\n\n# 3. Create session state\nstate = SessionState(\n    metadata=SessionMetadata(\n        session_id=session_id,\n        workflow_name=\"my-workflow\",\n        spec_hash=spec_hash,\n        pattern_type=\"chain\",\n        status=SessionStatus.RUNNING,\n        created_at=now_iso8601(),\n        updated_at=now_iso8601()\n    ),\n    variables={\"topic\": \"AI\"},\n    runtime_config={\"provider\": \"ollama\", \"model_id\": \"llama2\"},\n    pattern_state={\"current_step\": 0, \"step_history\": []},\n    token_usage=TokenUsage()\n)\n\n# 4. Save to repository\nrepo = FileSessionRepository()\nspec_content = spec_path.read_text()\nrepo.save(state, spec_content)\n\nprint(f\"Session created: {session_id}\")\n</code></pre>"},{"location":"reference/session-api/#checkpointing-during-execution","title":"Checkpointing During Execution","text":"<pre><code># Inside executor (e.g., run_chain)\nif session_repo and session_state:\n    # Update pattern state\n    session_state.pattern_state[\"current_step\"] = step_index + 1\n    session_state.pattern_state[\"step_history\"].append(step_result)\n\n    # Update token usage\n    session_state.token_usage.total_input_tokens += input_tokens\n    session_state.token_usage.total_output_tokens += output_tokens\n    session_state.token_usage.by_agent[agent_id] = (\n        session_state.token_usage.by_agent.get(agent_id, 0) + total_tokens\n    )\n\n    # Update metadata\n    session_state.metadata.updated_at = now_iso8601()\n\n    # Save checkpoint\n    spec_content = (\n        session_repo._session_dir(session_state.metadata.session_id) \n        / \"spec_snapshot.yaml\"\n    ).read_text()\n    session_repo.save(session_state, spec_content)\n\n    logger.debug(\"checkpoint_saved\", step=step_index+1)\n</code></pre>"},{"location":"reference/session-api/#loading-and-resuming","title":"Loading and Resuming","text":"<pre><code>from strands_cli.session.file_repository import FileSessionRepository\nfrom strands_cli.session import SessionStatus\nfrom strands_cli.loader import load_spec\n\n# 1. Load session\nrepo = FileSessionRepository()\nstate = repo.load(\"abc123-def456-...\")\n\nif not state:\n    raise ValueError(\"Session not found\")\n\nif state.metadata.status == SessionStatus.COMPLETED:\n    raise ValueError(\"Session already completed\")\n\n# 2. Load spec from snapshot\nspec_path = repo._session_dir(state.metadata.session_id) / \"spec_snapshot.yaml\"\nspec = load_spec(spec_path, state.variables)\n\n# 3. Validate spec hash\nfrom strands_cli.session.utils import compute_spec_hash\ncurrent_hash = compute_spec_hash(spec_path)\nif current_hash != state.metadata.spec_hash:\n    logger.warning(\"spec_changed\", original=state.metadata.spec_hash, current=current_hash)\n\n# 4. Resume execution\nresult = await run_chain(spec, state.variables, session_state=state, session_repo=repo)\n</code></pre>"},{"location":"reference/session-api/#session-directory-layout","title":"Session Directory Layout","text":"<pre><code>~/.strands/sessions/session_a1b2c3d4-e5f6-7890-abcd-ef1234567890/\n\u251c\u2500\u2500 session.json              # SessionMetadata + variables + runtime + token_usage + artifacts\n\u251c\u2500\u2500 pattern_state.json        # Pattern-specific state (current_step, step_history, etc.)\n\u251c\u2500\u2500 spec_snapshot.yaml        # Original workflow spec for hash validation\n\u2514\u2500\u2500 agents/                   # Strands SDK agent sessions\n    \u251c\u2500\u2500 researcher/\n    \u2502   \u251c\u2500\u2500 agent.json        # Agent state (key-value store)\n    \u2502   \u2514\u2500\u2500 messages/\n    \u2502       \u251c\u2500\u2500 message_0.json\n    \u2502       \u2514\u2500\u2500 message_1.json\n    \u2514\u2500\u2500 analyst/\n        \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"reference/session-api/#sessionjson-format","title":"session.json Format","text":"<pre><code>{\n  \"metadata\": {\n    \"session_id\": \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\",\n    \"workflow_name\": \"research-chain\",\n    \"spec_hash\": \"abc123def456...\",\n    \"pattern_type\": \"chain\",\n    \"status\": \"running\",\n    \"created_at\": \"2025-11-09T10:00:00Z\",\n    \"updated_at\": \"2025-11-09T10:15:00Z\",\n    \"error\": null\n  },\n  \"variables\": {\n    \"topic\": \"AI agents\",\n    \"format\": \"markdown\"\n  },\n  \"runtime_config\": {\n    \"provider\": \"ollama\",\n    \"model_id\": \"llama2\",\n    \"host\": \"http://localhost:11434\"\n  },\n  \"token_usage\": {\n    \"total_input_tokens\": 3000,\n    \"total_output_tokens\": 2000,\n    \"by_agent\": {\n      \"researcher\": 2000,\n      \"analyst\": 3000\n    }\n  },\n  \"artifacts_written\": [\n    \"./output/step1.md\",\n    \"./output/step2.json\"\n  ]\n}\n</code></pre>"},{"location":"reference/session-api/#pattern_statejson-format-chain","title":"pattern_state.json Format (Chain)","text":"<pre><code>{\n  \"current_step\": 2,\n  \"step_history\": [\n    {\n      \"index\": 0,\n      \"agent\": \"researcher\",\n      \"response\": \"Research findings about AI agents...\",\n      \"tokens_estimated\": 2000\n    },\n    {\n      \"index\": 1,\n      \"agent\": \"analyst\",\n      \"response\": \"Analysis of research findings...\",\n      \"tokens_estimated\": 3000\n    }\n  ]\n}\n</code></pre>"},{"location":"reference/session-api/#testing-patterns","title":"Testing Patterns","text":""},{"location":"reference/session-api/#unit-test-example","title":"Unit Test Example","text":"<pre><code>import pytest\nfrom pathlib import Path\nfrom strands_cli.session import SessionState, SessionMetadata, SessionStatus, TokenUsage\nfrom strands_cli.session.file_repository import FileSessionRepository\nfrom strands_cli.session.utils import generate_session_id\n\ndef test_save_and_load_session(tmp_path):\n    \"\"\"Test saving and loading a session.\"\"\"\n    repo = FileSessionRepository(storage_dir=tmp_path)\n    session_id = generate_session_id()\n\n    # Create session state\n    state = SessionState(\n        metadata=SessionMetadata(\n            session_id=session_id,\n            workflow_name=\"test-workflow\",\n            spec_hash=\"abc123\",\n            pattern_type=\"chain\",\n            status=SessionStatus.RUNNING,\n            created_at=\"2025-11-09T10:00:00Z\",\n            updated_at=\"2025-11-09T10:00:00Z\"\n        ),\n        variables={\"topic\": \"AI\"},\n        runtime_config={\"provider\": \"ollama\"},\n        pattern_state={\"current_step\": 1, \"step_history\": []},\n        token_usage=TokenUsage(total_input_tokens=100, total_output_tokens=50)\n    )\n\n    # Save\n    repo.save(state, \"version: 0\\nname: test\")\n\n    # Load\n    loaded = repo.load(session_id)\n    assert loaded is not None\n    assert loaded.metadata.session_id == session_id\n    assert loaded.variables[\"topic\"] == \"AI\"\n    assert loaded.pattern_state[\"current_step\"] == 1\n</code></pre>"},{"location":"reference/session-api/#architecture-overview","title":"Architecture Overview","text":""},{"location":"reference/session-api/#design-principles","title":"Design Principles","text":"<p>The session management system is built on these core principles:</p> <ol> <li>Leverage Strands SDK: Use native <code>FileSessionManager</code> for agent conversation persistence</li> <li>File-based Storage: Local filesystem storage for MVP (cloud storage in future phases)</li> <li>Checkpoint After Completion: Save state after each step/task/branch/node finishes</li> <li>Idempotent Resume: Safe to resume multiple times without side effects</li> <li>Pattern-Specific State: Each pattern defines its own execution state structure</li> </ol>"},{"location":"reference/session-api/#checkpoint-timing","title":"Checkpoint Timing","text":"<p>Checkpoints are saved automatically at these milestones:</p> Pattern Checkpoint Trigger Chain After each step completes Workflow After each task completes Parallel After each branch completes Routing After router decision and selected agent execution Evaluator-Optimizer After each iteration Orchestrator-Workers After each round and reduce step Graph After each node transition"},{"location":"reference/session-api/#agent-conversation-restoration","title":"Agent Conversation Restoration","text":"<p>Agent conversation history is managed by the Strands SDK <code>FileSessionManager</code>:</p> <ul> <li>Each agent has a unique session ID: <code>{session_id}_{agent_id}</code></li> <li>Messages stored in <code>agents/{agent_id}/messages/message_*.json</code></li> <li>Agent state (key-value store) in <code>agents/{agent_id}/agent.json</code></li> <li>Automatic restoration on resume via <code>AgentCache.get_or_build_agent()</code></li> </ul>"},{"location":"reference/session-api/#implementation-modules","title":"Implementation Modules","text":"<ul> <li><code>session/__init__.py</code>: Core data models (SessionState, SessionMetadata, TokenUsage)</li> <li><code>session/file_repository.py</code>: File-based persistence (save, load, list, delete)</li> <li><code>session/utils.py</code>: Utilities (session ID generation, spec hashing, timestamps)</li> <li><code>exec/chain.py</code>: Chain pattern checkpointing reference implementation</li> <li><code>exec/utils.py</code>: AgentCache with session restoration support</li> </ul>"},{"location":"reference/session-api/#related-documentation","title":"Related Documentation","text":"<ul> <li>Session Management Guide - User-facing session management</li> <li>Workflow Manual - Workflow spec reference</li> </ul>"},{"location":"reference/spec/","title":"Workflow Specification Reference","text":"<p>Comprehensive reference for the Strands workflow specification format.</p> <p>Complete Specification</p> <p>For the full, detailed specification including all patterns and examples, see the Workflow Manual.</p>"},{"location":"reference/spec/#quick-reference","title":"Quick Reference","text":""},{"location":"reference/spec/#minimal-valid-spec","title":"Minimal Valid Spec","text":"<pre><code>version: 0\nname: \"my-workflow\"\nruntime:\n  provider: ollama\n  model_id: \"llama3.2:3b\"\n  host: \"http://localhost:11434\"\n\nagents:\n  assistant:\n    prompt: \"You are a helpful assistant.\"\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent: assistant\n        input: \"Hello, world!\"\n</code></pre>"},{"location":"reference/spec/#top-level-structure","title":"Top-Level Structure","text":"Field Required Type Description <code>version</code> \u2705 integer/string Spec version (use <code>0</code>) <code>name</code> \u2705 string Workflow name <code>description</code> \u274c string Human-friendly description <code>tags</code> \u274c array[string] Classification tags <code>runtime</code> \u2705 object Default model/provider/limits <code>inputs</code> \u274c object Parameter definitions <code>env</code> \u274c object Secrets and mounts <code>telemetry</code> \u274c object OTEL configuration <code>context_policy</code> \u274c object Compaction, notes, retrieval <code>skills</code> \u274c array Skill bundles <code>tools</code> \u274c object Python/MCP/HTTP tools <code>agents</code> \u2705 object Agent definitions (min 1) <code>pattern</code> \u2705 object Workflow pattern <code>outputs</code> \u274c object Artifact definitions <code>security</code> \u274c object Guardrails"},{"location":"reference/spec/#runtime-configuration","title":"Runtime Configuration","text":"<p>Provider-specific requirements and common settings.</p>"},{"location":"reference/spec/#bedrock","title":"Bedrock","text":"<pre><code>runtime:\n  provider: bedrock\n  model_id: \"us.anthropic.claude-3-sonnet-20240229-v1:0\"\n  region: \"us-east-1\"  # Required\n  temperature: 0.7\n  max_tokens: 2000\n</code></pre> <p>Requirements: - AWS credentials configured - <code>region</code> field required - Model access enabled in Bedrock console</p>"},{"location":"reference/spec/#openai","title":"OpenAI","text":"<pre><code>runtime:\n  provider: openai\n  model_id: \"gpt-4o-mini\"\n  temperature: 0.7\n  max_tokens: 2000\n</code></pre> <p>Requirements: - <code>OPENAI_API_KEY</code> environment variable - Optional: <code>host</code> for OpenAI-compatible servers</p>"},{"location":"reference/spec/#ollama","title":"Ollama","text":"<pre><code>runtime:\n  provider: ollama\n  model_id: \"llama3.2:3b\"\n  host: \"http://localhost:11434\"  # Required\n  temperature: 0.7\n  max_tokens: 2000\n</code></pre> <p>Requirements: - Ollama server running - Model pulled: <code>ollama pull llama3.2:3b</code></p>"},{"location":"reference/spec/#common-fields","title":"Common Fields","text":"Field Type Default Description <code>provider</code> string - <code>bedrock</code>, <code>openai</code>, <code>ollama</code> <code>model_id</code> string provider-specific Model identifier <code>region</code> string - AWS region (Bedrock only) <code>host</code> string - Server URL (Ollama/OpenAI) <code>temperature</code> float (0.0-2.0) 0.7 Sampling temperature <code>max_tokens</code> integer (\u22651) 2000 Max output tokens <code>top_p</code> float (0.0-1.0) 0.95 Nucleus sampling <code>max_parallel</code> integer (\u22651) 4 Concurrent task limit"},{"location":"reference/spec/#budgets","title":"Budgets","text":"<pre><code>runtime:\n  budgets:\n    max_steps: 200        # Maximum workflow steps\n    max_tokens: 800000    # Token limit (cumulative)\n    max_duration_s: 900   # Time limit (seconds)\n</code></pre>"},{"location":"reference/spec/#failure-policy","title":"Failure Policy","text":"<pre><code>runtime:\n  failure_policy:\n    retries: 2                # Retry count (0-10)\n    backoff: exponential      # constant | exponential | jittered\n</code></pre>"},{"location":"reference/spec/#agents","title":"Agents","text":"<p>Agent definitions with prompts, tools, and overrides.</p> <pre><code>agents:\n  researcher:\n    prompt: |\n      You are a research specialist.\n      Cite sources with links.\n    tools: [\"http_request\"]\n    model_id: \"gpt-4o\"  # Override runtime model\n    inference:\n      temperature: 0.2\n      max_tokens: 4000\n\n  writer:\n    prompt: \"Write concise reports for {{audience}}.\"\n</code></pre> Field Required Type Description <code>prompt</code> \u2705 string System prompt (supports <code>{{vars}}</code>) <code>tools</code> \u274c array[string] Tool references <code>provider</code> \u274c string Override runtime provider <code>model_id</code> \u274c string Override runtime model <code>inference</code> \u274c object Override temperature/tokens/top_p"},{"location":"reference/spec/#patterns","title":"Patterns","text":""},{"location":"reference/spec/#chain","title":"Chain","text":"<p>Sequential steps with single agent.</p> <pre><code>pattern:\n  type: chain\n  config:\n    steps:\n      - agent: researcher\n        input: \"Find sources on {{topic}}\"\n      - agent: writer\n        input: \"Write a summary\"\n</code></pre> <p>See: Chain Pattern Guide</p>"},{"location":"reference/spec/#workflow-dag","title":"Workflow (DAG)","text":"<p>Multi-task execution with dependencies.</p> <pre><code>pattern:\n  type: workflow\n  config:\n    tasks:\n      - id: extract\n        agent: researcher\n        description: \"Fetch sources\"\n      - id: analyze\n        agent: researcher\n        deps: [extract]\n        description: \"Analyze trends\"\n      - id: report\n        agent: writer\n        deps: [analyze]\n        description: \"Write report\"\n</code></pre> <p>See: Workflow Pattern Guide</p>"},{"location":"reference/spec/#routing","title":"Routing","text":"<p>Dynamic agent selection based on classifier.</p> <pre><code>pattern:\n  type: routing\n  config:\n    router:\n      agent: classifier\n      input: \"Classify request\"\n    routes:\n      faq:\n        then:\n          - agent: writer\n            input: \"Answer briefly\"\n      research:\n        then:\n          - agent: researcher\n            input: \"Deep dive\"\n</code></pre> <p>See: Routing Pattern Guide</p>"},{"location":"reference/spec/#parallel","title":"Parallel","text":"<p>Concurrent branches with optional reduce.</p> <pre><code>pattern:\n  type: parallel\n  config:\n    branches:\n      - id: web\n        steps:\n          - agent: researcher\n            input: \"Search web\"\n      - id: docs\n        steps:\n          - agent: researcher\n            input: \"Search docs\"\n    reduce:\n      agent: writer\n      input: \"Merge findings\"\n</code></pre> <p>See: Parallel Pattern Guide</p>"},{"location":"reference/spec/#evaluator-optimizer","title":"Evaluator-Optimizer","text":"<p>Iterative refinement loop.</p> <pre><code>pattern:\n  type: evaluator_optimizer\n  config:\n    producer: writer\n    evaluator:\n      agent: critic\n      input: \"Score 0-100 and provide feedback\"\n    accept:\n      min_score: 85\n      max_iters: 3\n    revise_prompt: \"Improve based on feedback\"\n</code></pre> <p>See: Evaluator-Optimizer Pattern Guide</p>"},{"location":"reference/spec/#orchestrator-workers","title":"Orchestrator-Workers","text":"<p>Orchestrator decomposes tasks, workers execute.</p> <pre><code>pattern:\n  type: orchestrator_workers\n  config:\n    orchestrator:\n      agent: planner\n      limits:\n        max_workers: 6\n        max_rounds: 3\n    worker_template:\n      agent: researcher\n      tools: [\"http_request\"]\n    reduce:\n      agent: writer\n      input: \"Synthesize results\"\n</code></pre> <p>See: Orchestrator-Workers Pattern Guide</p>"},{"location":"reference/spec/#graph","title":"Graph","text":"<p>State machine with conditional transitions.</p> <pre><code>pattern:\n  type: graph\n  config:\n    max_iterations: 5\n    nodes:\n      intake:\n        agent: classifier\n      handle_tech:\n        agent: tech_support\n      escalate:\n        agent: manager\n    edges:\n      - from: intake\n        choose:\n          - when: \"{{ 'technical' in nodes.intake.response }}\"\n            to: handle_tech\n          - when: else\n            to: escalate\n      - from: handle_tech\n        to: [escalate]\n</code></pre> <p>See: Graph Pattern Guide</p>"},{"location":"reference/spec/#inputs-and-variables","title":"Inputs and Variables","text":""},{"location":"reference/spec/#required-inputs","title":"Required Inputs","text":"<pre><code>inputs:\n  required:\n    topic: string\n    audience: string\n</code></pre>"},{"location":"reference/spec/#optional-inputs-with-defaults","title":"Optional Inputs with Defaults","text":"<pre><code>inputs:\n  optional:\n    priority:\n      type: string\n      description: \"Priority level\"\n      default: \"medium\"\n      enum: [\"low\", \"medium\", \"high\"]\n</code></pre>"},{"location":"reference/spec/#variable-interpolation","title":"Variable Interpolation","text":"<p>Use <code>{{variable}}</code> in any string field:</p> <pre><code>agents:\n  writer:\n    prompt: \"Write for {{audience}} about {{topic}}\"\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent: writer\n        input: \"Priority: {{priority}}\"\n\noutputs:\n  artifacts:\n    - path: \"{{topic}}_report.md\"\n      from: \"{{ last_response }}\"\n</code></pre>"},{"location":"reference/spec/#cli-variable-overrides","title":"CLI Variable Overrides","text":"<pre><code>strands run spec.yaml --var topic=\"AI Ethics\" --var audience=\"executives\"\n</code></pre>"},{"location":"reference/spec/#tools","title":"Tools","text":""},{"location":"reference/spec/#python-callables","title":"Python Callables","text":"<pre><code>tools:\n  python:\n    - \"strands_tools.http_request\"\n    - \"strands_tools.file_read\"\n    - \"./local_tools/custom.py:my_function\"\n</code></pre> <p>Allowlist (v0.11): - <code>strands_tools.http_request</code> - <code>strands_tools.file_read</code> - <code>strands_tools.file_write</code> (requires consent) - <code>strands_tools.calculator</code> - <code>strands_tools.current_time</code></p>"},{"location":"reference/spec/#mcp-servers","title":"MCP Servers","text":"<pre><code>tools:\n  mcp:\n    - id: \"filesystem\"\n      command: \"npx\"\n      args: [\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/path/to/allowed\"]\n</code></pre>"},{"location":"reference/spec/#http-executors","title":"HTTP Executors","text":"<pre><code>tools:\n  http_executors:\n    - id: \"github\"\n      base_url: \"https://api.github.com\"\n      headers:\n        Authorization: \"Bearer ${GITHUB_TOKEN}\"\n      timeout: 30\n</code></pre> <p>Security: See Security Reference for SSRF protection.</p>"},{"location":"reference/spec/#outputs","title":"Outputs","text":""},{"location":"reference/spec/#artifacts","title":"Artifacts","text":"<pre><code>outputs:\n  artifacts:\n    - path: \"./reports/{{name}}.md\"\n      from: \"{{ last_response }}\"\n    - path: \"./trace.json\"\n      from: \"$TRACE\"\n</code></pre> <p>Template Variables: - <code>{{ last_response }}</code> - Final pattern output - <code>{{ steps[0].response }}</code> - Chain step response - <code>{{ tasks.task_id.response }}</code> - Workflow task response - <code>{{ branches.branch_id.response }}</code> - Parallel branch response - <code>{{ nodes.node_id.response }}</code> - Graph node response - <code>$TRACE</code> - OTEL trace export</p>"},{"location":"reference/spec/#context-policy","title":"Context Policy","text":""},{"location":"reference/spec/#compaction","title":"Compaction","text":"<pre><code>context_policy:\n  compaction:\n    enabled: true\n    when_tokens_over: 150000\n</code></pre>"},{"location":"reference/spec/#notes","title":"Notes","text":"<pre><code>context_policy:\n  notes:\n    file: \"./artifacts/NOTES.md\"\n    include_last: 10\n</code></pre>"},{"location":"reference/spec/#jit-retrieval","title":"JIT Retrieval","text":"<pre><code>context_policy:\n  retrieval:\n    jit_tools: [\"grep\", \"head\", \"tail\", \"search\"]\n</code></pre> <p>See: Context Management Guide</p>"},{"location":"reference/spec/#telemetry","title":"Telemetry","text":"<pre><code>telemetry:\n  otel:\n    endpoint: \"http://localhost:4318/v1/traces\"\n    service_name: \"my-workflow\"\n    sample_ratio: 1.0\n  redact:\n    tool_inputs: true\n    tool_outputs: false\n</code></pre> <p>See: Telemetry Guide</p>"},{"location":"reference/spec/#security","title":"Security","text":"<pre><code>security:\n  guardrails:\n    deny_network: false\n    pii_redaction: true\n    allow_tools: [\"http_request\"]\n</code></pre> <p>See: Security Model | Security Reference</p>"},{"location":"reference/spec/#further-reading","title":"Further Reading","text":"<ul> <li>Complete Specification: Workflow Manual</li> <li>JSON Schema: <code>src/strands_cli/schema/strands-workflow.schema.json</code></li> <li>How-To Guides: Pattern Guides, Tools</li> <li>Examples: Example Catalog</li> </ul>"},{"location":"reference/troubleshooting/","title":"Troubleshooting Guide","text":"<p>Common issues and solutions for strands-cli users.</p>"},{"location":"reference/troubleshooting/#quick-diagnostics","title":"Quick Diagnostics","text":"<p>Always start with the health check:</p> <pre><code>uv run strands doctor\n</code></pre> <p>This will identify most common issues with your installation.</p>"},{"location":"reference/troubleshooting/#installation-issues","title":"Installation Issues","text":""},{"location":"reference/troubleshooting/#python-version-too-old","title":"Python Version Too Old","text":"<p>Symptom: Error message stating <code>Python &gt;= 3.12 required</code></p> <p>Solution: 1. Check your Python version: <code>python --version</code> 2. Install Python 3.12 or newer from python.org 3. Verify with: <code>python3.12 --version</code> 4. Reinstall strands-cli using the new Python version</p>"},{"location":"reference/troubleshooting/#missing-dependencies","title":"Missing Dependencies","text":"<p>Symptom: <code>ModuleNotFoundError</code> or <code>ImportError</code> when running commands</p> <p>Solution: <pre><code># Reinstall all dependencies\nuv sync --dev\n\n# Verify installation\nuv run strands doctor\n</code></pre></p>"},{"location":"reference/troubleshooting/#schema-file-not-found","title":"Schema File Not Found","text":"<p>Symptom: Error about missing <code>strands-workflow.schema.json</code></p> <p>Solution: <pre><code># Ensure you're in the strands-cli directory\ncd strands-cli\n\n# Verify schema file exists\nls src/strands_cli/schema/strands-workflow.schema.json\n\n# If missing, re-clone the repository\ngit pull origin main\n</code></pre></p>"},{"location":"reference/troubleshooting/#ollama-issues","title":"Ollama Issues","text":""},{"location":"reference/troubleshooting/#ollama-server-not-running","title":"Ollama Server Not Running","text":"<p>Symptom:  - <code>strands doctor</code> shows Ollama not reachable - Error: <code>Connection refused</code> when running workflows</p> <p>Solution: <pre><code># Start Ollama server\nollama serve\n\n# In another terminal, verify it's running\ncurl http://localhost:11434/api/tags\n</code></pre></p> <p>Alternative: Ollama may be running on a different port or host. Check your <code>runtime.host</code> in the spec: <pre><code>runtime:\n  provider: ollama\n  host: \"http://localhost:11434\"  # Verify this matches your setup\n</code></pre></p>"},{"location":"reference/troubleshooting/#ollama-model-not-found","title":"Ollama Model Not Found","text":"<p>Symptom: Error: <code>model 'gpt-oss' not found</code></p> <p>Solution: <pre><code># List available models\nollama list\n\n# Pull the required model\nollama pull gpt-oss\n\n# Or use a different model in your spec\n# Update runtime.model_id to match an installed model\n</code></pre></p>"},{"location":"reference/troubleshooting/#ollama-not-installed","title":"Ollama Not Installed","text":"<p>Symptom: <code>ollama: command not found</code></p> <p>Solution: 1. Install Ollama from https://ollama.ai 2. Follow platform-specific instructions:    - macOS: <code>brew install ollama</code>    - Linux: <code>curl https://ollama.ai/install.sh | sh</code>    - Windows: Download installer from ollama.ai 3. Verify: <code>ollama --version</code> 4. Start server: <code>ollama serve</code></p>"},{"location":"reference/troubleshooting/#aws-bedrock-issues","title":"AWS Bedrock Issues","text":""},{"location":"reference/troubleshooting/#aws-credentials-not-configured","title":"AWS Credentials Not Configured","text":"<p>Symptom:  - Error: <code>NoCredentialsError</code> or <code>Unable to locate credentials</code> - Workflow fails immediately with authentication error</p> <p>Solution: <pre><code># Option 1: Configure via AWS CLI\naws configure\n# Enter your: Access Key ID, Secret Access Key, Region, Output format\n\n# Option 2: Set environment variables\nexport AWS_ACCESS_KEY_ID=\"your-access-key\"\nexport AWS_SECRET_ACCESS_KEY=\"your-secret-key\"\nexport AWS_REGION=\"us-east-1\"\n\n# Option 3: Use named profile\nexport AWS_PROFILE=\"your-profile-name\"\n\n# Verify credentials\naws sts get-caller-identity\n</code></pre></p>"},{"location":"reference/troubleshooting/#bedrock-model-access-denied","title":"Bedrock Model Access Denied","text":"<p>Symptom: Error: <code>AccessDeniedException</code> or <code>You don't have access to the model</code></p> <p>Solution: 1. Log into AWS Console \u2192 Bedrock \u2192 Model access 2. Request access to the model you want to use (e.g., Claude 3 Sonnet) 3. Wait for approval (usually instant for most models) 4. Verify in your spec that <code>runtime.model_id</code> matches an approved model</p>"},{"location":"reference/troubleshooting/#wrong-aws-region","title":"Wrong AWS Region","text":"<p>Symptom: Error: <code>Model not found in region</code></p> <p>Solution: <pre><code># Update your spec or set environment variable\nruntime:\n  provider: bedrock\n  region: \"us-east-1\"  # Ensure Bedrock is available in this region\n</code></pre></p> <p>Or: <pre><code>export STRANDS_AWS_REGION=\"us-east-1\"\n</code></pre></p> <p>Note: Bedrock availability varies by region. Use <code>us-east-1</code> or <code>us-west-2</code> for broadest model access.</p>"},{"location":"reference/troubleshooting/#schema-validation-errors","title":"Schema Validation Errors","text":""},{"location":"reference/troubleshooting/#invalid-yaml-syntax","title":"Invalid YAML Syntax","text":"<p>Symptom:  - <code>Failed to parse spec.yaml</code> - Error points to specific line number</p> <p>Solution: 1. Validate YAML syntax: yamllint.com 2. Common issues:    - Incorrect indentation (use spaces, not tabs)    - Missing colons after keys    - Unquoted special characters 3. Example fix: <pre><code># \u274c Wrong (tab indentation, no colon)\nruntime\n    provider bedrock\n\n# \u2705 Correct\nruntime:\n  provider: bedrock\n</code></pre></p>"},{"location":"reference/troubleshooting/#schema-validation-failed","title":"Schema Validation Failed","text":"<p>Symptom: Error with JSONPointer like <code>/runtime/provider: must be one of [bedrock, ollama]</code></p> <p>Solution: 1. Run validation: <code>uv run strands validate spec.yaml --verbose</code> 2. Error message includes exact location (JSONPointer) and expected format 3. Check schema reference: <code>src/strands_cli/schema/strands-workflow.schema.json</code> 4. Common fixes:    - Enum values must be exact: <code>bedrock</code> not <code>Bedrock</code>    - Required fields must be present: <code>name</code>, <code>version</code>, <code>agents</code>, <code>runtime</code>, <code>pattern</code>    - Field types must match: <code>version</code> is an integer, not string</p>"},{"location":"reference/troubleshooting/#missing-required-fields","title":"Missing Required Fields","text":"<p>Symptom: <code>Missing required property: 'agents'</code></p> <p>Solution: <pre><code># Minimum valid spec requires:\nname: my-workflow\nversion: 1\nagents:\n  analyst:  # At least one agent required\n    prompt: \"You are a helpful analyst.\"\nruntime:\n  provider: ollama  # or bedrock\n  host: \"http://localhost:11434\"  # for ollama\npattern:\n  type: chain  # or workflow\n  config:\n    steps:  # for chain\n      - id: step1\n        agent_id: analyst\n        input: \"Analyze this.\"\n</code></pre></p>"},{"location":"reference/troubleshooting/#unsupported-features-exit-code-18","title":"Unsupported Features (Exit Code 18)","text":""},{"location":"reference/troubleshooting/#multiple-agents","title":"Multiple Agents","text":"<p>Symptom: <code>Unsupported feature: multiple agents detected</code></p> <p>Solution: MVP only supports single-agent workflows. Reduce to one agent: <pre><code># \u274c Not supported in MVP\nagents:\n  analyst: ...\n  critic: ...\n\n# \u2705 Supported\nagents:\n  analyst: ...\n</code></pre></p>"},{"location":"reference/troubleshooting/#multi-step-workflows","title":"Multi-Step Workflows","text":"<p>Symptom: <code>Unsupported: chain with &gt;1 steps</code></p> <p>Solution: <pre><code># \u274c Not supported in MVP\npattern:\n  type: chain\n  config:\n    steps:\n      - id: step1\n        ...\n      - id: step2  # Second step not supported\n        ...\n\n# \u2705 Supported\npattern:\n  type: chain\n  config:\n    steps:\n      - id: step1\n        ...\n</code></pre></p>"},{"location":"reference/troubleshooting/#routingparallel-patterns","title":"Routing/Parallel Patterns","text":"<p>Symptom: <code>Unsupported pattern type: routing</code></p> <p>Solution: MVP only supports <code>chain</code> (1 step) or <code>workflow</code> (1 task). Use <code>chain</code>: <pre><code>pattern:\n  type: chain  # Supported\n  # type: routing  # Not supported in MVP\n</code></pre></p> <p>Get Details: <pre><code>uv run strands explain spec.yaml\n</code></pre></p> <p>This generates a detailed report of unsupported features with remediation steps.</p>"},{"location":"reference/troubleshooting/#runtime-execution-errors","title":"Runtime Execution Errors","text":""},{"location":"reference/troubleshooting/#template-rendering-failed","title":"Template Rendering Failed","text":"<p>Symptom: <code>Failed to render task input: 'topic' is undefined</code></p> <p>Solution: Ensure all template variables are provided: <pre><code># \u274c Missing variable\nuv run strands run spec.yaml\n\n# \u2705 Provide required variables\nuv run strands run spec.yaml --var topic=\"AI ethics\"\n</code></pre></p> <p>Or define defaults in spec: <pre><code>inputs:\n  values:\n    topic: \"default topic\"  # Fallback if --var not provided\n</code></pre></p>"},{"location":"reference/troubleshooting/#agent-build-failed","title":"Agent Build Failed","text":"<p>Symptom: <code>Failed to build agent: No such tool</code></p> <p>Solution: Verify tool names match allowlist: <pre><code>agents:\n  analyst:\n    tools:\n      # \u2705 Allowed\n      - python:strands_tools.http_request\n      - python:strands_tools.file_read\n      # \u274c Not allowed (security restriction)\n      - python:my_custom_tool\n</code></pre></p>"},{"location":"reference/troubleshooting/#timeout-errors","title":"Timeout Errors","text":"<p>Symptom: Workflow fails after long wait</p> <p>Solution: Increase timeout in failure policy: <pre><code>runtime:\n  failure_policy:\n    retries: 3\n    wait_max: 120  # Increase from default 60s\n</code></pre></p>"},{"location":"reference/troubleshooting/#artifact-output-issues","title":"Artifact Output Issues","text":""},{"location":"reference/troubleshooting/#file-already-exists","title":"File Already Exists","text":"<p>Symptom: <code>Artifact file exists, use --force to overwrite</code></p> <p>Solution: <pre><code># Option 1: Use --force flag\nuv run strands run spec.yaml --force\n\n# Option 2: Use different output directory\nuv run strands run spec.yaml --out ./output-$(date +%s)\n\n# Option 3: Delete existing artifacts\nrm -rf ./artifacts\n</code></pre></p>"},{"location":"reference/troubleshooting/#permission-denied","title":"Permission Denied","text":"<p>Symptom: <code>PermissionError: [Errno 13] Permission denied</code></p> <p>Solution: <pre><code># Check directory permissions\nls -la ./artifacts\n\n# Ensure write access\nchmod +w ./artifacts\n\n# Or use different output directory\nuv run strands run spec.yaml --out ~/my-artifacts\n</code></pre></p>"},{"location":"reference/troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"reference/troubleshooting/#slow-validation","title":"Slow Validation","text":"<p>Symptom: <code>strands validate</code> takes &gt;1 second</p> <p>Solution: This may indicate a very large spec file. Check: <pre><code># Check file size\nls -lh spec.yaml\n\n# Maximum allowed: 10MB\n# If larger, split into smaller specs or remove unused content\n</code></pre></p>"},{"location":"reference/troubleshooting/#slow-execution","title":"Slow Execution","text":"<p>Symptom: Workflow takes much longer than expected</p> <p>Solution: 1. Check Ollama/Bedrock latency: <code>time curl http://localhost:11434/api/tags</code> 2. Review retry configuration (excessive retries slow things down) 3. Use <code>--verbose</code> to see where time is spent 4. Consider using faster models (e.g., <code>gpt-oss</code> vs larger models)</p>"},{"location":"reference/troubleshooting/#getting-more-help","title":"Getting More Help","text":""},{"location":"reference/troubleshooting/#enable-verbose-mode","title":"Enable Verbose Mode","text":"<pre><code>uv run strands run spec.yaml --verbose\n</code></pre> <p>This shows detailed logs including: - Workflow lifecycle events - Provider requests/responses - Template rendering details - Timing information</p>"},{"location":"reference/troubleshooting/#check-exit-codes","title":"Check Exit Codes","text":"<p>Exit codes indicate failure type: - 0: Success - 3: Schema validation error - 10: Runtime error (provider, model, tool) - 12: I/O error (artifact write) - 18: Unsupported features - 70: Unknown error</p>"},{"location":"reference/troubleshooting/#run-health-check","title":"Run Health Check","text":"<pre><code>uv run strands doctor\n</code></pre>"},{"location":"reference/troubleshooting/#review-logs","title":"Review Logs","text":"<p>Structured logs are written to stdout in JSON format (when <code>STRANDS_LOG_FORMAT=json</code>): <pre><code>export STRANDS_LOG_FORMAT=console  # Human-readable\nexport STRANDS_LOG_LEVEL=DEBUG     # More detail\n\nuv run strands run spec.yaml\n</code></pre></p>"},{"location":"reference/troubleshooting/#report-issues","title":"Report Issues","text":"<p>If you encounter a bug: 1. Run with <code>--verbose</code> and capture output 2. Check GitHub Issues 3. Create new issue with:    - strands-cli version: <code>uv run strands version</code>    - Python version: <code>python --version</code>    - OS: Windows/macOS/Linux    - Minimal reproducible spec    - Full error output with <code>--verbose</code></p>"},{"location":"reference/troubleshooting/#common-error-messages-reference","title":"Common Error Messages Reference","text":"Error Message Cause Solution <code>Spec file not found</code> Wrong path or file doesn't exist Check path with <code>ls spec.yaml</code> <code>Spec file too large</code> File &gt;10MB Reduce spec size or split into multiple files <code>Invalid variable format</code> Wrong <code>--var</code> syntax Use <code>--var key=value</code> (no spaces around <code>=</code>) <code>No such tool</code> Tool not in allowlist Use allowed tools: <code>strands_tools.http_request</code>, <code>strands_tools.file_read</code> <code>Provider requires runtime.host</code> Missing Ollama host Add <code>runtime.host: \"http://localhost:11434\"</code> <code>Provider requires runtime.region</code> Missing AWS region Add <code>runtime.region: \"us-east-1\"</code> or set <code>STRANDS_AWS_REGION</code> <code>Invalid retry config</code> wait_min &gt; wait_max Fix <code>failure_policy</code>: ensure <code>wait_min &lt;= wait_max</code> <code>Unsupported pattern type</code> Using MVP-unsupported pattern Change to <code>chain</code> or <code>workflow</code>, or run <code>strands explain</code>"},{"location":"reference/troubleshooting/#additional-resources","title":"Additional Resources","text":"<ul> <li>Schema Reference: <code>src/strands_cli/schema/strands-workflow.schema.json</code></li> <li>Full Manual: <code>docs/strands-workflow-manual.md</code></li> <li>MVP Requirements: <code>docs/PRD_SingleAgent_MVP.md</code></li> <li>Examples: <code>examples/</code> directory</li> <li>GitHub Repository: https://github.com/ThomasRohde/strands-cli</li> </ul>"},{"location":"reference/workflow-manual/","title":"Strands Workflow Spec Manual (v0)","text":"<p>Date: 2025-11-03</p> <p>This manual describes a declarative workflow specification for running agentic AI workflows with the AWS Strands SDK via a CLI. The spec is provided as a JSON Schema (Draft 2020\u201112) and can be authored as YAML or JSON. It captures runtime, agents, tools, telemetry, security, and common agent patterns (chain, routing, parallel, orchestrator\u2011workers, evaluator\u2011optimizer, graph, workflow) inspired by industry guidance.</p> <p>Download the JSON Schema: <code>strands-workflow.schema.json</code> (place alongside your workflow files).</p>"},{"location":"reference/workflow-manual/#1-design-goals","title":"1) Design Goals","text":"<ul> <li>Declarative, not imperative: Keep orchestration in the spec; keep code minimal.</li> <li>Portable: Works as YAML or JSON; validated via the published JSON Schema.</li> <li>Composable: Patterns are re-usable abstractions tuned for agent work.</li> <li>Safe-by-default: Budgets, retries, and guardrails built in.</li> <li>Observable: OpenTelemetry tracing, artifact outputs, clear inputs/vars.</li> <li>AWS-first: Defaults assume Bedrock/regions, but providers are abstracted.</li> </ul>"},{"location":"reference/workflow-manual/#2-file-anatomy","title":"2) File Anatomy","text":"<p>A minimal file looks like this (YAML shown; JSON equivalent also valid):</p> <pre><code>version: 0\nname: \"research-brief\"\nruntime:\n  provider: bedrock\n  model_id: \"us.anthropic.claude-sonnet-4-20250514-v1:0\"\n  region: \"eu-central-1\"\n\nagents:\n  researcher:\n    prompt: \"Research {{topic}} and cite sources.\"\n    tools: [\"strands_tools.http_request\"]\n  writer:\n    prompt: \"Write a 600-word report for {{audience}}.\"\n\ninputs:\n  required:\n    topic: string\n  optional:\n    audience: string\n\npattern:\n  type: chain\n  config:\n    steps:\n      - agent: researcher\n        input: \"Find 6 diverse sources.\"\n      - agent: writer\n        input: \"Write the final report with citations.\"\n\noutputs:\n  artifacts:\n    - path: \"./artifacts/report.md\"\n      from: \"{{ last_response }}\"\n</code></pre> <p>Top-level keys (all defined by the schema): - <code>version</code> (int/string): spec version. Use <code>0</code>. [REQUIRED] - <code>name</code>: workflow name. [REQUIRED] - <code>description</code>: human-friendly description. [optional] - <code>tags</code>: array of tag strings. [optional] - <code>runtime</code>: default model/provider/limits for all agents. [REQUIRED] - <code>inputs</code>: parameters your CLI fills (<code>--var key=value</code>). [optional] - <code>env</code>: secrets and filesystem mounts. [optional] - <code>telemetry</code>: OTEL + redaction options. [optional] - <code>context_policy</code>: compaction, notes, and JIT retrieval hints. [optional] - <code>skills</code>: optional skill bundles (metadata + files). [optional] - <code>tools</code>: Python callables, MCP servers, HTTP executors. [optional] - <code>agents</code>: reusable agent templates. [REQUIRED, must have at least 1] - <code>pattern</code>: one of the supported orchestration patterns. [REQUIRED] - <code>outputs</code>: artifacts to write to disk. [optional] - <code>security</code>: guardrails like network controls and PII redaction. [optional]</p>"},{"location":"reference/workflow-manual/#3-cli-quick-start","title":"3) CLI Quick Start","text":"<p>Your CLI (<code>strands-cli</code>) should support:</p> <pre><code># Run with variables\nstrands-cli run flow.yaml --var topic=\"L3 credit risk\" --var audience=exec\n\n# Validate against the JSON Schema\nstrands-cli validate flow.yaml --schema strands-workflow.schema.json\n\n# Dry-run planner (renders resolved DAG/graph)\nstrands-cli plan flow.yaml\n\n# Inspect / export OTEL trace\nstrands-cli trace &lt;session-id&gt;\n\n# Resume a previous session (from artifacts/ state)\nstrands-cli resume &lt;session-id&gt;\n</code></pre> <p>Variable precedence: <code>--var</code> &gt; environment &gt; <code>inputs.optional.default</code> (if present).</p>"},{"location":"reference/workflow-manual/#4-runtime","title":"4) Runtime","text":"<pre><code>runtime:\n  provider: bedrock                 # REQUIRED: e.g., bedrock | openai | azure_openai | local\n  model_id: \"us.anthropic.claude-sonnet-4-20250514-v1:0\"  # optional (default for agents)\n  region: \"eu-central-1\"            # optional (required for bedrock)\n  host: \"http://localhost:11434\"    # optional (required for ollama, optional for openai)\n  temperature: 0.7                  # optional (0.0-2.0)\n  max_tokens: 2000                  # optional (min: 1)\n  top_p: 0.95                       # optional (0.0-1.0)\n  max_parallel: 4                   # optional (min: 1)\n  budgets:                          # optional\n    max_steps: 200                  # optional (min: 1)\n    max_tokens: 800000              # optional (min: 1)\n    max_duration_s: 900             # optional (min: 1)\n  failure_policy:                   # optional\n    retries: 2                      # optional (min: 0)\n    backoff: exponential            # optional: constant | exponential | jittered (default: exponential)\n</code></pre>"},{"location":"reference/workflow-manual/#provider-specific-requirements","title":"Provider-Specific Requirements","text":"<p>Bedrock - Requires: <code>region</code> (e.g., <code>us-east-1</code>, <code>eu-central-1</code>) - Authentication: AWS credentials via environment, <code>~/.aws/credentials</code>, or IAM role - Default model: <code>us.anthropic.claude-3-sonnet-20240229-v1:0</code> - Example model IDs: <code>us.anthropic.claude-3-sonnet-20240229-v1:0</code>, <code>anthropic.claude-3-haiku-20240307-v1:0</code></p> <p>OpenAI - Requires: <code>OPENAI_API_KEY</code> environment variable - Optional: <code>host</code> for OpenAI-compatible servers (default: OpenAI API) - Default model: <code>gpt-4o-mini</code> - Example model IDs: <code>gpt-4o</code>, <code>gpt-4o-mini</code>, <code>gpt-4-turbo</code>, <code>gpt-3.5-turbo</code> - Get API key from: https://platform.openai.com/api-keys</p> <p>Ollama - Requires: <code>host</code> (e.g., <code>http://localhost:11434</code>) - Authentication: None (local server) - Default model: <code>gpt-oss</code> - Example model IDs: <code>llama3</code>, <code>gpt-oss</code>, <code>mistral</code> - Install from: https://ollama.ai/</p> <p>Best practices - Keep a default model in <code>runtime</code> and override per-agent only when needed. - Use budgets to avoid runaway loops. - Prefer exponential backoff with small retry counts; surface failures early. - Store provider credentials securely (environment variables or AWS secrets, never in spec files)</p>"},{"location":"reference/workflow-manual/#5-inputs-and-interpolation","title":"5) Inputs and Interpolation","text":"<pre><code>inputs:\n  required:\n    topic: string                   # shorthand type name\n  optional:\n    audience:\n      type: string\n      description: \"Target reader\"\n      default: \"stakeholders\"       # default value (can be any JSON type)\n    priority:\n      type: string\n      enum: [\"low\", \"medium\", \"high\"]  # constrain to specific values\n</code></pre> <p>You can interpolate values inside strings using <code>{{var}}</code>. Defaults are specified in the <code>inputs.optional</code> section using the <code>default</code> property. The CLI performs variable substitution before execution.</p>"},{"location":"reference/workflow-manual/#6-environment-and-secrets","title":"6) Environment and Secrets","text":"<pre><code>env:\n  secrets:\n    - name: GITHUB_TOKEN\n      source: env             # env | secrets_manager | ssm | file\n  mounts:\n    workdir: \"./artifacts\"\n</code></pre> <ul> <li>Avoid embedding secrets in files; use <code>source: env</code> or AWS secrets.</li> <li>Mounts offer stable, named paths for tools and outputs.</li> </ul>"},{"location":"reference/workflow-manual/#7-telemetry-and-redaction","title":"7) Telemetry and Redaction","text":"<pre><code>telemetry:\n  otel:\n    endpoint: \"http://localhost:4317\"\n    service_name: \"strands-yaml-cli\"\n    sample_ratio: 1.0\n  redact:\n    tool_inputs: true\n    tool_outputs: false\n</code></pre> <ul> <li>Use a lower <code>sample_ratio</code> in production (e.g., <code>0.1</code>).</li> <li>Turn on redaction where required by policy.</li> </ul>"},{"location":"reference/workflow-manual/#8-context-policy-compaction-notes-retrieval","title":"8) Context Policy (Compaction, Notes, Retrieval)","text":"<pre><code>context_policy:\n  compaction:\n    enabled: true\n    when_tokens_over: 150000\n  notes:\n    file: \"./artifacts/NOTES.md\"\n    include_last: 10\n  retrieval:\n    jit_tools: [\"grep\", \"head\", \"tail\", \"search\"]\n</code></pre> <ul> <li>Compaction: trigger a summarization/compaction policy when token count passes a threshold.</li> <li>Notes: structured note-taking for continuity and memory.</li> <li>JIT Retrieval: Just-In-Time retrieval tools provide file system access during agent execution.</li> </ul>"},{"location":"reference/workflow-manual/#81-compaction","title":"8.1 Compaction","text":"<p>Compaction reduces context size when token counts exceed limits. When <code>enabled: true</code> and conversation tokens surpass <code>when_tokens_over</code>, the system triggers a summarization policy.</p>"},{"location":"reference/workflow-manual/#82-notes","title":"8.2 Notes","text":"<p>Structured note-taking helps agents maintain continuity across runs. The <code>notes</code> configuration: - <code>file</code>: Path to markdown file where notes are stored - <code>include_last</code>: Number of most recent notes to include in agent context</p>"},{"location":"reference/workflow-manual/#83-jit-retrieval-tools","title":"8.3 JIT Retrieval Tools","text":"<p>Phase 6.3 Feature: Just-In-Time (JIT) retrieval tools are automatically injected into agents when <code>context_policy.retrieval.jit_tools</code> is configured. These tools provide safe, read-only file system access without pre-loading large files into context.</p>"},{"location":"reference/workflow-manual/#configuration","title":"Configuration","text":"<pre><code>context_policy:\n  retrieval:\n    jit_tools:\n      - \"grep\"    # Pattern search with context lines\n      - \"head\"    # Read first N lines\n      - \"tail\"    # Read last N lines\n      - \"search\"  # Keyword/regex search with highlighting\n</code></pre>"},{"location":"reference/workflow-manual/#available-jit-tools","title":"Available JIT Tools","text":"<p>All JIT tools are cross-platform (Windows, macOS, Linux) and use pure Python implementations (no shell commands).</p> <p>1. grep - Pattern search with context - Purpose: Search files for regex/literal patterns with surrounding context - Parameters:   - <code>path</code> (required): Absolute file path   - <code>pattern</code> (required): Search pattern (regex or literal string)   - <code>context_lines</code> (optional, default=2): Lines before/after matches   - <code>is_regex</code> (optional, default=true): Treat pattern as regex   - <code>case_sensitive</code> (optional, default=false): Case-sensitive matching   - <code>max_matches</code> (optional, default=100): Maximum matches to return - Returns: Matched lines with line numbers and context - Example: \"Use grep to search for 'TODO' in src/main.py with 5 lines of context\"</p> <p>2. head - Read first N lines - Purpose: Read beginning of file without loading entire contents - Parameters:   - <code>path</code> (required): Absolute file path   - <code>lines</code> (optional, default=10): Number of lines to read   - <code>encoding</code> (optional, default=\"utf-8\"): File encoding - Returns: First N lines with line numbers - Example: \"Use head to read the first 20 lines of README.md\"</p> <p>3. tail - Read last N lines - Purpose: Read end of file (useful for logs, recent changes) - Parameters:   - <code>path</code> (required): Absolute file path   - <code>lines</code> (optional, default=10): Number of lines to read   - <code>encoding</code> (optional, default=\"utf-8\"): File encoding - Returns: Last N lines with line numbers - Example: \"Use tail to check the last 50 lines of error.log\"</p> <p>4. search - Keyword/regex search - Purpose: Multi-keyword search with match highlighting - Parameters:   - <code>path</code> (required): Absolute file path   - <code>keywords</code> (required): Search terms (string or array)   - <code>is_regex</code> (optional, default=false): Treat keywords as regex   - <code>case_sensitive</code> (optional, default=false): Case-sensitive matching   - <code>context_lines</code> (optional, default=1): Lines around matches   - <code>max_results</code> (optional, default=50): Maximum results - Returns: Matches with highlighting (\u2192 markers) - Example: \"Search config.yaml for 'database' or 'connection'\"</p>"},{"location":"reference/workflow-manual/#security-path-validation","title":"Security &amp; Path Validation","text":"<p>All JIT tools enforce strict path validation: - Absolute paths only: Relative paths are rejected - Symlink prevention: Symlinks are blocked to prevent directory traversal - Binary file detection: Binary files are rejected (only text files allowed) - Encoding handling: Graceful fallback to latin-1 for mixed-encoding files</p>"},{"location":"reference/workflow-manual/#usage-patterns","title":"Usage Patterns","text":"<p>Pattern 1: Research &amp; Analysis <pre><code>agents:\n  researcher:\n    prompt: \"Analyze repository structure and recent changes\"\n    tools: []  # No explicit tools - use JIT only\n\ncontext_policy:\n  retrieval:\n    jit_tools: [\"grep\", \"head\", \"tail\", \"search\"]\n</code></pre></p> <p>The agent can now: - <code>grep</code> for function definitions - <code>head</code> to read file headers - <code>tail</code> to check recent log entries - <code>search</code> for configuration keys</p> <p>Pattern 2: Debugging Workflows <pre><code>agents:\n  debugger:\n    prompt: \"Find TODO comments and error messages\"\n\ncontext_policy:\n  retrieval:\n    jit_tools: [\"grep\", \"search\"]\n</code></pre></p> <p>Pattern 3: Mixed Tools <pre><code>agents:\n  analyzer:\n    prompt: \"Analyze code and make API calls\"\n    tools: [\"http_request\"]  # Explicit tool\n\ncontext_policy:\n  retrieval:\n    jit_tools: [\"grep\", \"head\"]  # Auto-injected\n\ntools:\n  python:\n    - callable: \"strands_tools.http_request\"\n</code></pre></p> <p>The agent gets both <code>http_request</code> (from <code>tools.python</code>) and JIT retrieval tools (auto-injected).</p>"},{"location":"reference/workflow-manual/#best-practices","title":"Best Practices","text":"<ol> <li>Explicit opt-in: JIT tools are only available when <code>context_policy.retrieval.jit_tools</code> is configured</li> <li>Tool selection: Only enable tools you need (e.g., just <code>[\"grep\", \"search\"]</code> for code analysis)</li> <li>No duplicates: If a tool is in both <code>agent.tools</code> and <code>jit_tools</code>, it's only loaded once</li> <li>Cross-platform: All tools use pure Python - no shell command dependencies</li> <li>Read-only: All JIT tools are read-only (no file modification capabilities)</li> </ol>"},{"location":"reference/workflow-manual/#limitations-phase-6-scope","title":"Limitations (Phase 6 Scope)","text":"<ul> <li>Read-only: No file writing, moving, or deletion</li> <li>Text files only: Binary files are rejected</li> <li>No directory operations: Can't list directories or create folders</li> <li>No shell execution: All operations use pure Python</li> <li>MCP servers: <code>mcp_servers</code> field is reserved for Phase 9 (not yet implemented)</li> </ul>"},{"location":"reference/workflow-manual/#future-mcp-servers-phase-9","title":"Future: MCP Servers (Phase 9)","text":"<pre><code>context_policy:\n  retrieval:\n    jit_tools: [\"grep\", \"head\"]\n    mcp_servers: [\"filesystem\", \"github\"]  # Phase 9 feature\n</code></pre> <p>Model Context Protocol (MCP) servers will provide extended retrieval capabilities in Phase 9, including directory operations, git integration, and custom data sources.</p>"},{"location":"reference/workflow-manual/#9-skills-optional","title":"9) Skills (Optional)","text":"<pre><code>skills:\n  - id: \"pdf-editing\"\n    path: \"./skills/pdf\"\n    preload_metadata: true\n</code></pre> <ul> <li>Each skill directory should include a <code>SKILL.md</code> with name/description/instructions and any referenced files.</li> <li>If <code>preload_metadata</code> is true, the CLI injects the skill name/description into the agent\u2019s system prompt; content is still read on-demand via tools.</li> </ul>"},{"location":"reference/workflow-manual/#10-tools","title":"10) Tools","text":"<pre><code>tools:\n  python:\n    - \"strands_tools.http_request\"\n    - \"./local_tools/confluence.py:search_pages\"\n  mcp:\n    - id: \"domains\"\n      command: \"uvx\"\n      args: [\"fastdomaincheck-mcp-server\"]\n  http_executors:\n    - id: \"gh\"\n      base_url: \"https://api.github.com\"\n      headers:\n        Authorization: \"Bearer ${GITHUB_TOKEN}\"\n</code></pre> <ul> <li>python: fully qualified callables or module paths (importable by the CLI).</li> <li>mcp: external Model Context Protocol servers.</li> <li>http_executors: declarative HTTP configs for simple GET/POST tooling.</li> </ul> <p>Keep toolsets lean. Overlapping tools reduce determinism and increase cost.</p>"},{"location":"reference/workflow-manual/#11-agents","title":"11) Agents","text":"<pre><code>agents:\n  researcher:\n    prompt: |                       # REQUIRED: agent system prompt\n      You are a research specialist. Cite sources with links.\n    tools: [\"strands_tools.http_request\", \"gh\"]  # optional: tool references\n    provider: bedrock               # optional: overrides runtime.provider\n    model_id: \"us.anthropic.claude-sonnet-4-20250514-v1:0\"  # optional: overrides runtime.model_id\n    inference:                      # optional\n      temperature: 0.2              # 0.0-2.0\n      top_p: 0.95                   # 0.0-1.0\n      max_tokens: 4000              # min: 1\n\n  writer:\n    prompt: \"Produce a crisp, sectioned report for {{audience}}.\"\n</code></pre> <ul> <li>Each agent requires only a <code>prompt</code> field; all other fields are optional.</li> <li>Agents inherit from <code>runtime</code> unless overridden.</li> <li>Avoid setting wildly different temperatures across agents in the same flow.</li> <li>The <code>agents</code> object must contain at least one agent.</li> </ul>"},{"location":"reference/workflow-manual/#12-patterns","title":"12) Patterns","text":"<p>The schema supports 7 pattern types: <code>chain</code>, <code>routing</code>, <code>parallel</code>, <code>orchestrator_workers</code>, <code>evaluator_optimizer</code>, <code>graph</code>, and <code>workflow</code>. Each pattern has a specific <code>config</code> structure validated by the schema.</p>"},{"location":"reference/workflow-manual/#121-chain","title":"12.1 Chain","text":"<pre><code>pattern:\n  type: chain\n  config:\n    steps:\n      - agent: researcher\n        input: \"Research {{topic}} and list top 6 sources.\"\n      - agent: writer\n        input: \"Write a 600-word brief with citations.\"\n</code></pre> <p>Use for: straight-line handoffs and deterministic flows.</p>"},{"location":"reference/workflow-manual/#122-routing","title":"12.2 Routing","text":"<pre><code>pattern:\n  type: routing\n  config:\n    router:\n      agent: researcher\n      input: \"Classify the request into one route: faq, research, or coding.\"\n    routes:\n      faq:\n        then:\n          - agent: writer\n            input: \"Answer briefly with 3 bullets.\"\n      research:\n        then:\n          - agent: researcher\n            input: \"Deep dive and gather evidence.\"\n          - agent: writer\n            input: \"Summarize with links.\"\n      coding:\n        then:\n          - agent: writer\n            input: \"Create a step-by-step plan.\"\n</code></pre> <p>Router output: your router agent should emit a small JSON dict (<code>{{route: 'faq'|'research'|'coding', rationale: '...'}}</code>), which the CLI interprets.</p>"},{"location":"reference/workflow-manual/#123-parallel","title":"12.3 Parallel","text":"<pre><code>pattern:\n  type: parallel\n  config:\n    branches:                       # REQUIRED: min 2 branches\n      - id: web                     # REQUIRED: unique branch identifier\n        steps:                      # REQUIRED: min 1 step per branch\n          - agent: researcher\n            input: \"Collect web sources.\"\n      - id: docs\n        steps:\n          - agent: researcher\n            input: \"Collect internal docs.\"\n    reduce:                         # optional: aggregation step\n      agent: writer\n      input: \"Merge findings and remove duplicates.\"\n</code></pre> <p>Use for: fanning out and reducing into a single result. CLI must join branch results deterministically. Requirements: At least 2 branches required; each branch must have at least 1 step.</p>"},{"location":"reference/workflow-manual/#124-orchestratorworkers","title":"12.4 Orchestrator\u2011Workers","text":"<pre><code>pattern:\n  type: orchestrator_workers\n  config:\n    orchestrator:\n      agent: researcher\n      limits:\n        max_workers: 6\n        max_rounds: 3\n    worker_template:\n      agent: researcher\n      tools: [\"strands_tools.http_request\", \"gh\"]\n    reduce:\n      agent: writer\n      input: \"Synthesize workers' findings; deduplicate and score sources.\"\n    writeup:\n      agent: writer\n      input: \"Final brief with executive summary and open questions.\"\n</code></pre> <p>Use for: multi-subtask research; maps to Strands Swarm/team behavior.</p>"},{"location":"reference/workflow-manual/#125-evaluatoroptimizer","title":"12.5 Evaluator\u2011Optimizer","text":"<pre><code>pattern:\n  type: evaluator_optimizer\n  config:\n    producer: writer\n    evaluator:\n      agent: researcher\n      input: |\n        Critique for accuracy and structure.\n        Return JSON: {{score: 0..100, issues: [], fixes: []}}.\n    accept:\n      min_score: 85\n      max_iters: 3\n    revise_prompt: \"Revise the draft using evaluator fixes; do not invent citations.\"\n</code></pre> <p>Use for: iterative refinement with measurable gates.</p>"},{"location":"reference/workflow-manual/#126-graph","title":"12.6 Graph","text":"<p>Pattern: Explicit control flow with nodes, edges, and conditional transitions.</p> <p>Use for: State machines, decision trees, iterative refinement loops, and complex workflows requiring dynamic routing based on previous agent responses.</p>"},{"location":"reference/workflow-manual/#core-concepts","title":"Core Concepts","text":"<p>Nodes: Individual execution points, each running a specific agent. - Entry node: First node in <code>nodes:</code> map (Python 3.7+ dict insertion order) - Terminal nodes: Nodes with no outgoing edges (workflow stops when reached) - Iterations: Nodes can be revisited multiple times (tracked automatically)</p> <p>Edges: Define allowed transitions between nodes. - Static edges: Always transition to target node(s)   <pre><code>- from: node_a\n  to: [node_b]\n</code></pre> - Conditional edges: Choose path based on runtime conditions   <pre><code>- from: node_a\n  choose:\n    - when: \"{{ condition_1 }}\"\n      to: node_b\n    - when: \"{{ condition_2 }}\"\n      to: node_c\n    - when: else\n      to: node_d\n</code></pre></p> <p>Conditions: Jinja2 expressions evaluated against execution context. - Access node responses: <code>{{ nodes.node_a.response }}</code> - Access node iteration: <code>{{ nodes.node_a.iteration }}</code> - Boolean operators: <code>and</code>, <code>or</code>, <code>not</code> - Comparisons: <code>==</code>, <code>!=</code>, <code>&lt;</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&gt;=</code> - String operations: <code>in</code>, <code>lower()</code>, <code>upper()</code> - Special keyword: <code>else</code> always evaluates to <code>True</code> (catch-all)</p> <p>Cycle Protection: Dual-limit enforcement prevents infinite loops. - Global limit: <code>runtime.budgets.max_steps</code> (default 100) - total workflow steps - Per-node limit: <code>pattern.config.max_iterations</code> (default 10) - max visits per node</p>"},{"location":"reference/workflow-manual/#configuration_1","title":"Configuration","text":"<pre><code>pattern:\n  type: graph\n  config:\n    max_iterations: 5  # Optional: per-node iteration limit (default: 10)\n\n    nodes:\n      # Entry node (first in map)\n      intake:\n        agent: classifier\n        input: \"{{ user_request }}\"  # Optional: override agent prompt\n\n      # Standard nodes\n      handle_technical:\n        agent: tech_support\n\n      handle_billing:\n        agent: billing_support\n\n      # Terminal node (no outgoing edges)\n      escalate:\n        agent: senior_manager\n\n    edges:\n      # Entry: Route based on classification\n      - from: intake\n        choose:\n          - when: \"{{ 'technical' in nodes.intake.response.lower() }}\"\n            to: handle_technical\n          - when: \"{{ 'billing' in nodes.intake.response.lower() }}\"\n            to: handle_billing\n          - when: else\n            to: escalate\n\n      # Technical path: Check priority\n      - from: handle_technical\n        choose:\n          - when: \"{{ 'high' in nodes.intake.response.lower() }}\"\n            to: escalate\n          # Otherwise terminal (no else clause)\n\n      # Billing path: Always escalate\n      - from: handle_billing\n        to: [escalate]\n</code></pre>"},{"location":"reference/workflow-manual/#condition-evaluation","title":"Condition Evaluation","text":"<p>Conditions are evaluated using Jinja2 with access to the execution context:</p> <p>Available Context: <pre><code>{\n  \"nodes\": {\n    \"node_id\": {\n      \"response\": \"Agent response text\",\n      \"agent\": \"agent_id\",\n      \"status\": \"success|error\",\n      \"iteration\": 2  # How many times this node has executed\n    }\n  },\n  \"last_response\": \"Most recent node response\",\n  \"total_steps\": 5,\n  # Plus any inputs.values variables\n}\n</code></pre></p> <p>Example Conditions: <pre><code># Simple string matching\nwhen: \"{{ 'approve' in nodes.reviewer.response.lower() }}\"\n\n# Numeric comparison\nwhen: \"{{ nodes.validator.iteration &gt;= 3 }}\"\n\n# Boolean operators\nwhen: \"{{ 'valid' in nodes.check.response and nodes.check.iteration &lt; 5 }}\"\n\n# Multiple conditions with else\nchoose:\n  - when: \"{{ nodes.score.response | int &gt;= 85 }}\"\n    to: approve\n  - when: \"{{ nodes.score.response | int &gt;= 60 }}\"\n    to: review\n  - when: else\n    to: reject\n</code></pre></p>"},{"location":"reference/workflow-manual/#loop-patterns","title":"Loop Patterns","text":"<p>Iterative Refinement (with quality threshold): <pre><code>nodes:\n  writer:\n    agent: coder\n    input: \"{{ task }}\"\n\n  reviewer:\n    agent: reviewer\n\n  finalize:\n    agent: finalizer\n\nedges:\n  - from: writer\n    to: [reviewer]\n\n  - from: reviewer\n    choose:\n      - when: \"{{ 'approve' in nodes.reviewer.response.lower() }}\"\n        to: finalize\n      - when: \"{{ nodes.writer.iteration &gt;= 3 }}\"\n        to: finalize  # Force exit after 3 attempts\n      - when: else\n        to: writer  # Loop back for revision\n</code></pre></p> <p>Bounded Retry (with iteration limit): <pre><code>edges:\n  - from: processor\n    choose:\n      - when: \"{{ 'success' in nodes.processor.response.lower() }}\"\n        to: complete\n      - when: \"{{ nodes.processor.iteration &gt;= 5 }}\"\n        to: error_handler\n      - when: else\n        to: processor  # Retry\n</code></pre></p>"},{"location":"reference/workflow-manual/#execution-flow","title":"Execution Flow","text":"<ol> <li>Entry: Execute first node in <code>nodes:</code> map</li> <li>Edge Traversal: For each node, find matching edges:</li> <li>Evaluate <code>choose</code> conditions in order (first match wins)</li> <li>Execute static <code>to</code> if no <code>choose</code> clause</li> <li>Stop if no outgoing edges (terminal node)</li> <li>Iteration Tracking: Increment node iteration counter on each visit</li> <li>Cycle Detection: </li> <li>Check per-node iteration limit (raise error if exceeded)</li> <li>Check global step limit (raise error if exceeded)</li> <li>Termination: Stop when terminal node reached or limits hit</li> </ol>"},{"location":"reference/workflow-manual/#output-templates","title":"Output Templates","text":"<p>Access node data in output artifacts:</p> <pre><code>outputs:\n  artifacts:\n    - path: ./result.md\n      from: |\n        # Workflow Result\n\n        {% if nodes.approve %}\n        ## Approved\n        {{ nodes.approve.response }}\n        {% endif %}\n\n        {% if nodes.reject %}\n        ## Rejected\n        {{ nodes.reject.response }}\n        Attempts: {{ nodes.processor.iteration }}\n        {% endif %}\n\n        Terminal Node: {{ terminal_node }}\n        Total Steps: {{ total_steps }}\n</code></pre>"},{"location":"reference/workflow-manual/#visualization","title":"Visualization","text":"<p>Use <code>strands plan</code> to generate DOT visualization:</p> <pre><code>uv run strands plan examples/graph-state-machine-openai.yaml\n</code></pre> <p>Generates Graphviz DOT format showing: - Green nodes: Entry points - Red nodes: Terminal nodes - Blue nodes: Standard nodes - Solid arrows: Static edges - Dashed arrows: Conditional edges (labeled with condition)</p>"},{"location":"reference/workflow-manual/#examples","title":"Examples","text":"<p>See full working examples: - <code>examples/graph-state-machine-openai.yaml</code> - Customer support routing - <code>examples/graph-decision-tree-bedrock.yaml</code> - Approval workflow - <code>examples/graph-iterative-refinement-ollama.yaml</code> - Code review loop</p>"},{"location":"reference/workflow-manual/#127-workflow-dag","title":"12.7 Workflow (DAG)","text":"<pre><code>pattern:\n  type: workflow\n  config:\n    tasks:\n      - id: extract\n        agent: researcher\n        description: \"Fetch 3\u20135 sources on {{topic}}\"\n      - id: trend\n        agent: researcher\n        deps: [extract]\n        description: \"Extract trends with evidence\"\n      - id: report\n        agent: writer\n        deps: [trend]\n        description: \"Write the final report\"\n</code></pre> <p>Use for: fixed DAGs; supports parallel execution where deps allow.</p>"},{"location":"reference/workflow-manual/#13-outputs-and-artifacts","title":"13) Outputs and Artifacts","text":"<pre><code>outputs:\n  artifacts:\n    - path: \"./artifacts/{{name}}.md\"\n      from: \"{{ last_response }}\"\n    - path: \"./artifacts/trace.json\"\n      from: \"$TRACE\"\n</code></pre> <ul> <li><code>{{ last_response }}</code> is the final agent message from the pattern runner.</li> <li><code>$TRACE</code> is a special symbol instructing the CLI to export an OTEL trace JSON snapshot.</li> </ul>"},{"location":"reference/workflow-manual/#14-security-guardrails","title":"14) Security &amp; Guardrails","text":"<pre><code>security:\n  guardrails:\n    deny_network: false\n    pii_redaction: true\n    allow_tools: [\"strands_tools.http_request\", \"gh\"]\n</code></pre> <ul> <li>Prefer allow-lists for tools in controlled environments.</li> <li>Toggle <code>deny_network</code> for fully offline runs with pre-provided corpora.</li> </ul>"},{"location":"reference/workflow-manual/#15-validation","title":"15) Validation","text":"<ul> <li>Use the provided JSON Schema (<code>strands-workflow.schema.json</code>) to validate files.</li> <li>Any proper JSON Schema validator works:</li> <li>Node: <code>ajv validate -s strands-workflow.schema.json -d flow.yaml</code></li> <li>Python: <code>jsonschema.validate(instance, schema)</code></li> <li>The CLI should perform validation before attempting execution.</li> </ul>"},{"location":"reference/workflow-manual/#16-execution-model-informative","title":"16) Execution Model (Informative)","text":"<ul> <li>The CLI compiles <code>agents</code> to Strands agent instances (e.g., via a config-to-agent helper) and binds tools.</li> <li>A pattern runner translates <code>pattern</code> into the corresponding Strands primitive (Swarm/Graph/Workflow) or a small deterministic loop (chain/routing/evaluator).</li> <li>Budgets are enforced both at pattern and agent call sites.</li> <li>Compaction and notes apply between steps/rounds when thresholds are met.</li> <li>Telemetry spans are emitted per step/tool call; errors attach structured metadata.</li> </ul>"},{"location":"reference/workflow-manual/#17-style-guide-best-practices","title":"17) Style Guide &amp; Best Practices","text":"<ul> <li>Keep prompts short and task-specific; use <code>input</code> to pass per-step instructions.</li> <li>Limit agent count to the minimum needed; over-segmentation hurts reliability.</li> <li>Prefer routing over giant \u201cdo-everything\u201d prompts.</li> <li>In parallel and orchestrator patterns, set a clear reduce strategy.</li> <li>Always include budgets and retries with sane defaults.</li> <li>Keep tools minimal and well\u2011named; avoid overlapping responsibilities.</li> <li>Use artifacts to make outputs and traces easy to consume downstream.</li> </ul>"},{"location":"reference/workflow-manual/#18-reference-json-example-valid","title":"18) Reference: JSON Example (Valid)","text":"<pre><code>{{\n  \"version\": 0,\n  \"name\": \"research-brief\",\n  \"runtime\": {{\n    \"provider\": \"bedrock\",\n    \"model_id\": \"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n    \"region\": \"eu-central-1\",\n    \"budgets\": {{\"max_steps\": 200, \"max_tokens\": 800000, \"max_duration_s\": 900}}\n  }},\n  \"inputs\": {{\n    \"required\": {{\"topic\": \"string\"}},\n    \"optional\": {{\"audience\": \"string\"}}\n  }},\n  \"tools\": {{\n    \"python\": [\"strands_tools.http_request\"],\n    \"http_executors\": [{{\"id\": \"gh\", \"base_url\": \"https://api.github.com\", \"headers\": {{\"Authorization\": \"Bearer ${GITHUB_TOKEN}\"}}}}]\n  }},\n  \"agents\": {{\n    \"researcher\": {{\"prompt\": \"Research {{{{topic}}}} and cite sources.\", \"tools\": [\"strands_tools.http_request\", \"gh\"]}},\n    \"writer\": {{\"prompt\": \"Write a concise report for {{{{audience}}}}.\"}}\n  }},\n  \"pattern\": {{\n    \"type\": \"chain\",\n    \"config\": {{\n      \"steps\": [\n        {{\"agent\": \"researcher\", \"input\": \"Find 6 diverse sources.\"}},\n        {{\"agent\": \"writer\", \"input\": \"Produce a 600-word brief with citations.\"}}\n      ]\n    }}\n  }},\n  \"outputs\": {{\n    \"artifacts\": [\n      {{\"path\": \"./artifacts/research-brief.md\", \"from\": \"{{{{ last_response }}}}\"}}\n    ]\n  }}\n}}\n</code></pre> <p>Note the doubled braces in this manual\u2019s JSON block to avoid Markdown templating conflicts.</p>"},{"location":"reference/workflow-manual/#19-troubleshooting","title":"19) Troubleshooting","text":"<ul> <li>Schema validation fails: run <code>strands-cli validate</code> with <code>--verbose</code> to see the exact path and expected type.</li> <li>Tool import errors: confirm your <code>PYTHONPATH</code> and the callable name (<code>module:func</code>).</li> <li>Secrets missing: verify environment variables or configure AWS Secrets Manager/SSM.</li> <li>No artifacts produced: ensure <code>outputs.artifacts</code> is configured and the chosen pattern emits <code>last_response</code>.</li> <li>Infinite loops: tighten <code>budgets.max_steps</code> and configure <code>failure_policy</code>.</li> </ul>"},{"location":"reference/workflow-manual/#20-telemetry-observability","title":"20) Telemetry &amp; Observability","text":"<p>Strands CLI integrates with OpenTelemetry (OTEL) to provide production-grade observability. Enable distributed tracing to monitor workflow execution, identify bottlenecks, and debug issues across multi-agent systems.</p>"},{"location":"reference/workflow-manual/#configuration_2","title":"Configuration","text":""},{"location":"reference/workflow-manual/#basic-setup","title":"Basic Setup","text":"<pre><code>telemetry:\n  otel:\n    endpoint: http://localhost:4318/v1/traces  # OTLP/HTTP endpoint\n    service_name: my-workflow-service          # Service identifier in traces\n    sample_ratio: 1.0                          # Trace 100% of requests\n</code></pre>"},{"location":"reference/workflow-manual/#configuration-reference","title":"Configuration Reference","text":"Field Type Default Description <code>endpoint</code> string <code>null</code> OTLP endpoint URL (HTTP/gRPC). If null, tracing disabled. <code>service_name</code> string <code>\"strands-cli\"</code> Service name for trace identification <code>sample_ratio</code> float <code>1.0</code> Sampling rate (0.0-1.0). 0.0=disabled, 1.0=trace all"},{"location":"reference/workflow-manual/#span-hierarchy","title":"Span Hierarchy","text":"<p>Spans follow a consistent hierarchy across all workflow patterns:</p> <pre><code>execute.&lt;pattern_type&gt;              (root span)\n\u251c\u2500\u2500 execute.chain                   (for route execution in routing pattern)\n\u2502   \u251c\u2500\u2500 agent.invoke                (per step - from Strands SDK)\n\u2502   \u2502   \u251c\u2500\u2500 tool.&lt;tool_name&gt;        (per tool call - from Strands SDK)\n\u2502   \u2502   \u2514\u2500\u2500 llm.completion          (from Strands SDK)\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 ...\n</code></pre> <p>Pattern-Specific Span Names: - Chain: <code>execute.chain</code> - Workflow: <code>execute.workflow</code> - Routing: <code>execute.routing</code> (contains nested <code>execute.chain</code> for route) - Parallel: <code>execute.parallel</code> - Evaluator-Optimizer: <code>execute.evaluator_optimizer</code> - Orchestrator-Workers: <code>execute.orchestrator_workers</code> - Graph: <code>execute.graph</code></p>"},{"location":"reference/workflow-manual/#span-attributes-reference","title":"Span Attributes Reference","text":""},{"location":"reference/workflow-manual/#common-attributes-all-patterns","title":"Common Attributes (All Patterns)","text":"Attribute Type Example Description <code>spec.name</code> string <code>\"my-workflow\"</code> Workflow name from spec <code>spec.version</code> string <code>\"1.0.0\"</code> Workflow version <code>pattern.type</code> string <code>\"chain\"</code> Pattern type <code>runtime.provider</code> string <code>\"openai\"</code> LLM provider <code>runtime.model_id</code> string <code>\"gpt-4o\"</code> Model identifier <code>runtime.region</code> string <code>\"us-east-1\"</code> AWS region (Bedrock only)"},{"location":"reference/workflow-manual/#pattern-specific-attributes","title":"Pattern-Specific Attributes","text":"<p>Chain: - <code>chain.step_count</code> (int) - Total steps in chain</p> <p>Workflow: - <code>workflow.task_count</code> (int) - Total tasks - <code>workflow.layer_count</code> (int) - DAG execution layers</p> <p>Routing: - <code>routing.router_agent</code> (string) - Router agent ID - <code>routing.route_count</code> (int) - Available routes - <code>routing.max_retries</code> (int) - Max retries for router</p> <p>Parallel: - <code>parallel.branch_count</code> (int) - Number of branches - <code>parallel.has_reduce</code> (bool) - Reduce step present - <code>parallel.max_parallel</code> (int) - Concurrency limit</p> <p>Evaluator-Optimizer: - <code>evaluator_optimizer.max_iterations</code> (int) - Iteration limit - <code>evaluator_optimizer.evaluator_agent</code> (string) - Evaluator ID - <code>evaluator_optimizer.optimizer_agent</code> (string) - Optimizer ID</p> <p>Orchestrator-Workers: - <code>orchestrator_workers.orchestrator_agent</code> (string) - Orchestrator ID - <code>orchestrator_workers.worker_count</code> (int) - Worker pool size</p> <p>Graph: - <code>graph.node_count</code> (int) - Total nodes - <code>graph.edge_count</code> (int) - Total edges/transitions - <code>graph.start_node</code> (string) - Entry point node</p>"},{"location":"reference/workflow-manual/#span-events-reference","title":"Span Events Reference","text":"<p>Events mark key milestones during workflow execution.</p>"},{"location":"reference/workflow-manual/#common-events-all-patterns","title":"Common Events (All Patterns)","text":"Event Attributes Description <code>execution_start</code> - Workflow execution begins <code>execution_complete</code> <code>duration_seconds</code>, <code>cumulative_tokens</code> Workflow finishes successfully"},{"location":"reference/workflow-manual/#pattern-specific-events","title":"Pattern-Specific Events","text":"<p>Chain: | Event | Attributes | Description | |-------|------------|-------------| | <code>step_start</code> | <code>step_index</code>, <code>agent_id</code> | Chain step begins | | <code>step_complete</code> | <code>step_index</code>, <code>agent_id</code>, <code>response_length</code>, <code>cumulative_tokens</code> | Chain step finishes |</p> <p>Workflow: | Event | Attributes | Description | |-------|------------|-------------| | <code>task_complete</code> | <code>task_id</code>, <code>agent_id</code>, <code>response_length</code>, <code>cumulative_tokens</code> | Task finishes |</p> <p>Routing: | Event | Attributes | Description | |-------|------------|-------------| | <code>agent_selected</code> | <code>chosen_route</code>, <code>router_agent</code> | Router selects route |</p> <p>Parallel: | Event | Attributes | Description | |-------|------------|-------------| | <code>branch_complete</code> | <code>branch_id</code>, <code>response_length</code>, <code>tokens</code> | Branch execution finishes | | <code>reduce_start</code> | - | Reduce step begins (if configured) |</p> <p>Evaluator-Optimizer: | Event | Attributes | Description | |-------|------------|-------------| | <code>iteration_start</code> | <code>iteration_number</code> | Iteration begins | | <code>evaluation_complete</code> | <code>score</code>, <code>feedback</code> | Evaluator finishes | | <code>optimization_complete</code> | <code>improved</code> | Optimizer finishes | | <code>iteration_complete</code> | <code>iteration_number</code>, <code>converged</code> | Iteration finishes |</p> <p>Orchestrator-Workers: | Event | Attributes | Description | |-------|------------|-------------| | <code>orchestrator_planning</code> | <code>task_count</code> | Orchestrator creates work plan | | <code>worker_assigned</code> | <code>worker_id</code>, <code>task_id</code> | Task assigned to worker | | <code>worker_complete</code> | <code>worker_id</code>, <code>task_id</code>, <code>success</code> | Worker finishes task | | <code>orchestrator_synthesis</code> | <code>results_count</code> | Orchestrator aggregates results |</p> <p>Graph: | Event | Attributes | Description | |-------|------------|-------------| | <code>node_entered</code> | <code>node_id</code>, <code>visit_count</code> | Node execution starts | | <code>node_complete</code> | <code>node_id</code>, <code>next_transition</code> | Node execution finishes | | <code>transition</code> | <code>from_node</code>, <code>to_node</code>, <code>condition</code> | Graph state transition |</p> <p>Utility Events (Cross-Pattern): | Event | Attributes | Description | |-------|------------|-------------| | <code>retry_attempt</code> | <code>attempt</code>, <code>error</code>, <code>wait_seconds</code> | Retry triggered | | <code>budget_warning</code> | <code>current_tokens</code>, <code>max_tokens</code>, <code>threshold</code>, <code>usage_percent</code> | Approaching budget limit | | <code>budget_exceeded</code> | <code>current_tokens</code>, <code>max_tokens</code>, <code>overage</code> | Budget limit exceeded |</p>"},{"location":"reference/workflow-manual/#sampling-strategies","title":"Sampling Strategies","text":""},{"location":"reference/workflow-manual/#development-debugging","title":"Development &amp; Debugging","text":"<p><pre><code>telemetry:\n  otel:\n    sample_ratio: 1.0  # Trace all requests\n</code></pre> Use When: Local development, debugging issues, performance profiling</p>"},{"location":"reference/workflow-manual/#production-low-traffic","title":"Production (Low Traffic)","text":"<p><pre><code>telemetry:\n  otel:\n    sample_ratio: 0.5  # Trace 50% of requests\n</code></pre> Use When: &lt;1000 requests/day, cost-sensitive environments</p>"},{"location":"reference/workflow-manual/#production-high-traffic","title":"Production (High Traffic)","text":"<p><pre><code>telemetry:\n  otel:\n    sample_ratio: 0.01  # Trace 1% of requests\n</code></pre> Use When: &gt;10,000 requests/day, high-scale deployments</p>"},{"location":"reference/workflow-manual/#emergency-disable","title":"Emergency Disable","text":"<p><pre><code>telemetry:\n  otel:\n    sample_ratio: 0.0  # Disable tracing\n</code></pre> Use When: OTEL collector down, incident mitigation</p>"},{"location":"reference/workflow-manual/#backend-setup","title":"Backend Setup","text":""},{"location":"reference/workflow-manual/#option-1-jaeger-recommended-for-development","title":"Option 1: Jaeger (Recommended for Development)","text":"<pre><code># Start Jaeger all-in-one\ndocker run -d --name jaeger \\\n  -p 16686:16686 \\\n  -p 4318:4318 \\\n  jaegertracing/all-in-one:latest\n\n# Access UI: http://localhost:16686\n</code></pre>"},{"location":"reference/workflow-manual/#option-2-otel-collector-backend","title":"Option 2: OTEL Collector + Backend","text":"<pre><code># otel-collector-config.yaml\nreceivers:\n  otlp:\n    protocols:\n      http:\n        endpoint: 0.0.0.0:4318\n\nexporters:\n  jaeger:\n    endpoint: jaeger:14250\n  logging:\n    loglevel: debug\n\nservice:\n  pipelines:\n    traces:\n      receivers: [otlp]\n      exporters: [jaeger, logging]\n</code></pre> <pre><code>docker run -p 4318:4318 \\\n  -v $(pwd)/otel-collector-config.yaml:/etc/otel/config.yaml \\\n  otel/opentelemetry-collector:latest \\\n  --config=/etc/otel/config.yaml\n</code></pre>"},{"location":"reference/workflow-manual/#option-3-production-aws-x-ray-datadog-etc","title":"Option 3: Production (AWS X-Ray, DataDog, etc.)","text":"<p>Strands CLI uses standard OTLP protocol - compatible with all major APM vendors: - AWS X-Ray: Use AWS Distro for OpenTelemetry - DataDog: Configure DataDog agent with OTLP receiver - New Relic: Use New Relic OTLP endpoint - Honeycomb: Use Honeycomb OTLP endpoint</p>"},{"location":"reference/workflow-manual/#troubleshooting","title":"Troubleshooting","text":""},{"location":"reference/workflow-manual/#no-traces-appearing","title":"No Traces Appearing","text":"<ol> <li>Check <code>sample_ratio</code> &gt; 0.0</li> <li>Verify OTEL endpoint is reachable: <code>curl http://localhost:4318/v1/traces</code></li> <li>Check logs for OTLP export errors: <code>strands run --verbose ...</code></li> </ol>"},{"location":"reference/workflow-manual/#trace-sampling-too-aggressive","title":"Trace Sampling Too Aggressive","text":"<ul> <li>Increase <code>sample_ratio</code> for more traces</li> <li>TraceIdRatioBased sampler is deterministic (same trace ID = same sampling decision)</li> </ul>"},{"location":"reference/workflow-manual/#high-trace-volume-costs","title":"High Trace Volume Costs","text":"<ul> <li>Decrease <code>sample_ratio</code> to reduce data volume</li> <li>Use head-based sampling (configured here) + tail-based sampling (at collector) for best results</li> </ul>"},{"location":"reference/workflow-manual/#best-practices_1","title":"Best Practices","text":"<ol> <li>Use Consistent Service Names: Group related workflows with same <code>service_name</code></li> <li>Set Appropriate Sampling: Start with 1.0 in dev, tune down in production based on traffic</li> <li>Monitor Span Attributes: Use <code>spec.name</code> and <code>pattern.type</code> for filtering in trace UI</li> <li>Track Events for Debugging: Events like <code>retry_attempt</code> and <code>budget_warning</code> highlight issues</li> <li>Combine with Structured Logs: Trace context (trace_id, span_id) automatically injected into logs via structlog</li> </ol>"},{"location":"reference/workflow-manual/#21-migration-extensibility","title":"21) Migration &amp; Extensibility","text":"<ul> <li>Add new pattern types by extending the schema and the CLI\u2019s runner registry.</li> <li>Keep <code>version</code> to gate breaking changes (introduce <code>1</code> when you add incompatible keys).</li> <li>Consider a <code>manual_gate</code> step type (human approval via Slack/Jira) in a future minor version.</li> </ul>"},{"location":"reference/workflow-manual/#22-appendix-schema-fields-at-a-glance","title":"22) Appendix: Schema Fields (At-a-Glance)","text":"<p>Required top-level fields: <code>version</code>, <code>name</code>, <code>runtime</code>, <code>agents</code> (min 1), <code>pattern</code></p> <ul> <li>runtime [REQUIRED]: </li> <li><code>provider</code> [REQUIRED]</li> <li><code>model_id</code>, <code>region</code>, <code>max_parallel</code>, <code>budgets</code>, <code>failure_policy</code> [all optional]</li> <li>inputs [optional]: required/optional var map with type, description, default, enum</li> <li>env [optional]: secrets (env/secrets_manager/ssm/file), mounts</li> <li>telemetry [optional]: otel (endpoint, service_name, sample_ratio), redact (tool_inputs, tool_outputs)</li> <li>context_policy [optional]: compaction, notes, retrieval</li> <li>skills [optional]: id, path, preload_metadata</li> <li>tools [optional]: python[], mcp[], http_executors[]</li> <li>agents [REQUIRED, min 1]: </li> <li><code>prompt</code> [REQUIRED per agent]</li> <li><code>tools[]</code>, <code>provider</code>, <code>model_id</code>, <code>inference</code> [all optional]</li> <li>pattern [REQUIRED, exactly 1]:</li> <li>chain: steps[] (min 1)</li> <li>routing: router, routes..then[] <li>parallel: branches[] (min 2), reduce [optional]</li> <li>orchestrator_workers: orchestrator, worker_template, reduce [optional], writeup [optional]</li> <li>evaluator_optimizer: producer, evaluator, accept, revise_prompt [optional]</li> <li>graph: nodes (min 1), edges (min 1) with conditional <code>choose</code></li> <li>workflow: tasks[] (min 1) with <code>deps</code></li> <li>outputs [optional]: artifacts[] (<code>path</code>, <code>from</code>)</li> <li>security [optional]: guardrails (deny_network, pii_redaction, allow_tools)</li>"},{"location":"reference/workflow-manual/#23-files","title":"23) Files","text":"<ul> <li>Schema: <code>strands-workflow.schema.json</code></li> <li>Manual (this doc): <code>strands-workflow-manual.md</code></li> </ul>"},{"location":"reference/api/","title":"API Reference","text":"<p>Complete Python API documentation for Strands CLI.</p>"},{"location":"reference/api/#module-overview","title":"Module Overview","text":"<p>Strands CLI is organized into several key modules:</p>"},{"location":"reference/api/#core-modules","title":"Core Modules","text":"<ul> <li>Runtime - Provider adapters, context management, and budget enforcement</li> <li>Execution - Workflow pattern executors (chain, workflow, routing, etc.)</li> <li>Loader - YAML/JSON parsing and template rendering</li> <li>Schema - JSON Schema validation and Pydantic models</li> <li>Telemetry - OpenTelemetry tracing and PII redaction</li> </ul>"},{"location":"reference/api/#supporting-modules","title":"Supporting Modules","text":"<ul> <li>Tools - Native tool registry and implementations</li> <li>Artifacts - Artifact I/O operations</li> <li>Visualization - Graph pattern visualization</li> <li>Capability - Feature compatibility checking</li> </ul>"},{"location":"reference/api/#quick-links","title":"Quick Links","text":"<ul> <li>Types and Models - Core Pydantic models</li> <li>Configuration - Environment variable configuration</li> <li>Exit Codes - Standard exit codes</li> <li>Utilities - Shared utilities</li> </ul>"},{"location":"reference/api/#usage","title":"Usage","text":"<p>All public APIs are importable from their respective modules:</p> <pre><code>from strands_cli.types import Spec, Runtime, Agent\nfrom strands_cli.loader import load_workflow_spec\nfrom strands_cli.runtime.providers import create_model\nfrom strands_cli.exec.chain import run_chain\n</code></pre>"},{"location":"reference/api/#type-hints","title":"Type Hints","text":"<p>All modules use strict type hints and are checked with Mypy. See individual module documentation for detailed type signatures.</p>"},{"location":"reference/api/artifacts/","title":"Artifacts Module","text":"<p>The artifacts module handles artifact I/O operations with path validation.</p>"},{"location":"reference/api/artifacts/#artifact-io","title":"Artifact I/O","text":""},{"location":"reference/api/artifacts/#strands_cli.artifacts.io","title":"<code>strands_cli.artifacts.io</code>","text":"<p>Artifact output file management.</p> <p>Handles writing workflow execution outputs to files using template rendering. Supports Jinja2 templates for dynamic artifact content generation.</p> Features <ul> <li>Template rendering with {{ last_response }}, {{ TRACE }}, and other variables</li> <li>Directory creation (parents created automatically)</li> <li>Overwrite protection (--force flag required)</li> <li>Error handling for I/O failures</li> <li>UTF-8 encoding</li> <li>Path sanitization to prevent traversal attacks</li> </ul> Artifact Templates <p>Current: {{ last_response }} - final agent output          {{ TRACE }} - complete trace JSON with spans and metadata Future: {{ PROVENANCE }}, etc.</p>"},{"location":"reference/api/artifacts/#strands_cli.artifacts.io.ArtifactError","title":"<code>ArtifactError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when artifact writing fails.</p>"},{"location":"reference/api/artifacts/#strands_cli.artifacts.io.sanitize_filename","title":"<code>sanitize_filename(filename, max_length=100)</code>","text":"<p>Sanitize a filename to prevent path traversal and filesystem issues.</p> <p>Removes path separators, special characters, and limits length. Ensures the resulting filename is safe for all platforms.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Raw filename (may contain unsafe characters)</p> required <code>max_length</code> <code>int</code> <p>Maximum length of output (default: 100)</p> <code>100</code> <p>Returns:</p> Type Description <code>str</code> <p>Sanitized filename safe for filesystem use</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sanitize_filename(\"../etc/passwd\")\n'etc_passwd'\n&gt;&gt;&gt; sanitize_filename(\"my-spec-name\")\n'my-spec-name'\n&gt;&gt;&gt; sanitize_filename(\"spec@#$%name\")\n'spec_name'\n</code></pre>"},{"location":"reference/api/artifacts/#strands_cli.artifacts.io.write_artifacts","title":"<code>write_artifacts(spec_artifacts, last_response, output_dir='./artifacts', force=False, *, variables=None, execution_context=None, spec_name=None, pattern_type=None)</code>","text":"<p>Write output artifacts from workflow execution.</p> <p>Renders each artifact template with execution context (last_response, etc.) and writes to the specified paths. Creates parent directories as needed.</p> <p>Parameters:</p> Name Type Description Default <code>spec_artifacts</code> <code>list[Any]</code> <p>List of artifact configs from spec.outputs.artifacts</p> required <code>last_response</code> <code>str</code> <p>The agent's last response text (for {{ last_response }} template)</p> required <code>output_dir</code> <code>str | Path</code> <p>Directory to write artifacts to (default: ./artifacts)</p> <code>'./artifacts'</code> <code>force</code> <code>bool</code> <p>If True, overwrite existing files; if False, error on existing files</p> <code>False</code> <code>variables</code> <code>dict[str, str] | None</code> <p>User-provided variables from --var flags (for template rendering)</p> <code>None</code> <code>execution_context</code> <code>dict[str, Any] | None</code> <p>Additional context (steps, tasks) for template rendering</p> <code>None</code> <code>spec_name</code> <code>str | None</code> <p>Name of spec (for $TRACE metadata)</p> <code>None</code> <code>pattern_type</code> <code>str | None</code> <p>Pattern type (for $TRACE metadata)</p> <code>None</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of written file paths (absolute)</p> <p>Raises:</p> Type Description <code>ArtifactError</code> <p>If directory creation fails, files exist without force=True,           template rendering fails, or file write fails</p>"},{"location":"reference/api/capability/","title":"Capability Module","text":"<p>The capability module provides feature compatibility checking and reporting.</p>"},{"location":"reference/api/capability/#capability-checker","title":"Capability Checker","text":""},{"location":"reference/api/capability/#strands_cli.capability.checker","title":"<code>strands_cli.capability.checker</code>","text":"<p>Capability checking for compatibility analysis.</p> <p>Analyzes validated workflow specs to determine if they can be executed with current capabilities. Gracefully rejects unsupported features with structured error reports rather than silently ignoring them.</p> <p>Supported Features (Phase 9):     - Multiple agents (for all pattern types)     - Pattern: chain (multi-step), workflow (multi-task with DAG), routing, parallel, evaluator_optimizer, orchestrator_workers, graph     - Providers: bedrock, ollama, openai     - Python tools: strands_tools.{http_request, file_read, file_write, calculator, current_time}.{function}     - HTTP executors: full support     - MCP tools: stdio and HTTPS transports     - Secrets: source=env only     - Skills: metadata injection (no code execution)</p> <p>Unsupported (with remediation):     - Non-env secret sources     - Non-allowlisted Python callables</p>"},{"location":"reference/api/capability/#strands_cli.capability.checker.check_capability","title":"<code>check_capability(spec)</code>","text":"<p>Check if a spec is compatible with current capabilities.</p> <p>Orchestrates validation across all feature areas: - Agent configuration - Provider requirements - Pattern type and configuration - Secrets and tools</p> <p>For supported specs, extracts normalized execution parameters. For unsupported specs, generates detailed issues with JSONPointer locations.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>Spec</code> <p>Loaded and validated workflow spec (passed schema validation)</p> required <p>Returns:</p> Type Description <code>CapabilityReport</code> <p>CapabilityReport with:</p> <code>CapabilityReport</code> <ul> <li>supported: True if fully compatible, False otherwise</li> </ul> <code>CapabilityReport</code> <ul> <li>issues: List of incompatibilities with remediation guidance</li> </ul> <code>CapabilityReport</code> <ul> <li>normalized: Extracted parameters for execution (if supported)</li> </ul>"},{"location":"reference/api/capability/#strands_cli.capability.checker.detect_cycles_in_dag","title":"<code>detect_cycles_in_dag(tasks)</code>","text":"<p>Detect cycles in workflow task dependencies using Kahn's algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>list[Any]</code> <p>List of WorkflowTask objects with id and deps fields</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of error messages describing cycles found (empty if no cycles)</p>"},{"location":"reference/api/capability/#capability-reporter","title":"Capability Reporter","text":""},{"location":"reference/api/capability/#strands_cli.capability.reporter","title":"<code>strands_cli.capability.reporter</code>","text":"<p>Generate capability reports for unsupported features.</p> <p>Provides human-readable and machine-readable reports when workflows contain unsupported features. Reports include:</p> <ul> <li>Spec fingerprint (SHA-256) for tracking</li> <li>Detailed issue list with JSONPointer locations</li> <li>Specific remediation steps for each issue</li> <li>Minimal working example for reference</li> </ul> Report Formats <ul> <li>Markdown: Human-readable with formatting for readability</li> <li>JSON: Structured data for programmatic processing</li> </ul>"},{"location":"reference/api/capability/#strands_cli.capability.reporter.generate_json_report","title":"<code>generate_json_report(spec_path, spec_content, report)</code>","text":"<p>Generate a JSON report for unsupported features.</p> <p>Parameters:</p> Name Type Description Default <code>spec_path</code> <code>str</code> <p>Path to the original spec file</p> required <code>spec_content</code> <code>str</code> <p>Raw content of the spec file</p> required <code>report</code> <code>CapabilityReport</code> <p>Capability report with issues</p> required <p>Returns:</p> Type Description <code>str</code> <p>JSON-formatted report</p>"},{"location":"reference/api/capability/#strands_cli.capability.reporter.generate_markdown_report","title":"<code>generate_markdown_report(spec_path, spec_content, report)</code>","text":"<p>Generate a Markdown report for unsupported features.</p> <p>Creates a comprehensive report with: - Spec metadata (path, fingerprint, issue count) - Detailed issue breakdown with remediation steps - Minimal working example - Next steps guidance</p> <p>Parameters:</p> Name Type Description Default <code>spec_path</code> <code>str</code> <p>Path to the original spec file (for reference)</p> required <code>spec_content</code> <code>str</code> <p>Raw content of the spec file (for fingerprinting)</p> required <code>report</code> <code>CapabilityReport</code> <p>Capability report with unsupported feature issues</p> required <p>Returns:</p> Type Description <code>str</code> <p>Markdown-formatted report suitable for file output or display</p>"},{"location":"reference/api/config/","title":"Configuration","text":"<p>Environment variable configuration using Pydantic Settings.</p>"},{"location":"reference/api/config/#settings","title":"Settings","text":"<p>See also: Environment Variables Reference</p>"},{"location":"reference/api/config/#strands_cli.config","title":"<code>strands_cli.config</code>","text":"<p>Configuration management for Strands CLI.</p> <p>Provides environment-based configuration using Pydantic Settings. All settings can be overridden via environment variables with STRANDS_ prefix.</p> Example <p>export STRANDS_AWS_REGION=us-west-2 export STRANDS_BEDROCK_MODEL_ID=anthropic.claude-3-haiku-20240307-v1:0 export STRANDS_LOG_LEVEL=DEBUG</p>"},{"location":"reference/api/config/#strands_cli.config.StrandsConfig","title":"<code>StrandsConfig</code>","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Configuration settings for Strands CLI.</p> <p>Loads settings from environment variables (STRANDS_ prefix) and .env file. Settings cascade: .env file &lt; environment variables &lt; explicit overrides.</p> Configuration Groups <p>AWS: Region and profile for Bedrock access Bedrock: Default model selection Workflow: Schema path for validation Cache: Enable/disable and directory configuration Observability: OTEL endpoint and logging preferences</p>"},{"location":"reference/api/config/#strands_cli.config.StrandsConfig.config_dir","title":"<code>config_dir</code>  <code>property</code>","text":"<p>Get platform-specific config directory.</p> <p>Returns:</p> Type Description <code>Path</code> <p>Path to config directory:</p> <code>Path</code> <ul> <li>Linux/macOS: ~/.config/strands</li> </ul> <code>Path</code> <ul> <li>Windows: %APPDATA%\\strands</li> </ul>"},{"location":"reference/api/config/#strands_cli.config.StrandsConfig.data_dir","title":"<code>data_dir</code>  <code>property</code>","text":"<p>Get platform-specific data directory for session storage.</p> <p>Returns:</p> Type Description <code>Path</code> <p>Path to data directory:</p> <code>Path</code> <ul> <li>Linux/macOS: ~/.local/share/strands</li> </ul> <code>Path</code> <ul> <li>Windows: %LOCALAPPDATA%\\strands</li> </ul>"},{"location":"reference/api/exec/","title":"Execution Module","text":"<p>The execution module contains all workflow pattern executors and execution utilities.</p>"},{"location":"reference/api/exec/#single-agent","title":"Single Agent","text":""},{"location":"reference/api/exec/#strands_cli.exec.single_agent","title":"<code>strands_cli.exec.single_agent</code>","text":"<p>Single-agent workflow executor.</p> <p>Executes single-agent workflows with retry logic and error handling. Supports both chain and workflow patterns (limited to 1 step/task).</p> Execution Flow <ol> <li>Extract agent and pattern configuration</li> <li>Render task input with Jinja2 template (inject variables)</li> <li>Get or build Strands Agent with tools and model (via AgentCache)</li> <li>Execute agent asynchronously with retry logic</li> <li>Capture response and timing information</li> <li>Return RunResult with success/error status</li> </ol> Phase 3 Optimizations <ul> <li>Converted to async function to eliminate per-call event loop creation</li> <li>Integrated AgentCache to enable agent reuse (preparation for future multi-step)</li> <li>Proper cleanup of HTTP clients via AgentCache.close()</li> </ul> Retry Strategy <ul> <li>Exponential backoff for transient errors (timeout, connection)</li> <li>Configurable via spec.runtime.failure_policy</li> <li>Default: 3 attempts, 1s-60s backoff</li> </ul>"},{"location":"reference/api/exec/#strands_cli.exec.single_agent.ExecutionError","title":"<code>ExecutionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when workflow execution fails.</p>"},{"location":"reference/api/exec/#strands_cli.exec.single_agent.run_single_agent","title":"<code>run_single_agent(spec, variables=None, session_state=None, session_repo=None)</code>  <code>async</code>","text":"<p>Execute a single-agent workflow asynchronously.</p> <p>Complete execution workflow: 1. Extract agent configuration and pattern details 2. Render task input using Jinja2 with variables from spec.inputs.values 3. Get or build Strands Agent with model, tools, and system prompt (via AgentCache) 4. Configure retry policy from spec.runtime.failure_policy 5. Execute agent asynchronously with exponential backoff retry 6. Capture timing (start, end, duration) and response 7. Clean up HTTP clients and cached resources 8. Return RunResult with success status and artifacts</p> <p>Phase 3 Changes: - Converted to async function (no more asyncio.run() inside executor) - Added AgentCache for agent reuse and proper cleanup - HTTP clients properly closed in finally block</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>Spec</code> <p>Validated workflow spec (must pass capability check first)</p> required <code>variables</code> <code>dict[str, str] | None</code> <p>Optional variables from CLI (already merged into spec.inputs)</p> <code>None</code> <code>session_state</code> <code>SessionState | None</code> <p>Existing session state for resume (None = fresh start)</p> <code>None</code> <code>session_repo</code> <code>FileSessionRepository | None</code> <p>Repository for checkpointing (None = no checkpoints)</p> <code>None</code> <p>Returns:</p> Type Description <code>RunResult</code> <p>RunResult with:</p> <code>RunResult</code> <ul> <li>success: True if agent executed without errors</li> </ul> <code>RunResult</code> <ul> <li>last_response: Agent's final output (for artifact templating)</li> </ul> <code>RunResult</code> <ul> <li>error: Error message if execution failed</li> </ul> <code>RunResult</code> <ul> <li>Timing information (started_at, completed_at, duration_seconds)</li> </ul> <p>Raises:</p> Type Description <code>ExecutionError</code> <p>If pattern is unsupported, template rendering fails,            or agent construction fails (not for agent runtime errors)</p>"},{"location":"reference/api/exec/#chain-pattern","title":"Chain Pattern","text":""},{"location":"reference/api/exec/#strands_cli.exec.chain","title":"<code>strands_cli.exec.chain</code>","text":"<p>Multi-step chain executor.</p> <p>Executes sequential multi-step chains with context passing between steps. Each step receives the outputs of previous steps via template variables.</p> Execution Flow <ol> <li>Validate chain configuration (at least 1 step)</li> <li>For each step in sequence:     a. Build template context (prior step responses + user variables + step.vars)     b. Render step input with Jinja2     c. Build/reuse agent for step (with optional tool_overrides)     d. Execute agent asynchronously with retry logic     e. Track token budget and warn at 80% threshold     f. Capture step response and timing</li> <li>Return RunResult with final step response and all step history</li> </ol> Context Threading <ul> <li>Explicit step references: {{ steps[0].response }}, {{ steps[1].response }}</li> <li>Each step receives all prior step outputs in template context</li> <li>Optional per-step variable overrides via step.vars</li> <li>Fail-fast: Stop on first step failure</li> </ul> Budget Enforcement <ul> <li>Track cumulative tokens across all steps</li> <li>Warn at 80% of budgets.max_tokens</li> <li>Hard stop at 100% (if configured)</li> </ul>"},{"location":"reference/api/exec/#strands_cli.exec.chain.ChainExecutionError","title":"<code>ChainExecutionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when chain execution fails.</p>"},{"location":"reference/api/exec/#strands_cli.exec.chain.run_chain","title":"<code>run_chain(spec, variables=None, session_state=None, session_repo=None, hitl_response=None)</code>  <code>async</code>","text":"<p>Execute a multi-step chain workflow with optional session persistence and HITL support.</p> <p>Executes steps sequentially with context passing. Each step receives all prior step responses via {{ steps[n].response }} template variables.</p> Phase 1 HITL Support <ul> <li>Detects HITL steps (type: hitl) and pauses execution</li> <li>Saves session state before displaying HITL prompt</li> <li>Exits with EX_HITL_PAUSE for user to provide response</li> <li>Resumes with hitl_response and injects into step_history</li> </ul> Phase 4 Performance Optimizations <ul> <li>Agent caching: Reuses agents across steps with same (agent_id, tools)</li> <li>Single event loop: No per-step asyncio.run() overhead</li> <li>HTTP client cleanup: Proper resource management via AgentCache.close()</li> </ul> Phase 2 Session Support <ul> <li>Resume from checkpoint: Skip completed steps on resume</li> <li>Incremental checkpointing: Save state after each step</li> <li>Agent session restoration: Restore conversation history via Strands SDK</li> </ul> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>Spec</code> <p>Workflow spec with chain pattern</p> required <code>variables</code> <code>dict[str, str] | None</code> <p>Optional CLI --var overrides</p> <code>None</code> <code>session_state</code> <code>SessionState | None</code> <p>Existing session state for resume (None = fresh start)</p> <code>None</code> <code>session_repo</code> <code>FileSessionRepository | None</code> <p>Repository for checkpointing (None = no checkpoints)</p> <code>None</code> <code>hitl_response</code> <code>str | None</code> <p>User response when resuming from HITL pause (None = not HITL resume)</p> <code>None</code> <p>Returns:</p> Type Description <code>RunResult</code> <p>RunResult with final step response and execution metadata</p> <p>Raises:</p> Type Description <code>ChainExecutionError</code> <p>If chain execution fails at any step</p> <code>ValueError</code> <p>If session_state and session_repo not both provided or both None</p>"},{"location":"reference/api/exec/#workflow-pattern","title":"Workflow Pattern","text":""},{"location":"reference/api/exec/#strands_cli.exec.workflow","title":"<code>strands_cli.exec.workflow</code>","text":"<p>Multi-task workflow executor with DAG support.</p> <p>Executes workflows with task dependencies using topological sort. Tasks execute in dependency order with parallel execution where possible.</p> Execution Flow <ol> <li>Validate workflow configuration (at least 1 task, no cycles)</li> <li>Build task dependency graph and topological sort</li> <li>Execute tasks in layers (parallel where deps allow):     a. Build template context (completed task responses + user variables)     b. Render task input with Jinja2     c. Build agent for task     d. Execute agent asynchronously     e. Track token budget and warn at 80% threshold     f. Capture task response and timing</li> <li>Return RunResult with final task response (or aggregated result)</li> </ol> Dependency Resolution <ul> <li>Topological sort ensures tasks run after all dependencies complete</li> <li>Parallel execution within each dependency layer (respecting max_parallel)</li> <li>Fail-fast: Stop on first task failure</li> </ul> Context Threading <ul> <li>{{ tasks..response }} - Access completed task outputs <li>{{ tasks..status }} - Task completion status (success/failed)"},{"location":"reference/api/exec/#strands_cli.exec.workflow.WorkflowExecutionError","title":"<code>WorkflowExecutionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when workflow execution fails.</p>"},{"location":"reference/api/exec/#strands_cli.exec.workflow.run_workflow","title":"<code>run_workflow(spec, variables=None, session_state=None, session_repo=None)</code>  <code>async</code>","text":"<p>Execute a multi-task workflow with DAG dependencies and optional session persistence.</p> <p>Executes tasks in topological order with parallel execution within each layer. Tasks can reference completed task outputs via {{ tasks..response }}. Phase 5 Performance Optimizations <ul> <li>Agent caching: Reuses agents across tasks with same (agent_id, tools)</li> <li>Single event loop: No per-layer asyncio.run() overhead</li> <li>HTTP client cleanup: Proper resource management via AgentCache.close()</li> </ul> <p>Phase 3.1 Session Support:     - Resume from checkpoint: Skip completed tasks on resume     - Layer checkpointing: Save state after each layer completes     - Partial layer resume: Handle tasks completed mid-layer</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>Spec</code> <p>Workflow spec with workflow pattern</p> required <code>variables</code> <code>dict[str, str] | None</code> <p>Optional CLI --var overrides</p> <code>None</code> <code>session_state</code> <code>SessionState | None</code> <p>Existing session state for resume (None = fresh start)</p> <code>None</code> <code>session_repo</code> <code>FileSessionRepository | None</code> <p>Repository for checkpointing (None = no checkpoints)</p> <code>None</code> <p>Returns:</p> Type Description <code>RunResult</code> <p>RunResult with final task response and execution metadata</p> <p>Raises:</p> Type Description <code>WorkflowExecutionError</code> <p>If workflow execution fails</p> <code>ValueError</code> <p>If session_state and session_repo not both provided or both None</p>"},{"location":"reference/api/exec/#routing-pattern","title":"Routing Pattern","text":""},{"location":"reference/api/exec/#strands_cli.exec.routing","title":"<code>strands_cli.exec.routing</code>","text":"<p>Routing pattern executor.</p> <p>Executes routing pattern with router agent classification and conditional route execution. Router agent analyzes input and returns JSON decision specifying which route to execute.</p> Execution Flow <ol> <li>Validate routing configuration (router + routes)</li> <li>Execute router agent with classification prompt</li> <li>Parse router response to extract JSON {\"route\": \"\"} <li>Retry on malformed JSON (up to max_retries, default 2)</li> <li>Validate selected route exists</li> <li>Execute selected route's steps as a chain</li> <li>Return RunResult with route execution outcome</li> Router Output <ul> <li>Expected JSON: {\"route\": \"\"} <li>Parsing strategies: direct JSON, extract JSON block, regex extraction</li> <li>Retry with clarification prompt on malformed responses</li> Error Handling <ul> <li>Malformed JSON \u2192 retry with clarification (up to max_retries)</li> <li>Invalid route name \u2192 fail with ExecutionError listing valid routes</li> <li>No fallback behavior (explicit failures only)</li> </ul>"},{"location":"reference/api/exec/#strands_cli.exec.routing.RoutingExecutionError","title":"<code>RoutingExecutionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when routing execution fails.</p>"},{"location":"reference/api/exec/#strands_cli.exec.routing.run_routing","title":"<code>run_routing(spec, variables=None, session_state=None, session_repo=None)</code>  <code>async</code>","text":"<p>Execute a routing pattern workflow with optional session persistence.</p> <p>Phase 6 Performance Optimization: - Async execution with shared AgentCache for router and route execution - Single event loop eliminates per-route loop churn - Agents reused when router and route use same agent configuration</p> <p>Phase 3.1 Session Support: - Resume from checkpoint: Skip router if decision already made - Router decision checkpoint: Save route choice before execution - Route execution with resume: Delegate to chain resume logic</p> <p>Executes router agent to classify input, then runs the selected route's chain. Router decision is injected into route context as {{ router.chosen_route }}.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>Spec</code> <p>Workflow spec with routing pattern</p> required <code>variables</code> <code>dict[str, str] | None</code> <p>Optional CLI --var overrides</p> <code>None</code> <code>session_state</code> <code>SessionState | None</code> <p>Existing session state for resume (None = fresh start)</p> <code>None</code> <code>session_repo</code> <code>FileSessionRepository | None</code> <p>Repository for checkpointing (None = no checkpoints)</p> <code>None</code> <p>Returns:</p> Type Description <code>RunResult</code> <p>RunResult with selected route execution outcome</p> <p>Raises:</p> Type Description <code>RoutingExecutionError</code> <p>If routing execution fails</p> <code>ValueError</code> <p>If session_state and session_repo not both provided or both None</p>"},{"location":"reference/api/exec/#parallel-pattern","title":"Parallel Pattern","text":""},{"location":"reference/api/exec/#strands_cli.exec.parallel","title":"<code>strands_cli.exec.parallel</code>","text":"<p>Parallel branch executor.</p> <p>Executes parallel branches concurrently with optional reduce step for aggregation. Each branch executes its steps sequentially while branches run in parallel.</p> Execution Flow <ol> <li>Validate parallel configuration (at least 2 branches)</li> <li>Execute all branches concurrently:     a. Build branch context (user variables only - isolated from other branches)     b. Execute branch steps sequentially (like chain)     c. Track tokens per branch     d. Respect max_parallel limit via semaphore</li> <li>Collect all branch results in alphabetical order by branch ID</li> <li>Optionally execute reduce step with {{ branches..response }} context <li>Return RunResult with final response (reduced or aggregated)</li> Branch Execution <ul> <li>Each branch is independent (no cross-branch context during execution)</li> <li>Steps within a branch execute sequentially with {{ steps[n].response }} access</li> <li>Fail-fast: First branch failure stops all branches (asyncio.gather with return_exceptions=False)</li> </ul> Budget Enforcement <ul> <li>Track cumulative tokens across all branches and reduce step</li> <li>Warn at 80% of budgets.max_tokens</li> <li>Hard stop at 100% (if configured)</li> </ul> Reduce Step <ul> <li>Aggregates all branch outputs via template context</li> <li>Template access: {{ branches.web.response }}, {{ branches['docs'].status }}</li> <li>Branch results ordered alphabetically by branch ID for determinism</li> </ul>"},{"location":"reference/api/exec/#strands_cli.exec.parallel.ParallelExecutionError","title":"<code>ParallelExecutionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when parallel execution fails.</p>"},{"location":"reference/api/exec/#strands_cli.exec.parallel.run_parallel","title":"<code>run_parallel(spec, variables=None, session_state=None, session_repo=None)</code>  <code>async</code>","text":"<p>Execute parallel pattern with concurrent branches and optional session persistence.</p> <p>Phase 6 Performance Optimization: - Async execution with shared AgentCache across all branches and reduce step - Single event loop eliminates per-branch loop churn - Agents reused when branches use same agent configuration</p> <p>Phase 3.2 Session Support: - Resume from checkpoint: Skip completed branches on resume - Branch-level checkpointing: Save state after all branches complete - Reduce gate: Execute reduce step once after all branches</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>Spec</code> <p>Validated workflow spec with parallel pattern</p> required <code>variables</code> <code>dict[str, str] | None</code> <p>CLI --var overrides</p> <code>None</code> <code>session_state</code> <code>SessionState | None</code> <p>Existing session state for resume (None = fresh start)</p> <code>None</code> <code>session_repo</code> <code>FileSessionRepository | None</code> <p>Repository for checkpointing (None = no checkpoints)</p> <code>None</code> <p>Returns:</p> Type Description <code>RunResult</code> <p>RunResult with final response (reduced or aggregated)</p> <p>Raises:</p> Type Description <code>ParallelExecutionError</code> <p>If validation, execution, or reduce fails</p> <code>ValueError</code> <p>If session_state and session_repo not both provided or both None</p>"},{"location":"reference/api/exec/#evaluator-optimizer-pattern","title":"Evaluator-Optimizer Pattern","text":""},{"location":"reference/api/exec/#strands_cli.exec.evaluator_optimizer","title":"<code>strands_cli.exec.evaluator_optimizer</code>","text":"<p>Evaluator-optimizer pattern executor.</p> <p>Executes iterative refinement pattern with producer-evaluator feedback loops. Producer generates draft, evaluator scores and critiques, producer revises based on feedback.</p> Execution Flow <ol> <li>Validate evaluator-optimizer configuration</li> <li>Execute producer agent to generate initial draft</li> <li>Evaluation loop (up to max_iters):     a. Execute evaluator agent with current draft     b. Parse JSON response: {\"score\": int, \"issues\": [...], \"fixes\": [...]}     c. Retry once on malformed JSON with clarification prompt     d. If score &gt;= min_score \u2192 SUCCESS, return draft     e. If score &lt; min_score \u2192 prepare revision context     f. Execute producer agent with revision prompt + evaluator feedback</li> <li>If max_iters exhausted \u2192 FAILURE with detailed iteration history</li> </ol> Evaluator Output <ul> <li>Expected JSON: {\"score\": 0-100, \"issues\": [\"...\"], \"fixes\": [\"...\"]}</li> <li>Parsing strategies: direct JSON, extract JSON block, regex extraction</li> <li>Retry once with clarification prompt on malformed responses</li> </ul> <p>Template Context (Revision):     - {{ draft }}: Current draft text     - {{ evaluation.score }}: Current score (0-100)     - {{ evaluation.issues }}: List of identified issues     - {{ evaluation.fixes }}: List of suggested fixes     - {{ iteration }}: Current iteration number (1-based)</p> Error Handling <ul> <li>Malformed evaluator JSON \u2192 retry once with clarification</li> <li>Max iterations exhausted \u2192 raise EvaluatorOptimizerExecutionError with history</li> <li>No fallback behavior (explicit failures only)</li> </ul>"},{"location":"reference/api/exec/#strands_cli.exec.evaluator_optimizer.EvaluatorOptimizerExecutionError","title":"<code>EvaluatorOptimizerExecutionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when evaluator-optimizer execution fails.</p>"},{"location":"reference/api/exec/#strands_cli.exec.evaluator_optimizer.run_evaluator_optimizer","title":"<code>run_evaluator_optimizer(spec, variables=None, session_state=None, session_repo=None)</code>  <code>async</code>","text":"<p>Execute evaluator-optimizer pattern workflow with optional session persistence.</p> <p>Phase 4 Implementation: - Producer-evaluator feedback loops with iterative refinement - JSON parsing with single retry on malformed evaluator responses - Nested template context: {{ evaluation.score }}, {{ evaluation.issues }}, {{ evaluation.fixes }} - Fail on max_iters exhaustion with detailed iteration history - Agent caching for producer/evaluator reuse - Cumulative token budget tracking across all iterations</p> <p>Phase 3.3 Session Support: - Resume from checkpoint: Skip completed iterations on resume - Incremental checkpointing: Save state after each iteration - Iteration history restoration: Preserve draft and evaluation history - Acceptance check on resume: Exit early if already accepted</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>Spec</code> <p>Validated workflow specification</p> required <code>variables</code> <code>dict[str, str] | None</code> <p>User-provided template variables</p> <code>None</code> <code>session_state</code> <code>SessionState | None</code> <p>Existing session state for resume (None = fresh start)</p> <code>None</code> <code>session_repo</code> <code>FileSessionRepository | None</code> <p>Repository for checkpointing (None = no checkpoints)</p> <code>None</code> <p>Returns:</p> Type Description <code>RunResult</code> <p>RunResult with final draft and execution metadata</p> <p>Raises:</p> Type Description <code>EvaluatorOptimizerExecutionError</code> <p>On configuration errors, max iterations, or unrecoverable failures</p> <code>ValueError</code> <p>If session_state and session_repo not both provided or both None</p>"},{"location":"reference/api/exec/#orchestrator-workers-pattern","title":"Orchestrator-Workers Pattern","text":""},{"location":"reference/api/exec/#strands_cli.exec.orchestrator_workers","title":"<code>strands_cli.exec.orchestrator_workers</code>","text":"<p>Orchestrator-workers executor.</p> <p>Implements dynamic task delegation with worker pools. The orchestrator agent breaks down tasks into subtasks and delegates to workers for parallel execution.</p> Execution Flow <ol> <li>Orchestrator invocation: Request JSON array of subtasks</li> <li>Worker execution: Execute subtasks in parallel (respecting max_workers)</li> <li>Track rounds: Count orchestrator delegation cycles (not worker count)</li> <li>Optional reduce: Aggregate worker outputs</li> <li>Optional writeup: Final synthesis step</li> </ol> Orchestrator Protocol <ul> <li>Expected JSON response: [{\"task\": \"description\"}, ...]</li> <li>Retry on malformed JSON (up to 2 retries with clarification)</li> <li>Empty array [] signals \"no work needed\" (success)</li> </ul> Worker Execution <ul> <li>Workers execute in parallel batches (semaphore control via max_workers)</li> <li>Indexed template access: {{ workers[0].response }}, {{ workers[1].status }}</li> <li>Fail-fast: First worker failure cancels all remaining workers</li> </ul> Round Semantics <ul> <li>Round = orchestrator delegation cycle (not individual worker executions)</li> <li>max_rounds limits total orchestrator invocations</li> <li>Single round can spawn multiple workers</li> </ul> Budget Enforcement <ul> <li>Cumulative token tracking across orchestrator + workers + reduce + writeup</li> <li>Warn at 80%, hard stop at 100%</li> </ul>"},{"location":"reference/api/exec/#strands_cli.exec.orchestrator_workers.OrchestratorExecutionError","title":"<code>OrchestratorExecutionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when orchestrator execution fails.</p>"},{"location":"reference/api/exec/#strands_cli.exec.orchestrator_workers.run_orchestrator_workers","title":"<code>run_orchestrator_workers(spec, variables=None, session_state=None, session_repo=None)</code>  <code>async</code>","text":"<p>Execute orchestrator-workers pattern workflow with optional session persistence.</p> <p>Phase 3.2 Session Support: - Resume from checkpoint: Skip orchestrator if workers already executed - Worker-level checkpointing: Save state after workers complete - Reduce/writeup gates: Execute once after workers</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>Spec</code> <p>Validated workflow specification</p> required <code>variables</code> <code>dict[str, str] | None</code> <p>CLI variable overrides (from --var flags)</p> <code>None</code> <code>session_state</code> <code>SessionState | None</code> <p>Existing session state for resume (None = fresh start)</p> <code>None</code> <code>session_repo</code> <code>FileSessionRepository | None</code> <p>Repository for checkpointing (None = no checkpoints)</p> <code>None</code> <p>Returns:</p> Type Description <code>RunResult</code> <p>RunResult with final response and execution metadata</p> <p>Raises:</p> Type Description <code>OrchestratorExecutionError</code> <p>If orchestrator or worker execution fails</p> <code>ValueError</code> <p>If session_state and session_repo not both provided or both None</p>"},{"location":"reference/api/exec/#graph-pattern","title":"Graph Pattern","text":""},{"location":"reference/api/exec/#strands_cli.exec.graph","title":"<code>strands_cli.exec.graph</code>","text":"<p>Graph pattern executor.</p> <p>Executes graph-based workflows with nodes, edges, and conditional transitions. Supports state machines, decision trees, and iterative refinement with cycle protection.</p> Execution Flow <ol> <li>Validate graph configuration (nodes, edges)</li> <li>Start at entry node (first in YAML order)</li> <li>For each node execution:     a. Check iteration limits (global max_steps + per-node max_iterations)     b. Build template context with {{ nodes..response }} access     c. Execute node agent with retry logic     d. Find next node via edge traversal:         - Evaluate static 'to' edges (sequential execution)         - Evaluate conditional 'choose' edges (first match wins)     e. Track token budget and warn at 80% threshold <li>Terminate at terminal node (no outgoing edges)</li> <li>Return RunResult with terminal node response</li> Edge Traversal <ul> <li>Static edges: Execute 'to' targets sequentially in array order</li> <li>Conditional edges: Evaluate 'choose' conditions in order, transition to first match</li> <li>Special 'else' keyword: Always matches (default fallback)</li> <li>Terminal nodes: Nodes with no outgoing edges (workflow completion)</li> </ul> Cycle Protection <ul> <li>Global limit: runtime.budgets.max_steps (default 100) total node executions</li> <li>Per-node limit: pattern.config.max_iterations (default 10) visits per node</li> <li>Prevents infinite loops with clear error messages</li> </ul> Template Context <ul> <li>{{ nodes..response }}: Access node outputs <li>{{ nodes..agent }}: Agent used by node <li>{{ nodes..status }}: Execution status (success/error) <li>{{ nodes..iteration }}: Number of times node executed (for loops)"},{"location":"reference/api/exec/#strands_cli.exec.graph.GraphExecutionError","title":"<code>GraphExecutionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when graph execution fails.</p>"},{"location":"reference/api/exec/#strands_cli.exec.graph.run_graph","title":"<code>run_graph(spec, variables=None, session_state=None, session_repo=None)</code>  <code>async</code>","text":"<p>Execute a graph pattern workflow with optional session persistence.</p> <p>Executes nodes via edge traversal with condition evaluation and cycle protection.</p> <p>Phase 3.3 Session Support: - Resume from checkpoint: Restore node results and execution path - Incremental checkpointing: Save state after each node execution - Iteration count restoration: Preserve per-node visit counts for cycle protection - Deterministic edge evaluation: Resume from current_node with full context</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>Spec</code> <p>Workflow spec with graph pattern configuration</p> required <code>variables</code> <code>dict[str, str] | None</code> <p>User-provided variables from --var flags</p> <code>None</code> <code>session_state</code> <code>SessionState | None</code> <p>Existing session state for resume (None = fresh start)</p> <code>None</code> <code>session_repo</code> <code>FileSessionRepository | None</code> <p>Repository for checkpointing (None = no checkpoints)</p> <code>None</code> <p>Returns:</p> Type Description <code>RunResult</code> <p>RunResult with terminal node response and execution metadata</p> <p>Raises:</p> Type Description <code>GraphExecutionError</code> <p>If graph configuration invalid or execution fails</p> <code>ValueError</code> <p>If session_state and session_repo not both provided or both None</p>"},{"location":"reference/api/exec/#conditions","title":"Conditions","text":""},{"location":"reference/api/exec/#strands_cli.exec.conditions","title":"<code>strands_cli.exec.conditions</code>","text":"<p>Condition evaluation for graph pattern.</p> <p>Provides safe evaluation of conditional expressions in graph edges. Uses Jinja2 template engine for expression evaluation with restricted environment.</p>"},{"location":"reference/api/exec/#strands_cli.exec.conditions.ConditionEvaluationError","title":"<code>ConditionEvaluationError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when condition evaluation fails.</p>"},{"location":"reference/api/exec/#strands_cli.exec.conditions.evaluate_condition","title":"<code>evaluate_condition(when_expr, context)</code>","text":"<p>Evaluate a conditional expression using Jinja2.</p> <p>Security: Uses SandboxedEnvironment to prevent code execution. Blocks dangerous patterns like class, eval, exec, etc.</p> <p>Supports: - Comparisons: ==, !=, &lt;, &lt;=, &gt;, &gt;= - Boolean operators: and, or, not - Template variables: {{ nodes.analyze.score }} - Special keyword: \"else\" (always true) - Safe filters: default, length, lower, upper, search</p> <p>Parameters:</p> Name Type Description Default <code>when_expr</code> <code>str</code> <p>Condition expression or \"else\"</p> required <code>context</code> <code>dict[str, Any]</code> <p>Template context with variables (nodes, steps, etc.)</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if condition evaluates to true, False otherwise</p> <p>Raises:</p> Type Description <code>ConditionEvaluationError</code> <p>If expression is malformed, contains dangerous patterns, or evaluation fails</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; evaluate_condition(\"else\", {})\nTrue\n&gt;&gt;&gt; evaluate_condition(\"score &gt;= 85\", {\"score\": 90})\nTrue\n&gt;&gt;&gt; evaluate_condition(\"nodes.analyze.score &gt;= 85\", {\"nodes\": {\"analyze\": {\"score\": 90}}})\nTrue\n</code></pre>"},{"location":"reference/api/exec/#strands_cli.exec.conditions.validate_condition_syntax","title":"<code>validate_condition_syntax(when_expr)</code>","text":"<p>Validate condition syntax without evaluating.</p> <p>Useful for early validation without requiring full context.</p> <p>Parameters:</p> Name Type Description Default <code>when_expr</code> <code>str</code> <p>Condition expression to validate</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Tuple of (is_valid, error_message)</p> <code>str | None</code> <ul> <li>(True, None) if valid</li> </ul> <code>tuple[bool, str | None]</code> <ul> <li>(False, error_message) if invalid</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; validate_condition_syntax(\"score &gt;= 85\")\n(True, None)\n&gt;&gt;&gt; validate_condition_syntax(\"invalid syntax }\")\n(False, \"...\")\n</code></pre>"},{"location":"reference/api/exec/#hooks","title":"Hooks","text":""},{"location":"reference/api/exec/#strands_cli.exec.hooks","title":"<code>strands_cli.exec.hooks</code>","text":"<p>Context management hooks for intelligent workflow execution.</p> <p>This module provides hooks that integrate with Strands SDK's hook system to enable proactive context management during long-running workflows.</p> Hooks <p>ProactiveCompactionHook: Triggers context compaction before token overflow NotesAppenderHook: Appends structured notes after each agent invocation</p>"},{"location":"reference/api/exec/#strands_cli.exec.hooks.NotesAppenderHook","title":"<code>NotesAppenderHook</code>","text":"<p>               Bases: <code>HookProvider</code></p> <p>Append structured notes after each agent invocation.</p> <p>Captures execution history (input, tools used, outcome) and persists to a Markdown notes file for cross-step continuity and multi-session workflows.</p> <p>Error Handling Policy: Note write failures are logged but do not raise exceptions. This ensures workflow execution continues even if notes persistence fails (e.g., due to file permissions). Notes are considered auxiliary/observability features, not critical to workflow success.</p> <p>Attributes:</p> Name Type Description <code>notes_manager</code> <p>NotesManager instance for file operations</p> <code>step_counter_ref</code> <p>Mutable list container for tracking step count across invocations</p> <code>agent_tools</code> <p>Mapping of agent_id to list of tool names for tool tracking</p> Example <p>step_counter = [0] notes_manager = NotesManager(\"artifacts/notes.md\") agent_tools = {\"research-agent\": [\"http_request\"]} hook = NotesAppenderHook(notes_manager, step_counter, agent_tools) agent = Agent(name=\"research-agent\", model=model, hooks=[hook])</p>"},{"location":"reference/api/exec/#strands_cli.exec.hooks.NotesAppenderHook.__init__","title":"<code>__init__(notes_manager, step_counter_ref, agent_tools=None)</code>","text":"<p>Initialize the notes appender hook.</p> <p>Parameters:</p> Name Type Description Default <code>notes_manager</code> <code>NotesManager</code> <p>NotesManager instance for writing notes</p> required <code>step_counter_ref</code> <code>list[int]</code> <p>Mutable list [counter] for tracking step index across invocations</p> required <code>agent_tools</code> <code>dict[str, list[str]] | None</code> <p>Optional mapping of agent_id to list of configured tool names</p> <code>None</code>"},{"location":"reference/api/exec/#strands_cli.exec.hooks.NotesAppenderHook.register_hooks","title":"<code>register_hooks(registry, **kwargs)</code>","text":"<p>Register hook callbacks with the agent's hook registry.</p> <p>Parameters:</p> Name Type Description Default <code>registry</code> <code>HookRegistry</code> <p>Hook registry from the agent</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments (not used)</p> <code>{}</code>"},{"location":"reference/api/exec/#strands_cli.exec.hooks.ProactiveCompactionHook","title":"<code>ProactiveCompactionHook</code>","text":"<p>               Bases: <code>HookProvider</code></p> <p>Proactively trigger context compaction before token overflow.</p> <p>Monitors token usage after each agent invocation via accumulated usage metrics and triggers compaction when approaching the configured threshold. This prevents reactive overflow handling and enables controlled context reduction.</p> <p>Token Counting Strategy: Uses provider-reported metrics when available, falls back to TokenCounter estimation when metrics are missing or stale. This ensures reliable compaction triggering across all providers (Bedrock, Ollama, OpenAI).</p> <p>Single-Fire Behavior: Compaction triggers only once per hook instance to avoid repeated compaction cycles within the same workflow. For multi-session workflows or workflows requiring multiple compactions, create a new hook instance.</p> <p>Attributes:</p> Name Type Description <code>threshold_tokens</code> <p>Token count at which to trigger compaction</p> <code>model_id</code> <p>Model identifier for TokenCounter fallback</p> <code>compacted</code> <p>Flag tracking whether compaction has been triggered (single-fire)</p> <code>token_counter</code> <code>TokenCounter | None</code> <p>TokenCounter instance for fallback estimation</p> Example <p>hook = ProactiveCompactionHook( ...     threshold_tokens=60000, model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\" ... ) agent = Agent( ...     name=\"research-agent\", model=model, conversation_manager=manager, hooks=[hook] ... )</p>"},{"location":"reference/api/exec/#strands_cli.exec.hooks.ProactiveCompactionHook.__init__","title":"<code>__init__(threshold_tokens, model_id=None)</code>","text":"<p>Initialize the proactive compaction hook.</p> <p>Parameters:</p> Name Type Description Default <code>threshold_tokens</code> <code>int</code> <p>Trigger compaction when total tokens exceed this value</p> required <code>model_id</code> <code>str | None</code> <p>Optional model identifier for TokenCounter fallback</p> <code>None</code>"},{"location":"reference/api/exec/#strands_cli.exec.hooks.ProactiveCompactionHook.register_hooks","title":"<code>register_hooks(registry, **kwargs)</code>","text":"<p>Register hook callbacks with the agent's hook registry.</p> <p>Parameters:</p> Name Type Description Default <code>registry</code> <code>HookRegistry</code> <p>Hook registry from the agent</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments (not used)</p> <code>{}</code>"},{"location":"reference/api/exec/#execution-utilities","title":"Execution Utilities","text":""},{"location":"reference/api/exec/#strands_cli.exec.utils","title":"<code>strands_cli.exec.utils</code>","text":"<p>Shared execution utilities for all pattern executors.</p> <p>Provides common helpers for retry configuration, budget tracking, and agent execution patterns used across chain, workflow, routing, parallel, and single-agent executors.</p> <p>This module eliminates code duplication across executors and ensures consistent behavior for retry logic, budget enforcement, and error handling.</p> Phase 2 Additions <ul> <li>AgentCache: Executor-scoped agent caching to eliminate redundant builds</li> </ul>"},{"location":"reference/api/exec/#strands_cli.exec.utils.AgentCache","title":"<code>AgentCache</code>","text":"<p>Executor-scoped agent cache to eliminate redundant builds.</p> <p>Phase 2 Performance Optimization: Caches agents by (agent_id, frozenset(tool_ids)) to reuse agent instances across multiple steps/tasks in the same workflow execution. This eliminates redundant model client creation and agent initialization overhead.</p> <p>Key Features: - Cache keying: (agent_id, frozenset(tool_ids)) ensures correct reuse - Tool tracking: Maintains separate tool instances for cleanup - Async cleanup: Properly closes HTTP executor clients on workflow completion - Observability: Logs cache hits/misses for debugging</p> <p>Lifecycle: 1. Created at start of executor (run_chain, run_workflow, etc.) 2. Used via get_or_build_agent() for each step/task 3. Cleaned up via close() in finally block</p> Example <p>cache = AgentCache() try:     agent = await cache.get_or_build_agent(spec, \"agent-1\", agent_config)     result = await agent.invoke_async(prompt) finally:     await cache.close()</p>"},{"location":"reference/api/exec/#strands_cli.exec.utils.AgentCache.__init__","title":"<code>__init__()</code>","text":"<p>Initialize empty agent cache.</p>"},{"location":"reference/api/exec/#strands_cli.exec.utils.AgentCache.close","title":"<code>close()</code>  <code>async</code>","text":"<p>Clean up cached resources.</p> <p>Closes all HTTP executor clients and MCP server connections to release sockets and prevent resource leaks. Should be called in finally block of executor.</p> <p>Phase 9: MCP clients need explicit cleanup despite ToolProvider interface. Without this, MCP server processes remain running and the program hangs.</p> <p>This is critical for long-running workflows with many agents/tools to avoid socket exhaustion and hanging processes.</p>"},{"location":"reference/api/exec/#strands_cli.exec.utils.AgentCache.get_or_build_agent","title":"<code>get_or_build_agent(spec, agent_id, agent_config, tool_overrides=None, conversation_manager=None, hooks=None, injected_notes=None, worker_index=None, session_manager=None)</code>  <code>async</code>","text":"<p>Get cached agent or build new one.</p> <p>Checks cache for existing agent with matching (agent_id, tools, conversation_manager_type, worker_index, session_id). If found, returns cached instance (cache hit). Otherwise, builds new agent and caches it (cache miss).</p> <p>Note: injected_notes is passed through to build_agent but NOT included in cache key, as notes change per step. Agents are cached by identity, tools, and session.</p> <p>Phase 2 Addition: session_manager parameter enables agent conversation restoration from saved sessions. When provided, Strands SDK FileSessionManager restores message history for resume. Session ID from session_manager is included in cache key to ensure proper isolation.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>Spec</code> <p>Full workflow spec for agent construction</p> required <code>agent_id</code> <code>str</code> <p>Agent identifier from spec.agents</p> required <code>agent_config</code> <code>Agent</code> <p>Agent configuration</p> required <code>tool_overrides</code> <code>list[str] | None</code> <p>Optional tool ID list (overrides agent_config.tools)</p> <code>None</code> <code>conversation_manager</code> <code>Any | None</code> <p>Optional conversation manager for context compaction</p> <code>None</code> <code>hooks</code> <code>list[Any] | None</code> <p>Optional list of hooks (e.g., ProactiveCompactionHook, NotesAppenderHook)</p> <code>None</code> <code>injected_notes</code> <code>str | None</code> <p>Optional Markdown notes from previous steps (Phase 6.2)</p> <code>None</code> <code>worker_index</code> <code>int | None</code> <p>Optional worker index for orchestrator-workers pattern isolation</p> <code>None</code> <code>session_manager</code> <code>Any | None</code> <p>Optional Strands SDK session manager for resume (Phase 2)</p> <code>None</code> <p>Returns:</p> Type Description <code>Agent</code> <p>Cached or newly-built Agent instance</p> <p>Raises:</p> Type Description <code>AdapterError</code> <p>If agent build fails (from build_agent)</p>"},{"location":"reference/api/exec/#strands_cli.exec.utils.ExecutionUtilsError","title":"<code>ExecutionUtilsError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when execution utility operations fail.</p>"},{"location":"reference/api/exec/#strands_cli.exec.utils.create_retry_decorator","title":"<code>create_retry_decorator(max_attempts, wait_min, wait_max)</code>","text":"<p>Create a retry decorator with exponential backoff.</p> <p>Centralizes retry decorator creation for consistent behavior across all executors.</p> <p>Parameters:</p> Name Type Description Default <code>max_attempts</code> <code>int</code> <p>Maximum number of attempts</p> required <code>wait_min</code> <code>int</code> <p>Minimum wait time in seconds</p> required <code>wait_max</code> <code>int</code> <p>Maximum wait time in seconds</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Configured retry decorator from tenacity</p>"},{"location":"reference/api/exec/#strands_cli.exec.utils.estimate_tokens","title":"<code>estimate_tokens(input_text, output_text)</code>","text":"<p>Estimate token count from text (simple word-based heuristic).</p> <p>This is a simple estimation based on word count. In production, this should be replaced with actual token counting from the provider.</p> <p>Parameters:</p> Name Type Description Default <code>input_text</code> <code>str</code> <p>Input prompt</p> required <code>output_text</code> <code>str</code> <p>Agent response</p> required <p>Returns:</p> Type Description <code>int</code> <p>Estimated token count</p>"},{"location":"reference/api/exec/#strands_cli.exec.utils.get_retry_config","title":"<code>get_retry_config(spec)</code>","text":"<p>Get retry configuration from spec.</p> <p>Extracts retry policy from spec.runtime.failure_policy or uses defaults. Used by all executors for consistent retry behavior.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>Spec</code> <p>Workflow spec with optional failure_policy</p> required <p>Returns:</p> Type Description <code>tuple[int, int, int]</code> <p>Tuple of (max_attempts, wait_min, wait_max) in seconds</p> <p>Raises:</p> Type Description <code>ExecutionUtilsError</code> <p>If retry configuration is invalid</p>"},{"location":"reference/api/exec/#strands_cli.exec.utils.invoke_agent_with_retry","title":"<code>invoke_agent_with_retry(agent, input_text, max_attempts, wait_min, wait_max)</code>  <code>async</code>","text":"<p>Invoke an agent asynchronously with retry logic.</p> <p>Wraps agent invocation with stdout capture and retry handling. Used across all executors for consistent agent execution.</p> <p>Parameters:</p> Name Type Description Default <code>agent</code> <code>Any</code> <p>Strands Agent instance</p> required <code>input_text</code> <code>str</code> <p>Input prompt for the agent</p> required <code>max_attempts</code> <code>int</code> <p>Maximum retry attempts</p> required <code>wait_min</code> <code>int</code> <p>Minimum backoff wait (seconds)</p> required <code>wait_max</code> <code>int</code> <p>Maximum backoff wait (seconds)</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Agent response (string or AgentResult)</p> <p>Raises:</p> Type Description <code>TRANSIENT_ERRORS</code> <p>After all retry attempts exhausted</p> <code>Exception</code> <p>For non-transient errors (fail immediately)</p>"},{"location":"reference/api/exit-codes/","title":"Exit Codes","text":"<p>Standard exit codes for the Strands CLI.</p>"},{"location":"reference/api/exit-codes/#exit-code-constants","title":"Exit Code Constants","text":""},{"location":"reference/api/exit-codes/#strands_cli.exit_codes","title":"<code>strands_cli.exit_codes</code>","text":"<p>Exit codes for the Strands CLI.</p> <p>Follows Unix conventions for consistent error reporting across different failure modes. These codes allow shell scripts and CI/CD pipelines to distinguish between validation errors, runtime failures, and unsupported features.</p> Usage <p>Always use named constants instead of raw integers:</p> <p>from strands_cli.exit_codes import EX_SCHEMA, EX_OK sys.exit(EX_SCHEMA)  # GOOD sys.exit(3)  # BAD - unclear meaning</p> Exit Code Categories <p>0: Success 2-3: User/input errors (bad flags, invalid spec) 10-18: Runtime errors (provider failures, unsupported features) 70: System/unexpected errors</p>"},{"location":"reference/api/exit-codes/#strands_cli.exit_codes.EX_BUDGET_EXCEEDED","title":"<code>EX_BUDGET_EXCEEDED = 20</code>  <code>module-attribute</code>","text":"<p>Token budget exhausted during workflow execution.</p> <p>The workflow exceeded the configured <code>budgets.max_tokens</code> limit and was aborted to prevent cost overruns. This exit code is returned when: - Cumulative token usage reaches 100% of max_tokens - Budget enforcement is enabled (budgets.max_tokens is set)</p> <p>A warning is logged at the configured threshold (default 80%) before abort. If context compaction is enabled, it will be triggered automatically on warning to attempt extending the workflow runway.</p> <p>To resolve: - Increase budgets.max_tokens if the workflow legitimately needs more tokens - Enable context_policy.compaction to reduce context size during execution - Optimize prompts and agent responses to use fewer tokens - Split complex workflows into multiple smaller workflows</p>"},{"location":"reference/api/exit-codes/#strands_cli.exit_codes.EX_HITL_PAUSE","title":"<code>EX_HITL_PAUSE = 19</code>  <code>module-attribute</code>","text":"<p>Workflow paused for human-in-the-loop input.</p> <p>The workflow has reached a HITL (Human-in-the-Loop) step that requires user input or approval before continuing. Session state has been saved automatically.</p> To resume the workflow <p>strands run --resume  --hitl-response 'your response' <p>The session ID is displayed when the workflow pauses. Use 'strands sessions list' to find paused sessions.</p> <p>HITL steps are defined in the workflow spec with <code>type: hitl</code> and include: - prompt: Message requesting user input - context_display: Context to help user make decision (optional) - default: Default response if user provides empty input (optional) - timeout_seconds: Time limit before timeout (optional, Phase 2)</p> <p>This exit code indicates normal workflow pause, not an error condition.</p>"},{"location":"reference/api/exit-codes/#strands_cli.exit_codes.EX_IO","title":"<code>EX_IO = 12</code>  <code>module-attribute</code>","text":"<p>Artifact write or I/O error (can't create directory, write file, etc.).</p>"},{"location":"reference/api/exit-codes/#strands_cli.exit_codes.EX_OK","title":"<code>EX_OK = 0</code>  <code>module-attribute</code>","text":"<p>Successful execution.</p>"},{"location":"reference/api/exit-codes/#strands_cli.exit_codes.EX_RUNTIME","title":"<code>EX_RUNTIME = 10</code>  <code>module-attribute</code>","text":"<p>Provider/model/tool runtime failure (Bedrock error, tool crash, etc.).</p>"},{"location":"reference/api/exit-codes/#strands_cli.exit_codes.EX_SCHEMA","title":"<code>EX_SCHEMA = 3</code>  <code>module-attribute</code>","text":"<p>JSON Schema validation error.</p> <p>The workflow spec doesn't conform to the strands-workflow.schema.json. Validation uses JSON Schema Draft 2020-12 and reports precise error locations using JSONPointer paths.</p>"},{"location":"reference/api/exit-codes/#strands_cli.exit_codes.EX_SESSION","title":"<code>EX_SESSION = 17</code>  <code>module-attribute</code>","text":"<p>Session-related error (not found, corrupted, already completed).</p> <p>Returned when session persistence operations fail: - Session ID not found during resume attempt - Session data corrupted or invalid JSON - Attempting to resume an already-completed session - Session spec hash mismatch (spec changed since session creation) - HITL resume attempted without --hitl-response flag</p> <p>Distinct from EX_IO: Session errors indicate logical failures in the session lifecycle, not general filesystem I/O problems. Use EX_IO for file permission errors or disk space issues; use EX_SESSION for session-specific validation.</p> <p>To resolve: - Verify session ID exists via 'strands sessions list' - Check session directory for corruption - Use 'strands sessions show ' to inspect session state - Delete corrupted sessions via 'strands sessions delete ' - For HITL sessions, provide --hitl-response flag when resuming <p>See also: Exit Codes Reference</p>"},{"location":"reference/api/exit-codes/#strands_cli.exit_codes.EX_UNKNOWN","title":"<code>EX_UNKNOWN = 70</code>  <code>module-attribute</code>","text":"<p>Unexpected exception not handled by specific error codes.</p> <p>Indicates a bug in the CLI or an unhandled edge case. When this occurs, use --verbose to see the full traceback and report the issue.</p>"},{"location":"reference/api/exit-codes/#strands_cli.exit_codes.EX_UNSUPPORTED","title":"<code>EX_UNSUPPORTED = 18</code>  <code>module-attribute</code>","text":"<p>Feature present in spec but not supported in current implementation.</p> <p>When this code is returned, a detailed Markdown remediation report is written to the artifacts directory. The report includes: - JSONPointer locations of unsupported features - Reason each feature is unsupported - Specific remediation steps - Minimal working example</p> <p>This allows graceful degradation: parse the full schema but reject unsupported features with actionable guidance rather than silently ignoring them.</p>"},{"location":"reference/api/exit-codes/#strands_cli.exit_codes.EX_USAGE","title":"<code>EX_USAGE = 2</code>  <code>module-attribute</code>","text":"<p>Command-line usage error (bad flags, missing file, etc.).</p>"},{"location":"reference/api/loader/","title":"Loader Module","text":"<p>The loader module handles YAML/JSON parsing, template rendering, and workflow specification loading.</p>"},{"location":"reference/api/loader/#yaml-loader","title":"YAML Loader","text":""},{"location":"reference/api/loader/#strands_cli.loader.yaml_loader","title":"<code>strands_cli.loader.yaml_loader</code>","text":"<p>YAML/JSON loader for workflow specifications.</p> <p>Handles loading, parsing, and validating workflow specs from YAML or JSON files. Supports CLI variable overrides (--var) which are merged into inputs.values.</p> Validation Flow <ol> <li>Read and parse YAML/JSON file</li> <li>Merge CLI variables into inputs.values</li> <li>Validate against JSON Schema Draft 2020-12</li> <li>Convert to typed Pydantic Spec model</li> </ol> Supported Formats <ul> <li>.yaml, .yml: Parsed with ruamel.yaml (safe mode)</li> <li>.json: Parsed with standard json module</li> </ul>"},{"location":"reference/api/loader/#strands_cli.loader.yaml_loader.LoadError","title":"<code>LoadError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a spec file cannot be loaded or parsed.</p>"},{"location":"reference/api/loader/#strands_cli.loader.yaml_loader.load_spec","title":"<code>load_spec(file_path, variables=None)</code>","text":"<p>Load and validate a workflow spec from YAML or JSON.</p> <p>This is the primary entry point for loading workflow specifications. Performs multi-stage validation: file parsing, schema validation, and Pydantic model conversion for type safety.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | Path</code> <p>Path to the spec file (.yaml, .yml, or .json)</p> required <code>variables</code> <code>dict[str, str] | None</code> <p>Optional CLI variables (--var k=v) to merge into inputs.values.        These override values in the spec file.</p> <code>None</code> <p>Returns:</p> Type Description <code>Spec</code> <p>Validated Spec object with full type information</p> <p>Raises:</p> Type Description <code>LoadError</code> <p>If file cannot be read, parsed, or format is unsupported</p> <code>SchemaValidationError</code> <p>If spec doesn't conform to JSON Schema</p> <code>ValidationError</code> <p>If spec cannot be converted to typed Spec                      (should be rare if schema validation passed)</p>"},{"location":"reference/api/loader/#strands_cli.loader.yaml_loader.parse_variables","title":"<code>parse_variables(var_args)</code>","text":"<p>Parse --var arguments into a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>var_args</code> <code>list[str]</code> <p>List of \"key=value\" strings from CLI</p> required <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dictionary of variables</p> <p>Raises:</p> Type Description <code>LoadError</code> <p>If a variable is malformed</p>"},{"location":"reference/api/loader/#template-rendering","title":"Template Rendering","text":""},{"location":"reference/api/loader/#strands_cli.loader.template","title":"<code>strands_cli.loader.template</code>","text":"<p>Template rendering with Jinja2 and safety controls.</p> <p>Provides secure template rendering for prompts and artifacts using Jinja2. Safety controls prevent common issues:</p> <ol> <li>StrictUndefined: Raises error on undefined variables (no silent failures)</li> <li>Control character stripping: Removes potentially harmful control chars</li> <li>Unicode normalization: Ensures consistent text representation</li> <li>Token budget enforcement: Optional output length limiting</li> <li>No file system access: Templates are strings only (no file loader)</li> </ol> <p>Custom Filters (Phase 1):     - truncate(n): Truncate text to n characters with ellipsis     - tojson: Serialize Python object to JSON string</p> Used for <ul> <li>Rendering agent prompts with input variables</li> <li>Generating output artifacts with {{ last_response }}</li> <li>Injecting runtime context into system prompts</li> <li>Multi-step context: {{ steps[0].response }}, {{ tasks..response }}"},{"location":"reference/api/loader/#strands_cli.loader.template.TemplateError","title":"<code>TemplateError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when template rendering fails.</p>"},{"location":"reference/api/loader/#strands_cli.loader.template.TemplateRenderer","title":"<code>TemplateRenderer</code>","text":"<p>Reusable template renderer with consistent configuration.</p> <p>This is a lightweight wrapper for consistency and future extensibility (e.g., adding custom filters, caching compiled templates, etc.).</p>"},{"location":"reference/api/loader/#strands_cli.loader.template.TemplateRenderer.__init__","title":"<code>__init__(max_output_chars=None)</code>","text":"<p>Initialize renderer.</p> <p>Parameters:</p> Name Type Description Default <code>max_output_chars</code> <code>int | None</code> <p>Optional max output length for all renders</p> <code>None</code>"},{"location":"reference/api/loader/#strands_cli.loader.template.TemplateRenderer.render","title":"<code>render(template_str, variables)</code>","text":"<p>Render a template.</p> <p>Parameters:</p> Name Type Description Default <code>template_str</code> <code>str</code> <p>Template string</p> required <code>variables</code> <code>dict[str, Any]</code> <p>Variables to inject</p> required <p>Returns:</p> Type Description <code>str</code> <p>Rendered string</p> <p>Raises:</p> Type Description <code>TemplateError</code> <p>If rendering fails</p>"},{"location":"reference/api/loader/#strands_cli.loader.template.TemplateSecurityError","title":"<code>TemplateSecurityError</code>","text":"<p>               Bases: <code>TemplateError</code></p> <p>Raised when template attempts unsafe operations.</p>"},{"location":"reference/api/loader/#strands_cli.loader.template.render_template","title":"<code>render_template(template_str, variables, max_output_chars=None)</code>","text":"<p>Render a Jinja2 template with safety controls.</p> <p>Creates an isolated Jinja2 environment (no file system access) and renders the template with strict undefined variable checking. Output is sanitized to remove control characters and optionally truncated for token budget control.</p> <p>Parameters:</p> Name Type Description Default <code>template_str</code> <code>str</code> <p>Template string with Jinja2 syntax (e.g., \"{{ variable }}\")</p> required <code>variables</code> <code>dict[str, Any]</code> <p>Dictionary of variables to inject into template</p> required <code>max_output_chars</code> <code>int | None</code> <p>Optional max output length for token budget enforcement.               Output is truncated (not errored) if exceeded.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Rendered and sanitized template string</p> <p>Raises:</p> Type Description <code>TemplateError</code> <p>If template syntax is invalid, variable is undefined,           or rendering fails for any reason</p>"},{"location":"reference/api/runtime/","title":"Runtime Module","text":"<p>The runtime module provides provider adapters, context management, and budget enforcement for workflow execution.</p>"},{"location":"reference/api/runtime/#providers","title":"Providers","text":""},{"location":"reference/api/runtime/#strands_cli.runtime.providers","title":"<code>strands_cli.runtime.providers</code>","text":"<p>Provider-specific client configuration for Bedrock and Ollama.</p> <p>Adapts runtime configuration to provider-specific model clients using the Strands Agents SDK. Each provider has different requirements:</p> Bedrock <ul> <li>Requires AWS region configured via environment or ~/.aws/config</li> <li>Model IDs follow AWS format (e.g., anthropic.claude-3-sonnet-...)</li> <li>BedrockModel creates its own boto3 client internally</li> </ul> Ollama <ul> <li>Requires host URL (e.g., http://localhost:11434)</li> <li>Model IDs are local model names (e.g., gpt-oss, llama2)</li> </ul> <p>Both providers support model_id override from runtime or agent config.</p> Performance Optimization <ul> <li>Model clients are cached using functools.lru_cache with maxsize=16</li> <li>This prevents redundant client creation in multi-step workflows</li> <li>Cache is keyed by (provider, model_id, region, host) tuple</li> </ul>"},{"location":"reference/api/runtime/#strands_cli.runtime.providers.ProviderError","title":"<code>ProviderError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when provider configuration or initialization fails.</p>"},{"location":"reference/api/runtime/#strands_cli.runtime.providers.RuntimeConfig","title":"<code>RuntimeConfig</code>  <code>dataclass</code>","text":"<p>Hashable runtime configuration for LRU cache key.</p> <p>Frozen dataclass containing only the fields needed to uniquely identify a model client configuration. Used as the cache key for _create_model_cached.</p> <p>Attributes:</p> Name Type Description <code>provider</code> <code>str</code> <p>Provider type (bedrock, ollama, openai)</p> <code>model_id</code> <code>str | None</code> <p>Specific model identifier (or None for defaults)</p> <code>region</code> <code>str | None</code> <p>AWS region (Bedrock only)</p> <code>host</code> <code>str | None</code> <p>Host URL (Ollama/OpenAI only)</p> <code>temperature</code> <code>float | None</code> <p>Sampling temperature (OpenAI only)</p> <code>top_p</code> <code>float | None</code> <p>Nucleus sampling parameter (OpenAI only)</p> <code>max_tokens</code> <code>int | None</code> <p>Maximum tokens to generate (OpenAI only)</p>"},{"location":"reference/api/runtime/#strands_cli.runtime.providers.create_bedrock_model","title":"<code>create_bedrock_model(runtime)</code>","text":"<p>Create a Bedrock model client.</p> <p>Initializes AWS Bedrock runtime client using boto3 and wraps it with Strands BedrockModel adapter. Uses default AWS credential chain (environment variables, ~/.aws/credentials, instance role, etc.).</p> <p>Parameters:</p> Name Type Description Default <code>runtime</code> <code>Runtime</code> <p>Runtime configuration with provider=bedrock</p> required <p>Returns:</p> Type Description <code>BedrockModel</code> <p>Configured BedrockModel ready for agent creation</p> <p>Raises:</p> Type Description <code>ProviderError</code> <p>If region is missing or client creation fails</p>"},{"location":"reference/api/runtime/#strands_cli.runtime.providers.create_model","title":"<code>create_model(runtime)</code>","text":"<p>Create a model client based on the provider.</p> <p>This function converts the Runtime object to a hashable RuntimeConfig and delegates to the cached _create_model_cached function. This enables model client reuse across multiple agent builds in multi-step workflows.</p> <p>Cache statistics are logged periodically for observability.</p> <p>Parameters:</p> Name Type Description Default <code>runtime</code> <code>Runtime</code> <p>Runtime configuration</p> required <p>Returns:</p> Type Description <code>BedrockModel | OllamaModel | OpenAIModel</code> <p>Strands model (BedrockModel, OllamaModel, or OpenAIModel)</p> <p>Raises:</p> Type Description <code>ProviderError</code> <p>If provider is unsupported or configuration is invalid</p>"},{"location":"reference/api/runtime/#strands_cli.runtime.providers.create_ollama_model","title":"<code>create_ollama_model(runtime)</code>","text":"<p>Create an Ollama model client.</p> <p>Initializes Ollama client pointing to specified host URL. Assumes Ollama server is running and accessible.</p> <p>Parameters:</p> Name Type Description Default <code>runtime</code> <code>Runtime</code> <p>Runtime configuration with provider=ollama</p> required <p>Returns:</p> Type Description <code>OllamaModel</code> <p>Configured OllamaModel ready for agent creation</p> <p>Raises:</p> Type Description <code>ProviderError</code> <p>If host is missing or client creation fails</p>"},{"location":"reference/api/runtime/#strands_cli.runtime.providers.create_openai_model","title":"<code>create_openai_model(runtime)</code>","text":"<p>Create an OpenAI model client.</p> <p>Initializes OpenAI client using API key from environment. Supports optional base_url for OpenAI-compatible servers.</p> <p>Parameters:</p> Name Type Description Default <code>runtime</code> <code>Runtime</code> <p>Runtime configuration with provider=openai</p> required <p>Returns:</p> Type Description <code>OpenAIModel</code> <p>Configured OpenAIModel ready for agent creation</p> <p>Raises:</p> Type Description <code>ProviderError</code> <p>If API key is missing or client creation fails</p>"},{"location":"reference/api/runtime/#strands-adapter","title":"Strands Adapter","text":""},{"location":"reference/api/runtime/#strands_cli.runtime.strands_adapter","title":"<code>strands_cli.runtime.strands_adapter</code>","text":"<p>Strands agent adapter \u2014 map workflow Spec to Strands Agent.</p> <p>Transforms validated workflow specifications into executable Strands Agent instances. Handles:</p> <ol> <li>System prompt construction (agent prompt + skills + runtime context)</li> <li>Model client creation (provider-specific)</li> <li>Tool loading and validation (Python callables, HTTP executors)</li> <li>Agent assembly with Strands SDK</li> </ol> <p>The adapter pattern isolates Strands SDK specifics from workflow spec logic, making it easier to support alternative agent frameworks in the future.</p>"},{"location":"reference/api/runtime/#strands_cli.runtime.strands_adapter.AdapterError","title":"<code>AdapterError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when agent construction fails.</p>"},{"location":"reference/api/runtime/#strands_cli.runtime.strands_adapter.build_agent","title":"<code>build_agent(spec, agent_id, agent_config, tool_overrides=None, conversation_manager=None, hooks=None, injected_notes=None, agent_cache=None, session_manager=None)</code>","text":"<p>Build a Strands Agent from a spec.</p> <p>Complete agent construction workflow: 1. Create provider-specific model client (Bedrock or Ollama) 2. Build system prompt from agent config, skills, notes, and runtime context 3. Load and validate Python callable tools (allowlist check) 4. Create HTTP executor adapters 5. Assemble Strands Agent with all components 6. Attach conversation manager and hooks (for context management)</p> <p>Phase 2 Addition: session_manager parameter enables agent conversation restoration from saved sessions. When provided, Strands SDK FileSessionManager restores message history for resume.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>Spec</code> <p>Full workflow spec (used for runtime, tools, skills)</p> required <code>agent_id</code> <code>str</code> <p>ID of the agent to build from spec.agents</p> required <code>agent_config</code> <code>Agent</code> <p>Configuration for this agent</p> required <code>tool_overrides</code> <code>list[str] | None</code> <p>Optional list of tool IDs to use instead of agent's default tools            (used for per-step tool_overrides in chain pattern)</p> <code>None</code> <code>conversation_manager</code> <code>Any | None</code> <p>Optional conversation manager for context compaction</p> <code>None</code> <code>hooks</code> <code>list[Any] | None</code> <p>Optional list of hooks (e.g., ProactiveCompactionHook, NotesAppenderHook)</p> <code>None</code> <code>injected_notes</code> <code>str | None</code> <p>Optional Markdown notes from previous steps (Phase 6.2)</p> <code>None</code> <code>agent_cache</code> <code>Any | None</code> <p>Optional AgentCache instance for tracking MCP clients (Phase 9)</p> <code>None</code> <code>session_manager</code> <code>Any | None</code> <p>Optional Strands SDK session manager for resume (Phase 2)</p> <code>None</code> <p>Returns:</p> Type Description <code>Agent</code> <p>Configured Strands Agent ready for invoke_async()</p> <p>Raises:</p> Type Description <code>AdapterError</code> <p>If model creation, tool loading, or agent assembly fails</p>"},{"location":"reference/api/runtime/#strands_cli.runtime.strands_adapter.build_system_prompt","title":"<code>build_system_prompt(agent_config, spec, agent_id, injected_notes=None)</code>","text":"<p>Build the system prompt for an agent.</p> <p>Combines multiple sources into a comprehensive system prompt: 1. Agent's base prompt (agent.prompt) - core instructions 2. Structured notes (optional) - previous workflow steps for continuity 3. Skills metadata injection - available tools/capabilities 4. Runtime banner - workflow context, budgets, tags</p> <p>Skills are injected as metadata only (id, path, description). No code execution occurs; this provides context to the LLM.</p> <p>Parameters:</p> Name Type Description Default <code>agent_config</code> <code>Agent</code> <p>Agent configuration from spec.agents[agent_id]</p> required <code>spec</code> <code>Spec</code> <p>Full workflow spec for context</p> required <code>agent_id</code> <code>str</code> <p>ID of this agent</p> required <code>injected_notes</code> <code>str | None</code> <p>Optional Markdown notes from previous steps (Phase 6.2)</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Complete system prompt for agent initialization</p>"},{"location":"reference/api/runtime/#context-manager","title":"Context Manager","text":""},{"location":"reference/api/runtime/#strands_cli.runtime.context_manager","title":"<code>strands_cli.runtime.context_manager</code>","text":"<p>Context manager factory for intelligent conversation management.</p> <p>This module provides factory functions to create Strands SDK conversation managers from workflow spec configurations. Leverages native SummarizingConversationManager for context compaction with optional custom summarization agents.</p> Key Functions <p>create_from_policy: Create conversation manager from ContextPolicy config create_summarization_agent: Create optional cheaper agent for summarization</p>"},{"location":"reference/api/runtime/#strands_cli.runtime.context_manager.create_from_policy","title":"<code>create_from_policy(context_policy, spec)</code>","text":"<p>Create conversation manager from context policy configuration.</p> <p>Builds a SummarizingConversationManager with settings from spec.context_policy.compaction. If a custom summarization model is specified, creates a pooled model client for it.</p> <p>Parameters:</p> Name Type Description Default <code>context_policy</code> <code>ContextPolicy | None</code> <p>Context policy configuration (may be None)</p> required <code>spec</code> <code>Spec</code> <p>Full workflow spec for runtime and agent access</p> required <p>Returns:</p> Type Description <code>SummarizingConversationManager | None</code> <p>Configured SummarizingConversationManager if compaction is enabled, else None</p> Example <p>manager = create_from_policy(spec.context_policy, spec) agent = Agent(name=\"research-agent\", model=model, conversation_manager=manager)</p>"},{"location":"reference/api/runtime/#budget-enforcer","title":"Budget Enforcer","text":""},{"location":"reference/api/runtime/#strands_cli.runtime.budget_enforcer","title":"<code>strands_cli.runtime.budget_enforcer</code>","text":"<p>Token budget enforcement hook for workflow execution.</p> <p>Provides real-time budget tracking with configurable warning thresholds and hard limits. Integrates with context compaction to extend workflow runway before aborting on budget exhaustion.</p> <p>Key Features: - Configurable warning threshold (default 80%) - Structured logging for observability - Raises BudgetExceededError at 100% with EX_BUDGET_EXCEEDED - Compatible with all workflow patterns (chain, workflow, parallel, etc.)</p> Example <p>from strands_cli.runtime.budget_enforcer import BudgetEnforcerHook</p> <p>hook = BudgetEnforcerHook(max_tokens=100000, warn_threshold=0.75)</p>"},{"location":"reference/api/runtime/#strands_cli.runtime.budget_enforcer--hook-automatically-tracks-usage-via-agentaccumulated_usage","title":"Hook automatically tracks usage via agent.accumulated_usage","text":""},{"location":"reference/api/runtime/#strands_cli.runtime.budget_enforcer.BudgetEnforcerHook","title":"<code>BudgetEnforcerHook</code>","text":"<p>Hook to enforce token budgets during workflow execution.</p> <p>Tracks cumulative token usage across all steps/tasks and enforces configured limits with warnings and hard abort. Designed to run AFTER ProactiveCompactionHook to allow compaction to reduce tokens before checking hard limit.</p> <p>Attributes:</p> Name Type Description <code>max_tokens</code> <p>Maximum allowed token budget</p> <code>warn_threshold</code> <p>Percentage (0.0-1.0) at which to log warning</p> <code>warned</code> <p>Whether warning has been logged (prevents spam)</p> <code>cumulative_tokens</code> <p>Running total of tokens used</p>"},{"location":"reference/api/runtime/#strands_cli.runtime.budget_enforcer.BudgetEnforcerHook.__init__","title":"<code>__init__(max_tokens, warn_threshold=0.8, telemetry_exporter=None)</code>","text":"<p>Initialize budget enforcer.</p> <p>Parameters:</p> Name Type Description Default <code>max_tokens</code> <code>int</code> <p>Maximum token budget (from budgets.max_tokens)</p> required <code>warn_threshold</code> <code>float</code> <p>Warning threshold percentage (default 0.8 = 80%)</p> <code>0.8</code> <code>telemetry_exporter</code> <code>Any | None</code> <p>Optional OTEL exporter (Phase 10, reserved)</p> <code>None</code>"},{"location":"reference/api/runtime/#strands_cli.runtime.budget_enforcer.BudgetEnforcerHook.register_hooks","title":"<code>register_hooks(registry, **kwargs)</code>","text":"<p>Register hook callbacks with the agent's hook registry.</p> <p>Parameters:</p> Name Type Description Default <code>registry</code> <code>Any</code> <p>Hook registry from the agent</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments (not used)</p> <code>{}</code>"},{"location":"reference/api/runtime/#strands_cli.runtime.budget_enforcer.BudgetExceededError","title":"<code>BudgetExceededError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when token budget is exhausted.</p> <p>This exception is caught by executors and translated to EX_BUDGET_EXCEEDED exit code. Includes diagnostic information about token usage.</p> <p>Attributes:</p> Name Type Description <code>message</code> <p>Human-readable error description</p> <code>cumulative_tokens</code> <p>Total tokens used</p> <code>max_tokens</code> <p>Configured budget limit</p> <code>exit_code</code> <p>Exit code to use (EX_BUDGET_EXCEEDED)</p>"},{"location":"reference/api/runtime/#strands_cli.runtime.budget_enforcer.BudgetExceededError.__init__","title":"<code>__init__(message, cumulative_tokens, max_tokens)</code>","text":"<p>Initialize budget exceeded error.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Error description</p> required <code>cumulative_tokens</code> <code>int</code> <p>Total tokens consumed</p> required <code>max_tokens</code> <code>int</code> <p>Budget limit</p> required"},{"location":"reference/api/runtime/#token-counter","title":"Token Counter","text":""},{"location":"reference/api/runtime/#strands_cli.runtime.token_counter","title":"<code>strands_cli.runtime.token_counter</code>","text":"<p>Token counting utilities using tiktoken for accurate estimation.</p> <p>Provides token counting for all supported providers (Bedrock, Ollama, OpenAI) by mapping model IDs to appropriate tiktoken encodings. Used for proactive budget tracking and context management.</p> <p>Key Features: - Provider-aware encoding selection - Message format compatible with Strands SDK - Accounts for message overhead (4 tokens per message) - Fallback to cl100k_base for unknown models</p> Example <p>counter = TokenCounter(\"anthropic.claude-3-sonnet-20240229-v1:0\") messages = [     {\"role\": \"user\", \"content\": \"Hello\"},     {\"role\": \"assistant\", \"content\": \"Hi there!\"} ] tokens = counter.count_messages(messages)</p>"},{"location":"reference/api/runtime/#strands_cli.runtime.token_counter.TokenCounter","title":"<code>TokenCounter</code>","text":"<p>Count tokens in messages using tiktoken.</p> <p>Maps provider model IDs to appropriate tiktoken encodings for accurate token estimation across Bedrock, Ollama, and OpenAI providers.</p> <p>Attributes:</p> Name Type Description <code>model_id</code> <p>The model identifier (provider-specific)</p> <code>encoding</code> <p>The tiktoken encoding instance for this model</p>"},{"location":"reference/api/runtime/#strands_cli.runtime.token_counter.TokenCounter.__init__","title":"<code>__init__(model_id)</code>","text":"<p>Initialize token counter for a specific model.</p> <p>Parameters:</p> Name Type Description Default <code>model_id</code> <code>str</code> <p>Provider-specific model identifier - Bedrock: \"anthropic.claude-3-sonnet-20240229-v1:0\" - OpenAI: \"gpt-4\", \"gpt-3.5-turbo\" - Ollama: \"llama2\", \"mistral\"</p> required"},{"location":"reference/api/runtime/#strands_cli.runtime.token_counter.TokenCounter.count_messages","title":"<code>count_messages(messages)</code>","text":"<p>Count tokens in a list of messages.</p> <p>Follows OpenAI's token counting methodology: - 4 tokens overhead per message - Encode all message content (role, content, name if present)</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>list[dict[str, Any]]</code> <p>List of message dicts with 'role' and 'content' keys</p> required <p>Returns:</p> Type Description <code>int</code> <p>Total token count including overhead</p>"},{"location":"reference/api/runtime/#tools","title":"Tools","text":""},{"location":"reference/api/runtime/#strands_cli.runtime.tools","title":"<code>strands_cli.runtime.tools</code>","text":"<p>Safe tool adapters for Python tools.</p> <p>Provides controlled tool execution with security boundaries:</p> Python Tools <ul> <li>Allowlist enforcement (only approved imports)</li> <li>Dynamic import validation</li> <li>Callable verification</li> </ul> HTTP Executors <ul> <li>Now handled by tools/http_executor_factory.py</li> <li>Creates proper native tool modules with TOOL_SPEC</li> </ul> <p>All tools raise ToolError on failures for consistent error handling.</p>"},{"location":"reference/api/runtime/#strands_cli.runtime.tools.ToolError","title":"<code>ToolError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when tool initialization or execution fails.</p>"},{"location":"reference/api/runtime/#strands_cli.runtime.tools.load_python_callable","title":"<code>load_python_callable(import_path)</code>","text":"<p>Load a Python tool from an import path.</p> <p>Handles two types of tools based on Strands patterns: 1. @tool decorated functions: Returns the decorated function object 2. Module-based tools: Returns the module itself (has TOOL_SPEC)</p> <p>Security: Only loads from the ALLOWED_PYTHON_CALLABLES allowlist and native tools registry to prevent arbitrary code execution.</p> <p>Supports multiple path formats: - Native short ID: \"python_exec\" (resolved via registry) - Native full path: \"strands_cli.tools.python_exec\" - Old format: \"strands_tools.http_request\" (infers function name) - New format: \"strands_tools.http_request.http_request\" (explicit)</p> <p>Parameters:</p> Name Type Description Default <code>import_path</code> <code>str</code> <p>Dotted import path, short ID, or legacy format</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Either a decorated function tool or a module-based tool object</p> <p>Raises:</p> Type Description <code>ToolError</code> <p>If tool is not in allowlist, cannot be loaded, or is invalid</p>"},{"location":"reference/api/schema/","title":"Schema Module","text":"<p>The schema module provides JSON Schema validation and schema utilities.</p>"},{"location":"reference/api/schema/#validator","title":"Validator","text":""},{"location":"reference/api/schema/#strands_cli.schema.validator","title":"<code>strands_cli.schema.validator</code>","text":"<p>Schema validation for Strands workflow specifications.</p> <p>Validates workflow specs against the JSON Schema Draft 2020-12 schema. Provides precise error reporting using JSONPointer to locate validation failures.</p> Validation Architecture <ul> <li>Schema loaded once at module import time (cached)</li> <li>Draft202012Validator used for JSON Schema 2020-12 compliance</li> <li>Errors include JSONPointer paths for exact location reporting</li> <li>Validation is required before Pydantic model conversion</li> </ul> Schema Location <p>Statically embedded in package: strands_cli/schema/strands-workflow.schema.json Loaded via importlib.resources for proper packaging support</p>"},{"location":"reference/api/schema/#strands_cli.schema.validator.SchemaValidationError","title":"<code>SchemaValidationError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a spec fails JSON Schema validation.</p>"},{"location":"reference/api/schema/#strands_cli.schema.validator.SchemaValidationError.__init__","title":"<code>__init__(message, errors)</code>","text":"<p>Initialize with message and structured error details.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error summary</p> required <code>errors</code> <code>list[dict[str, Any]]</code> <p>List of error details with JSONPointer paths</p> required"},{"location":"reference/api/schema/#strands_cli.schema.validator.get_schema","title":"<code>get_schema()</code>","text":"<p>Get the loaded schema dictionary.</p> <p>Returns a copy of the cached schema for inspection or documentation purposes.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>The strands-workflow.schema.json as a dict (copied to prevent mutation)</p>"},{"location":"reference/api/schema/#strands_cli.schema.validator.validate_spec","title":"<code>validate_spec(spec_data)</code>","text":"<p>Validate a workflow spec against the JSON Schema.</p> <p>Uses JSON Schema Draft 2020-12 validation to ensure the spec conforms to the strands-workflow.schema.json. Validation errors include JSONPointer paths for precise error location reporting (e.g., /runtime/provider).</p> <p>This is the first validation gate; Pydantic model conversion follows.</p> <p>Parameters:</p> Name Type Description Default <code>spec_data</code> <code>dict[str, Any]</code> <p>Parsed YAML/JSON spec as a dictionary</p> required <p>Raises:</p> Type Description <code>SchemaValidationError</code> <p>If validation fails, with detailed error information                   including JSONPointer locations, messages, and validator types</p>"},{"location":"reference/api/schema/#schema-definition","title":"Schema Definition","text":"<p>The JSON Schema definition is located at <code>src/strands_cli/schema/strands-workflow.schema.json</code> and uses JSON Schema Draft 2020-12.</p> <p>See Schema Reference for the complete schema documentation.</p>"},{"location":"reference/api/telemetry/","title":"Telemetry Module","text":"<p>The telemetry module provides OpenTelemetry tracing and PII redaction capabilities.</p>"},{"location":"reference/api/telemetry/#opentelemetry","title":"OpenTelemetry","text":""},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel","title":"<code>strands_cli.telemetry.otel</code>","text":"<p>OpenTelemetry tracing integration.</p> <p>Provides OTEL tracing with: - TracerProvider with configurable sampling (TraceIdRatioBased) - OTLP/Console exporters based on endpoint configuration - Auto-instrumentation for httpx and logging - Structlog trace context injection - Redaction of sensitive data per telemetry.redact config</p> <p>The CLI's global TracerProvider is set before any SDK calls, ensuring Strands SDK's automatic agent/model/tool spans nest under CLI workflow spans.</p> <p>Span Architecture: - CLI creates workflow-level spans (execute., build_agent, etc.) - SDK automatically creates nested agent/model/tool spans - Both share the same TracerProvider for unified traces - Attributes used for queryable metadata (spec.name, pattern.type) - Events used for timestamped execution milestones (step_start, step_complete)"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.CollectingSpanExporter","title":"<code>CollectingSpanExporter</code>","text":"<p>               Bases: <code>SpanExporter</code></p> <p>Span exporter that captures spans to TraceCollector.</p> <p>Wraps another exporter to pass spans through while collecting them. Optionally applies redaction to span attributes before collection.</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.CollectingSpanExporter.__init__","title":"<code>__init__(collector, wrapped_exporter, redaction_engine=None, redact_tool_inputs=False, redact_tool_outputs=False)</code>","text":"<p>Initialize collecting exporter.</p> <p>Parameters:</p> Name Type Description Default <code>collector</code> <code>TraceCollector</code> <p>TraceCollector to store spans in</p> required <code>wrapped_exporter</code> <code>SpanExporter</code> <p>Underlying exporter to pass spans to</p> required <code>redaction_engine</code> <code>RedactionEngine | None</code> <p>Optional RedactionEngine for PII scrubbing</p> <code>None</code> <code>redact_tool_inputs</code> <code>bool</code> <p>Whether to redact tool.input.* attributes</p> <code>False</code> <code>redact_tool_outputs</code> <code>bool</code> <p>Whether to redact tool.output.* attributes</p> <code>False</code>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.CollectingSpanExporter.export","title":"<code>export(spans)</code>","text":"<p>Export spans to collector and wrapped exporter.</p> <p>Applies redaction to span attributes before storing in collector.</p> <p>Parameters:</p> Name Type Description Default <code>spans</code> <code>Sequence[ReadableSpan]</code> <p>Sequence of ReadableSpan objects</p> required <p>Returns:</p> Type Description <code>SpanExportResult</code> <p>Export result from wrapped exporter</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.CollectingSpanExporter.force_flush","title":"<code>force_flush(timeout_millis=30000)</code>","text":"<p>Force flush wrapped exporter.</p> <p>Parameters:</p> Name Type Description Default <code>timeout_millis</code> <code>int</code> <p>Timeout in milliseconds</p> <code>30000</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if flush succeeded</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.CollectingSpanExporter.shutdown","title":"<code>shutdown()</code>","text":"<p>Shutdown wrapped exporter and log redaction summary.</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.NoOpSpan","title":"<code>NoOpSpan</code>","text":"<p>No-op span context manager.</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.NoOpSpan.__enter__","title":"<code>__enter__()</code>","text":"<p>Enter context.</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.NoOpSpan.__exit__","title":"<code>__exit__(*args)</code>","text":"<p>Exit context.</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.NoOpSpan.add_event","title":"<code>add_event(name, attributes=None)</code>","text":"<p>No-op add event.</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.NoOpSpan.set_attribute","title":"<code>set_attribute(key, value)</code>","text":"<p>No-op set attribute.</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.NoOpSpan.set_status","title":"<code>set_status(status)</code>","text":"<p>No-op set status.</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.NoOpTracer","title":"<code>NoOpTracer</code>","text":"<p>No-op tracer that does nothing.</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.NoOpTracer.start_as_current_span","title":"<code>start_as_current_span(name, **kwargs)</code>","text":"<p>Return no-op span (context manager).</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.NoOpTracer.start_span","title":"<code>start_span(name, **kwargs)</code>","text":"<p>Return no-op span.</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.NoOpTracerProvider","title":"<code>NoOpTracerProvider</code>","text":"<p>No-op tracer provider for when telemetry is disabled.</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.NoOpTracerProvider.get_tracer","title":"<code>get_tracer(name)</code>","text":"<p>Return no-op tracer.</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.NoOpTracerProvider.shutdown","title":"<code>shutdown()</code>","text":"<p>No-op shutdown.</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.TraceCollector","title":"<code>TraceCollector</code>","text":"<p>Thread-safe in-memory span collector for trace export.</p> <p>Captures spans as they are exported by BatchSpanProcessor, storing them for later retrieval as trace artifacts.</p> <p>Thread-safe for concurrent span collection with bounded memory usage. Uses FIFO eviction when span limit is exceeded to prevent OOM.</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.TraceCollector.__init__","title":"<code>__init__(max_spans=None)</code>","text":"<p>Initialize empty trace collector.</p> <p>Parameters:</p> Name Type Description Default <code>max_spans</code> <code>int | None</code> <p>Maximum number of spans to store (default: 1000).        Can also be set via STRANDS_MAX_TRACE_SPANS env var.</p> <code>None</code>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.TraceCollector.add_span","title":"<code>add_span(span, redacted_attrs=None)</code>","text":"<p>Add span to collection with FIFO eviction if limit exceeded.</p> <p>Parameters:</p> Name Type Description Default <code>span</code> <code>ReadableSpan</code> <p>ReadableSpan to store</p> required <code>redacted_attrs</code> <code>dict[str, Any] | None</code> <p>Optional redacted attributes to use instead of span.attributes</p> <code>None</code>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.TraceCollector.clear","title":"<code>clear()</code>","text":"<p>Clear all collected spans and reset counters.</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.TraceCollector.get_trace_data","title":"<code>get_trace_data(spec_name=None, pattern=None)</code>","text":"<p>Get complete trace data as JSON-serializable dict.</p> <p>Parameters:</p> Name Type Description Default <code>spec_name</code> <code>str | None</code> <p>Name of spec for metadata</p> <code>None</code> <code>pattern</code> <code>str | None</code> <p>Pattern type for metadata</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Trace data with trace_id, spans, metadata, and eviction stats</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.add_otel_context","title":"<code>add_otel_context(logger, method_name, event_dict)</code>","text":"<p>Structlog processor to inject OTEL trace context.</p> <p>Extracts trace_id and span_id from current span and adds to event dict.</p> <p>Parameters:</p> Name Type Description Default <code>logger</code> <code>Any</code> <p>Logger instance</p> required <code>method_name</code> <code>str</code> <p>Log method name</p> required <code>event_dict</code> <code>dict[str, Any]</code> <p>Event dictionary</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Event dict with trace_id and span_id added</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.add_session_attributes","title":"<code>add_session_attributes(session_id=None, resumed=False, steps_skipped=0, checkpoint_count=0)</code>","text":"<p>Add session-specific attributes to current span.</p> <p>Instruments workflow execution with session metrics for observability and debugging. Call this from executors when session persistence is active.</p> <p>Parameters:</p> Name Type Description Default <code>session_id</code> <code>str | None</code> <p>Session ID if using session persistence</p> <code>None</code> <code>resumed</code> <code>bool</code> <p>Whether execution was resumed from checkpoint</p> <code>False</code> <code>steps_skipped</code> <code>int</code> <p>Number of steps/tasks/branches skipped during resume</p> <code>0</code> <code>checkpoint_count</code> <code>int</code> <p>Number of checkpoints saved during execution</p> <code>0</code> Example <p>from strands_cli.telemetry import add_session_attributes add_session_attributes( ...     session_id=\"abc-123\", resumed=True, steps_skipped=5, checkpoint_count=3 ... )</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.configure_telemetry","title":"<code>configure_telemetry(spec_telemetry=None)</code>","text":"<p>Configure OpenTelemetry tracing (thread-safe).</p> <p>Sets up global TracerProvider with sampling, OTLP/Console exporters, and auto-instrumentation for httpx and logging.</p> <p>Thread-safe: Multiple concurrent calls will be serialized with a lock.</p> <p>Parameters:</p> Name Type Description Default <code>spec_telemetry</code> <code>dict[str, Any] | None</code> <p>Telemetry config from spec (otel, redact)</p> <code>None</code>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.force_flush_telemetry","title":"<code>force_flush_telemetry(timeout_millis=30000)</code>","text":"<p>Force flush pending spans to exporters.</p> <p>This ensures all queued spans in BatchSpanProcessor are exported before proceeding. Critical for trace artifact generation.</p> <p>Parameters:</p> Name Type Description Default <code>timeout_millis</code> <code>int</code> <p>Maximum time to wait for flush (default: 30 seconds)</p> <code>30000</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if flush succeeded within timeout, False otherwise</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.get_trace_collector","title":"<code>get_trace_collector()</code>","text":"<p>Get global trace collector.</p> <p>Returns:</p> Type Description <code>TraceCollector | None</code> <p>TraceCollector instance if telemetry configured, else None</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.get_tracer","title":"<code>get_tracer(name)</code>","text":"<p>Get tracer for instrumenting code.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Tracer name (usually name)</p> required <p>Returns:</p> Type Description <code>Tracer | NoOpTracer</code> <p>Tracer instance (real or no-op based on configuration)</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.otel.shutdown_telemetry","title":"<code>shutdown_telemetry()</code>","text":"<p>Shutdown telemetry and flush pending spans.</p>"},{"location":"reference/api/telemetry/#pii-redaction","title":"PII Redaction","text":""},{"location":"reference/api/telemetry/#strands_cli.telemetry.redaction","title":"<code>strands_cli.telemetry.redaction</code>","text":"<p>PII redaction engine for OpenTelemetry spans.</p> <p>Provides pattern-based redaction of sensitive data in span attributes, including emails, credit cards, SSNs, phone numbers, and API keys.</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.redaction.RedactionEngine","title":"<code>RedactionEngine</code>","text":"<p>Engine for detecting and redacting PII in span attributes.</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.redaction.RedactionEngine.__init__","title":"<code>__init__(custom_patterns=None)</code>","text":"<p>Initialize redaction engine.</p> <p>Parameters:</p> Name Type Description Default <code>custom_patterns</code> <code>list[str] | None</code> <p>Optional list of regex patterns for additional PII types.</p> <code>None</code>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.redaction.RedactionEngine.get_redaction_count","title":"<code>get_redaction_count()</code>","text":"<p>Get total number of redactions performed.</p> <p>Returns:</p> Type Description <code>int</code> <p>Count of redacted values.</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.redaction.RedactionEngine.redact_span_attributes","title":"<code>redact_span_attributes(attributes, redact_tool_inputs=False, redact_tool_outputs=False)</code>","text":"<p>Redact PII from span attributes based on configuration.</p> <p>Parameters:</p> Name Type Description Default <code>attributes</code> <code>dict[str, Any]</code> <p>Span attributes dictionary.</p> required <code>redact_tool_inputs</code> <code>bool</code> <p>Whether to redact tool.input.* attributes.</p> <code>False</code> <code>redact_tool_outputs</code> <code>bool</code> <p>Whether to redact tool.output.* attributes.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[dict[str, Any], bool]</code> <p>Tuple of (redacted_attributes, was_redacted).</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.redaction.RedactionEngine.redact_value","title":"<code>redact_value(value, is_sensitive_context=True)</code>","text":"<p>Redact PII from a value of any type.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>Value to redact (str, dict, list, or primitive).</p> required <code>is_sensitive_context</code> <code>bool</code> <p>If True (default), apply all patterns including API key.                   If False, skip API key pattern (for non-sensitive attributes).</p> <code>True</code> <p>Returns:</p> Type Description <code>Any</code> <p>Redacted value with same structure.</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.redaction.RedactionEngine.reset_count","title":"<code>reset_count()</code>","text":"<p>Reset redaction counter.</p>"},{"location":"reference/api/telemetry/#strands_cli.telemetry.redaction.redact_json_string","title":"<code>redact_json_string(json_str, engine=None)</code>","text":"<p>Redact PII from a JSON string.</p> <p>Parses JSON, redacts values, and re-serializes.</p> <p>Parameters:</p> Name Type Description Default <code>json_str</code> <code>str</code> <p>JSON string to redact.</p> required <code>engine</code> <code>RedactionEngine | None</code> <p>Optional RedactionEngine instance (creates new if None).</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Redacted JSON string.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If json_str is not valid JSON.</p>"},{"location":"reference/api/tools/","title":"Tools Module","text":"<p>The tools module contains the native tool registry and tool implementations.</p>"},{"location":"reference/api/tools/#tool-registry","title":"Tool Registry","text":""},{"location":"reference/api/tools/#strands_cli.tools.registry","title":"<code>strands_cli.tools.registry</code>","text":"<p>Minimal tool registry for native tools.</p> <p>This module provides auto-discovery and registration of native tools that follow the Strands SDK module-based pattern with TOOL_SPEC exports.</p>"},{"location":"reference/api/tools/#strands_cli.tools.registry.ToolInfo","title":"<code>ToolInfo</code>  <code>dataclass</code>","text":"<p>Minimal tool metadata for discovery.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Tool identifier (e.g., \"http_request\")</p> <code>module_path</code> <code>str</code> <p>Full import path (e.g., \"strands_cli.tools.http_request\")</p> <code>description</code> <code>str</code> <p>Tool description from TOOL_SPEC</p>"},{"location":"reference/api/tools/#strands_cli.tools.registry.ToolInfo.import_path","title":"<code>import_path</code>  <code>property</code>","text":"<p>Full import path for loading.</p> <p>Returns:</p> Type Description <code>str</code> <p>The module_path (e.g., \"strands_cli.tools.http_request\")</p>"},{"location":"reference/api/tools/#strands_cli.tools.registry.ToolInfo.legacy_path","title":"<code>legacy_path</code>  <code>property</code>","text":"<p>Backward-compatible 'strands_tools.*' path.</p> <p>Returns:</p> Type Description <code>str</code> <p>Legacy format path (e.g., \"strands_tools.http_request.http_request\")</p>"},{"location":"reference/api/tools/#strands_cli.tools.registry.ToolInfo.legacy_short","title":"<code>legacy_short</code>  <code>property</code>","text":"<p>Old short format.</p> <p>Returns:</p> Type Description <code>str</code> <p>Legacy short format (e.g., \"strands_tools.http_request\")</p>"},{"location":"reference/api/tools/#strands_cli.tools.registry.ToolRegistry","title":"<code>ToolRegistry</code>","text":"<p>Simple singleton registry for native tools.</p> <p>Auto-discovers tools from the strands_cli.tools module on first instantiation. Tools must export a TOOL_SPEC dictionary following the Strands SDK pattern.</p>"},{"location":"reference/api/tools/#strands_cli.tools.registry.ToolRegistry.__new__","title":"<code>__new__()</code>","text":"<p>Singleton pattern - ensures only one registry instance exists.</p>"},{"location":"reference/api/tools/#strands_cli.tools.registry.ToolRegistry.get","title":"<code>get(tool_id)</code>","text":"<p>Get tool by ID.</p> <p>Parameters:</p> Name Type Description Default <code>tool_id</code> <code>str</code> <p>Tool identifier (e.g., \"http_request\")</p> required <p>Returns:</p> Type Description <code>ToolInfo | None</code> <p>ToolInfo if found, None otherwise</p>"},{"location":"reference/api/tools/#strands_cli.tools.registry.ToolRegistry.get_allowlist","title":"<code>get_allowlist()</code>","text":"<p>Generate complete allowlist for capability checker.</p> <p>Returns all valid import formats for all discovered tools: - Short ID: \"python_exec\" - New format: \"strands_cli.tools.python_exec\" - Legacy full: \"strands_tools.python_exec.python_exec\" - Legacy short: \"strands_tools.python_exec\"</p> <p>Returns:</p> Type Description <code>set[str]</code> <p>Set of all valid import path formats</p>"},{"location":"reference/api/tools/#strands_cli.tools.registry.ToolRegistry.list_all","title":"<code>list_all()</code>","text":"<p>List all registered tools.</p> <p>Returns:</p> Type Description <code>list[ToolInfo]</code> <p>List of all ToolInfo objects in the registry</p>"},{"location":"reference/api/tools/#strands_cli.tools.registry.ToolRegistry.resolve","title":"<code>resolve(user_input)</code>","text":"<p>Resolve user input to canonical import path.</p> <p>Supports multiple formats for backward compatibility: - Direct ID: \"http_request\" \u2192 \"strands_cli.tools.http_request\" - Legacy short: \"strands_tools.http_request\" \u2192 \"strands_cli.tools.http_request\" - Legacy full: \"strands_tools.http_request.http_request\" \u2192 \"strands_cli.tools.http_request\"</p> <p>Parameters:</p> Name Type Description Default <code>user_input</code> <code>str</code> <p>Tool reference from workflow spec</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Canonical import path or None if not found</p>"},{"location":"reference/api/tools/#strands_cli.tools.registry.get_registry","title":"<code>get_registry()</code>","text":"<p>Get the global tool registry singleton.</p> <p>Returns:</p> Type Description <code>ToolRegistry</code> <p>The singleton ToolRegistry instance</p>"},{"location":"reference/api/tools/#python-execution","title":"Python Execution","text":""},{"location":"reference/api/tools/#strands_cli.tools.python_exec","title":"<code>strands_cli.tools.python_exec</code>","text":"<p>Python code execution tool (Strands SDK module-based pattern).</p> <p>Execute Python code safely with restricted builtins and stdout capture. MVP implementation - production version should add proper sandboxing.</p>"},{"location":"reference/api/tools/#strands_cli.tools.python_exec.python_exec","title":"<code>python_exec(tool, **kwargs)</code>","text":"<p>Execute Python code with restricted builtins and stdout capture.</p> <p>MVP Implementation: - Uses exec() with restricted globals - Captures stdout via StringIO - Returns result or error</p> <p>Security Limitations (MVP): - No proper sandboxing (subprocess/docker) - No resource limits (memory, CPU) - No timeout enforcement - Limited builtin allowlist - No AST parsing for dangerous operations</p> <p>Production version should address all security limitations.</p> <p>Parameters:</p> Name Type Description Default <code>tool</code> <code>dict[str, Any]</code> <p>Tool invocation object with toolUseId and input</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments (unused)</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>ToolResult dict with status and content</p>"},{"location":"reference/api/tools/#grep-tool","title":"Grep Tool","text":""},{"location":"reference/api/tools/#strands_cli.tools.grep","title":"<code>strands_cli.tools.grep</code>","text":"<p>JIT grep tool - cross-platform pattern search with context lines.</p> <p>Pure Python implementation using regex and pathlib for portability. No shell dependencies - works on Windows, macOS, and Linux.</p>"},{"location":"reference/api/tools/#strands_cli.tools.grep.grep","title":"<code>grep(tool, **kwargs)</code>","text":"<p>Search for pattern in file with context lines.</p> <p>Cross-platform implementation using pure Python (no subprocess/shell). Validates paths to prevent directory traversal and handles encoding errors.</p> <p>Parameters:</p> Name Type Description Default <code>tool</code> <code>dict[str, Any]</code> <p>Tool invocation object with toolUseId and input</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments (unused)</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>ToolResult dict with status and content</p>"},{"location":"reference/api/tools/#head-tool","title":"Head Tool","text":""},{"location":"reference/api/tools/#strands_cli.tools.head","title":"<code>strands_cli.tools.head</code>","text":"<p>JIT head tool - read first N lines from file.</p> <p>Pure Python implementation using pathlib for cross-platform support. Useful for reading file headers, metadata, or previewing file contents.</p>"},{"location":"reference/api/tools/#strands_cli.tools.head.head","title":"<code>head(tool, **kwargs)</code>","text":"<p>Read first N lines from a file.</p> <p>Cross-platform implementation using pure Python (no subprocess/shell). Validates paths and handles encoding errors gracefully.</p> <p>Parameters:</p> Name Type Description Default <code>tool</code> <code>dict[str, Any]</code> <p>Tool invocation object with toolUseId and input</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments (unused)</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>ToolResult dict with status and content</p>"},{"location":"reference/api/tools/#tail-tool","title":"Tail Tool","text":""},{"location":"reference/api/tools/#strands_cli.tools.tail","title":"<code>strands_cli.tools.tail</code>","text":"<p>JIT tail tool - read last N lines from file.</p> <p>Pure Python implementation using deque for efficient tail reading. Useful for reading log file endings or recent entries without loading entire files.</p>"},{"location":"reference/api/tools/#strands_cli.tools.tail.tail","title":"<code>tail(tool, **kwargs)</code>","text":"<p>Read last N lines from a file.</p> <p>Cross-platform implementation using deque for efficiency. Validates paths and handles encoding errors gracefully.</p> <p>Parameters:</p> Name Type Description Default <code>tool</code> <code>dict[str, Any]</code> <p>Tool invocation object with toolUseId and input</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments (unused)</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>ToolResult dict with status and content</p>"},{"location":"reference/api/tools/#search-tool","title":"Search Tool","text":""},{"location":"reference/api/tools/#strands_cli.tools.search","title":"<code>strands_cli.tools.search</code>","text":"<p>JIT search tool - keyword/regex search with match highlighting.</p> <p>Pure Python implementation with colored output and line numbers. Similar to grep but with simpler output format and match highlighting.</p>"},{"location":"reference/api/tools/#strands_cli.tools.search.search","title":"<code>search(tool, **kwargs)</code>","text":"<p>Search for keyword/pattern in file with line numbers.</p> <p>Cross-platform implementation using pure Python (no subprocess/shell). Validates paths and handles encoding errors gracefully.</p> <p>Parameters:</p> Name Type Description Default <code>tool</code> <code>dict[str, Any]</code> <p>Tool invocation object with toolUseId and input</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments (unused)</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>ToolResult dict with status and content</p>"},{"location":"reference/api/tools/#notes-manager","title":"Notes Manager","text":""},{"location":"reference/api/tools/#strands_cli.tools.notes_manager","title":"<code>strands_cli.tools.notes_manager</code>","text":"<p>Structured notes manager for workflow execution history.</p> <p>Provides persistent note-taking capabilities for long-running workflows, enabling cross-step continuity and multi-session workflow resumption.</p> <p>Key features: - Markdown-formatted notes with ISO8601 timestamps - Agent attribution and step tracking - Thread-safe concurrent writes via filelock - Read last N notes for context injection - Atomic writes for reliability</p> Format"},{"location":"reference/api/tools/#strands_cli.tools.notes_manager--2025-11-07t143200z-agent-research-agent-step-1","title":"[2025-11-07T14:32:00Z] \u2014 Agent: research-agent (Step 1)","text":"<ul> <li>Input: Analyze sentiment of customer reviews</li> <li>Tools used: http_request, file_read</li> <li>Outcome: Positive sentiment (0.82 score)</li> </ul>"},{"location":"reference/api/tools/#strands_cli.tools.notes_manager.NotesManager","title":"<code>NotesManager</code>","text":"<p>Manages structured workflow notes with thread-safe file operations.</p> <p>Handles: - Appending notes after each workflow step/task - Reading last N notes for context injection - Markdown formatting with timestamps and agent attribution - Concurrent write safety via file locking</p> Example <p>manager = NotesManager(\"artifacts/workflow-notes.md\") manager.append_entry(     timestamp=\"2025-11-07T14:32:00Z\",     agent_name=\"research-agent\",     step_index=1,     input_summary=\"Analyze reviews\",     tools_used=[\"http_request\", \"file_read\"],     outcome=\"Found 247 positive reviews\" ) last_notes = manager.read_last_n(3)</p>"},{"location":"reference/api/tools/#strands_cli.tools.notes_manager.NotesManager.__init__","title":"<code>__init__(file_path)</code>","text":"<p>Initialize notes manager.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to notes file (e.g., \"artifacts/workflow-notes.md\")</p> required"},{"location":"reference/api/tools/#strands_cli.tools.notes_manager.NotesManager.append_entry","title":"<code>append_entry(timestamp, agent_name, step_index, input_summary, tools_used, outcome)</code>","text":"<p>Append a note entry to the notes file.</p> <p>Thread-safe operation using file locking for concurrent writes.</p> <p>Parameters:</p> Name Type Description Default <code>timestamp</code> <code>str</code> <p>ISO8601 timestamp (e.g., \"2025-11-07T14:32:00Z\")</p> required <code>agent_name</code> <code>str</code> <p>Name/ID of the agent that executed this step</p> required <code>step_index</code> <code>int</code> <p>Step number (1-based)</p> required <code>input_summary</code> <code>str</code> <p>Brief description of step input/prompt</p> required <code>tools_used</code> <code>list[str] | None</code> <p>List of tool names used, or None</p> required <code>outcome</code> <code>str</code> <p>Brief description of step outcome/result</p> required <p>Raises:</p> Type Description <code>NotesManagerError</code> <p>If file write fails</p>"},{"location":"reference/api/tools/#strands_cli.tools.notes_manager.NotesManager.generate_timestamp","title":"<code>generate_timestamp()</code>  <code>staticmethod</code>","text":"<p>Generate ISO8601 timestamp for current UTC time.</p> <p>Returns:</p> Type Description <code>str</code> <p>ISO8601 timestamp string (e.g., \"2025-11-07T14:32:00Z\")</p>"},{"location":"reference/api/tools/#strands_cli.tools.notes_manager.NotesManager.get_last_n_for_injection","title":"<code>get_last_n_for_injection(n)</code>","text":"<p>Read the last N note entries for injection into agent context.</p> <p>This is the primary method for retrieving notes to inject into agent prompts. Uses efficient streaming read from end of file to handle large notes files without loading entire file into memory.</p> <p>Alias: read_last_n() is maintained for backwards compatibility.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of recent entries to read</p> required <p>Returns:</p> Type Description <code>str</code> <p>Markdown string containing last N entries, or empty string if file doesn't exist</p> <p>Raises:</p> Type Description <code>NotesManagerError</code> <p>If file read fails</p>"},{"location":"reference/api/tools/#strands_cli.tools.notes_manager.NotesManager.read_last_n","title":"<code>read_last_n(n)</code>","text":"<p>Read the last N note entries from the file.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of recent entries to read</p> required <p>Returns:</p> Type Description <code>str</code> <p>Markdown string containing last N entries, or empty string if file doesn't exist</p> <p>Raises:</p> Type Description <code>NotesManagerError</code> <p>If file read fails</p>"},{"location":"reference/api/tools/#strands_cli.tools.notes_manager.NotesManagerError","title":"<code>NotesManagerError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when notes operations fail.</p>"},{"location":"reference/api/tools/#http-executor-factory","title":"HTTP Executor Factory","text":""},{"location":"reference/api/tools/#strands_cli.tools.http_executor_factory","title":"<code>strands_cli.tools.http_executor_factory</code>","text":"<p>HTTP executor factory for creating native tool modules.</p> <p>Dynamically creates Strands SDK-compatible module-based tools from HttpExecutor configurations. Each HTTP executor becomes a proper native tool with TOOL_SPEC and matching callable function.</p> <p>This integrates HTTP executors into the native tools framework rather than treating them as a separate tool type.</p>"},{"location":"reference/api/tools/#strands_cli.tools.http_executor_factory.HttpExecutorToolError","title":"<code>HttpExecutorToolError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when HTTP executor tool execution fails.</p>"},{"location":"reference/api/tools/#strands_cli.tools.http_executor_factory.close_http_executor_tool","title":"<code>close_http_executor_tool(module)</code>","text":"<p>Close HTTP client for an HTTP executor tool module.</p> <p>Should be called during cleanup to release sockets and connections.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>ModuleType</code> <p>HTTP executor tool module created by create_http_executor_tool</p> required"},{"location":"reference/api/tools/#strands_cli.tools.http_executor_factory.create_http_executor_tool","title":"<code>create_http_executor_tool(config, spec=None)</code>","text":"<p>Create a native tool module for an HTTP executor configuration.</p> <p>Generates a proper Strands SDK module-based tool with: - Module-level TOOL_SPEC dictionary - Function matching TOOL_SPEC[\"name\"] - Proper tool invocation signature: tool(dict, **kwargs) -&gt; dict</p> <p>The created tool maintains an httpx.Client for efficient connection pooling and follows the same error handling patterns as other native tools.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>HttpExecutor</code> <p>HTTP executor configuration (id, base_url, headers, timeout)</p> required <code>spec</code> <code>Spec | None</code> <p>Optional workflow spec for resolving secret placeholders in headers</p> <code>None</code> <p>Returns:</p> Type Description <code>ModuleType</code> <p>Module object compatible with Strands SDK and native tools registry</p> Example <p>from strands_cli.types import HttpExecutor config = HttpExecutor( ...     id=\"github_api\", ...     base_url=\"https://api.github.com\", ...     headers={\"Authorization\": \"Bearer ${GITHUB_TOKEN}\"}, ... ) tool_module = create_http_executor_tool(config, spec)</p>"},{"location":"reference/api/tools/#strands_cli.tools.http_executor_factory.create_http_executor_tool--headers-will-have-github_token-resolved-from-environment","title":"Headers will have ${GITHUB_TOKEN} resolved from environment","text":""},{"location":"reference/api/tools/#spec-verify","title":"Spec Verify","text":""},{"location":"reference/api/tools/#strands_cli.tools.spec_verify","title":"<code>strands_cli.tools.spec_verify</code>","text":"<p>Spec verification tool (Strands SDK module-based pattern).</p> <p>Validate workflow specifications and return structured validation reports. Enables agentic workflows to programmatically verify and refine specs.</p>"},{"location":"reference/api/tools/#strands_cli.tools.spec_verify.spec_verify","title":"<code>spec_verify(tool, **kwargs)</code>","text":"<p>Validate a workflow spec and return structured validation report.</p> <p>Performs three-layer validation: 1. Parse YAML/JSON content 2. Validate against JSON Schema Draft 2020-12 3. Convert to Pydantic Spec model 4. Optionally check MVP capability compatibility</p> <p>Parameters:</p> Name Type Description Default <code>tool</code> <code>dict[str, Any]</code> <p>Tool invocation object with toolUseId and input</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments (unused)</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>ToolResult dict with status and JSON validation report in content</p>"},{"location":"reference/api/types/","title":"Types and Models","text":"<p>Core Pydantic models and type definitions for Strands CLI.</p>"},{"location":"reference/api/types/#overview","title":"Overview","text":"<p>All types and models are defined in <code>strands_cli.types</code> using Pydantic v2 with strict validation.</p>"},{"location":"reference/api/types/#core-models","title":"Core Models","text":""},{"location":"reference/api/types/#strands_cli.types","title":"<code>strands_cli.types</code>","text":"<p>Type definitions for the Strands CLI.</p> <p>All workflow specs and internal data structures use Pydantic v2 models for strict validation and type safety. These models map directly from the validated JSON Schema to typed Python objects.</p> Key Models <p>Spec: Top-level workflow specification Runtime: Model provider and execution configuration Agent: Individual agent configuration with prompt and tools Pattern: Workflow execution pattern (chain, workflow, etc.) Tools: Tool configurations (Python callables, HTTP executors, MCP) CapabilityReport: Compatibility analysis results RunResult: Execution outcome with timing and artifacts</p>"},{"location":"reference/api/types/#strands_cli.types.Spec","title":"<code>Spec</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete workflow specification.</p> <p>This is the top-level Pydantic model for a workflow spec, mapped from validated YAML/JSON input after JSON Schema validation.</p> Structure <ul> <li>Runtime: Model provider and execution settings</li> <li>Agents: Map of agent_id -&gt; Agent configuration</li> <li>Pattern: Orchestration pattern (chain, workflow, etc.)</li> <li>Tools: Python callables, HTTP executors, MCP servers</li> <li>Outputs: Artifact generation templates</li> <li>Environment: Secrets and mounts</li> <li>Telemetry: OTEL configuration (parsed but not emitted)</li> </ul>"},{"location":"reference/api/types/#strands_cli.types.Runtime","title":"<code>Runtime</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Runtime configuration for model execution.</p> <p>Specifies which LLM provider to use, model selection, inference parameters, and execution policies. Budget and failure policies are logged but not enforced.</p>"},{"location":"reference/api/types/#strands_cli.types.Agent","title":"<code>Agent</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Agent configuration.</p>"},{"location":"reference/api/types/#strands_cli.types.Pattern","title":"<code>Pattern</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Workflow execution pattern.</p>"},{"location":"reference/api/types/#strands_cli.types.PatternConfig","title":"<code>PatternConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Pattern-specific configuration.</p>"},{"location":"reference/api/types/#strands_cli.types.RoutingConfig","title":"<code>RoutingConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Routing pattern configuration.</p> <p>Attributes:</p> Name Type Description <code>router</code> <code>RouterConfig</code> <p>Router agent configuration</p> <code>routes</code> <code>dict[str, Route]</code> <p>Map of route names to route definitions</p>"},{"location":"reference/api/types/#strands_cli.types.RunResult","title":"<code>RunResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result of executing a single-agent workflow.</p> <p>Captures execution outcome, timing, and artifact locations. Used for both successful and failed executions.</p> <p>Attributes:</p> Name Type Description <code>success</code> <code>bool</code> <p>True if workflow completed without errors</p> <code>last_response</code> <code>str | None</code> <p>Final agent response text (for artifact templating)</p> <code>error</code> <code>str | None</code> <p>Error message if execution failed</p> <code>agent_id</code> <code>str</code> <p>ID of the agent that executed</p> <code>pattern_type</code> <code>PatternType</code> <p>Pattern used for execution</p> <code>started_at</code> <code>str</code> <p>ISO 8601 timestamp of execution start</p> <code>completed_at</code> <code>str</code> <p>ISO 8601 timestamp of execution completion</p> <code>duration_seconds</code> <code>float</code> <p>Total execution time</p> <code>artifacts_written</code> <code>list[str]</code> <p>Paths to generated artifact files</p> <code>execution_context</code> <code>dict[str, Any]</code> <p>Additional context for artifact templating (steps, tasks, etc.)</p> <code>spec</code> <code>Spec | None</code> <p>Optional workflow spec (attached during resume for artifact writing)</p> <code>variables</code> <code>dict[str, Any] | None</code> <p>Optional user variables (attached during resume for artifact writing)</p>"},{"location":"reference/api/utils/","title":"Utilities","text":"<p>Shared utility functions and helpers.</p>"},{"location":"reference/api/utils/#general-utilities","title":"General Utilities","text":""},{"location":"reference/api/utils/#strands_cli.utils","title":"<code>strands_cli.utils</code>","text":"<p>Utility functions and context managers for strands-cli.</p> <p>Provides common utilities used across the codebase.</p>"},{"location":"reference/api/utils/#strands_cli.utils.capture_and_display_stdout","title":"<code>capture_and_display_stdout(prefix='')</code>","text":"<p>Context manager to capture stdout while allowing normal console operations.</p> <p>Uses a tee-like approach to capture stdout (e.g., LLM streaming responses) without breaking Rich Console, structlog, or other stdout users. The captured output is displayed as it's generated (streaming effect).</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>Optional prefix to add before captured output (not currently used     since we're displaying in real-time)</p> <code>''</code> Example <p>with capture_and_display_stdout():     response = await agent.invoke_async(prompt)     # Streaming output appears in real-time</p> <p>Yields:</p> Type Description <code>None</code> <p>None</p>"},{"location":"reference/api/visualization/","title":"Visualization Module","text":"<p>The visualization module provides graph pattern visualization capabilities.</p>"},{"location":"reference/api/visualization/#graph-visualization","title":"Graph Visualization","text":""},{"location":"reference/api/visualization/#strands_cli.visualization.graph_viz","title":"<code>strands_cli.visualization.graph_viz</code>","text":"<p>Graph visualization for plan command.</p> <p>Generates DOT format (Graphviz) visualization of graph pattern workflows.</p>"},{"location":"reference/api/visualization/#strands_cli.visualization.graph_viz.generate_dot","title":"<code>generate_dot(spec)</code>","text":"<p>Generate Graphviz DOT format representation of graph pattern.</p> <p>Creates a directed graph showing: - Nodes as labeled boxes with agent names - Entry node highlighted in green - Terminal nodes highlighted in red - Static edges as solid arrows - Conditional edges as dashed arrows with condition labels</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>Spec</code> <p>Workflow spec with graph pattern</p> required <p>Returns:</p> Type Description <code>str</code> <p>DOT format string suitable for Graphviz rendering</p> Example <p>dot = generate_dot(spec)</p>"},{"location":"reference/api/visualization/#strands_cli.visualization.graph_viz.generate_dot--save-to-file-dot-tpng-graphdot-o-graphpng","title":"Save to file: dot -Tpng graph.dot -o graph.png","text":""},{"location":"reference/api/visualization/#strands_cli.visualization.graph_viz.generate_text_visualization","title":"<code>generate_text_visualization(spec)</code>","text":"<p>Generate simple text-based visualization of graph.</p> <p>Fallback for environments without Graphviz. Shows nodes, edges, and connectivity in plain text.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>Spec</code> <p>Workflow spec with graph pattern</p> required <p>Returns:</p> Type Description <code>str</code> <p>Multi-line string with text graph representation</p>"},{"location":"tutorials/first-multi-step/","title":"Building Your First Multi-Step Workflow","text":"<p>This tutorial teaches you how to build powerful multi-step workflows using the chain pattern. You'll learn how to pass context between steps, transform data, and create complex AI-driven processes.</p>"},{"location":"tutorials/first-multi-step/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Understanding the chain pattern</li> <li>Passing context between workflow steps</li> <li>Using template variables and filters</li> <li>Accessing previous step results</li> <li>Creating structured outputs</li> <li>Best practices for multi-step workflows</li> </ul>"},{"location":"tutorials/first-multi-step/#prerequisites","title":"Prerequisites","text":"<p>You should have:</p> <ul> <li>Completed at least one quickstart tutorial (Ollama, Bedrock, or OpenAI)</li> <li>Basic understanding of YAML syntax</li> <li>Familiarity with Jinja2 template syntax (helpful but not required)</li> </ul>"},{"location":"tutorials/first-multi-step/#what-is-the-chain-pattern","title":"What is the Chain Pattern?","text":"<p>The chain pattern executes multiple steps sequentially, where each step can access the outputs of previous steps. Think of it like a pipeline where data flows from one stage to the next.</p> <pre><code>graph LR\n    A[Step 1] --&gt; B[Step 2]\n    B --&gt; C[Step 3]\n    C --&gt; D[Output]</code></pre> <p>Use cases: - Research \u2192 Analysis \u2192 Summary - Idea \u2192 Outline \u2192 Full Article - Code \u2192 Review \u2192 Documentation - Question \u2192 Research \u2192 Answer</p>"},{"location":"tutorials/first-multi-step/#step-1-create-a-simple-two-step-chain","title":"Step 1: Create a Simple Two-Step Chain","text":"<p>Let's start with a simple workflow that generates content in two steps.</p> <p>Create <code>content-chain.yaml</code>:</p> <pre><code>version: 0\nname: content-chain\ndescription: Two-step content generation workflow\n\nruntime:\n  provider: ollama  # or openai, bedrock\n  model_id: llama3.2  # or gpt-4o-mini, anthropic.claude-3-sonnet...\n\ninputs:\n  values:\n    topic: \"renewable energy\"\n    format: \"blog post\"\n\nagents:\n  writer:\n    prompt: |\n      You are a skilled content writer who creates engaging, informative content.\n      Write in a clear, accessible style suitable for a general audience.\n\npattern:\n  type: chain\n  config:\n    steps:\n      # Step 1: Generate an outline\n      - agent: writer\n        input: \"Create a detailed outline for a {{ format }} about {{ topic }}. Include 3-5 main points.\"\n\n      # Step 2: Write full content from outline\n      - agent: writer\n        input: |\n          Use this outline to write a complete {{ format }}:\n\n          {{ last_response }}\n\n          Make it informative, engaging, and approximately 500 words.\n\noutputs:\n  artifacts:\n    - path: ./{{ topic | replace(' ', '-') }}.md\n      from: \"{{ last_response }}\"\n</code></pre>"},{"location":"tutorials/first-multi-step/#key-concepts","title":"Key Concepts","text":"<ul> <li><code>pattern.type: chain</code>: Enables sequential step execution</li> <li><code>steps</code>: Array of workflow steps (executed in order)</li> <li><code>{{ last_response }}</code>: References the most recent step's output</li> <li><code>{{ topic | replace(' ', '-') }}</code>: Jinja2 filter to transform variables</li> </ul>"},{"location":"tutorials/first-multi-step/#run-it","title":"Run It","text":"<pre><code>uv run strands run content-chain.yaml\n</code></pre> <p>You'll see: 1. Step 1 generates an outline 2. Step 2 uses that outline to write full content 3. Final content saved to <code>renewable-energy.md</code></p>"},{"location":"tutorials/first-multi-step/#step-2-access-specific-step-results","title":"Step 2: Access Specific Step Results","text":"<p>Instead of just using <code>last_response</code>, you can access any previous step by index.</p> <p>Create <code>research-chain.yaml</code>:</p> <pre><code>version: 0\nname: research-chain\ndescription: Three-step research workflow with specific step references\n\nruntime:\n  provider: openai\n  model_id: gpt-4o-mini\n\ninputs:\n  values:\n    topic: \"quantum computing\"\n\nagents:\n  researcher:\n    prompt: |\n      You are a research assistant with expertise in technology and science.\n      Provide accurate, well-structured information.\n\npattern:\n  type: chain\n  config:\n    steps:\n      # Step 0: Gather key facts\n      - agent: researcher\n        input: \"Research {{ topic }}. List 5 key facts or concepts.\"\n\n      # Step 1: Deep dive on one aspect\n      - agent: researcher\n        input: |\n          Based on this research:\n          {{ steps[0].response }}\n\n          Choose the most interesting fact and explain it in detail.\n\n      # Step 2: Create summary combining both\n      - agent: researcher\n        input: |\n          Using this information:\n\n          Key Facts:\n          {{ steps[0].response }}\n\n          Detailed Explanation:\n          {{ steps[1].response }}\n\n          Write a 2-paragraph summary for a non-technical audience.\n\noutputs:\n  artifacts:\n    - path: ./research-report.md\n      from: |\n        # Research Report: {{ topic }}\n\n        ## Key Facts\n        {{ steps[0].response }}\n\n        ## Deep Dive\n        {{ steps[1].response }}\n\n        ## Summary\n        {{ last_response }}\n</code></pre>"},{"location":"tutorials/first-multi-step/#key-concepts_1","title":"Key Concepts","text":"<ul> <li><code>steps[0].response</code>: Access first step's output (0-indexed)</li> <li><code>steps[1].response</code>: Access second step's output</li> <li>Multi-line artifact template: Combine multiple step results</li> </ul>"},{"location":"tutorials/first-multi-step/#run-it_1","title":"Run It","text":"<pre><code>uv run strands run research-chain.yaml\n</code></pre> <p>The final report includes all three sections with proper formatting.</p>"},{"location":"tutorials/first-multi-step/#step-3-use-variables-in-steps","title":"Step 3: Use Variables in Steps","text":"<p>Each step can define its own variables to control behavior.</p> <p>Create <code>adaptive-chain.yaml</code>:</p> <pre><code>version: 0\nname: adaptive-chain\ndescription: Chain with step-level variables\n\nruntime:\n  provider: openai\n  model_id: gpt-4o-mini\n\ninputs:\n  values:\n    product: \"smart home thermostat\"\n    audience: \"homeowners\"\n\nagents:\n  marketer:\n    prompt: \"You are a professional marketing copywriter.\"\n\npattern:\n  type: chain\n  config:\n    steps:\n      # Step 1: Generate benefits\n      - agent: marketer\n        input: \"List 3 key benefits of {{ product }} for {{ audience }}.\"\n        vars:\n          style: \"concise\"\n\n      # Step 2: Create tagline\n      - agent: marketer\n        input: |\n          Based on these benefits:\n          {{ last_response }}\n\n          Create a memorable tagline (max 10 words).\n        vars:\n          creativity: \"high\"\n\n      # Step 3: Write full description\n      - agent: marketer\n        input: |\n          Tagline: {{ steps[1].response }}\n\n          Benefits: {{ steps[0].response }}\n\n          Write a 100-word product description for {{ audience }}.\n\noutputs:\n  artifacts:\n    - path: ./marketing-copy.md\n      from: |\n        # {{ product }}\n\n        **Tagline**: {{ steps[1].response }}\n\n        ## Benefits\n        {{ steps[0].response }}\n\n        ## Description\n        {{ last_response }}\n</code></pre>"},{"location":"tutorials/first-multi-step/#key-concepts_2","title":"Key Concepts","text":"<ul> <li><code>vars</code>: Step-specific variables (available in that step's context)</li> <li>Combining global and local variables: <code>{{ product }}</code> (global) and <code>{{ style }}</code> (local)</li> </ul>"},{"location":"tutorials/first-multi-step/#step-4-advanced-template-filters","title":"Step 4: Advanced Template Filters","text":"<p>Jinja2 provides powerful filters for transforming data.</p> <p>Create <code>filtered-chain.yaml</code>:</p> <pre><code>version: 0\nname: filtered-chain\ndescription: Using Jinja2 filters in workflows\n\nruntime:\n  provider: openai\n  model_id: gpt-4o-mini\n\ninputs:\n  values:\n    topic: \"climate change impacts\"\n\nagents:\n  analyst:\n    prompt: \"You are a data analyst and science communicator.\"\n\npattern:\n  type: chain\n  config:\n    steps:\n      # Step 1: Generate long-form analysis\n      - agent: analyst\n        input: \"Provide a comprehensive analysis of {{ topic }}. Be detailed and thorough.\"\n\n      # Step 2: Create executive summary\n      - agent: analyst\n        input: |\n          Full analysis (first 500 chars):\n          {{ steps[0].response | truncate(500) }}\n\n          Create a 3-bullet executive summary of the key takeaways.\n\n      # Step 3: Generate tweet\n      - agent: analyst\n        input: |\n          Analysis: {{ steps[0].response | truncate(200) }}\n\n          Summary: {{ steps[1].response }}\n\n          Write a Twitter thread (3 tweets, 280 chars each) explaining {{ topic }}.\n\noutputs:\n  artifacts:\n    - path: ./{{ topic | replace(' ', '_') | lower }}_analysis.md\n      from: |\n        # {{ topic | title }}\n\n        ## Full Analysis\n        {{ steps[0].response }}\n\n        ## Executive Summary\n        {{ steps[1].response }}\n\n        ## Social Media (Twitter Thread)\n        {{ last_response }}\n</code></pre>"},{"location":"tutorials/first-multi-step/#common-jinja2-filters","title":"Common Jinja2 Filters","text":"Filter Example Result <code>truncate(n)</code> <code>{{ text \\| truncate(100) }}</code> First 100 chars + \"...\" <code>lower</code> <code>{{ \"HELLO\" \\| lower }}</code> \"hello\" <code>upper</code> <code>{{ \"hello\" \\| upper }}</code> \"HELLO\" <code>title</code> <code>{{ \"hello world\" \\| title }}</code> \"Hello World\" <code>replace(old, new)</code> <code>{{ \"a b\" \\| replace(' ', '-') }}</code> \"a-b\" <code>trim</code> <code>{{ \"  text  \" \\| trim }}</code> \"text\""},{"location":"tutorials/first-multi-step/#step-5-error-handling-and-debugging","title":"Step 5: Error Handling and Debugging","text":"<p>When building complex chains, debugging is important.</p>"},{"location":"tutorials/first-multi-step/#enable-debug-mode","title":"Enable Debug Mode","text":"<pre><code>uv run strands run workflow.yaml --debug --verbose\n</code></pre> <p>This shows: - Each step's input before execution - Each step's output after execution - Token usage per step - Timing information</p>"},{"location":"tutorials/first-multi-step/#validate-before-running","title":"Validate Before Running","text":"<pre><code>uv run strands validate workflow.yaml\n</code></pre> <p>Catches: - YAML syntax errors - Missing required fields - Invalid template syntax - Type mismatches</p>"},{"location":"tutorials/first-multi-step/#common-errors-and-solutions","title":"Common Errors and Solutions","text":"<p>Error: <code>TemplateSyntaxError: unexpected '}'</code></p> <p>Solution: Check Jinja2 syntax - use <code>{{ variable }}</code> not <code>{variable}</code></p> <p>Error: <code>KeyError: 'steps'</code></p> <p>Solution: <code>steps[n].response</code> only works in chain pattern, not single_agent</p> <p>Error: <code>IndexError: list index out of range</code></p> <p>Solution: Can't access <code>steps[2]</code> from step 1 - only previous steps available</p>"},{"location":"tutorials/first-multi-step/#step-6-real-world-example-blog-post-generator","title":"Step 6: Real-World Example - Blog Post Generator","text":"<p>Let's create a practical workflow that generates a complete blog post.</p> <p>Create <code>blog-generator.yaml</code>:</p> <pre><code>version: 0\nname: blog-generator\ndescription: Complete blog post generation workflow\n\nruntime:\n  provider: openai\n  model_id: gpt-4o-mini\n  temperature: 0.7\n  max_tokens: 8000\n\ninputs:\n  values:\n    topic: \"productivity tips for remote workers\"\n    target_words: 800\n    tone: \"friendly and practical\"\n\nagents:\n  content_creator:\n    prompt: |\n      You are a professional content creator and blogger.\n      Write in a {{ tone }} style.\n      Use clear headings, bullet points, and examples.\n\npattern:\n  type: chain\n  config:\n    steps:\n      # Step 1: Research and brainstorm\n      - agent: content_creator\n        input: |\n          Brainstorm ideas for a blog post about: {{ topic }}\n\n          Provide:\n          - 3 potential titles\n          - 5 main points to cover\n          - 3 relevant examples or stories\n\n      # Step 2: Create outline\n      - agent: content_creator\n        input: |\n          Using these ideas:\n          {{ last_response }}\n\n          Create a detailed outline for a {{ target_words }}-word blog post.\n          Include:\n          - Introduction hook\n          - 3-5 main sections with subsections\n          - Conclusion with call-to-action\n\n      # Step 3: Write full article\n      - agent: content_creator\n        input: |\n          Write a complete blog post following this outline:\n\n          {{ last_response }}\n\n          Requirements:\n          - Target length: {{ target_words }} words\n          - Tone: {{ tone }}\n          - Use markdown formatting\n          - Include practical examples\n\n      # Step 4: Generate SEO metadata\n      - agent: content_creator\n        input: |\n          For this blog post:\n          {{ steps[2].response | truncate(500) }}\n\n          Generate:\n          - SEO title (60 chars max)\n          - Meta description (155 chars max)\n          - 5 relevant keywords\n\noutputs:\n  artifacts:\n    - path: ./blog-posts/{{ topic | replace(' ', '-') | lower }}.md\n      from: |\n        ---\n        title: \"{{ topic | title }}\"\n        date: \"{{ now }}\"\n        keywords: {{ steps[3].response }}\n        ---\n\n        {{ steps[2].response }}\n\n        ---\n\n        ## SEO Metadata\n        {{ steps[3].response }}\n</code></pre>"},{"location":"tutorials/first-multi-step/#run-the-blog-generator","title":"Run the Blog Generator","text":"<pre><code>uv run strands run blog-generator.yaml\n</code></pre> <p>Or customize it:</p> <pre><code>uv run strands run blog-generator.yaml \\\n  --var topic=\"healthy eating on a budget\" \\\n  --var target_words=1200 \\\n  --var tone=\"authoritative yet approachable\"\n</code></pre>"},{"location":"tutorials/first-multi-step/#best-practices-for-multi-step-workflows","title":"Best Practices for Multi-Step Workflows","text":""},{"location":"tutorials/first-multi-step/#1-keep-steps-focused","title":"1. Keep Steps Focused","text":"<p>Each step should have a clear, single purpose.</p> <pre><code># Good: Clear, focused steps\nsteps:\n  - agent: writer\n    input: \"Create outline for {{ topic }}\"\n  - agent: writer\n    input: \"Write introduction based on: {{ last_response }}\"\n\n# Bad: Too much in one step\nsteps:\n  - agent: writer\n    input: \"Create outline, write introduction, and draft conclusion for {{ topic }}\"\n</code></pre>"},{"location":"tutorials/first-multi-step/#2-use-descriptive-step-names-via-comments","title":"2. Use Descriptive Step Names (via comments)","text":"<pre><code>steps:\n  # Step 0: Research phase\n  - agent: researcher\n    input: \"Research {{ topic }}\"\n\n  # Step 1: Analysis phase\n  - agent: analyst\n    input: \"Analyze: {{ steps[0].response }}\"\n</code></pre>"},{"location":"tutorials/first-multi-step/#3-truncate-long-context","title":"3. Truncate Long Context","text":"<p>Avoid passing massive text between steps:</p> <pre><code># Good: Truncate to relevant portion\ninput: \"Summarize: {{ steps[0].response | truncate(1000) }}\"\n\n# Bad: Can hit token limits\ninput: \"Summarize: {{ steps[0].response }}\"\n</code></pre>"},{"location":"tutorials/first-multi-step/#4-test-incrementally","title":"4. Test Incrementally","text":"<p>Build chains one step at a time:</p> <pre><code># Test with just first step\nstrands run workflow.yaml\n\n# Add second step, test again\n# Add third step, test again\n</code></pre>"},{"location":"tutorials/first-multi-step/#5-use-variables-for-reusability","title":"5. Use Variables for Reusability","text":"<pre><code>inputs:\n  values:\n    provider: \"openai\"\n    model: \"gpt-4o-mini\"\n    topic: \"machine learning\"\n\nruntime:\n  provider: \"{{ provider }}\"\n  model_id: \"{{ model }}\"\n</code></pre>"},{"location":"tutorials/first-multi-step/#next-steps","title":"Next Steps","text":"<p>You now understand multi-step workflows! Explore more advanced patterns:</p> <ol> <li>Workflow Pattern: Parallel task execution with dependencies (How-to Guide)</li> <li>Routing Pattern: Dynamic agent selection (How-to Guide)</li> <li>Evaluator-Optimizer: Iterative refinement (How-to Guide)</li> <li>Graph Pattern: Complex control flow with loops (How-to Guide)</li> </ol>"},{"location":"tutorials/first-multi-step/#key-concepts-recap","title":"Key Concepts Recap","text":"Concept Description Example Chain Pattern Sequential step execution <code>pattern.type: chain</code> <code>last_response</code> Most recent step output <code>{{ last_response }}</code> <code>steps[n].response</code> Specific step output (0-indexed) <code>{{ steps[0].response }}</code> Template Filters Transform variables <code>{{ text \\| truncate(100) }}</code> Step Variables Local vars for specific step <code>vars: {style: \"formal\"}</code> Multi-line Templates Combine multiple outputs <code>from: \\|</code> (literal block)"},{"location":"tutorials/first-multi-step/#common-commands","title":"Common Commands","text":"<pre><code># Validate workflow\nstrands validate workflow.yaml\n\n# Run workflow\nstrands run workflow.yaml\n\n# Run with overrides\nstrands run workflow.yaml --var topic=\"AI ethics\"\n\n# Debug mode\nstrands run workflow.yaml --debug --verbose\n\n# Preview without execution\nstrands plan workflow.yaml\n</code></pre>"},{"location":"tutorials/first-multi-step/#template-variable-reference","title":"Template Variable Reference","text":"Variable Description Available In <code>{{ last_response }}</code> Most recent step output All steps after first <code>{{ steps[n].response }}</code> Specific step output Steps after step n <code>{{ inputs.variable }}</code> Input variable All steps <code>{{ now }}</code> Current timestamp All contexts"},{"location":"tutorials/first-multi-step/#further-reading","title":"Further Reading","text":"<ul> <li>Chain Pattern Reference - Complete chain pattern guide</li> <li>Schema Reference - Complete spec documentation</li> <li>Jinja2 Filters - Complete filter list</li> <li>Pattern Comparison - When to use each pattern</li> <li>Context Management - Managing token budgets</li> </ul>"},{"location":"tutorials/quickstart-bedrock/","title":"Quickstart with AWS Bedrock","text":"<p>This tutorial will guide you through setting up and running your first Strands workflow using AWS Bedrock, Amazon's managed service for foundation models. Bedrock provides enterprise-grade AI with built-in security, compliance, and scalability.</p>"},{"location":"tutorials/quickstart-bedrock/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>How to configure AWS credentials for Bedrock</li> <li>How to select and use Bedrock models</li> <li>How to create and run a Bedrock workflow</li> <li>Understanding regions and model availability</li> <li>Best practices for production deployments</li> </ul>"},{"location":"tutorials/quickstart-bedrock/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have:</p> <ul> <li>Python 3.12 or higher installed</li> <li>AWS Account with Bedrock access</li> <li>Basic command-line experience</li> <li>AWS CLI installed (recommended)</li> <li>IAM permissions for Bedrock model invocation</li> </ul>"},{"location":"tutorials/quickstart-bedrock/#step-1-enable-bedrock-model-access","title":"Step 1: Enable Bedrock Model Access","text":"<p>AWS Bedrock requires explicit model access activation in your AWS account.</p> <ol> <li>Sign in to AWS Console: Navigate to the AWS Bedrock Console</li> <li>Select Region: Choose your preferred region (e.g., <code>us-east-1</code>)</li> <li>Enable Model Access:</li> <li>Click \"Model access\" in the left sidebar</li> <li>Click \"Manage model access\"</li> <li>Select the models you want to use (we recommend starting with Claude 3 Sonnet)</li> <li>Click \"Request model access\"</li> </ol> <p>Model Access Approval</p> <p>Some models require approval, which may take a few minutes to several hours. Claude models are typically instant.</p>"},{"location":"tutorials/quickstart-bedrock/#recommended-models","title":"Recommended Models","text":"Model ID Use Case Claude 3.5 Sonnet <code>anthropic.claude-3-5-sonnet-20241022-v2:0</code> Best overall performance Claude 3 Sonnet <code>anthropic.claude-3-sonnet-20240229-v1:0</code> Balanced performance/cost Claude 3 Haiku <code>anthropic.claude-3-haiku-20240307-v1:0</code> Fast, cost-effective"},{"location":"tutorials/quickstart-bedrock/#step-2-configure-aws-credentials","title":"Step 2: Configure AWS Credentials","text":""},{"location":"tutorials/quickstart-bedrock/#option-1-aws-cli-recommended","title":"Option 1: AWS CLI (Recommended)","text":"<pre><code># Install AWS CLI if not already installed\n# macOS: brew install awscli\n# Windows: Download from aws.amazon.com/cli/\n# Linux: pip install awscli\n\n# Configure credentials\naws configure\n</code></pre> <p>You'll be prompted for:</p> <ul> <li>AWS Access Key ID: Your IAM access key</li> <li>AWS Secret Access Key: Your IAM secret key</li> <li>Default region: e.g., <code>us-east-1</code></li> <li>Default output format: <code>json</code></li> </ul>"},{"location":"tutorials/quickstart-bedrock/#option-2-environment-variables","title":"Option 2: Environment Variables","text":"<pre><code># Linux/macOS\nexport AWS_ACCESS_KEY_ID=your-access-key-id\nexport AWS_SECRET_ACCESS_KEY=your-secret-access-key\nexport AWS_DEFAULT_REGION=us-east-1\n\n# Windows PowerShell\n$env:AWS_ACCESS_KEY_ID = \"your-access-key-id\"\n$env:AWS_SECRET_ACCESS_KEY = \"your-secret-access-key\"\n$env:AWS_DEFAULT_REGION = \"us-east-1\"\n</code></pre>"},{"location":"tutorials/quickstart-bedrock/#option-3-iam-role-ec2ecslambda","title":"Option 3: IAM Role (EC2/ECS/Lambda)","text":"<p>If running on AWS infrastructure, use IAM roles instead of credentials. No configuration needed!</p>"},{"location":"tutorials/quickstart-bedrock/#verify-access","title":"Verify Access","text":"<pre><code># Test Bedrock access\naws bedrock list-foundation-models --region us-east-1\n</code></pre>"},{"location":"tutorials/quickstart-bedrock/#step-3-check-iam-permissions","title":"Step 3: Check IAM Permissions","text":"<p>Your IAM user or role needs these permissions:</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"bedrock:InvokeModel\",\n        \"bedrock:InvokeModelWithResponseStream\"\n      ],\n      \"Resource\": [\n        \"arn:aws:bedrock:*::foundation-model/anthropic.claude-*\"\n      ]\n    }\n  ]\n}\n</code></pre> <p>Least Privilege</p> <p>For production, restrict to specific model ARNs and regions you actually use.</p>"},{"location":"tutorials/quickstart-bedrock/#step-4-install-strands-cli","title":"Step 4: Install Strands CLI","text":"<p>Install Strands CLI with AWS dependencies:</p> Using uv (recommended)Using pip <pre><code># Install uv if not already installed\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Install Strands CLI with AWS support\nuv pip install \"strands-cli[aws]\"\n\n# Verify installation\nuv run strands --version\n</code></pre> <pre><code># Install Strands CLI with AWS support\npip install \"strands-cli[aws]\"\n\n# Verify installation\nstrands --version\n</code></pre>"},{"location":"tutorials/quickstart-bedrock/#step-5-create-your-first-bedrock-workflow","title":"Step 5: Create Your First Bedrock Workflow","text":"<p>Create a new file called <code>my-bedrock-workflow.yaml</code>:</p> <pre><code>version: 0\nname: my-bedrock-workflow\ndescription: My first Strands workflow using AWS Bedrock\n\nruntime:\n  provider: bedrock\n  model_id: anthropic.claude-3-sonnet-20240229-v1:0\n  region: us-east-1\n\ninputs:\n  values:\n    company: \"Acme Corp\"\n    product: \"cloud storage solution\"\n\nagents:\n  copywriter:\n    prompt: |\n      You are a professional marketing copywriter with expertise in B2B SaaS.\n      Create compelling, benefit-focused copy that resonates with decision-makers.\n      Format your response in clean Markdown.\n\npattern:\n  type: single_agent\n  config:\n    agent: copywriter\n    input: |\n      Write a compelling product tagline and 3-sentence value proposition\n      for {{ company }}'s {{ product }}.\n\n      Focus on benefits, not features. Make it memorable and actionable.\n\noutputs:\n  artifacts:\n    - path: ./marketing-copy.md\n      from: \"{{ last_response }}\"\n</code></pre>"},{"location":"tutorials/quickstart-bedrock/#understanding-bedrock-specific-settings","title":"Understanding Bedrock-Specific Settings","text":"<ul> <li><code>provider: bedrock</code>: Tells Strands to use AWS Bedrock</li> <li><code>model_id</code>: Full Bedrock model identifier (includes version)</li> <li><code>region</code>: AWS region where your model access is enabled</li> <li>If omitted, uses <code>AWS_DEFAULT_REGION</code> or <code>us-east-1</code></li> </ul>"},{"location":"tutorials/quickstart-bedrock/#step-6-validate-your-workflow","title":"Step 6: Validate Your Workflow","text":"<pre><code>uv run strands validate my-bedrock-workflow.yaml\n</code></pre> <p>Expected output:</p> <pre><code>\u2713 Workflow is valid\n</code></pre>"},{"location":"tutorials/quickstart-bedrock/#step-7-run-your-workflow","title":"Step 7: Run Your Workflow","text":"<pre><code>uv run strands run my-bedrock-workflow.yaml\n</code></pre> <p>Expected output:</p> <pre><code>\ud83d\ude80 Starting workflow: my-bedrock-workflow\n\ud83d\udcca Runtime: bedrock (anthropic.claude-3-sonnet-20240229-v1:0)\n\ud83c\udf0d Region: us-east-1\n\ud83e\udd16 Agent: copywriter\n\u2705 Workflow completed successfully\n\ud83d\udcdd Artifact written: ./marketing-copy.md\n</code></pre>"},{"location":"tutorials/quickstart-bedrock/#step-8-check-the-output","title":"Step 8: Check the Output","text":"<pre><code>cat marketing-copy.md\n</code></pre> <p>You'll see Claude's marketing copy for your fictional product.</p>"},{"location":"tutorials/quickstart-bedrock/#step-9-use-environment-configuration","title":"Step 9: Use Environment Configuration","text":"<p>Instead of hardcoding settings, use environment variables:</p> <pre><code>version: 0\nname: configurable-bedrock-workflow\ndescription: Workflow with environment-based configuration\n\nruntime:\n  provider: bedrock\n  # model_id and region will use environment defaults\n  # Override with STRANDS_BEDROCK_MODEL_ID and STRANDS_AWS_REGION\n\nagents:\n  assistant:\n    prompt: \"You are a helpful AI assistant.\"\n\npattern:\n  type: single_agent\n  config:\n    agent: assistant\n    input: \"{{ prompt }}\"\n</code></pre> <p>Then run with overrides:</p> <pre><code># Set defaults\nexport STRANDS_BEDROCK_MODEL_ID=anthropic.claude-3-haiku-20240307-v1:0\nexport STRANDS_AWS_REGION=us-west-2\n\n# Run with variable override\nuv run strands run configurable-bedrock-workflow.yaml \\\n  --var prompt=\"Explain serverless computing\"\n</code></pre>"},{"location":"tutorials/quickstart-bedrock/#region-and-model-availability","title":"Region and Model Availability","text":"<p>Different models are available in different AWS regions:</p> Region Code Claude 3.5 Sonnet Claude 3 Sonnet Claude 3 Haiku US East (N. Virginia) <code>us-east-1</code> \u2705 \u2705 \u2705 US West (Oregon) <code>us-west-2</code> \u2705 \u2705 \u2705 Europe (Frankfurt) <code>eu-central-1</code> \u2705 \u2705 \u2705 Asia Pacific (Tokyo) <code>ap-northeast-1</code> \u2705 \u2705 \u2705 Asia Pacific (Singapore) <code>ap-southeast-1</code> \u2705 \u2705 \u2705 <p>Check the AWS Bedrock documentation for the latest availability.</p>"},{"location":"tutorials/quickstart-bedrock/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/quickstart-bedrock/#access-denied-errors","title":"Access Denied Errors","text":"<p>Problem: <code>AccessDeniedException: User is not authorized to perform: bedrock:InvokeModel</code></p> <p>Solution: 1. Verify IAM permissions include <code>bedrock:InvokeModel</code> 2. Check the resource ARN matches your model 3. Ensure credentials are correctly configured</p> <pre><code># Verify current identity\naws sts get-caller-identity\n\n# List accessible models\naws bedrock list-foundation-models --region us-east-1\n</code></pre>"},{"location":"tutorials/quickstart-bedrock/#model-not-found","title":"Model Not Found","text":"<p>Problem: <code>ResourceNotFoundException: Could not find model</code></p> <p>Solution: 1. Verify model access is enabled in Bedrock console 2. Check model ID is correct (including version) 3. Verify model is available in your selected region</p>"},{"location":"tutorials/quickstart-bedrock/#throttling-errors","title":"Throttling Errors","text":"<p>Problem: <code>ThrottlingException: Rate exceeded</code></p> <p>Solution: 1. Add retry logic (Strands does this automatically) 2. Request a quota increase in AWS Service Quotas 3. Implement exponential backoff in high-volume scenarios 4. Use multiple models or regions for load balancing</p>"},{"location":"tutorials/quickstart-bedrock/#invalid-region","title":"Invalid Region","text":"<p>Problem: <code>ValidationException: Invalid region</code></p> <p>Solution: 1. Use a region where Bedrock is available 2. Set region explicitly in workflow or environment 3. Check <code>aws bedrock list-foundation-models --region &lt;region&gt;</code></p>"},{"location":"tutorials/quickstart-bedrock/#cost-optimization","title":"Cost Optimization","text":""},{"location":"tutorials/quickstart-bedrock/#understanding-bedrock-pricing","title":"Understanding Bedrock Pricing","text":"<p>Bedrock charges per token (input and output separately):</p> Model Input (per 1K tokens) Output (per 1K tokens) Claude 3.5 Sonnet $0.003 $0.015 Claude 3 Sonnet $0.003 $0.015 Claude 3 Haiku $0.00025 $0.00125"},{"location":"tutorials/quickstart-bedrock/#tips-to-reduce-costs","title":"Tips to Reduce Costs","text":"<ol> <li>Use Haiku for simple tasks: 10x cheaper than Sonnet</li> <li>Minimize prompt size: Remove unnecessary context</li> <li>Set output limits: Use max_tokens in agent configuration</li> <li>Cache prompts: Use Strands' agent caching for repeated tasks</li> <li>Monitor with CloudWatch: Track token usage and costs</li> </ol>"},{"location":"tutorials/quickstart-bedrock/#production-best-practices","title":"Production Best Practices","text":""},{"location":"tutorials/quickstart-bedrock/#1-use-iam-roles-instead-of-keys","title":"1. Use IAM Roles Instead of Keys","text":"<pre><code># Good: Implicit credentials from IAM role (EC2/ECS/Lambda)\nruntime:\n  provider: bedrock\n  model_id: anthropic.claude-3-sonnet-20240229-v1:0\n  region: us-east-1\n</code></pre>"},{"location":"tutorials/quickstart-bedrock/#2-enable-cloudwatch-logging","title":"2. Enable CloudWatch Logging","text":"<pre><code># Enable model invocation logging in Bedrock console\n# Settings \u2192 Model invocation logging \u2192 Enable\n</code></pre>"},{"location":"tutorials/quickstart-bedrock/#3-implement-budget-controls","title":"3. Implement Budget Controls","text":"<pre><code>runtime:\n  provider: bedrock\n  model_id: anthropic.claude-3-sonnet-20240229-v1:0\n  region: us-east-1\n  budgets:\n    token_budget:\n      max_input_tokens: 50000\n      max_output_tokens: 10000\n</code></pre>"},{"location":"tutorials/quickstart-bedrock/#4-use-multi-region-fallback","title":"4. Use Multi-Region Fallback","text":"<pre><code># Primary region\nSTRANDS_AWS_REGION=us-east-1\n\n# Fallback to us-west-2 if us-east-1 has issues\n# (Requires application-level logic or load balancer)\n</code></pre>"},{"location":"tutorials/quickstart-bedrock/#5-tag-resources-for-cost-tracking","title":"5. Tag Resources for Cost Tracking","text":"<p>Use AWS tags to track Bedrock usage by project, environment, or team.</p>"},{"location":"tutorials/quickstart-bedrock/#next-steps","title":"Next Steps","text":"<p>Now that you have Bedrock configured, explore advanced features:</p> <ol> <li>Multi-step workflows: Learn the chain pattern tutorial</li> <li>Add custom tools: Integrate APIs with HTTP executors</li> <li>Enable telemetry: Track execution with OpenTelemetry</li> <li>Explore examples: Check <code>examples/</code> for Bedrock workflows:</li> <li><code>examples/minimal-bedrock.yaml</code> - Minimal configuration</li> <li><code>examples/evaluator-optimizer-code-review-bedrock.yaml</code> - Iterative refinement</li> </ol>"},{"location":"tutorials/quickstart-bedrock/#key-concepts-recap","title":"Key Concepts Recap","text":"Concept Description Model ID Full Bedrock model identifier including version Region AWS region where model access is enabled IAM Role Preferred authentication method for AWS resources Model Access Must be explicitly enabled per region in console Streaming Bedrock supports streaming responses (automatic)"},{"location":"tutorials/quickstart-bedrock/#common-commands-reference","title":"Common Commands Reference","text":"<pre><code># Validate workflow\nstrands validate workflow.yaml\n\n# Run workflow\nstrands run workflow.yaml\n\n# Run with specific region\nstrands run workflow.yaml --var region=us-west-2\n\n# Debug mode\nstrands run workflow.yaml --debug --verbose\n\n# Check available Bedrock models\naws bedrock list-foundation-models --region us-east-1\n\n# Test Bedrock access\naws bedrock-runtime invoke-model \\\n  --model-id anthropic.claude-3-haiku-20240307-v1:0 \\\n  --body '{\"anthropic_version\":\"bedrock-2023-05-31\",\"max_tokens\":100,\"messages\":[{\"role\":\"user\",\"content\":\"Hi\"}]}' \\\n  --region us-east-1 \\\n  output.json\n</code></pre>"},{"location":"tutorials/quickstart-bedrock/#environment-variables-reference","title":"Environment Variables Reference","text":"Variable Description Default <code>STRANDS_AWS_REGION</code> AWS region for Bedrock <code>us-east-1</code> <code>STRANDS_BEDROCK_MODEL_ID</code> Default Bedrock model <code>anthropic.claude-3-sonnet-20240229-v1:0</code> <code>AWS_ACCESS_KEY_ID</code> AWS access key (from AWS CLI) <code>AWS_SECRET_ACCESS_KEY</code> AWS secret key (from AWS CLI) <code>AWS_SESSION_TOKEN</code> Temporary session token (optional) <code>AWS_PROFILE</code> AWS CLI profile name <code>default</code>"},{"location":"tutorials/quickstart-bedrock/#further-reading","title":"Further Reading","text":"<ul> <li>AWS Bedrock Documentation - Official AWS docs</li> <li>Claude on Bedrock Guide - Anthropic's guide</li> <li>Bedrock Pricing - Cost calculator</li> <li>Workflow Schema Reference - Complete YAML spec</li> <li>Security Best Practices - Production security</li> </ul>"},{"location":"tutorials/quickstart-ollama/","title":"Quickstart with Ollama","text":"<p>This tutorial will guide you through setting up and running your first Strands workflow using Ollama, a local AI model runtime that lets you run large language models on your own hardware without API costs.</p>"},{"location":"tutorials/quickstart-ollama/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>How to install and configure Ollama</li> <li>How to create and validate a simple workflow</li> <li>How to run workflows and understand the output</li> <li>Basic debugging techniques</li> </ul>"},{"location":"tutorials/quickstart-ollama/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have:</p> <ul> <li>Python 3.12 or higher installed</li> <li>Basic command-line experience</li> <li>At least 8GB of RAM (for running local models)</li> <li>5-10GB of free disk space (for model downloads)</li> </ul>"},{"location":"tutorials/quickstart-ollama/#step-1-install-ollama","title":"Step 1: Install Ollama","text":""},{"location":"tutorials/quickstart-ollama/#macos-and-linux","title":"macOS and Linux","text":"<pre><code># Download and install Ollama\ncurl -fsSL https://ollama.com/install.sh | sh\n</code></pre>"},{"location":"tutorials/quickstart-ollama/#windows","title":"Windows","text":"<p>Download and run the installer from ollama.com/download/windows</p>"},{"location":"tutorials/quickstart-ollama/#verify-installation","title":"Verify Installation","text":"<pre><code># Check Ollama version\nollama --version\n\n# Start Ollama service (if not auto-started)\nollama serve\n</code></pre> <p>The Ollama service should now be running on <code>http://localhost:11434</code>.</p>"},{"location":"tutorials/quickstart-ollama/#step-2-pull-a-model","title":"Step 2: Pull a Model","text":"<p>Ollama supports many models. We'll use <code>llama3.2</code> which provides a good balance of performance and resource usage:</p> <pre><code># Pull the model (this may take a few minutes)\nollama pull llama3.2\n\n# Verify the model is available\nollama list\n</code></pre> <p>Other Models</p> <p>You can use other models like <code>llama3.2:70b</code>, <code>mistral</code>, <code>qwen2.5</code>, or <code>gemma2</code>. See ollama.com/library for the full list.</p>"},{"location":"tutorials/quickstart-ollama/#step-3-install-strands-cli","title":"Step 3: Install Strands CLI","text":"<p>Install Strands CLI using pip or uv:</p> Using uv (recommended)Using pip <pre><code># Install uv if not already installed\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Install Strands CLI\nuv pip install strands-cli\n\n# Verify installation\nuv run strands --version\n</code></pre> <pre><code># Install Strands CLI\npip install strands-cli\n\n# Verify installation\nstrands --version\n</code></pre>"},{"location":"tutorials/quickstart-ollama/#step-4-create-your-first-workflow","title":"Step 4: Create Your First Workflow","text":"<p>Create a new file called <code>my-first-workflow.yaml</code>:</p> <pre><code>version: 0\nname: my-first-workflow\ndescription: My first Strands workflow using Ollama\n\nruntime:\n  provider: ollama\n  model_id: llama3.2\n  host: http://localhost:11434\n\ninputs:\n  values:\n    topic: \"quantum computing\"\n\nagents:\n  explainer:\n    prompt: |\n      You are a knowledgeable science educator who explains complex topics\n      in simple, accessible language. Use analogies and examples that anyone\n      can understand. Format your response in clear Markdown.\n\npattern:\n  type: single_agent\n  config:\n    agent: explainer\n    input: \"Explain {{ topic }} in simple terms that a beginner can understand.\"\n\noutputs:\n  artifacts:\n    - path: ./explanation.md\n      from: \"{{ last_response }}\"\n</code></pre>"},{"location":"tutorials/quickstart-ollama/#understanding-the-workflow","title":"Understanding the Workflow","text":"<p>Let's break down the key sections:</p> <ul> <li><code>runtime</code>: Configures which AI provider and model to use</li> <li><code>provider: ollama</code> tells Strands to use Ollama</li> <li><code>model_id: llama3.2</code> specifies which model to run</li> <li> <p><code>host</code> points to the Ollama service</p> </li> <li> <p><code>inputs</code>: Defines variables you can use in your workflow</p> </li> <li> <p>We define a <code>topic</code> variable that can be referenced later</p> </li> <li> <p><code>agents</code>: Defines AI agents with specific prompts and behaviors</p> </li> <li> <p>The <code>explainer</code> agent has instructions to explain things simply</p> </li> <li> <p><code>pattern</code>: Defines how the workflow executes</p> </li> <li><code>single_agent</code> is the simplest pattern - one agent, one response</li> <li> <p>The <code>input</code> uses <code>{{ topic }}</code> to inject our variable</p> </li> <li> <p><code>outputs</code>: Specifies where to save results</p> </li> <li>Creates a file <code>explanation.md</code> with the agent's response</li> </ul>"},{"location":"tutorials/quickstart-ollama/#step-5-validate-your-workflow","title":"Step 5: Validate Your Workflow","text":"<p>Before running, validate that your workflow is correctly formatted:</p> <pre><code>uv run strands validate my-first-workflow.yaml\n</code></pre> <p>You should see:</p> <pre><code>\u2713 Workflow is valid\n</code></pre> <p>If you see errors, check:</p> <ul> <li>YAML syntax (indentation, colons, quotes)</li> <li>Required fields are present</li> <li>Values match the expected types</li> </ul>"},{"location":"tutorials/quickstart-ollama/#step-6-run-your-workflow","title":"Step 6: Run Your Workflow","text":"<p>Execute the workflow:</p> <pre><code>uv run strands run my-first-workflow.yaml\n</code></pre> <p>You should see output like:</p> <pre><code>\ud83d\ude80 Starting workflow: my-first-workflow\n\ud83d\udcca Runtime: ollama (llama3.2)\n\ud83e\udd16 Agent: explainer\n\u2705 Workflow completed successfully\n\ud83d\udcdd Artifact written: ./explanation.md\n</code></pre>"},{"location":"tutorials/quickstart-ollama/#step-7-check-the-output","title":"Step 7: Check the Output","text":"<p>Open the generated <code>explanation.md</code> file to see the AI-generated explanation of quantum computing.</p> <pre><code>cat explanation.md\n</code></pre>"},{"location":"tutorials/quickstart-ollama/#step-8-customize-with-variables","title":"Step 8: Customize with Variables","text":"<p>You can override variables from the command line without editing the YAML:</p> <pre><code># Ask about a different topic\nuv run strands run my-first-workflow.yaml --var topic=\"black holes\"\n\n# Multiple variables\nuv run strands run my-first-workflow.yaml \\\n  --var topic=\"photosynthesis\" \\\n  --var output_file=\"photosynthesis.md\"\n</code></pre>"},{"location":"tutorials/quickstart-ollama/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/quickstart-ollama/#ollama-connection-failed","title":"Ollama Connection Failed","text":"<p>Problem: <code>Error: Could not connect to Ollama at http://localhost:11434</code></p> <p>Solution: <pre><code># Ensure Ollama is running\nollama serve\n\n# In another terminal, verify it's accessible\ncurl http://localhost:11434/api/tags\n</code></pre></p>"},{"location":"tutorials/quickstart-ollama/#model-not-found","title":"Model Not Found","text":"<p>Problem: <code>Error: Model 'llama3.2' not found</code></p> <p>Solution: <pre><code># Pull the model\nollama pull llama3.2\n\n# Verify it's available\nollama list\n</code></pre></p>"},{"location":"tutorials/quickstart-ollama/#out-of-memory-errors","title":"Out of Memory Errors","text":"<p>Problem: System freezes or Ollama crashes</p> <p>Solution: - Use a smaller model: <code>ollama pull llama3.2:1b</code> - Update the workflow to use <code>model_id: llama3.2:1b</code> - Close other memory-intensive applications</p>"},{"location":"tutorials/quickstart-ollama/#slow-response-times","title":"Slow Response Times","text":"<p>Problem: Workflow takes a very long time to complete</p> <p>Solution: - Use GPU acceleration if available - Try a smaller model variant - Reduce the complexity of your prompt - Use fewer tokens in the response</p>"},{"location":"tutorials/quickstart-ollama/#next-steps","title":"Next Steps","text":"<p>Now that you have a working Ollama setup, you can:</p> <ol> <li>Explore patterns: Try the multi-step workflow tutorial</li> <li>Add tools: Learn about built-in tools</li> <li>Enable telemetry: Set up observability</li> <li>Browse examples: Check the <code>examples/</code> folder for more complex workflows:</li> <li><code>examples/single-agent-workflow-ollama.yaml</code> - Basic single agent</li> <li><code>examples/evaluator-optimizer-writing-ollama.yaml</code> - Iterative refinement</li> <li><code>examples/single-agent-chain-ollama.yaml</code> - Simple chain pattern</li> </ol>"},{"location":"tutorials/quickstart-ollama/#key-concepts-recap","title":"Key Concepts Recap","text":"Concept Description Runtime Configures which AI provider and model to use Agent An AI entity with a specific prompt and behavior Pattern The execution flow (single_agent, chain, workflow, etc.) Variables Values you can reference with <code>{{ variable_name }}</code> Artifacts Output files generated by the workflow Validation Checking workflow syntax before execution"},{"location":"tutorials/quickstart-ollama/#common-commands-reference","title":"Common Commands Reference","text":"<pre><code># Validate workflow\nstrands validate workflow.yaml\n\n# Run workflow\nstrands run workflow.yaml\n\n# Run with variable overrides\nstrands run workflow.yaml --var key=value\n\n# Debug mode (shows detailed execution)\nstrands run workflow.yaml --debug --verbose\n\n# Check Strands CLI version\nstrands --version\n\n# Get help\nstrands --help\nstrands run --help\n</code></pre>"},{"location":"tutorials/quickstart-ollama/#see-also","title":"See Also","text":"<p>Next Steps:</p> <ul> <li>First Multi-Step Workflow - Build a chain pattern workflow</li> <li>Quickstart with Bedrock - Use AWS Bedrock instead</li> <li>Quickstart with OpenAI - Use OpenAI models</li> </ul> <p>How-To Guides:</p> <ul> <li>Run Workflows - Advanced execution options</li> <li>Validate Workflows - Schema validation techniques</li> <li>Working with Tools - Add tools to your agents</li> </ul> <p>Reference:</p> <ul> <li>CLI Reference - All available commands</li> <li>Schema Reference - Complete YAML spec</li> <li>Examples Catalog - Browse example workflows</li> </ul> <p>External:</p> <ul> <li>Ollama Model Library - Browse available models</li> <li>Ollama Documentation - Official Ollama docs</li> </ul>"},{"location":"tutorials/quickstart-openai/","title":"Quickstart with OpenAI","text":"<p>This tutorial will guide you through setting up and running your first Strands workflow using OpenAI's API. OpenAI provides access to powerful models like GPT-4o, GPT-4, and o1 with a simple pay-as-you-go pricing model.</p>"},{"location":"tutorials/quickstart-openai/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>How to set up an OpenAI API key</li> <li>How to configure and use OpenAI models</li> <li>How to create and run an OpenAI workflow</li> <li>Understanding model selection and pricing</li> <li>Best practices for API usage</li> </ul>"},{"location":"tutorials/quickstart-openai/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have:</p> <ul> <li>Python 3.12 or higher installed</li> <li>OpenAI account with API access</li> <li>Basic command-line experience</li> <li>Payment method added to OpenAI account</li> </ul>"},{"location":"tutorials/quickstart-openai/#step-1-create-an-openai-api-key","title":"Step 1: Create an OpenAI API Key","text":""},{"location":"tutorials/quickstart-openai/#sign-up-for-openai","title":"Sign Up for OpenAI","text":"<ol> <li>Go to platform.openai.com</li> <li>Sign in or create an account</li> <li>Add a payment method under Settings \u2192 Billing</li> </ol> <p>Free Credits</p> <p>New OpenAI accounts may receive free trial credits. Check your billing dashboard.</p>"},{"location":"tutorials/quickstart-openai/#generate-api-key","title":"Generate API Key","text":"<ol> <li>Navigate to API Keys</li> <li>Click \"Create new secret key\"</li> <li>Give it a name (e.g., \"Strands CLI\")</li> <li>Copy the key immediately (you won't see it again!)</li> <li>Store it securely</li> </ol> <p>Keep Your Key Safe</p> <p>Never commit API keys to version control. Use environment variables or secrets managers.</p>"},{"location":"tutorials/quickstart-openai/#step-2-configure-your-api-key","title":"Step 2: Configure Your API Key","text":""},{"location":"tutorials/quickstart-openai/#option-1-environment-variable-recommended","title":"Option 1: Environment Variable (Recommended)","text":"<pre><code># Linux/macOS\nexport OPENAI_API_KEY=sk-proj-...\n\n# Add to ~/.bashrc or ~/.zshrc for persistence\necho 'export OPENAI_API_KEY=sk-proj-...' &gt;&gt; ~/.bashrc\n\n# Windows PowerShell\n$env:OPENAI_API_KEY = \"sk-proj-...\"\n\n# Add to PowerShell profile for persistence\nAdd-Content $PROFILE \"`n`$env:OPENAI_API_KEY = 'sk-proj-...'\"\n</code></pre>"},{"location":"tutorials/quickstart-openai/#option-2-env-file-development","title":"Option 2: .env File (Development)","text":"<p>Create a <code>.env</code> file in your project directory:</p> <pre><code>OPENAI_API_KEY=sk-proj-...\n</code></pre> <p>Then load it before running workflows:</p> <pre><code># Linux/macOS\nexport $(cat .env | xargs)\n\n# Or use a tool like direnv or python-dotenv\n</code></pre> <p>Don't Commit .env Files</p> <p>Add <code>.env</code> to your <code>.gitignore</code> file!</p>"},{"location":"tutorials/quickstart-openai/#verify-setup","title":"Verify Setup","text":"<pre><code># Quick test using curl\ncurl https://api.openai.com/v1/models \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  | head -20\n</code></pre>"},{"location":"tutorials/quickstart-openai/#step-3-install-strands-cli","title":"Step 3: Install Strands CLI","text":"<p>Install Strands CLI using pip or uv:</p> Using uv (recommended)Using pip <pre><code># Install uv if not already installed\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Install Strands CLI\nuv pip install strands-cli\n\n# Verify installation\nuv run strands --version\n</code></pre> <pre><code># Install Strands CLI\npip install strands-cli\n\n# Verify installation\nstrands --version\n</code></pre>"},{"location":"tutorials/quickstart-openai/#step-4-choose-a-model","title":"Step 4: Choose a Model","text":"<p>OpenAI offers several models with different capabilities and pricing:</p> Model ID Use Case Cost (per 1M tokens) GPT-4o <code>gpt-4o</code> Best overall, multimodal Input: $2.50, Output: $10.00 GPT-4o mini <code>gpt-4o-mini</code> Fast and affordable Input: $0.15, Output: $0.60 o1 <code>o1</code> Advanced reasoning Input: $15.00, Output: $60.00 o1-mini <code>o1-mini</code> Fast reasoning Input: $3.00, Output: $12.00 GPT-4 Turbo <code>gpt-4-turbo</code> Previous flagship Input: $10.00, Output: $30.00 <p>Start with GPT-4o mini</p> <p>For learning and testing, use <code>gpt-4o-mini</code> - it's fast and cost-effective.</p>"},{"location":"tutorials/quickstart-openai/#step-5-create-your-first-openai-workflow","title":"Step 5: Create Your First OpenAI Workflow","text":"<p>Create a new file called <code>my-openai-workflow.yaml</code>:</p> <pre><code>version: 0\nname: my-openai-workflow\ndescription: My first Strands workflow using OpenAI\n\nruntime:\n  provider: openai\n  model_id: gpt-4o-mini\n\ninputs:\n  values:\n    language: \"Python\"\n    task: \"read a CSV file and calculate the average of a numeric column\"\n\nagents:\n  code_assistant:\n    prompt: |\n      You are an expert software developer who writes clean, well-documented code.\n      Provide complete, working examples with helpful comments.\n      Format code blocks with proper syntax highlighting.\n\npattern:\n  type: single_agent\n  config:\n    agent: code_assistant\n    input: |\n      Write a {{ language }} script to {{ task }}.\n\n      Include:\n      - Clear comments explaining each step\n      - Error handling for common edge cases\n      - Example usage\n\noutputs:\n  artifacts:\n    - path: ./generated-code.md\n      from: \"{{ last_response }}\"\n</code></pre>"},{"location":"tutorials/quickstart-openai/#understanding-openai-specific-settings","title":"Understanding OpenAI-Specific Settings","text":"<ul> <li><code>provider: openai</code>: Tells Strands to use OpenAI's API</li> <li><code>model_id: gpt-4o-mini</code>: Specifies which model to use</li> <li>No region required (OpenAI routes automatically)</li> <li>Model ID is simpler than Bedrock (no version suffix)</li> </ul>"},{"location":"tutorials/quickstart-openai/#step-6-validate-your-workflow","title":"Step 6: Validate Your Workflow","text":"<pre><code>uv run strands validate my-openai-workflow.yaml\n</code></pre> <p>Expected output:</p> <pre><code>\u2713 Workflow is valid\n</code></pre>"},{"location":"tutorials/quickstart-openai/#step-7-run-your-workflow","title":"Step 7: Run Your Workflow","text":"<pre><code>uv run strands run my-openai-workflow.yaml\n</code></pre> <p>Expected output:</p> <pre><code>\ud83d\ude80 Starting workflow: my-openai-workflow\n\ud83d\udcca Runtime: openai (gpt-4o-mini)\n\ud83e\udd16 Agent: code_assistant\n\u2705 Workflow completed successfully\n\ud83d\udcdd Artifact written: ./generated-code.md\n</code></pre>"},{"location":"tutorials/quickstart-openai/#step-8-check-the-output","title":"Step 8: Check the Output","text":"<pre><code>cat generated-code.md\n</code></pre> <p>You'll see GPT-4o mini's generated Python code with documentation.</p>"},{"location":"tutorials/quickstart-openai/#step-9-use-different-models","title":"Step 9: Use Different Models","text":"<p>Try different models by overriding the model_id:</p> <pre><code># Use GPT-4o (more capable, higher cost)\nuv run strands run my-openai-workflow.yaml \\\n  --var model_override=gpt-4o\n\n# Use o1-mini for complex reasoning\nuv run strands run my-openai-workflow.yaml \\\n  --var model_override=o1-mini\n</code></pre> <p>Or update your workflow to use environment variables:</p> <pre><code>runtime:\n  provider: openai\n  model_id: ${OPENAI_MODEL_ID:-gpt-4o-mini}  # Default to gpt-4o-mini\n</code></pre>"},{"location":"tutorials/quickstart-openai/#step-10-customize-with-variables","title":"Step 10: Customize with Variables","text":"<pre><code># Generate JavaScript code instead\nuv run strands run my-openai-workflow.yaml \\\n  --var language=\"JavaScript\" \\\n  --var task=\"fetch data from a REST API and parse JSON\"\n\n# Generate a different kind of script\nuv run strands run my-openai-workflow.yaml \\\n  --var language=\"Bash\" \\\n  --var task=\"backup files older than 30 days to a tar archive\"\n</code></pre>"},{"location":"tutorials/quickstart-openai/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/quickstart-openai/#authentication-error","title":"Authentication Error","text":"<p>Problem: <code>AuthenticationError: Invalid API key</code></p> <p>Solution: 1. Verify API key is correct (starts with <code>sk-proj-</code>) 2. Check environment variable is set: <code>echo $OPENAI_API_KEY</code> 3. Ensure key is active in OpenAI dashboard</p> <pre><code># Test API key manually\ncurl https://api.openai.com/v1/models \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n</code></pre>"},{"location":"tutorials/quickstart-openai/#rate-limit-exceeded","title":"Rate Limit Exceeded","text":"<p>Problem: <code>RateLimitError: Rate limit exceeded</code></p> <p>Solution: 1. Wait a few seconds and retry (Strands has automatic retry) 2. Upgrade to a paid tier for higher limits 3. Implement longer delays between requests 4. Use token budgets to limit usage</p> <pre><code>runtime:\n  provider: openai\n  model_id: gpt-4o-mini\n  budgets:\n    token_budget:\n      max_input_tokens: 10000\n      max_output_tokens: 5000\n</code></pre>"},{"location":"tutorials/quickstart-openai/#insufficient-quota","title":"Insufficient Quota","text":"<p>Problem: <code>InsufficientQuotaError: You have exceeded your quota</code></p> <p>Solution: 1. Add payment method to your OpenAI account 2. Check usage dashboard for current spending 3. Set up billing alerts 4. Request quota increase if needed</p>"},{"location":"tutorials/quickstart-openai/#model-not-found","title":"Model Not Found","text":"<p>Problem: <code>NotFoundError: Model not found</code></p> <p>Solution: 1. Verify model ID spelling (e.g., <code>gpt-4o-mini</code> not <code>gpt-4-mini</code>) 2. Check model availability for your account tier 3. Use a different model</p> <pre><code># List available models\ncurl https://api.openai.com/v1/models \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  | grep '\"id\":'\n</code></pre>"},{"location":"tutorials/quickstart-openai/#cost-management","title":"Cost Management","text":""},{"location":"tutorials/quickstart-openai/#understanding-pricing","title":"Understanding Pricing","text":"<p>OpenAI charges per token, with different rates for input and output:</p> <pre><code>Cost = (Input tokens / 1M \u00d7 Input price) + (Output tokens / 1M \u00d7 Output price)\n</code></pre> <p>Example: Using <code>gpt-4o-mini</code> with 1,000 input tokens and 500 output tokens: <pre><code>Cost = (1000/1M \u00d7 $0.15) + (500/1M \u00d7 $0.60) = $0.00045\n</code></pre></p>"},{"location":"tutorials/quickstart-openai/#monitor-usage","title":"Monitor Usage","text":"<ol> <li>OpenAI Dashboard: Check platform.openai.com/usage</li> <li>Set Budget Alerts: Configure email alerts for spending thresholds</li> <li>Use Token Budgets: Limit workflow token consumption</li> </ol> <pre><code>runtime:\n  provider: openai\n  model_id: gpt-4o-mini\n  budgets:\n    token_budget:\n      max_input_tokens: 50000   # Hard limit\n      max_output_tokens: 10000\n</code></pre>"},{"location":"tutorials/quickstart-openai/#cost-optimization-tips","title":"Cost Optimization Tips","text":"<ol> <li>Use gpt-4o-mini for simple tasks: 16x cheaper than gpt-4o</li> <li>Minimize prompt size: Remove unnecessary context</li> <li>Set max_tokens: Control output length</li> <li>Cache agents: Strands reuses agents to reduce overhead</li> <li>Batch workflows: Combine multiple tasks into one workflow</li> </ol>"},{"location":"tutorials/quickstart-openai/#model-selection-guide","title":"Model Selection Guide","text":""},{"location":"tutorials/quickstart-openai/#when-to-use-each-model","title":"When to Use Each Model","text":"Scenario Recommended Model Reason Simple Q&amp;A, content generation <code>gpt-4o-mini</code> Cost-effective, fast Complex analysis, multimodal <code>gpt-4o</code> Better reasoning, image support Advanced math, coding, research <code>o1</code> Superior reasoning capabilities Budget-constrained reasoning <code>o1-mini</code> Cheaper than o1, better than gpt-4o Legacy workflows <code>gpt-4-turbo</code> Compatibility with older code"},{"location":"tutorials/quickstart-openai/#model-capabilities","title":"Model Capabilities","text":"Feature gpt-4o-mini gpt-4o o1-mini o1 Text generation \u2705 \u2705 \u2705 \u2705 Code generation \u2705 \u2705 \u2705 \u2705 Image analysis \u2705 \u2705 \u274c \u274c Function calling \u2705 \u2705 \u274c \u274c Reasoning Good Great Excellent Superior Speed Fast Fast Medium Slow Cost Lowest Medium Medium Highest"},{"location":"tutorials/quickstart-openai/#best-practices","title":"Best Practices","text":""},{"location":"tutorials/quickstart-openai/#1-secure-api-key-management","title":"1. Secure API Key Management","text":"<pre><code># Good: Environment variable\nexport OPENAI_API_KEY=sk-proj-...\n\n# Bad: Hardcoded in YAML\nruntime:\n  provider: openai\n  api_key: sk-proj-...  # Don't do this!\n</code></pre>"},{"location":"tutorials/quickstart-openai/#2-implement-error-handling","title":"2. Implement Error Handling","text":"<p>Strands automatically retries failed API calls, but you can enhance this:</p> <pre><code>runtime:\n  provider: openai\n  model_id: gpt-4o-mini\n  max_retries: 3       # Retry failed calls\n  timeout_seconds: 60  # Per-request timeout\n</code></pre>"},{"location":"tutorials/quickstart-openai/#3-use-telemetry-for-debugging","title":"3. Use Telemetry for Debugging","text":"<pre><code># Enable debug mode\nuv run strands run workflow.yaml --debug --verbose\n\n# Export execution traces\nuv run strands run workflow.yaml --trace\n</code></pre>"},{"location":"tutorials/quickstart-openai/#4-version-control-workflows","title":"4. Version Control Workflows","text":"<pre><code># Good: Track workflow files\ngit add my-openai-workflow.yaml\n\n# Bad: Track API keys\ngit add .env  # Never commit this!\n</code></pre>"},{"location":"tutorials/quickstart-openai/#5-test-before-production","title":"5. Test Before Production","text":"<pre><code># Validate first\nstrands validate workflow.yaml\n\n# Run with minimal input for testing\nstrands run workflow.yaml --var task=\"simple test\"\n</code></pre>"},{"location":"tutorials/quickstart-openai/#next-steps","title":"Next Steps","text":"<p>Now that you have OpenAI configured, explore advanced features:</p> <ol> <li>Multi-step workflows: Learn the chain pattern tutorial</li> <li>Add tools: Use HTTP executors for API integration</li> <li>Enable observability: Set up OpenTelemetry</li> <li>Browse examples: Check <code>examples/</code> for OpenAI workflows:</li> <li><code>examples/single-agent-workflow-openai.yaml</code> - Basic single agent</li> <li><code>examples/chain-3-step-research-openai.yaml</code> - Sequential workflow</li> <li><code>examples/github-api-example-openai.yaml</code> - API integration</li> </ol>"},{"location":"tutorials/quickstart-openai/#key-concepts-recap","title":"Key Concepts Recap","text":"Concept Description API Key Secret key for OpenAI authentication (starts with <code>sk-</code>) Model ID Simple model identifier (e.g., <code>gpt-4o-mini</code>) Token Unit of text used for pricing (\u22484 chars) Rate Limit Maximum requests per minute based on tier Quota Maximum monthly spending limit"},{"location":"tutorials/quickstart-openai/#common-commands-reference","title":"Common Commands Reference","text":"<pre><code># Validate workflow\nstrands validate workflow.yaml\n\n# Run workflow\nstrands run workflow.yaml\n\n# Run with variable overrides\nstrands run workflow.yaml --var key=value\n\n# Debug mode\nstrands run workflow.yaml --debug --verbose\n\n# Check Strands version\nstrands --version\n\n# Test OpenAI API access\ncurl https://api.openai.com/v1/models \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n</code></pre>"},{"location":"tutorials/quickstart-openai/#environment-variables-reference","title":"Environment Variables Reference","text":"Variable Description Default <code>OPENAI_API_KEY</code> OpenAI API key (required) None <code>OPENAI_BASE_URL</code> Custom API endpoint <code>https://api.openai.com/v1</code> <code>OPENAI_ORG_ID</code> Organization ID None <code>OPENAI_TIMEOUT</code> Request timeout (seconds) 60"},{"location":"tutorials/quickstart-openai/#further-reading","title":"Further Reading","text":"<ul> <li>OpenAI Documentation - Official API docs</li> <li>OpenAI Models Guide - Model comparison</li> <li>OpenAI Pricing - Detailed pricing information</li> <li>Workflow Schema Reference - Complete YAML spec</li> <li>Token Budgets Guide - Cost control strategies</li> </ul>"}]}