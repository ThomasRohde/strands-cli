version: 0
name: "evaluator-optimizer-hitl-review"
description: "Evaluator-optimizer pattern with human review gate between iterations"

runtime:
  provider: openai
  model_id: gpt-4o-mini
  budgets:
    max_tokens: 50000

agents:
  writer:
    prompt: |
      You are an expert content writer. Create high-quality, engaging content
      based on the requirements provided.
      
      Write a comprehensive blog post about: {{ topic }}
      
      Make it informative, well-structured, and engaging for readers.

  critic:
    prompt: |
      You are an expert content evaluator. Analyze the provided content and return
      a structured JSON evaluation.
      
      Evaluate the following content:
      
      {{ draft }}
      
      Return your evaluation as JSON with this exact format:
      {
        "score": <number between 0-100>,
        "issues": ["issue 1", "issue 2", ...],
        "fixes": ["suggested fix 1", "suggested fix 2", ...]
      }
      
      Scoring criteria:
      - 90-100: Excellent quality, publication ready
      - 80-89: Good quality, minor improvements needed
      - 70-79: Acceptable quality, moderate improvements needed
      - Below 70: Significant improvements required

pattern:
  type: evaluator_optimizer
  config:
    producer: writer
    
    evaluator:
      agent: critic
    
    accept:
      min_score: 95
      max_iters: 3
    
    review_gate:
      type: hitl
      prompt: |
        Review iteration {{ iteration_index }} before continuing optimization.
        
        Respond with:
        - 'continue' to proceed with next iteration
        - 'stop' to accept current draft and end early
        - Any other feedback for context
      context_display: |
        ### Draft (Iteration {{ iteration_index + 1 }})
        {{ iterations[-1].draft_preview }}...
        
        ### Evaluation Results
        **Score:** {{ iterations[-1].score }}/100
        
        {% if iterations[-1].issues %}
        **Issues Identified:**
        {% for issue in iterations[-1].issues %}
        - {{ issue }}
        {% endfor %}
        {% endif %}
        
        {% if iterations[-1].fixes %}
        **Suggested Fixes:**
        {% for fix in iterations[-1].fixes %}
        - {{ fix }}
        {% endfor %}
        {% endif %}
      default: "continue"
      timeout_seconds: 1800  # 30 minutes
    
    revise_prompt: |
      You are revising your previous draft based on evaluator feedback.
      
      **Original Draft:**
      {{ draft }}
      
      **Evaluation Score:** {{ evaluation.score }}/100
      
      {% if evaluation.issues %}
      **Issues to Address:**
      {% for issue in evaluation.issues %}
      - {{ issue }}
      {% endfor %}
      {% endif %}
      
      {% if evaluation.fixes %}
      **Suggested Improvements:**
      {% for fix in evaluation.fixes %}
      - {{ fix }}
      {% endfor %}
      {% endif %}
      
      Please provide an improved version that addresses the feedback above.

outputs:
  artifacts:
    - path: "./optimized-content.md"
      from: "{{ last_response }}"
